Le système Pan-Européen de radio mobile numérique (DMR) cellulaire qui devrait entrer en fonction au début des années '90 utiliserait un codage de vitesse d'environ 16 kbit/s. On a établi au moins trois phases d'expérimentation : (1) épreuves de présélection nationale, (2) épreuves de sélection européenne, et (3) épreuves de caractérisation et de vérification finale avec codage de canal associé. Les premières 2 phases devaient utiliser seulement des épreuves d'écoute qui ne considéraient pas les effets de retard d'élaboration des codeurs/décodeurs. On a fixé comme objectif, un retard initial maximum de 65 ms. La phase finale emploiera les épreuves de conversation pour évaluer les effets de qualité, retard et écho ; ces épreuves seront complétées par des épreuves d'écoute à employer aussi pour la caractérisation des codeurs/décodeurs. Le mémoire décrit des méthodologies d'épreuves subjectives adoptées pour choisir les codeurs/décodeurs candidats appropriés qui peuvent être employés dans le système DMR proposé. Chaque administration participant aux tests doit convainere le Comité Européen (Conférence Européenne des Administrations des Postes et Télécommunications, CEPT) que la qualité de son propre codeur/décodeur candidat est meilleure ou au moins égale à la qualité des systèmes analogiques FM à 900 MHz maintenant employés en Europe.
On a mesuré la variabilité de la fréquence fondamentale (F 0) dans les formes isolées des tons lexicaux. Le thai est une langue à 5 tons lexicaux : moyen, bas, descendant, haut et montant. Vingt-et-un sujets ont participé à l'expérience : dix jeunes locuteurs masculins et dix locuteurs âgés, cinq hommes et cinq femmes. Des enregistrements de haute qualité ont été réalisés pour la production d'une série minimum de 5 mots monosyllabiques par chaque sujet. Les contours de F 0 ont été obtenus par une analyse cepstrale. On a comparé la variabilité inter- et intra-locuteur en ce qui concerne la production des cinq tons. Les résultats de l'analyse de la variance ont indique que le degré de la variabilité intersujets était plus élevé que la variabilité intra-locuteur au travers des cinq tons ; les locuteurs jeunes et âgés ont produit le même modèle de variabilité ; la variabilité dans la production du ton différait selon le ton lexical. Les tons descendants et montants ont produit de plus petits degrés de variabilité que les tons moyens, bas ou hauts. Les résultats sont interprétés pour souligner la nature de la variabilité de F 0, sa relation avec la quantité du mouvement de F 0 et les différences interlinguistiques de cette variabilité en fonction de la structure prosodique.
Des recherches précédentes ont montré que la charge de travail peut avoir un effet négatif sur l'utilisation des systèmes de reconnaissance de la parole. Dans cet article, on discute de la relation entre charge de travail et parole et l'on fournit les résultats de deux études. La première étude concerne le stress dû à la durée. La seconde étude étudie les performances pour une tâche double. Les deux études montrent que la charge de travail réduit les taux de reconnaissance et la performance de l'utilisateur. La nature de la détérioration semble dépendre des individus et du type de charge de travail. De plus, il apparaît que la charge de travail affecte la sélection des mots à utiliser, l'articulation des mots et la relation entre la tâche de parler à un système de reconnaissance automatique de la parole (RAP) et la réalisation d'autres travaux. On suggère que le fait de parler à un système de RAP est une tâche contraignante en elle-même, et que, lorsque la charge de travail augmente, la capacité de réalisation de cette tâche, dans les limites imposées par le système de reconnaissance, décroît.
Les Synonyma d'Isidore de Séville, oeuvre écrite dans un style synonymique mais de contenu moral, pouvaient être utilisés à la fois comme livre de grammaire et comme livre de morale. C'est cependant cette seconde lecture qui a clairement dominé au Moyen Âge, comme le prouve l'étude du paratexte et du contexte manuscrit, des inventaires médiévaux, des centons ou de la postérité littéraire.
Cette publication présente deux nouvelles approches de conception de réseaux d'antennes imprimées. La première est basée sur la technique des algorithmes génétiques inspirée des processus de l'évolution des espèces et de la génétique naturelle et la deuxième sur l'analogie entre la résolution des problèmes d'optimisation combinatoire et le recuit des solides. Ces deux approches permettent de rechercher simultanément la loi d'alimentation optimale et la répartition spatiale des éléments rayonnants pour que le diagramme de directivité du réseau soit aussi proche que possible d'un diagramme désiré optimal spécifié à partir d'une fonction ou d'un gabarit.
La mise en correspondance d'objets 3D est un problème important dans le domaine du traitement d'image. Il apparaît lorsque des données acquises par différents capteurs, à des moments ou/et des instants différents doivent être fusionnées. Si l'on suppose que les objets à mettre en correspondance sont rigides, nous avons à retrouver les paramètres d'une transformation rigide. Cet article présente une méthode itérative générale pour la mise en correspondance d'objets 3D. Son originalité réside dans ses fondements mécaniques : plutôt que de minimiser une énergie potentielle par rapport aux paramètres de la transformation rigide, qui est l'approche classique, nous étudions le mouvement d'un objet rigide, c'est-à-dire un solide, dans un champ de potentiel. Cette approche particulière prend en compte l'énergie cinétique du solide, ce qui permet de « sauter » certains maxima locaux de l'énergie potentielle et donc d'en éviter certains minima locaux. L'article est illustré par l'application de la méthode au recalage d'images médicales réelles, où nous utilisons la totalité du volume segmenté.
Différents modes de prescription sont décelables dans les listes de termes recommandés dans le cadre du circuit de terminologie officielle en France, tel qu'il fonctionne depuis plus de vingt ans (suite au décret Juppé en 1996). Diverses dynamiques sont observées dans ces listes officielles, où sont proposées de précieuses remarques. On tente de considérer ces éléments de prescription officielle comme on le ferait dans le cadre d'une analyse combinée métalexicographique et terminologique.
Cet article présente tout d'abord le web sémantique, qui vise à développer un niveau de connaissances indépendant de sa réalisation en langue. Nous montrons que ce projet est illusoire si on n'établit pas un lien entre les connaissances formalisées à travers des ontologies ou des réseaux sémantiques et les textes présents sur le web. L'article présente différentes approches permettant de faire ce lien et revient sur la question du rapport entre sources de connaissances générales et connaissances acquises à partir de textes.
Le contact entre les communautés vietnamienne et française durant l'occupation française au Viêt Nam a entraîné l'adaptation phonologique d'un nombre important d'emprunts au français. En vietnamien, ces emprunts se sont vu attribuer des tons. La littérature scientifique sur cette question (ainsi que sur celle du contact linguistique français-vietnamien) est jusqu'ici limitée et se fonde sur un nombre restreint d'emprunts. L'analyse phonologique et statistique de 600 mots vietnamiens d'origine française nous permet d'étudier les mécanismes d'attribution de tons à des syllabes qui en étaient dépourvues. Nous dénombrons l'occurrence de chaque ton, et dégageons quelques-uns des principes régissant l'intégration tonale des emprunts au français.
Dans cette étude, nous nous intéressons aux unités sonores, vocalises séparées par 2 silences, qui composent ces chants, à leurs récurrences, et à leurs structurations. Cependant, tous ces paramètres dépendent de l'année et du lieu d'enregistrement. Cet article propose un codage parcimonieux des chants afin de déterminer leurs composantes stables de celles qui varient, pour différentes échelles de temps. Une définition de la complexité du code est également proposée afin de séparer les composantes du chant du bruit mer. Cette étude montre statistiquement que les codes les plus courts sont les plus stables et surviennent avec une fréquence similaire sur deux années consécutives, tandis que les plus longues unités sont clairement différentes.
Le filtre à long-terme d'un codeur de parole CELP à bas-débit a une influence notable sur la qualité de la parole reconstruite. Dans cet article, nous proposons un pseudo-filtre de prédiction à long terme à plusieurs coefficients qui possède moins de degrés de liberté que le nombre de coefficients de prédiction, mais donne un meilleur gain en prédiction à long-terme et une meilleure réponse en fréquence qu'un filtre de prédiction conventionnel à un seul coefficient. Le gain de prédiction de ce filtre est comparé à celui des filtres classiques à un seul coefficient et à trois coefficients, avec des décalages entiers et fractionnaires. Elle donne de meilleurs résultats qu'un test de stabilité stricte. Pour finir, nous avons incorporé notre pseudo-filtre de prédiction à long terme à plusieurs coefficients dans un codeur CELP à 4.8 kbit/s. Tant le rapport objectif signal à bruit que la qualité subjective ont été améliorés par rapport à ceux mesurés avec un filtre de prédiction à long terme conventionnel à un seul coefficient.
L'algorithme SELP (“Stochastically Excited Linear Prediction”) offre de bonnes performances à un débit aussi faible que 4.8 kbit/s. La procédure de la prédiction linéaire supprime la corrélation à court terme. La boucle de mélodie enléve la corrélation à long terme, produisant un résidu proche du bruit qui est soumis à une quantification vectorielle. L'information décrivant les coefficients du filtre LPC, la prédiction à long terme et la quantification vectorielle est transmise. Dans cet article, nous décrivons des améliorations apportées à l'algorithme SELP qui aboutissent à une meilleure qualité de parole et à uapidité accrue de calcul. A boucle fermeé, le ciuit de mélodie peut être interpréte une quantification vectorielle du signal d'excitation désiré à l'aide d'un dictionnaire adaptatif composé de séquences antérieures d'excitations. Pour améliorer la modélisation de la non-stationnarité du signal de parole, nous enrichissons ce code avec un ensemble de candidats-vecteurs qui sont des transformées d'autres entrées du dictionnaire. La deuxième quantification vectorielle est exécutée avec un dictionnaire stochastique fixe. Dans sa forme originale, l'algorithme SELP nécessite un effort excessif de calcul. Nous utilisons un nouvel algorithme récursif de consultaton rapide du dictionnaire adaptatif. De cette manière, nous modifions le critère d'erreur et nous exploitons les symétries résultantes. La même quantification vectorielle rapide est appliquée au dictionnaire.
Ce papier présente une revue et une analyse des résultats obtenus par les auteurs et par leurs collaborateurs en ce qui concerne l'effet de la transition de phase dans le problème de l'appariement. Ce qui a été mis en évidence est que la recherche d'hypothèses, guidée par les heuristiques plus connues (gain d'information ou simplicité), finissent inévitablement dans la région TP : donc, on ne peut pas éviter cette région à haute complexité. Les conclusions qu'on peut en tirer pour l'apprentissage relationnel est qu'il semble difficile de pouvoir approcher des problèmes plus importants que ceux que l'on a actuellement.
Le choix d'une mesure de distance est très important pour la quantification vectorielle (QV) à la fois pour la construction du dictionnaire et pour la recherche de la valeur quantifié. La distance spectrale, qui est la plus significative, est peu souvent utilisé à cause de sa complexité calculatoire. La distance Euclidienne quadratique pondérée est mathématiquement plus attractive et par conséquent plus souvent utilisée. Selon la distance utilisée, on peut trouver des différences significatives en terme de performances. Dans cet article, une comparaison entre les différentes distances Euclidienne quadratique pondérée est étudiée. Une mesure de distance est proposée dans le cas de la QV des paires de raies spectrales (LSP) ou Cosinus des LSP (CLSP).
Bien que des systèmes de transcription de la prosodie existent depuis longtemps, la nécessité de représenter l'information prosodique dans de larges bases de données de parole impose à ces systémes des exigences nouvelles. Le système ToBI récemment élaboré aux Etats-Unis présente de nombreuses différences intéressantes par rapport au système “Standard britannique” utilisé depuis plusieurs dizaines d'années. Cet article analyse ces différences dans le contexte des recherches actuelles sur un corpus d'anglais parlé et examine la possibilité de conversion automatique entre les deux types de transcription.
Deux larynx humains excisés ont été utilisés pour étudier les effets du changement de l'acoustique supraglottique sur la fréquence fondamentale (F 0) d'oscillation des cordes vocales. Un tube artificiel supraglottique a été relié au larynx. Deux pistons cylindriques ont été introduits séparément dans le tube et déplacés à l'intérieur de celui-ci afin de représenter des voyelles neutres, avant et arrière. Quand le piston le plus petit a été introduit, on a pu mesurer, en général, une augmentation de la F 0. Les changements de la F 0 liés à l'utilisation du piston le plus grand n'ont pas montré de variations systématiques. Dans plusiers cas, on a pu mesurer une diminution de la F 0. La résultats sont interprétés en termes de rétroaction acoustico-mécanique dans l'interaction de la source et du conduit vocal. En conclusion, nous constatons que la F 0 intrinsèque des voyelles ne peut pas être expliquée à partir de bases acoustiques. Les conditions acoustiques pour le petit piston ont été simulées à l'aide d'un modéle théorique.
Nous décrivons un nouvel algorithme pour la détection robuste des fins de mots isolés. L'algorithme utilise des mesures simples basées sur l'énergie et le taux de passages à zéro afin de discriminer entre parole et silence. Au lieu du modèle conventionnel à deux états, un modèle à trois temps comprenant une phase de transition est introduit. Le taux de passages à zéro est traité de manière spéciale lors de la phase de transition afin d'améliorer la précision de la détection des fins de mots. L'algorithme est basé sur une classification en contexte et utilise quelques heuristiques sur base de connaissances afin de corriger des détections erronées. L'approche est celle utilisée lors de la détection visuelle de formes d'onde noyées dans du bruit. Aucune connaissance préalable de la nature du bruit n'est exigée et l'algorithme produit des résultats fiables même dans les cas où le signal débute par des bruits buccaux parasites. Un aspect important de l'algorithme est sa facilité d'implantation pour le traitement en temps réel. L'algorithme est adaptif et peut s'accommoder d'environnements dotés de rapports signal-sur-bruit variables. L'algorithme a été initialement développé sur la parole enregistrée dans une chambre anéchoïque. Les modifications nécessaires pour une application à la parole de qualité téléphonique sont décrites, ainsi que les résultats de tests préliminaires.
Une étude par analyse/synthèse de la pharyngalisation est réalisée dans le cadre du développement d'une synthèse par règles de l'Arabe. Dans ce travail nous utilisons un synthétiseur à formants pour la paramétrisation acoustique des consonnes pharyngalisées de l'Arabe/ /, / /, / /, / /, / /. L'étude acoustique montre que le système vocalique arabe traditionnellement décrit comme un ensemble de 3 voyelles brèves et de leurs 3 opposées longues est inadéquat. Un système de 12 voyelles dont 6 pharyngalisées est défini en compatibilité avec les faits acoustiques et phonologiques. Les règles régissant l'extension de la pharyngalisation au sein de la chaîne sonore sont établies et validées par synthèse.
Nous commençons par considérer les travaux d'histoire institutionnelle très récents, travaux qui nous conduisent à mieux comprendre une face cachée jusqu'alors de l'histoire de la norme en France : celle de l'exclusion du Parlement de Paris comme modèle de bon usage. Dans la seconde moitié de l'article nous abordons une question incontournable : celle de la portée des injonctions normatives sur l'usage, en examinant trois études de cas dans les domaines de la morphologie et du lexique.
Nous présentons les principaux travaux menés dans le projet Sample Orchestrator, destiné au développement de fonctions innovantes de manipulation d'échantillons sonores. Celles-ci se fondent sur des études consacrées à la description des sons, c 'est-à-dire à la formalisation de structures de données pertinentes pour caractériser le contenu et l'organisation des sons. Ces travaux ont été appliqués à l'indexation automatique des sons, ainsi qu 'à la réalisation d'applications inédites pour la création musicale - synthèse sonore interactive par corpus et aide informatisée à l'orchestration. Le projet a aussi comporté un important volet consacré au traitement de haute qualité des sons, à travers plusieurs perfectionnements du modèle de vocodeur de phase - traitement par modèle sinusoïdal dans le domaine spectral et calcul automatique des paramètres d'analyse.
La fonction de correction de pôles supérieurs (HPC) dans un modéle tout-pôle de production de parole, analogique ou numérique, est analysée en comparant celui-ci à une ligne de transmission (TL). La validité du modèle TL, qui sert de référence dans l'étude, est testée en comparant sa fonction de transfert aux mesures acoustiques effectuées sur un modéle physique du conduit vocal. La variation de la longueur efficace du conduit vocal s'est avérée être un paramètre important dans la formulation de la HPC. Même si les réponses en fréquencies de la HPC different dans les cas analogique et numérique. les changements relatifs dans la correction, qui sont influencés par les variations de la longueur efficace du conduit vocal, sont exactement les mêmes dans les deux cas. Nous formons ainsi un nouveau type de modèle de production de parole comportant des pôles et des zéros. Celui-ci est aussi mis en relation avec le modèle PARCAS [Laine, 1982].
On emploie dans cet article les réseaux connexionnistes pour deux problèmes concernant les mouvements articulatoires. Le premier est l'estimation du mouvement articulatoire à partir du signal de parole ; le second est la génération du mouvement articulatoire étant donnée une séquence de symboles phonémiques. Les réseaux connexionnistes sont un outil adapté au premier problème, puisque l'estimation des paramètres articulatoires est connue pour être une application non linéaire entre les paramètres accoustiques et les param`etres articulatoires. Pour le second, on construit efficacement un système de commande non linéaire pour produire le mouvement articulatoire, en combinant plusieurs réseaux connexionnistes.
Les variations temporelles du profil de la langue enregitrées dans des images cinéradiographiques sont décrites par les mouvements de quatre paramètres articulatoires. La variation temporelle de chaque paramètre (mouvement) est supposée être la sortie d'un filtre auto-régressif invariant dans le temps. Chaque filtre est excité par une séquence d'impulsions qui représente la commande articulatoire. Les coefficients du filtre, la position et l'amplitude des impulsions sont déterminés par la méthode de la MLPC. Le nombre minimum d'impulsions pour chaque paramètre articulatoire est déterminé en utilisant un critère acoustique. Il dépend du nombre des traits phonétiques dans la phrase dont la réalisation dépend d'un paramètre particulier.
Cet article concerne l'étude de l'influence des contours intonatifs, des durées segmentales et des caractéristiques spectrales sur l'identification perceptive de deux styles d'élocution. Deux locuteurs ont parlé “spontanément” à un interlocuteur et ont ensuite lu à haute voix la transcription littérale de leurs énoncés spontanés. On a ensuite sélectionné des paires d'énoncés qui étaient à la fois identiques dans les versions “spontanées” et lues, et “fluides” dans les deux versions (pas de reprise, pas d'hésitation, etc.). On a construit 5 conditions de test en manipulant les énoncés comme suit : (1) aucune manipulation ; (2) échange des durées segmentales entre les deux styles d'élocution ; (3) échange des contours intonatifs entre les deux styles d'élocution ; (4) application d'un contour intonatif monotone ; (5) combinaison des caractéristiques spectrales originales avec les contours prosodiques du style d'élocution opposé. La tâche des 32 auditeurs était de classer chaque stimulus dans l'une des deux catégories “lue” ou “spontanée”. Il apparaît que toutes les manipulations des énoncés avaient une influence sur cette classification. Diverses mesures acoustiques ont également été effectuées sur les énoncés originaux. Globalement, la parole lue semble avoir, par rapport à la parole spontanée : une vitesse d'articulation plus faible, des variations de F 0 plus amples, une déclinaison de F 0 plus marquée, moins de vibrato, et moins de réduction vocalique. Toutefois, aucun de ces traits acoustiques ne suffit à lui seul pour discriminer entre les deux styles d'élocution et l'on note une très grande variabilité dans les réalisations des locuteurs et les performances des auditeurs.
Ce document propose une structure des données sous forme de tableau, enrichie d'une grille de mots et d'un système d'analyse grammaticale exploitables dans le domaine de la reconnaissance de la parole. Ce tableau enrichi et l'algorithme d'analyse grammaticale qui y est associé peuvent représenter et analyser grammaticalement de façon très efficace une grille d'hypothèses de mots émis dans le domaine de la reconnaissance de la parole avec un niveau d'ambiguïté lexicale élevé, sans pour autant changer les principes fondamentaux de l'analyse grammaticale sous forme étendue. Chaque grille de mots peut être entrée avec ordre et cohérence dans le tableau enrichi parmi des hypothèses de mots bien mémorisées dans ledit tableau. Un point de rupture est déterminé par rapport à des points de liaison que représentent des hypothèses de mots séparés dans le texte mais qu'il est en réalité possible de relier. Les résultats expérimentaux préliminaires nous montrent que l'enrichissement de l'analyse grammaticale sous forme de diagramme étendu permet l'interprétation de tous les composants possibles à l'entrée du réseau lexical et élimine la nécessité de créer chaque composant plus d'une fois. Cela réduit la complexité des calculs de manière significative surtout en cas d'ambiguïté lexicale importante dans l'entrée de la grille lexicale comme cela arrive dans de nombreux problèmes de reconnaissance de la parole. Cet enrichissement de l'analyse grammaticale sous forme de tableau représente une approche très utile et très efficace en ce qui concerne les problèmes de traitement de l'information dans le domaine de la reconnaissance de la parole.
Les difficultés soulevées lors de la comparaison de signatures vibro-acoustiques d'équipements de commutation de haute puissance nous ont amené à développer un nouvel algorithme de recalage temporel. Cette comparaison de signatures est requise pour réaliser la surveillance de ces équipements. Or, ces signatures comportent une suite de transitoires générée par une séquence d'événements électromécaniques qui apparaissent avec une trame temporelle légèrement différente, d'une commutation à l'autre, selon, entre autres, la température et la charge. Cette distorsion temporelle génère une divergence significative entre les amplitudes instantanées des signatures. De plus, la grandeur de la déviation temporelle, entre la dernière signature et une référence, a une utilité diagnostique. L'algorithme de recalage temporel proposé permet de trouver la relation temporelle entre les événements de deux signatures, même en présence de discontinuités de la trame temporelle. Or, nous démontrons que ces discontinuités ne sont pas traitées adéquatement par l'algorithme de recalage temporel DTW (Dynamic Time Warping) utilisé couramment dans le traitement de la parole. Nous expliquons donc le fonctionnement de ces deux algorithmes et nous présentons des résultats démontrant la plus grande acuité de la corrélation multiéchelle. C'est en partie l'interpolation de la trace warp qui permet d'atteindre cette acuité. Cette trace warp est une fonction décrivant la déviation temporelle entre signatures, rapportant même la présence d'inversions dans l'ordre d'apparition de transitoires.
De nombreux domaines d'application font appel à des signaux à plus d'une dimension (ND) et le développement des moyens de calcul permet de mettre en œuvre des traitements adaptés à ces signaux. Après avoir précisé les limites du domaine couvert et donné quelques éléments de terminologie, nous présentons les modèles de signaux ND. Nous donnons ensuite une approche synthétique des méthodes d'estimation (ou de mesure) des caractéristiques des signaux ND. Notre exposé est complété par la présentation et l'étude des principaux opérateurs (filtres) utilisés dans le traitement des signaux ND en liaison avec les opérateurs déjà explorés dans le traitement des signaux 1D.
Les réseaux de neurones sont actuellement d'usage courant en traitement du signal et de l'image. Nous proposons un nouveau modèle de neurone qui utilise un codage particulier de sa sortie que nous nommerons « Représentation Scalaire Distribuée » (RSD). Cette représentation repose sur l'idée de représenter la sortie d'un neurone par une fonction et non par un scalaire. Nous montrons que la RSD induit un comportement non linéaire des connexions entre neurones. La RSD est décrite dans toute sa généralité, puis particularisée pour sa mise en œuvre pratique. Nous considérons notamment la mise en œuvre de la RSD dans un réseau de neurones de type Perceptron Multi-Couches, et nous proposons un algorithme d'apprentissage. Enfin, nous validons le modèle sur deux applications : la réduction de dimensionnalité et la prédiction. Dans les deux cas, un gain important par rapport au modèle classique est obtenu.
L'optimisation d'un système de détection distribuée parallèle comprenant N capteurs aboutit toujours à un système de 2 N + N équations non linéaires couplées, qui n'est résolu pour l'instant que pour des cas particuliers (en supposant par exemple l'indépendance des observations locales) et pour des systèmes comportant peu de capteurs. Le nombre d'équations à résoudre simultanément augmente très rapidement avec le nombre de capteurs. Les calculs nécessaires à la résolution de ces équations deviennent alors très vite inextricables. Dans cette contribution, une procédure de sélection de capteurs pertinents pour le processus de décision basée sur l'utilisation de l'entropie conditionnelle de Shannon est développée. Puis, ces systèmes sont optimisés via une méthode entropique. Celle-ci détermine les seuils locaux et construit un arbre de décision (qui représente l'opérateur de fusion) permettant de minimiser la probabilité d'erreur de décision. Les performances des systèmes distribués parallèles étant moins bonnes que celles des systèmes centralisés, les techniques d'optimisation précédentes seront étendues au problème de la quantification répartie afin d'obtenir un compromis entre la quantité d'information à envoyer à l'opérateur de fusion et les performances souhaitées du système de décision.
Un système permettant à un signal vocal d'être isolé de bruits de fond ou bien d'autres signaux vocaux non-désirés ainsi que d'autres interférences sous conditions réelles a été développé. En utilisant deux micros, placés à 25 cm 1'un de 1'autre, le système exploite des repères directionels et harmoniques dans un algorithme hybride qui profite de ces deux techniques. Le signal de sortie de l'algorithme a été testé de façon subjective par des auditeurs humains et de façon objective par un système de reconnaissance de voices. Les résultats démontrent une amélioration de l'intelligibilité du signal vocal désiré. Par exemple, dans une série de tests, les performances d'un système de reconnaissance de voies après ségrégation est comparable à une proportion signal/bruit de 6 dB comparé à une proportion signal/bruit de 20 dB sans ségrégation
Estimer une fonction échantillonnée irrégulièrement à partir d'un ensemble de points constitue un problème de régression classique. Des solutions basées sur les méthodes à noyaux existent mais leur mise en œuvre conduit à deux problèmes récurrents de sélection de modèles : l'optimisation des paramètres du noyau et le réglage du compromis biais-variance. Cet article présente une méthode novatrice pour estimer une fonction à partir d'un ensemble de points bruités dans le contexte des espaces de Hilbert à noyau reproduisant. Nous avons conçu l'algorithme du Kernel Basis Pursuit pour construire une solution reposant sur des noyaux multiples et une régularisation L\. Notre idée est de décomposer la fonction à apprendre dans l'espace engendré par un dictionnaire de fonctions explicatives, à la manière des statégies de poursuite. La mise en œuvre repose sur la formulation du LASSO (Least Absolute Shrinkage and Selection Operator) et nous avons utilisé l'algorithme Least Angle Regression Stepwise pour la résolution. Le calcul du chemin complet de régularisation nous permet d'utiliser des nouveaux critères pour déterminer automatiquement le compromis biais-variance optimal.
L'article propose un nouveau modèle de Prony à pôles dépendant du temps pou r modéliser des signaux non stationnaires. Ce modèle est basé sur une combinaison linéaire d'exponentielles complexes à coefficients variant avec le temps. Il est une extension des techniques d'estimation spectrale appliquée dans le cas stationnaire : l'amplitude et la phase du signal varient avec le temps. Nous présentons et justifions une méthode avec l'algorithme correspondant pour estimer complètement les paramètres du modèle. Le calcul des paramètres dépendant du temps nécessite cinq étapes : l'estimation des paramètres autorégressifs (AR) variant avec le temps, l'estimation des pôles à droite, la modélisation de ces pôles, le calcul des nouveaux pôles et l'estimation avec une méthode des moindres carrés des facteurs d'amplitudes. Pour valider le modèle, une simulation est effectuée sur un signal à deux composantes de loi en fréquence variant linéairement avec le temps.
De nombreux travaux présentent une combinaison d'apprentissage par démonstration et d'amélioration locale de politiques pour apprendre des contrôleurs pour des robots le long d'une trajectoire. Il manque à ces travaux une capacité de généralisation permettant d'apprendre sur tout l'espace atteignable par le robot. Dans cet article, nous présentons une méthode qui consiste à apprendre un tel contrôleur réactif en feedback et quasi optimal en deux étapes. Ensuite, le contrôleur en feedback est optimisé par des méthodes de recherche directe sur les politiques. Nous obtenons alors un contrôleur quasi optimal qui s'exécute 20 000 fois plus vite que l'original, pour une performance proche. Ce travail est réalisé en simulation.
Cet article présente le système dyd (Dial-Your-Disc/Choisissez votre disque), qui comprend entre autres la fonction de recherche dans une grande base de données d'information musicale, et celle de génération d'un monologue sous forme vocale, une fois que l'oeuvre musicale a été sélectionnée. L'article présente en détail la génération des monologues, avec un accent particulier sur la nécessité de recourir au contexte linguistique de l'énoncé pour effectuer différemment la génération en fonction de la position courante dans le monologue.
La plus grande partie des méthodes de classification de textures existantes consiste à alimenter un classifieur par un ensemble de paramètres caractéristiques calculés localement sur l'image texturée. La mise en œuvre de ces méthodes dans le cadre d'applications opérationnelles suppose, la prise en compte d'un élément important : le risque de confusion de classes dans l'espace paramétrique. Nous montrons qu'un classifieur connexionniste est capable d'exploiter efficacement ces paramètres.
Un système de reconnaissance automatique de consonnes sonorantes extraites à partir de la parole continue est décrit. Le système est basé sur des régles de la logique floue. Aprés avoir opéré une classification précatégorielle, dans laquelle l'extraction de traits est réalisée par des modules organisés en une hiérarche de niveaux, le message parlé est segmenté en noyaux pseudo-syllabiques et des hypothèse sur les voyelles et les consonnes sont émises. Les régles qui améliorent la classification des consonnes liquides et nasales de la langue italienne ont été inférées à partir d'expériences et tiennent compte des effets de coarticulation. Les résultats obtenus pour quatre locuteurs masculins et deux locuteurs féminins sont présentés de concert avec une motivation acoustico-phonétique de l'approche utilisée. Ces résultats montrent que cette méthode aboutit à des performances nettement supérieures à celles des approches antérieures.
Les modèles de reconnaissance de mots diffèrent en ce qui concerne la localisation des effets du contexte sémantique des phrases. En utilisant une technique de facilitation intermodale cette recherche examine la disponibilité des entrées lexicales en fonction de l'information présente dans le stimulus et des contraintes du contexte. Pour rechercher le locus exact des effets des contextes de phrase, des mots-sondes, reliés associativement à des mots contextuellement appropriés ou inappropriés ont été présentés à différentes positions avant ou en même temps que le mot parlé. Les résultats montrent que les contextes de phrase ne préselectionnent pas un ensemble de mots contextuellement approprié avant que ne soit disponible une information sensorielle concernant le mot parlé. En outre, durant l'accès lexical, défini ici comme le contact initial avec les entrées lexicales et leurs propriétés sémantiques et syntaxiques, des mots à la fois contextuellement appropriés et inappropriés sont activés. Les effets contextuels se produisent aprés l'accés lexical, à un stade où l'entrée sensorielle elle-même demeure insuffisamment informative pour choisir entrte les entrées activitées. Ceci suggère que les contextes sémantiques de phrase produisent leurs effets au cours du processus de sélection d'une des hypothèses de reconnaissance activées.
Les codes malveillants, tels que les virus et les vers, sont rarement écrits de zéro ; en conséquence, il existe des relations de nature évolutive entre ces différents codes. Etablir ces relations et construire une phylogénie précise permet d'espérer une meilleure capacité d'analyse de nouveaux codes malveillants et de disposer d'une méthode de fait de nommage de ces codes. La concordance de permutations de code avec des parties de codes malveillants sont susceptibles d'être très intéressante dans l'établissement d'une phylogénie, dans la mesure où les étapes évolutives réalisées par les auteurs de codes malveillants ne conservent généralement pas l'ordre des instructions présentes dans le code commun. Nous décrivons ici une famille de générateurs phylogénétiques réalisant des regroupements à l'aide de caractéristiques extraites d'arbres PQ. Une expérience a été réalisée, dans laquelle l'arbre produit par ces générateurs est évalué d'une part en le comparant avec les classificiations de références utilisées par les antivirus par scannage, et d'autre part en le comparant aux phylogénies produites à l'aide de polygrammes de taille n (n-grammes), pondérés. Les résultats démontrent l'intérêt de l'approche utilisant les permutations dans la génération phylogénétique des codes malveillants.
Nous présentons un modèle d'interlocuteur pour un agent virtuel. Il génère des comportements d'écoute (rétroactions) en fonction des comportements verbaux et non verbaux de l'utilisateur. La personnalité de l'agent virtuel doit influencer le choix de ses comportements d'écoute. Nous supposons que les agents extravertis ont tendance à montrer plus de rétroactions que les introvertis et que la stabilité émotionnelle est liée à la tendance des agents à imiter l'utilisateur. Des études perceptives sur internet ont été réalisées pour évaluer notre modèle dans une situation d'interaction agent-utilisateur.
Nous présentons une base de données de grande envergure pour la langue japonaise. Elle consiste en une base de données de mots et de parole continue ; elle est relative à un grand nombre de locuteurs et à la synthèse de la parole. De nombreuses transcriptions ont été réalisées à cinq niveaux allant d'une simple description phonémique à une description acoustico-phonétique détaillée. La base de données a été utilisée pour le développement d'algorithmes de reconnaissance de la parole, pour des études relatives à la synthèse et pour rechercher des marques acoustiques, phonétiques et linguistiques utiles aux technologies de la parole.
Le but de cet article est d'attirer l'attention sur le rôle que joue la structure prosodique dans la reconnaissance des mots. Nous commençons par soutenir que la notion de mot écrit a eu une influence bien trop grande sur les modéles de la reconnaissance des mots parlés. Nous discutons ensuite plusieurs propriétés de la structure prosodique qui sont importantes pour les questions de reconnaissance. Nous présentons ensuite une conception de la reconnaissance des mots “en continu” qui tient compte de l'alternance entre syllabes fortes et faibles dans le flux de la parole. L'Accès lexical est guidé par les syllabes fortes, tandis que les syllabes faibles sont identifiées par une analyse globale de leur distribution et par l'utilisation de règles phonotactiques et morphonémiques. Nous concluons par une discussion de la controverse sur les différences d'accès aux mots à contenu et aux mots à fonction à la lumière de notre conception.
La rétro-propagation a été utilisée pour entraîner un petit réseau à prédire la durée syllabique dans un système texte-parole. L'entrée et la sortie se présentent sous la forme de valeurs analogiques et le réseau effectue une fonction de régression multiple.
Des études récentes ont montré que les techniques de reconnaissance de la parole en sous-bandes peuvent améliorer les performances des systèmes classiques larges bandes dans des conditions de bruit additif à bande étroite. Un aspect important de l'implémentation de l'approche en sous-bandes est le choix de la mèthode de recombinaison des observations dans chaque bande. Ce papier présente une nouvelle méthode, appelée modèle d'union probabiliste, pour effectuer cette recombinaison. Ce nouveau modèle est basé sur la théorie de l'union des événements aléatoires, et représente une nouvelle méthode pour la modélisation d'observations partiellement bruitées sans (ou presque) connaissance a priori de la nature du bruit. Le nouveau modèle a été intégré aux modèles de Markov cachés (HMM) et testé dans une táche de reconnaissance indépendante du locuteur de parole corrompue par divers types de bruits additifs. Les résultats montrent que le nouveau modèle offre une bonne robustesse aux bruits bandes étroites, tout en ne nécessitant pas ou presque pas de connaissance des propriétés statistiques du bruit.
Nous présentons un nouvel algorithme réalisant un recalage multimodal d'images planes (2D, ARX) et tomographiques (3D, ARM). Le recalage 2D/3D est défini par la recherche de la meilleure transformation rigide permettant de replacer un ensemble de données multimodales dans un espace tridimensionnel commun. L'intérêt de la méthode proposée réside principalement en deux points. Tout d'abord, l'exploitation de données anatomiques offre la possibilité d'un recalage sans référentiel externe, donc la possibilité d'un examen minimalement invasif plus confortable pour le patient. Ensuite, après la sélection manuelle d'une structure anatomique de référence, la phase de recalage peut être réalisée indépendamment de l'opérateur, puisque l'initialisation est automatique. En premier lieu, les données de l'imagerie tomographique sont exploitées pour reconstruire une structure tridimensionnelle. Puis, la position optimale de cette structure dans le référentiel de l'ARX est recherchée au moyen d'une analyse multi-résolution et d'une procédure d'optimisation. Finalement, la position de la structure tridimensionnelle étant connue en ARX et ARM, il est possible d'avoir une correspondance tridimensionnelle entre les modalités, à la condition de disposer d'au moins deux incidences pour les images planes.
Le CV est un document textuel singulier : faible structure, informations éparses, contenu fortement symbolique, etc. d'où la difficulté de traitement de ces documents. Nous utilisons cet espace ainsi défini pour modéliser le ciblage par apprentissage supervisé. En utilisant des méthodes d'arbres d'induction et analyse discriminante, nous obtenons des résultats intéressants en apprentissage (86% de rappel et 88% de précision). Même si les résultats en validation peuvent paraître décevants (55% de rappel et 60% de précision), cette approche ouvre des perspectives intéressantes d'exploitation automatique de CV basée sur le contenu informationnel et non à partir de simples mots clefs.
Cet article propose deux méthodes de construction d'un modèle indépendant du phonème et du locuteur qui réduisent considérablement les calculs nécessaires à la normalisation de la similarité (ou de la vraisemblance) pour la vérification du locuteur. Pour chaque élocution, ces méthodes demandent de calculer la similarité avec un modèle unique, et non pas avec tous ceux des locuteurs de référence comme on le fait classiquement. De plus, ces nouvelles méthodes présentent des performances égales ou supérieures à celles des méthodes classiques. Le test de vérification du locuteur se fait en utilisant des groupes séparés d'usagers et d'imposteurs, ce qui permet d'évaluer sa performance pratique de fonctionnement. Les taux d'erreur sur les locuteurs (et sur les textes) sont dans ce cas approximativement une fois et demi plus grands que quand on utilise la même population pour les usagers et les imposteurs. Avec 15 usagers et un groupe séparé de 15 imposteurs, le taux d'erreur en vérification indépendante du texte est de 1.8% et celui obtenu en vérification du locuteur avec un texte imposé est de 1.1%. Ces deux chiffres sont obtenus grâce à la normalisation ; le second est environ deux fois plus élevé si on utilise la méthode sans normalisation.
Dans cet article, on présente un bilan de l'état de l'art en modélisation statistique pour l'élaboration de systèmes de dialogue oral. Ce bilan traite en particulier de la modélisation acoustique des unités de parole pour la reconnaissance de parole et de la modélisation du langage pour le traitement du langage naturel. On mentionne certaines des techniques émergentes pour la modélisation statistique et l'on montre la similarité qui existe entre la modélisation du langage et la modélisation acoustique. Enfin, on discute des problèmes de recherche et de décision liés à l'intégration de sources de connaissances en reconnaissance de la parole et traitement du langage naturel.
Cet article s'intéresse au problème de l'explication des résultats fournis par un arbre de décision utilisé en tant que système d'aide à la décision. On cherche à apporter une information supplémentaire à la classe prédite pour chaque vecteur particulier de données d'entrée. Actuellement on dispose surtout de la trace du classement (le chemin parcouru dans l'arbre), et d'une estimation du taux d'erreur ou d'un risque associé à un mauvais classement. Nous proposons ici deux nouvelles méthodes de qualification du résultat, basées sur une étude géométrique de la frontière de l'image inverse des différentes classes (la surface de décision). La première méthode consiste à identifier les séparateurs les plus déterminants pour expliquer le résultat, en effectuant une analyse de sensibilité, par projection des données initiales sur la surface de décision.
Dans cette époque de systèmes et d'interfaces multi-modales, de nombreuses équipes de recherche tentent de trouver pour quels usages l'utilisation de nouvelles combinaisons de modalités pourraient être nécessaires. Basées sur l'étude d'applications particulières, les recherches empiriques sur la fonctionnalité de la parole concernent des points d'un vaste espace multi-dimensionnel. Au mieux, des résultats solides permettent des généralisations de bas-niveau qui ne peuvent être utilisées que pour la mise au point d'applications quasi-identiques. De plus, l'appareil conceptuel et théorique nécessaire pour décrire ces résultats sur la base de principes, manque. Cet article défend la position suivant laquelle seul un changement de perspective peut permettre de traiter les questions de choix de modalités d'un point de vue tant scientifique que pratique. Au lieu de se focaliser empiriquement sur des fragments d'une combinatoire virtuellement infinie de tâches, d'environnements, de paramètres de performance, de groupes d'utilisateurs, de propriétés cognitives, etc., le problème de la fonctionnalité des modalités est traité comme un problème de choix parmi diverses modalités qui ont diverses propriétés par rapport à la représentation et à l'échange d'information entre l'utilisateur et le système. Sur la base de l'étude de 120 demandes d'usage de la fonctionnalité `parole' tirées de la littérature, on montre qu'un ensemble réduit de propriétés de cette modalité permet, avec une efficacité surprenante, de justifier, soutenir et corriger l'ensemble des demandes. Cet article analyse pourquoi les propriétés des modalités peuvent être utilisées pour ces usages et défend l'idée que leur efficacité peut être mise à la disposition des développeurs de systèmes et d'interfaces qui ont à faire un choix entre diverses modalités lors des premières phases d'élaboration d'interfaces et de systèmes à composante vocale. Avec l'hypertexte, nous illustrons comment cette efficacité peut être gérée pour permettre de soutenir de façon prédictive le choix de la modalité `parole' dans les premières phase de développement de systèmes et d'interfaces.
Des études antérieures ont montré que la discriminabilité entre une paire d'occlusives est fonction du couple proprement dit et de sa position dans une syllable CVC. Dans deux expériences, on a testé l'hypothèse selon laquelle les différences du pouvoir discriminatif sont liées à des différences dans la représentation auditive des stimuli telle qu'elle résulte de l'analyse en fréquence par le système auditif périphérique. La représentation auditive de chaque consonne en position initiale et finale a été ensuite mesurée par une technique de masquage simultané. Les deux indices qui identitient une consonne sont (a) le spectre instantané de la transition formantique au début ou à la fin de la syllable et (b) l'allure de la transition formantique. La discriminabilité de six paires de consonnes (trois initiales et trois finales) a été corrélée avec la différence entre leurs pattern de masquage au début ou à la fin (ϱ = 0.89) et avec les différences entre la représentation auditive des transitions (ϱ = 0.94). L'importance de ces corrélations indique que les variations du pouvoir discriminatif entre consonnes peuvent été predite a partir de la connaissance de leut représentation auditive au niveau périphérique avec une faible contribution de facteurs phonétiques, linguistiques ou cognitifs.
Dans cet article nous proposons de coupler la géométrie riemannienne avec les techniques d'apprentissage pour une biométrie faciale efficace et robuste aux changements d'expressions faciales. Nous représentons localement la forme des surfaces faciales par des collections de courbes 3D. Nous appliquons des techniques d'apprentissage afin de déterminer les courbes les plus pertinentes à la reconnaissance d'identité des personnes. Le taux de reconnaissance de l'ordre de 98, 02 % sur le benchmark de référence FRGC v2 confirme l'efficacité de coupler l'analyse géométrique de la forme avec des techniques d'apprentissage.
Une classification des différentes méthodes pour l'évaluation des systèmes de synthèse à partir du texte, selon les exigences imposées à l'auditeur, est suggérée et discutée. La classification est faite selon les quatre niveaux traditionnels d'évaluation : les niveaux Nominal, Ordinal, Intervalle et Relatif. Un cinquième niveau, le Supra-Nominal, qui comprend les processus de mémorisation, est proposé. Les méthodes sont divisées en méthodes qualitatives non métriques et en méthodes quantitatives métriques. Il en résulte que le niveau métrique d'évaluation le plus élevé (Relatif) n'est pas nécessairement le niveau qui impose les plus grandes exigences à l'auditeur. Tout au contraire, le niveau Nominal, qui se base sur une approche qualitative non métrique, impose à l'auditeur des exigences bien plus élevées.
Cette article s'intéresse à la fusion d'images sériées, et ce pour la restauration de l'image 2D d'un objet. Pour réaliser cette fusion, nous avons besoin d'estimer la fonction de transfert entre les courbes de sensibilités de ces films. Dans notre contexte, cette estimation est difficile car l'une des images est perturbée par des taches lumineuses. Dans ce cadre, nous montrons que l'on peut s'affranchir de la présence de ces taches afin de réaliser la restauration.
Il existe de nombreuses situations où le rehaussement de la parole ne nécessite pas d'être fait en temps-réel. Pour ce type d'applications, l'emploi de toutes les connaissances disponibles a priori peut permettre d'aboutir à des solutions plus efficaces. Dans cette étude, on a développé un nouvel algorithme de rehaussement de parole, dépendant du texte, pour des applications de ce type. Dans notre approche, le texte du dialogue concerné est utilisé pour répartir la parole bruitée en classes correspondant à des classifications phonétiques larges. Les classes considérées concernent les plosives, les fricatives, les affriquées, les nasales, les voyelles, les semi-voyelles, les diphtongues et le silence. Ces partitions sont ensuite utilisées pour piloter un nouveau procédé de rehaussement basé sur une quantification vectorielle dans lequel des contraintes liées aux classes phonétiques sont utilisées pour améliorer la qualité de la parole. L'algorithme proposé a été, évalué par des méthodes d'evaluation objectives et subjectives. On montre que cette approche, dépendante du texte, améliore la qualité de la parole dégradée pour un grand nombre de sources de bruit (par exemple bruit blanc de canal de transmission, bruit de cockpit d'avion, vrombissement d'hélicoptère et bruit d'autoroute). Dans chaque cas, la méthode proposée fournit une qualité de parole notablement supérieure à celle obtenue par soustraction spectrale linéaire ou généralisée, ou par la méthode Auto-LSP de rehaussement itératif contraint utilisant la mesure d'Itakura-Saito et un corpus d'évaluation de 100 phrases. Les évaluations de qualité subjective ont été menées sous la forme d'un test de comparaison A-B. Les résultats de ces évaluations montrent que, pour les distorsions dues à des bruits large-bande, l'algorithme proposé est préferé dans un rapport 2 à 1 par rapport à la parole bruitée non-traitée et qu'il est préféré dans un rapport 3 à 1 par rapport à la soustraction spectrale.
Pour la reconnaissance de la parole avec des méthodes probabilistes, il est souvent souhaitable de pouvoir estimer la contribution du modèle de langage et celle du modèle acoustique. Nous proposons une approche basée sur la théorie de l'information qui considère l'interaction entre ces deux sources d'informations. On présente des résultats expérimentaux concernant le prototype de reconnaissance d'IBM pour la langue italienne qui est capable de fonctionner en temps réel avec un dictionnaire de 20.000 mots.
Dans le cadre d'un modèle phonosyntaxique de l'intonation de la phrase [1–4], la structure prosodique de la phrase est indiquée par des contours mélodiques placés sur les voyelles accentuées. La description phonologique de ces contours utilise les traits [±Extreme], [±Montant] et [±Ample]. L'analyse acoustique de phrases lues montre que, à l'exception du contour final, l'intensite et la durée ne jouent pas de rôle significatif dans la différenciation des contours, qui contrastenteffectivement par leur pente montante ou descendante, et par l'amplitude relative de variation mélodique.
Ce papier propose une approche multi-agent locale, coopérative et temps réel pour la création de profils adaptatifs et incrémentaux dans laquelle un usager est supposé être représenté par un ensemble de documents textuels. Ces documents sont analysés séquentiellement conduisant alors à la création d'un réseau terminologique temporaire (RTT). Les résultats préliminaires obtenus ainsi que les perspectives associées sont enfin présentés.
Les consonnes du Néerlandais énoncées dans les listes de logatomes de deux syllabes du type CVCVC, et insérées dans des courtes phrase porteuses, ont été identifées ar des sujets sous diverses conditions de déformations acoustiques. Les 28 conditions étaient un mélange de quatre temps de réverbération, cinq rapports signal/bruit et cinq spectres de bruit différents. Les résultats d'indentification ont été sommés pour les six locuteurs et les cinq sujets. De cette manère, nous avons obtenu 28 matrices de confusion par position de la consonne (initiale, médiane, finale). Ces ensembles de matrices ont été traités par des programmes d'échelonnement multidimensionnel de différences individuelles, et, plus spécifiquement par TUCKALS (Kroonenberg et de Leeuw, [9]). La configuration de stimulus tridimensional qui en résulte pour les consonnes initiales est très stable et peut être représentée comme un tétraèdre avec /z, s/, /m, n/, /p, t, k, b, d/, et /f, v, χ/ aux quatre coins et /l, r, w, j, h/ au centre. Cette configuration de consonnes est discutée dans sa relation à langue néerlandaise, compte tenu des conditions expérimentales. La représentation des 28 conditions devient presqu'entièrement uni-dimensionelle en dépit des trois aspects différents (temps de réverbération, niveau de bruit, spectre de bruit) des déformations de l'environnement acoustique.
Nous présentons deux expériences concernant la perception de la distinction entre /ba/ et /pa/ et dont l'object est de cerner les indices perceptifs signalant le début du voisement. Ni le début de l'excitation périodique, ni le changement de balance spectrale ne paraissent constituer l'indice dominant pour le début du voisement. Dans chaque expérience, le niveau d'intensité globale fournit la meilleure métrique pour expliquer la position des frontiéres perceptives.
On se représente souvent la seconde moitié du XVII e siècle, en raison de l'importance de ses propositions prescriptives, comme un moment où les discours tenus ont été acceptés et suivis d'effet. C'est au volet « limites » que nous nous intéressons dans cette contribution. Après avoir apporté quelques précisions terminologiques sur ce que l'on peut appeler normes et prescriptions, nous revenons sur les fondements de l' « anti-prescriptivisme » au XVII e siècle, notamment dans l'espace des « remarques sur la langue » , et nous montrons comment ce courant de résistance aux prescriptions a été repris par la culture mondaine de la fin du siècle. Au total, nous considérons que, loin de pouvoir être considérée seulement comme une période de « réglage » , la seconde moitié du XVII e siècle peut être vue au contraire comme un moment conflictuel et polémique, caractérisé par une altération de la normativité traditionnelle de la grammaire et par l'installation de régimes sociaux d'opposition qui rendent difficile tout établissement d'une norme unique adossée à une prescription claire.
Les situations, les interprétations sémantiques du contexte, fournissent une meilleure base pour sélectionner des comportements adaptatifs que le contexte lui-même. La définition des situations repose typiquement sur la capacité de définir des expressions logiques et des méthodes d'inférences pour identifier des situations particulières. Dans ce papier, nous étendons cette approche pour fournir une organisation et une sélection efficaces à des systèmes avec un très grand nombre de situations entretenant des relations structurées entre elles. Nous appliquons les treillis de Gallois pour définir une relation de spécialisation sur les situations, et nous montrons comment le résultat peut être utilisé pour améliorer l'identification de situations utilisant les opérateurs du treillis et le raisonnement incertain. La technique présentée est finalement validée sur un ensemble de données de taille réelle.
Essai de définition du statut et de la valeur du manuscrit d'auteur en moyen français à partir de l'étude archéologique et philologique des mss originaux de quatre textes de Christine de Pizan (Cent Ballades, Debat de deux amans, Mutacion de Fortune, Advision). Trois étapes dans le processus de publication d'un texte sont envisagés (établissement du modèle ; transcription d'une copie d'envoi ; retour sur la transcription) afin de souligner que la transcription autographe, certes privilégiée, importe moins que le geste premier d'autorisation de la copie de la mise au net, rédigée et fréquemment relue par la main de l'auteur, et le geste final de visite du ms., visible dans les émendations du texte, les corrections rédactionnelles et l'ajout d'éléments de personnalisation du codex. Enfin, l'article pose les enjeux méthodologiques et éditoriaux d'une telle étude (intention de l'auteur, choix du ms. de base et pertinence d'une étude esthétique et génétique de ces documents).
L'objectif de cet article est de présenter le calculateur embarqué de traitement d'image SYMPHONIE, ainsi que la méthodologie mise en oeuvre pour sa réalisation. Afin de tenir compte des contraintes de volume et de consommation, un ASIC d'un million de portes a été développé. Pour réussir cette réalisation un modèle VHDL a été écrit permettant des simulations de l'ensemble du système. Par ailleurs, ce modèle a permis d'aborder la réalisation du circuit ASIC en faisant appel aux outils de synthèse VHDL. Nous terminerons cette présentation par quelques performances dans différents domaines d'applications.
La plupart des théories de l'acquisition du langage supposent que celui qui apprend le langage peut segmenter la parole en propositions. Dans l'étude que nous présentons, une procédure de préférence a été utilisée pour étudier si les enfants de 7–10 mois sont sensibles aux correlats acoustiques des propositions en anglais. Les enfants s'orientent plus longuement vers les exemples segmentés aux frontières des propositions. Une seconde expérience confirme que cette préférence dépend des endroits où sont insérées les pauses. Ces résultats ont des implications importantes pour comprendre comment le langage est appris. L'enfant prelinguistique possède apparemment les moyens de détecter des unités importantes telles que les propositions à l'intérieur desquelles les règles grammaticales s'appliquent.
Nous essayons de formuler une esquisse des propriétés de la voix humaine en parole continue. Six niveaux différents sont pris en compte : (1) les données de référence pour un locuteur donné ; (2) les valeurs segmentales et les interactions source/conduit ; (3) la coarticulation des gestes glottiques et l'interpolation aux frontières ; (4) les dépendances de base sur F 0 ; (5) l'influence du stress, de l'accentuation et de l'intensité de la voix ; (6) l'enveloppe syntagmatique des variations de la source. La paramétrisation des données de la source est fondée sur le modèle LF transformé et sur des correspondances dans le domaine fréquentiel (Fant, 1995), ce qui permet une puissance de spécification maximale avec un nombre limité de paramètres.
Cet article décrit une technique d'apprentissage automatique pour l'adaptation au locuteur et au canal téléphonique, basée sur la séparation des sources de variation spectrale de la parole, dans le contexte de reconnaissance de parole continue, indépendante du locuteur. On propose des méthodes statistiques pour éliminer les biais spectraux au niveau acoustique et pour adapter les paramètres des mélanges de densités gaussiennes au niveau des segments phonétiques. Le biais spectral est estimé en deux passes, en utilisant l'estimation, non-supervisée, du maximum de vraisemblance : on considère d'abord que la distribution de probabilité du contenu spectral est uniforme pour les canaux présentant une forte distorsion, puis le biais spectral est réestimé en utilisant les modèles gaussiens des segments. La taille du vocabulaire testéétait de 853 mots ; la grammaire avait une perplexité de 105 ; les données de parole de test ont été enregistrées dans diverses conditions, chaque séquence de test contenant 198 phrases. La réduction en deux passes du biais spectral a permis d'obtenir une réduction relative du taux d'erreur (RER) de 3 à 11% (suivant les locuteurs et les canaux) par rapport aux techniques conventionnelles de compensation cepstrale moyenne. La technique USPA donne une RER de 12 à 26% après la suppression en deux passes du biais ; la technique IPA fournit une RER supplémentaire de 8 à 19% après application de l'USPA.
La structure d'un système de synthèse vocale basée sur la proéminence comme paramètre central est présentée. Une définition de la proéminence, adaptée à cette application, est donnée. Comme validation empirique, la concordance entre les jugements de proéminence de différents auditeurs est déterminée. Ces jugements sont mis en relation avec les données acoustiques de F 0 et durée. Une relation linéaire entre valeurs de proéminence et données acoustiques est constatée. Deux algorithmes, conçus à transformer les valeurs de proéminence en paramètres prosodiques sont décrits ainsi que leur évaluation. L'application du paramètre proéminence à la synthèse des accents de focus est démontrée. Ces résultats démontrent la validité de l'approche basée sur la proéminence comme interface entre linguistique et acoustique.
Dans le cadre de la simulation multi-agent, la dynamique globale d'un système, au niveau macroscopique, est considérée comme étant le fruit de la dynamique issue des interactions qui se déroulent entre les entités du niveau microscopique. La manière dont un modèle de simulation multi-agent articule la dynamique de ces deux niveaux est donc fondamentale. Dans cet article, nous revenons en détail sur l'intérêt du modèle influence/réaction de Ferber et Müller pour traiter cette problématique. Nous montrons en quoi ce modèle constitue une solution intéressante et nous en proposons une variante mieux adaptée à la simulation : le modèle IRM4S. Ce modèle explicite clairement le principe influence/réaction et met en exergue sa capacité à articuler la modélisation du niveau micro avec celle du niveau macro.
Les spécialistes du monde routier et des travaux public s'intéressent depuis longtemps aux aspérités présentes sur les chaussées. Ces défauts de la route par rapport à une surface idéalement plane constituent ce que l'on appelle son uni. L'analyseur de profil en long, l'APL, a été conçu par le Laboratoire Central des Ponts et Chaussées de Nantes afin de mesurer cet uni. Le signal que délivre cet appareil peut être considéré comme la sortie d'un système linéaire dont l'entrée est le profil inconnu de la route. Le signal que délivre cet appareil peut être considéré comme la sortie d'un système linéaire dont l'entrée est le profil de la route. Il se pose donc le problème de la déconvolution du signal APL. Dans un premier temps on modélise l'APL par une fonction de transfert du 5ème ordre construite à partir d'une description des différents organes mécaniques et électroniques qui le constituent et d'une analyse harmonique expérimentale. La technique du double filtrage permet alors d'éliminer les distorsions de phases du signal APL et d'obtenir ainsi un pseudo profil qui ne diffère du profil exact que par des atténuations pour des fréquences extérieures à la bande passante de l'analyseur. La deuxième approche utilise un modèle de l'APL obtenu par identification paramétrique (méthode du maximum de vraisemblance) et un modèle du profil du type signal de Wiener. Après élimination des composantes polynomiales et basses fréquences le signal reconstruit suit fidèlement les variations de l'uni de la chaussée. Des résultats, obtenus à partir d'enregistrements effectués au banc d'essais et sur une piste expérimentale, sont présentés.
Dans cet article, nous généralisons les relations entre les signaux de parole bruitée et non bruitée en utilisant une extension des séries de vecteurs de Taylor (VTS) pour la reconnaissance de la parole robuste au bruit. Nous utilisons cette méthode tant pour la compensation des données bruitées que pour l'adaptation des paramètres des modèles de Markov cachés (HMM), et nous l'appliquons directement dans le domaine cepstral, alors que Moreno l'avait utilisée pour estimer les paramètres spectraux logarithmiques. Nous développons également une procédure détaillée pour estimer les variables environnementales dans le domaine cepstral en utilisant les algorithmes de prédiction et de maximisation (EM) basés sur une idée de maximum de vraisemblance. Des expériences de reconnaissance de mots isolés et de parole continue, en mode indépendant du locuteur, ont été menées pour évaluer la méthode. Comme sources de bruit, on a utilisé des bruits blancs gaussiens et des bruits de voiture ajoutés à la parole propre à différents rapports signal sur bruit. Des améliorations notables des performances ont été atteintes en utilisant des statistiques de bruit obtenues à partir de seulement trois échantillons de silence et de parole bruitée à reconnaı̂tre. En particulier, l'adaptation des paramètres HMM avec la VTS est plus efficace que la combinaison de modèles parallèles (PCM) basée sur l'hypothèse log-normale.
Un égaliseur aveugle nouveau (HOCFLN) basé sur le cepstre d'ordre supérieur hybride (HOC) et un réseau à liens fonctionnels (FLN) est présenté. Le système utilise initialement le cepstre complexe de la tranche 1-D des cumulants d'ordre quatre du signal reçu inconnu pour estimer partiellement les coefficients de l'égaliseur, puis il commute sur un égaliseur adaptatif FLN opérant en mode de conduite par décision (DDM) pour améliorer encore la convergence en erreur quadratique moyenne (MSE). Dans ce système deux non-linéarités sont utilisées : l'une sur les données d'entrée pour lesquelles le HOC est employé et l'autre dans le filtre d'égalisation FLN. Il est montré que dans le système nouveau HOCFLN des non-linéarités multiples produisent des améliorations de performances significatives pour une complexité de calcul réduite, particulièrement pour des distortions de canal importantes, vis-à-vis des algorithmes d'égalisation conventionnels. Cette méthode peut prendre en compte aussi bien des canaux MA que ARMA à phase non minimale. Des résultats pour des canaux donnant lieu à des changements abrupts de caractéristiques sont également présentés.
La description d'objets tridimensionnels indépendamment de leur position et de leur orientation est un problème important et difficile de l'analyse de formes. Dans cet article, nous traitons ce problème à l'aide d'une pseudo-transformation de Fourier sur le groupe M(3) des déplacements de l'espace euclidien à trois dimensions. Celle-ci nous permet de définir des descripteurs de volumes à niveaux de gris stables et invariants par rapport à M(3). Cette méthode est appliquée à la classification et la description automatiques d'os humains.
On a essayé de réduire la qualité phonétique de voyelles à la position des pics dans leur spectre tonotipique par rapport aux autres pics, simultanés ou précédents. Des voyelles synthétiques à deux formants ont été identifiées par des locuteurs dans les langues desquelles les distinctions entre voyelles hautes sont relativement riches (Suédois, Turc). Les paramètres F 1 (204–801 Hz) et F′2 (509–3702 Hz) ont été modifiés de manitore systématique par intervalles de 0.75 bande critique. La f0 a été maintenue légèrement au-dessous du F 1 dans toutes les voyelles. Celles-ci ont été présentées sous deux ordres differents d'après le caractére ascendant ou descendant du F′2. La plupart des sujets ont entendu des voyelles fermées de manière prédominante. On propose d'attribuer ce second point de référence à une représentation par défaut de la position du troisième formant ou équivalent.
Nous définissions un indice acoustique lié au rendement vocal et nous étudions ses performances de discrimination sur un ensemble de locuteurs dysphoniques et normaux. Cet indice de rendement vocal (IRV) est calculé à partir de la fonction d'autocorrélation d'une portion stationnaire de la voyelle du français /a/. Au moyen d'une simulation nous monorons que l'indice en question est sensible à des variations du taux de charge et de la forme de l'onde glottique. La simulation indique que l'IRV est d'autant plus faible que le quotient de fermeture de la glotte est petit et que la forme de l'onde est symétrique. Nous calculons ensuite l'IRV à partir d'un ensemble d'échantillons de signaux dysphoniques et normales. II permet de discriminer entre locuteurs normaux et dysphoniques et la classification qui en résulte peut être interprétée dans le cadre d'un modèle théorique [20].
Analyse d'une recherche centrée sur l'apprentissage du langage humain, développant des modéles mécanistes précis susceptibles, en principe, d'acquérir le langage à partir d'une exposition aux données linguistiques. Une telle recherche comporte des théorémes (empruntés à la linguistique mathématique) des modéles informatiques pour l'acquisition du langage (empruntés à la simulation cognitive et à l'intelligence artificielle) des modéles d'acquisition de la grammaire transformationnelle (empruntés à la linguistique théorique). On soutient que cette recherche repose étroitement sur les thèmes principaux de la psycholinguistique de développement et en particulier sur l'opposition nativisme-empirisme, sur le rôle des facteurs sémantiques et pragmatiques dans l'apprentissage du langage, sur le développement cognitif et l'importance du discours simplifié que les parents adressent aux enfants.
Cet article a pour projet de préciser la théorie du malentendu en la confrontant á l'organisation conversationnelle d'un malentendu apparu dans une séquence extraite d'un dialogue tutoriel. L'analyse interlocutoire (Trognon et Brassac, 1992) de la séquence soutenant le malentendu, révéle qu'une organisation conversationnelle d'un malentendu peut prendre des formes complexes. Dans la littérature l'organisation conversationnelle du malentendu repose sur une structure articulant trois éléments : T1, le contenu du tour de parole qui supporte le malentendu, T2, le contenu du tour de parole révélant le malentendu, et T3, le contenu du tour de parole résolvant le malentendu. Dans notre séquence, ces trois moments (T1, T2 et T3) ne se succédent pas directement mais s'agencent dans une structure hiérarchique complexe. Ces trois moments, plus précisément T2 et T3 se reproduisent plusieurs fois de suite. Aussi notre séquence a pour singularité d'illustrer une résolution de malentendu sans travail sur l'intersubjectivité.
Trois vocabulaires (mots de contrôle d'un cockpit, chiffres, et consonnes et initiales) ont été comparés en vue d'évaluer des systèmes de reconnaissance de la parole. Le but de cette étude est de comparer plusieurs méthodes d'évaluation orientées vers des applications pour contrôler des situations de laboratoire. Nous avons observé que la discrimination entre plusieurs conditions de reconnaissance est améliorée par l'utilisation de vocabulaires difficiles. Les confusions entre les stimuli et les réponses des mots de tests peuvent être utilisées comme un outil de diagnostic pour prédire les performances et les développements.
Dans cet article nous présentons des expériences réalisées au LIMSI-CNRS sur le développement et sur la portabilité d'un module de compréhension utilisant une méthode stochastique à d'autres langues humaines et d'autres applications. Le travail de recherche concerne l'application ATIS (Air Travel Information Services) en anglais ainsi que l'application française MASK (Multimodal-Multimedia Automated Service Kiosk). L'étude montre pour des applications limitées que, comparée à un module conventionnel de compréhension de la parole spontanée, une méthode stochastique fournit de meilleurs résultats. De plus nous montrons que l'avantage d'une telle méthode réside dans le fait que l'effort humain se limite à l'étiquetage des données, ce qui est plus aisé que la conception, la maintenance et l'extension des règles de grammaire. La méthode est donc relativement flexible et robuste.
Lorsqu'on trouve des problèmes dans les conversations, ce sont tout d'abord des problèmes collectifs et les participants doivent les co-gérer. Les participants à une conversation disposent de trois sortes de stratégies pour les gérer. (1) Ils essayent de prévenir les problèmes qui sont prévisibles mais évitables. (2) Ils avertissent leurs associés contre les problèmes prévisibles mais inévitables. (3) Ils réparent les problèmes qui se sont déjà révelés. Alors, les interlocuteurs et leurs destinaires agissent en commun à trois niveaux de la parole. Ils coordonnent (1) l'articulation de l'interlocuteur à l'attention des destinaires. Ils coordonnent (2) la présentation d'une expression par l'interlocuteur à l'identification de cette expression par les destinaires. Et ils coordonnent (3) la signification signalée par l'interlocuteur à la compréhension de cette signification par les destinaires. En somme, les participants à une conversation travaillent ensemble afin de prévenir, d'avertir et de réparer les problèmes à chacun de ces niveaux. En plus, toutes choses égales par ailleurs, ils préfèrent les préventions aux avertissements, et les avertissements aux réparations.
Nos travaux concernent la qualité de la représentation et la détection des points atypiques en apprentissage supervisé. Dans le cas où la variable à prédire est numérique - on parle alors d'apprentissage par la régression - nous avons proposé d'évaluer la qualité de ta représentation associée à un graphe de voisinage issu des prédicteurs à partir d'un coefficient d'autocorrélation de voisinage. Ce coefficient est construit sur le modèle du coefficient d'autocorrélation spatiale de Moran. Poursuivant l'analogie avec l'analyse spatiale, nous proposons dans ce papier de décompo.ser ce coefficient en une somme des coefficients locaux associés à chaque exemple et de tracer le diagramme de dispersion de Moran afin de repérer les exemples pour lesquels la valeur de la variable à prédire est atypique. L'expérimentation conduite sur diverses bases du site UCl Machine Learning a donné des résultats satisfaisants.
Le but de cet article est de donner un aperçu des progrès récents obtenus dans le domaine de la reconnaissance automatique de la parole. Il traite essentiellement de la reconnaissance vocale, mais mentionne également les progrès réalisés dans d'autres domaines du Traitement Automatique de la Parole (Reconnaissance du Locuteur, Synthèse de Parole. Analyse et Codage), qui utilisent des méthodes voisines. Ces méthodes ont conduit à des progrès obtenus concurremment suivant plusieurs axes, à des performances meilleures sur les vocabulaires difficiles, ou à des systèmes plus robustes. Quelques matériels spécialisés sont également décrits, ainsi que les efforts qui ont été consentis dans le but d'évaluer la qualité des systèmes de reconnaissance.
Au cours des siècles, les Zaydites ont été amenés à répondre à une série de remises en cause – du dedans comme du dehors – dirigées contre la cohésion interne de leur tradition. Remarquant que les Zaydites ne suivent généralement pas les opinions légales de leur ancêtre éponyme Zayd b. ʿAlī (m. 112/740), les critiques sunnites ont mis ceux-là au défi de justifier leur adoption du label « zaydite » . La réponse classique fut avancée par l'imam yéménite al-Manṣūr ʿAbd Allāh b. Ḥamza (m. 614/1217), lequel expliqua l'affiliation zaydite en termes théologiques et politiques. Au sein même du zaydisme, toutefois, des divergences opposant les principaux imams sur des questions légales causèrent des dissensions parmi leurs adeptes. Afin de contrer cette menace à l'unité dans leurs rangs, les jurists zaydites adoptèrent largement la théorie selon laquelle tous les experts légalement qualifiés (muğtahids) – ce qui incluait les imams zaydites – étaient égaux dans leurs avis. Plus techniques s'avérèrent les questions entourant le caractère de l'école juridique (maḏhab) devenue dominante chez les Zaydites yéménites. Elles touchaient tant la source des opinions légales qui avaient façonné la doctrine de l'école que la question liée de la structure de l'autorité de l'école. Ces questions, d'ordre historique et théorique, acquirent une acuité particulière à partir du xi e/xvii e siècle pour être popularisées grâce à la circulation du court poème d'Isḥāq b. Yūsuf (m. 1173/1760), ʿUqūd al-taškīk, lequel appelait les Zaydites yéménites à clarifier leur identité « légale » . Mais c'est également la structure d'autorité de l'ensemble des maḏhabs sunnites qui se trouva interrogée, si bien que certains points soulevés ici relèvent de la loi islamique de manière plus générale. Ce poème évoquait une palette de réponses, en prose et en vers, incluant un court traité de l'auteur du poème, al-Tafkīk li-ʿUqūd al-taškīk. Alors que nombre de défendeurs s'efforcèrent d'affirmer la viabilité de l'école juridique, d'autres, notamment Ibn al-Amīr al-Ṣanʿānī (m. 1182/1769) et Muḥammad b. ʿAlī l-Šawkānī (d. 1250/1834), considé­rèrent qu'elle ne pouvait être sauvée. Leurs objections à l'autorité légale traditionnelle (taqlīd), dans le cadre du zaydisme, furent largement reprises par les réformateurs musulmans des xix e et xx e siècles qui ambitionnaient de miner les maḏhabs sunnites et continuent, encore aujourd'hui, à jouir d'un réel crédit.
L'une des tâches majeures de l'auditeur lors du processus de compréhension de la parole est la segmentation du signal en mots. Quand les conditions d'écoute sont mauvaises, les locuteurs peuvent aider ceux qui les écoutent en articulant clairement. Nous avons examiné, au cours de quatre expériences, la production des frontières de mots dans la parole délibérément claire. Des mesures de la durée des syllabes qui précèdent les frontières de mots, ainsi que celle de pauses éventuelles ont été faites dans une série de phrases prononcées normalement et dans ces mêmes phrases prononcées de manière particulièrement claire. Nous avons trouvé que quand les locuteurs articulent très soigneusement, ils essaient effectivement de souligner les frontières de mots ; de plus, la manière dont ils s'y prennent suggère qu'ils sont sensibles aux besoins de ceux qui les écoutent. En effet, des études précédentes ont suggéré que les Anglais emploient une stratégie de segmentation telle qu'ils repèrent plus aisément les frontières de mots précédant les syllabes accentuées. Or, dans des conditions d'écoute difficiles, les locuteurs s'appliquent à souligner les frontières de mots précédant les syllabes faibles, c'est-à-dire celles-là mêmes quis seraient particulièrement difficiles à percevoir.
Les médianes pondérées avec des coefficients entiers utilisent largement les opérateurs non linéaires en traitement des signaux. Les filtres à médianes pondérées appartiennent à la classe des filtres en pile. Alors qu'un filtre en pile est uniquement spécifié par sa function positive et booléenne correspondante, cette dernière peut être utilisée pour analyser les caractéristiques du filtre. D'un autre côté, les médianes pondérées sont habituellement représentées par un ensemble donné de poids. Dans cet article, les médianes pondérées sont tout d'abord généralisées pour inclure des opérateurs utilisant des poids réels et positifs. Il est montré que tout poids réel est équivalent à une valeur de poids entière. En conséquence, une analyse précise peut toujours être réalisée pour représenter des poids médians réels avec une précision de poids médians finie. Ce résultat s'avère très utile car les valeurs adaptatives et optimales des médianes pondérés sont souvent réelles. Des algorithmes de conversion sont présentés pour trouver la fonction positive et booléenne représentant une médiane pondérée donnée et un ensemble de poids d'une médiane pondérée représentant une fonction donnée positive et booléenne si cela est possible.
L'algorithme d'itérations sur les valeurs avec approximations (IVA) permet de résoudre des problèmes de décision markoviens en grande dimension en approchant la fonction valeur optimale par une séquence de représentations V n calculées itérativement selon $ {V}_{n+1}=\mathcal{AT}{V}_n$ où $ \mathcal{T}$ est l'opérateur de Bellman et $ \mathcal{A}$ un opérateur d'approximation, ce dernier pouvant s'implémenter selon un algorithme d'apprentissage supervisé (AS). Les résultats usuels établissent des bornes sur la performance de IVA en fonction de la norme L ∞ des erreurs d'approximation induites par l'algorithme d'AS. Cependant, un algorithme d'AS résout généralement un problème de régression en minimisation une norme L p (p ≥ 1), rendant les majorations d'erreur en L ∞ inadéquates. Dans cet article, nous étendons ces résultats de majoration à des normes L p pondérées. Ceci permet d'exprimer les performances de l'algorithme IVA en fonction de la puissance d'approximation de l'algorithme d'AS, ce qui garantit la finesse et l'intérêt applicatif de ces bornes. Nous illustrons numériquement la qualité des majorations obtenues pour un problème de remplacement optimal.
La sélection de variables et la régularisation sont deux classes de méthodes couramment employées pour améliorer les capacités de régularisation des réseaux connexionnistes. Dans cet article, nous verrons comment l'utilisation d'une pénalisation sur la norme L1 des paramètres en tant que régulariseur permet de réaliser de façon simultanée une sélection des paramètres importants. Cette méthode formellement à mi-chemin entre la sélection de variables classique et la régularisation type weight-decay permet en fait de bénéficier des avantages des deux techniques. On obtient ainsi des modèles parcimonieux aux paramètres bien maîtrisés. Nous illustrons tout d'abord brièvement quelques propriétés de ce régulariseur par une étude analytique d'un modèle simple à un seul paramètre. On présente ensuite les résultats obtenus sur des réseaux de neurones pour la prédiction de séries chronologiques. Enfin, on discute des aspects pratiques comme l'estimation des paramètres ainsi que des liens avec une méthode similaire utilisée en statistique pour la régression linéaire.
Le décodage acoustico-phonétique constitue une étape importante en reconnaissance de la parole continue. Cet article rappelle d'abord les difficultés du problème et les principales méthodes qui ont été proposées pour le résoudre. Il présente ensuite les diverses approches complémentaires adoptées par notre équipe : système expert fondé sur l'activité de lecture de spectrogrammes, reconnaissance par triplets phonétiques, modèle connexionniste de colonne corticale et reconnaissance par méthode stochastique sans segmentation.
Dans cet article, nous présentons quelques résultats sur le développement d'un système de mosaïquage de visages panoramiques. Notre objectif est d'étudier la faisabilité de construction de visages panoramiques en temps réel. Ceci nous a conduit tout d'abord à concevoir un système d'acquisition très simple, composé de 5 caméras standards qui réalise la prise de 5 vues simultanément sous différents angles. Cet algorithme est basé sur des transformations linéaires successives, pour composer un visage panoramique de 150° à partir de ces 5 vues. La méthode a été testée sur une centaine de visages. Nous avons aussi effectué une étude préliminaire sur la reconnaissance de visages panoramiques dans le but de valider notre système de mosaïquage de visages. Nous pensons aussi utiliser notre système de mosaïquage dans d'autres applications comme la reconstruction rapide de visages 3D et la catégorisation des expressions basée sur le mouvement.
Dans cet article, nous présentons une application de la théorie des fonctions de croyance pour la classification d'états physiologiques dans un bioprocédé. Nous nous intéressons surtout à la pertinence des sources d'informations qui sont ici des paramètres biochimiques mesurés durant le procédé. La théorie des fonctions de croyance, et plus particulièrement la notion de conflit est utilisée pour évaluer la pertinence de chaque source d'information. Une autre mesure du conflit, basée sur une distance, est utilisée comme alternative, et fournit dans certains cas, des résultats plus cohérents qu'avec le conflit défini dans la théorie de Demspter et Shafer. Les résultats concernant deux types de bioprocédés (procédé batch correspondant à une classification supervisée, et procédé fed-batch correspondant à une classification non supervisée) sont présentés.
Une nouvelle approche en vue de la transcription phonémique d'un énoncé oral est décrite. Dans un premier temps, grâce à la “carte topologique auto-organisatrice de Kohonen”, nous quantifions vectoriellement le signal de parole pour obtenir une séquence de labels phonétiques tous les centièmes de seconde. Cette séquence de codes est convertie en une séquence de phonèmes en utilisant un réseau multi-couche entraîné par rétropropagation de l'erreur. Le réseau, une fois entraîné, agit comme un filtre qui enlève de la séquence de codes les transitions non désirées et les effets de coarticulation. Ceci rend quasiment trivial la conversion de la séquence de codes en une séquence de phonèmes. Dès lors, la nécessité d'utiliser des modèles statistiques de la parole tels que les modèles markoviens, disparaît. La nouvelle approche est comparée à une méthode déjà utilisée dans un système de reconnaissance de la parole et qui se base sur de simples règles de durée. Grâce à notre méthode, la précision de la transcription phonémique obteneu est de 4,8% supérieure à celle des méthodes habituelles (88,4% vs 83,6%).
Lorsqu'employée en reconnaissance des formes, la modélisation des mouvements humains vise, entre autres, à procurer certaines assises théoriques au traitement en ligne de l'écriture manuscrite et à fournir des connaissances fondamentales pouvant servir de balises dans la conception de systèmes automatiques. À ce jour, plusieurs approches ont été proposées pour modéliser la production des mouvements en général et de l'écriture en particulier : des modèles dynamiques, psychophysiques, cinématiques, à base de réseaux de neurones ou reposant sur des principes de minimisation. Parmi les modèles dits analytiques, la Théorie Cinématique et son équation delta-lognormale se sont avérées des plus prometteuses. Mais, bien qu'il ait été démontré que ce paradigme permettait de prendre en compte la majorité des phénomènes couramment observés en motricité fine, plusieurs problèmes théoriques et techniques ont retardé l'intégration directe ou indirecte de cette théorie dans la conception de systèmes. Dans cet article, nous faisons le point sur ces différentes difficultés et nous dévoilons les résultats de récents travaux que notre équipe a réalisés pour les surmonter. Dans un premier temps, dans une perspective de généralisation, nous présentons les principaux modèles de types log-normaux. Ensuite, du point de vue pratique, nous décrivons deux nouveaux algorithmes d'extraction de paramètres. Nous montrons également comment la nouvelle représentation qui en résulte peut être employée pour améliorer le traitement des signaux électromyographiques, ouvrant ainsi la porte à de nouvelles applications en génie biomédical. Nous concluons en présentant brièvement d'autres applications potentielles qui sont présentement en cours de développement dans notre laboratoire ou le seront dans un avenir rapproché.
Cet article étudie les possibilités offertes par l'utilisation du réseau neuronal de Kohonen pour la quantification vectorielle d'images. Quelques résultats théoriques sur la convergence du processus d'apprentissage du réseau précéderont les essais réalisés sur des images. On comparera d'abord, à l'aide d'une image test, les performances obtenues pour des dictionnaires de taille et de dimension différentes. On poursuivra alors les essais avec les meilleures combinaisons, en utilisant finalement plusieurs images pour élaborer les dictionnaires. Cette étude se particularise par l'emploi de cinq réseaux en parallèle, ainsi que par la variation de plusieurs paramètres, longueur de la séquence d'entraînement, nombre de classes de vecteurs, dimension des vecteurs, et nombre de vecteurs utilisés pour le codage.
Cet article décrit l'architecture et le fonctionnement du système de reconnaissance de la parole DIRA (DIRA : Dialogue Intégré et Reconnaissance Automatique) dans son état actuel. Ce système est un système multi-experts supervisé. Le superviseur organise les tâches de ses experts qui sont attachés aux diverses sources de connaissances : acoustico- phonétiques, lexicales, syntaxico-sémantiques, prosodiques et pragmatiques. Le tableau noir sert de boîte à lettre pour la communication de messages entre les divers modules ainsi que de mémoire à long terme où toutes les hypothèses en cours de construction sont consignées. Le superviseur est un planificateur opportuniste : il raisonne sur les données présentes dans le tableau noir et « calcule » la stratégie la meilleure pour activer les experts. Les experts sont également décrits dans cet article : les DAP (décodages acoustico-phonétiques) avec leurs bases de connaissance représentées sous forme de règles qui contrôlent les transitions d'un ATN (Augmented Transition Network), les analyseurs linguistiques utilisant aussi le concept d'ATN compilé et la notion de grammaire lexicale fonctionnelle, la compréhension fondée essentiellement sur le phénomène d'amorçage sémantique et enfin l'analyseur prosodique à base de règles. La mise en œuvre de ce système est commentée à travers des exemples et les résultats de reconnaissance sont discutés.
Nous présentons nos travaux sur la conception, l'ajustement et le recalage d'un modèle 3D articulé de la main pour son suivi dans des séquences d'images monoscopiques, sans recourir à des marqueurs. Après un état de l'art, nous décrivons notre modèle 3D générique de la main et son ajustement à la morphologie de l'opérateur sur une image de sa main ouverte. Nous comparons ensuite différentes fonctionnelles et méthodes d'optimisation pour le recalage. Enfin, des résultats sur des séquences d'images sont présentés. A terme, un tel système d'acquisition du geste par la vision artificielle pourrait être utilisé pour des interfaces homme-machine par le geste, pour l'animation d'humains virtuels, le codage à très bas débit du geste pour la téléprésence, ou la reconnaissance de la langue des signes.
Disposer de descriptions phonétiques précises de bases de données de parole est essentiel pour la recherche en traitement automatique de la parole : toutefois, la segmentation et l'étiquetage manuels sont des tâches longues et sujettes à erreurs. Dans cet article, nous présentons une méthode de segmentation automatique de la parole. Etant donnée une transcription phonétique ou une transcription orthographique, notre système fournit la segmentation phonétique correspondante. Cette méthode est basée sur l'utilisation d'un système de reconnaissance de parole utilisant les chaînes de Markov cachées (Hidden Markov Models, HMM) pour modéliser les unités acoustico-phonétiques. La base de données américaines DARPA-TIMIT a été utilisée pour l'apprentissage et le test du système. Pour évaluer notre système,d es expériences de segmentation et de transcription phonétique ont été effectuées dans différentes conditions. Des résultats satisfaisants ont été obtenus, en particulier lorsque le système est entrainé avec des signaux préalablement segmentés manuellement. La taille de ce corpus d'apprentissage joue un rôle important : les performances du système ont été évaluées en fonction de ce paramètre. Lorsque l'apprentissage est effectué avec seulement 256 phonétiquement équilibrées, le taux de frontières phonétiques correctement positionnées, avec une marge de 20 ms, est de 88.3%.
On suggère une nouvelle caractérisation qui s'appuie sur des données d'aphasiques agrammatiques parlant hébreux et sur le réexamen de données de patients russes et italiens. Cette caractérisation est en relation avec les niveaux linguistiques de représentation. On montre ensuite que la performance agrammatique dans des taˆches variées (y compris la compréhension) est une conséquence naturelle de cette condition.
Nous présentons, dans le cadre de la reconnaissance de la parole basée sur les phonèmes utilisant des modèles de Markov cachés (HMM, Hidden Markov Models) en conjonction avec des dictionnaires entraînés par quantification vectorielle supervisée (LVQ, Learning Vector Quantization), une nouvelle manière de modéliser les dépendances contextuelles. Nous utilisons les LVQ pour transformer les données acoustiques contextuelles en une forme phonémique indépendante du contexte. Cette transformation élimine le besoin d'utiliser des modèles de Markov dépendants du contexte, ainsi que les difficultés associées. Au contraire, des modèles simplifiés indépendants du contexte des observations discrètes sont suffisants. Nous avons obtenu par cette méthode d'excellents résultats pour une tâche dépendante du locuteur en Finnois.
Face à la nécessité de mieux comprende la variabilité du signal de parole, l'analyse des stratégies individuelles liées au processus d'encodage et de décodage de messages humains est fondamentale. L'étude phonologique présentée ici, concerne la langue française. Deux modules de règles de transformation graphème-phonème avec variantes du français ont été développés. Les tests de ces modules ainsi que la typologie des erreurs rencontrées sont présentés. L'étude des bases de données utilisées pour la création et les tests des règles a mis en lumière certaines exceptions à ces règles générales. L'analyse de ces exceptions nous a permis de dégager une certaine régularité dans leur occurrence, de rechercher les causes qui peuvent leur être associées, et de prévoir des liens entre différents phénomènes phonologiques.
La parole est un code naturel de correction d'erreurs. Le signal de la parole est riche en redondances contextuelles à de nombreux niveaux de représentation, qu'il s'agisse des variations allophoniques, de la phonotactique, de la structure syllabique, des domaines d'accentuation, de la morphologie, de la syntaxe, de la sémantique et de la pragmatique. Les recherches psycho-linguistiques ont eu tendance à insister sur des contraintes à des niveaux élevés comme la sémantique et la pragmatique et ont en général laissé de côté l'utilité de contraintes de niveau inférieur comme la variation allophonique. Il a même été dit que la variation allophonique est une source de confusion ou une sorte de bruit statistique qui rend la reconnaissance de la parole bien plus difficile qu'elle ne l'est déjà. Par opposition à ces idées, je soutiendrai que l'aspiration, le “flapping”, la palatalisation et d'autres indices qui varient de manière systématique avec le contexte syllabique peuvent être utilisés pour analyser les syllabes et les domaines d'accentuation. Ces constituants peuvent ensuite limiter le processus d'identification lexicale, de sorte que l'identification de la bonne entrée lexicale demandera bien moins de travail. Je proposerai donc que la structure syllabique et les domaines d'accentuation constituent un niveau intermédiaire de représentation entre la description phonétique et le lexique. Ma discussion est avant tout computationnelle et inclut la présentation d'un prototype de parseur phonétique qui a été implémenté en utilisant des mécanismes de parsing connus. Aucun résultat expérimental ne sera présenté.
Cet article s'intéresse à la synthèse automatique d'agents en environnement incertain, se plaçant dans le cadre de l'apprentissage par renforcement, et plus précisément des processus de décision markoviens partiellement observables. Les agents (dénués de modèle de leur environnement et de mémoire à court terme) sont confrontés à de multiples motivations/objectifs simultanés, problématique qui s'inscrit dans le domaine de la sélection d'action. Nous proposons et évaluons différentes architectures de sélection d'action. Elles ont en commun de combiner de manière adaptative des comportements de base déjà connus, en apprenant les réglages de la combinaison afin de maximiser les gains de l'agent. La suite logique de ces travaux est d'automatiser la sélection et la conception des comportements de base eux-mêmes.
La visualisation de données multidimensionnelles est un problème important. Nous proposons dans cet article d'utiliser l'image couleur pour obtenir une visualisation immédiate et synthétique des données initiales. L'apport de la couleur permet d'exhiber les principales structures de ces données complexes. Après avoir réduit la dimension du problème, notre méthode génére des pixels couleur en utilisant une transformation non triviale inspirée des travaux d'Ohta et al. Une dernière étape de tri et d'arrangement de ces pixels dans une image nous permet alors de visualiser nos données multidimensionnelles sur une image couleur.
L'hypothèse due à Chistovich et au groupe de Léningrad selon laquelle il existerait dans le système auditif une intégration spectrale à large bande (3–3.5 Bark) n'est supportée par aucune preuve réelle, puisque toutes les données expérimentales peuvent être expliquées sans cette théorie. Il nous semble en fait que l'existence d'un tel mécanisme ne peut être démontrée par un test d'ajustement, car si on demande à un sujet de remplacer un signal “complique” par un signal “plus simple”, il le fera, quel que soit le moyen qu'il utilisera. Pour mettre ce mécanisme “simplificateur” en évidence, il faut essayer de trouver des “traces” de son existence à l'aide d'une expérience où on ne demande pas explicitement au sujet une telle simplification. Nous sommes partis à la recherche d'une telle “trace de F 2 en mémoire” en soumettant nos sujets à la fois à un test d'identification et à un test de discrimination sur deux ensembles de voyelles synthétiques à 4 formants (antour des frontiéres phonétiques [i]-[y] et [e]-[ø] respectivement). Nous avons obtenu les principaux résultats suivants : • - les différences significantives observées dans les scores de discrimination ne peuvet être expliquées sans supposer l'existence d'une représentation in intégrée à large bande ; • - cette représentation intégrée fournit une trace en mémoire plus persistante que le classique representation en bandes critiques (1-Bark). L'argument crucial repose sur le fait que des stimuli associés à des valeurs ambiguës de F 2 dans tests d'adjustement sont aussi associés à des traces ambiguës en mémoire — mises en évidence par un taux fortement accru de fausses alarmes - dans une expérience de discrimination. Ces résultats nous ont fourni les “traces de F'2 en mémoire” que nous recherchions.
Dans cette approche, le MLP est entrainé pour la classification des phonèmes. Les valeurs de sortie du MLP sont ensuite utilisées comme pondérations dépendantes des états, ce qui améliore les performances par rapport à des HMMs sans pondération dépendante des états. Pour améliorer encore la discrimination entre classes concurrentes, l'apprentissage discriminant des pondérations dépendantes des états est effectué en calculant le gradient du critère d'optimisation pour les HMM pondérés par rapport aux paramètres des MLPs. Pour la reconnaissance de parole continue en mode indépendant du locuteur, l'algorithme proposé réduit notablement le taux d'erreur par rapport à celui des HMMs conventionnels.
Cet article propose un modèle segmentai probabiliste reposant sur une représentation polynomiale du signal de parole. A la différence du modèle probabiliste classique, opérant au niveau de la trame, ce modèle de segments regroupe les trames consécutives dont les caractéristiques sont semblables et représente l'ensemble du segment sur une base de polynômes orthogonaux. Un algorithme itératif d'estimation des paramètres du modèle est proposé. Le modèle segmentai est appliqué à la vérification du locuteur indépendante du texte. Les tests ont été réalisés sur une base de données de 20 locuteurs. La meilleure version du modèle permet d'obtenir un taux d'égale erreur de 0.59%, pour des énoncés de test composés de 10 chiffres. Ceci correspond à une réduction relative du taux d'erreur de plus de 50%, par rapport au modèle probabiliste conventionnel, opérant au niveau de la trame.
Afin de classer les objets présents dans leur environnement, les robots mobiles sous-marins peuvent exploiter des informations sensorielles acquises séquentiellement (sonar). Elles sont généralement qualifiées d'imparfaites, c'est-à-dire qu'elles sont imprécises, incertaines et incomplètes. L'incomplétude est vue ici comme l'indisponibilité d'un jeu de paramètres rendant impossible le calcul des critères de classification qui en dépendent, retardant ainsi la prise de décision. L'article propose de modéliser les informations dans le cadre de la théorie des possibilités, et d'appliquer le calcul flou afin d'évaluer des critères même en présence d'incomplétude. Les résultats ainsi obtenus sont fusionnés séquentiellement par un processus de combinaison dissymétrique. Les différentes lois de fusion dissymétrique sont passées en revue et une loi spécifique au traitement de l'incomplétude est proposée.
Cet article présente une étude comparée de différentes transformations utilisées pour calculer la section du conduit vocal à partir de la distance sagittale. Les distances sagittales et les sections du conduit vocal ont été mesurées sur des coupes obtenues par Résonance Magnétique pour les voyelles orales du Français prononcées par deux locuteurs. La section mesurée peut ainsi être comparée aux sections calculées au moyen des différentes transformations. L'évaluation est réalisée au moyen d'une technique de “jackknife” : les paramètres de la transformation sont estimés pour une région du conduit vocal à partir de l'ensemble des données sauf une, qui permet ensuite d'évaluer la transformation. Cette procédure permet d'étudier à la fois les performances des transformations et la stabilité des paramètres des transformations pour chaque région du conduit vocal. Trois formes différentes de transformation ont été comparées : linéaire, polynomiale et exponentielle. Les performances de quatre transformations existantes sont également présentées.
L'objet de cet article est de renouveler la compréhension du rôle joué par la théorie, comme par exemple la théorie du choix rationnel, dans la fabrication des décisions organisationnelles. Nous approchons la prise de décision comme une praxis performative, c'est-à-dire un ensemble d'activités par lesquelles les acteurs produisant des décisions transforment des théories en réalité sociale. Nous généralisons l'approche en termes de praxis performative, qui articule les processus de conventionnalisation, d'ingénierie et de marchandisation, pour rendre compte des formes de mobilisation directes et indirectes des représentations théoriques par les acteurs dans la fabrique de la décision organisationnelle.
Ce papier concerne le codage en sous-bandes par filtrage Pseudo-QMF des signaux d'images de télévision couleur. Les méthodes proposées sont basées sur des codages prédictifs et des quantifications scalaires, la qualité visée des images reconstruites devant être excellente. D'abord nous proposons et comparons un ensemble de trois fonctions de prédiction adaptatives. Ensuite nous développons trois stratégies de quantification présentant des niveaux d'adaptativité différents.
Le niveau faible des programmes de go n'est pas seulement dû à la complexité combinatoire du go, mais aussi à la difficulté de construire une fonction d'évaluation adéquate et complète d'une position. Cet article présente les nombreux concepts spatiaux que fait intervenir une fonction d'évaluation au go ; les principaux sont le regroupement, le fractionnement, l'encerclement, l'agrégation. La programmation go est une excellente illustration des théories du raisonnement spatial en raison de cette richesse conceptuelle. Pour chaque concept spatial, les outils mathématiques utilisés pour les simuler sur machine (morphologie mathématique, topologie, distance de Hausdorff, raisonnement spatial qualitatif) sont présentés. Cet article s'appuie sur une démarche expérimentale, basée sur une validation informatique, qui a produit le programme Indigo classé sur l'échelle internationale des programmes de go.
Dans cet article, nous décrivons une méthode efficace d'obtention des classes de mots pour des modèles de langage. Cette méthode emploie un algorithme d'échange qui utilise le critère d'amélioration de la perplexité. Les contributions nouvelles apportées par ce travail concernent l'extension aux trigrammes du critère de perplexité de bigrammes de classes, la description d'une implémentation efficace pour accélérer le processus de regroupement, l'analyse détaillée de la complexité calculatoire, et, finalement, des résultats expérimentaux sur de grands corpus de textes de 1, 4, 39 et 241 millions de mots, incluant des exemples de classes de mots produites, de perplexités de corpus de test comparées aux modèles de langage de mots, et des résultats de reconnaissance de parole.
Dans cet article, nous présentons un réseau adaptatif de microphones avec des contraintes linéaires sur l'adaptation, destiné à la suppression des bruits cohérents et incohérents présents sur le signal de parole. Nous utilisons une structure de type “generalized sidelobe canceller” (GSC) opérant dans le domaine fréquentiel ; cette structure permet d'obtenir séparément la suppression des bruits incohérents par ajustement adaptatif de la réponse dans la direction de visée et la suppression des bruits cohérents par ajustement des filtres adaptatifs du GSC. La fonction de transfert dans la direction de visée est celle d'un filtre de Wiener adaptatif, estimé au moyen de la transformée de Fourier à court terme, suivant la méthode de Nutall-Carter pour l'estimation spectrale. Les résultats expérimentaux montrent que la méthode proposée fonctionne bien dans une large gamme de temps de réverbération, et qu'elle est par conséquent capable d'opérer indépendamment des propriétés de corrélation du champ sonore.
Réaliser une aide visuelle pour l'apprentissage de la parole chez les mal entendants, impose de résoudre des problèmes très variés ayant trait à des domaines aussi différents que la phonétique, la reconnaissance automatique de la parole, la perception et la production de la parole les théories de l'apprentissage, l'ergonomie ou le développement et la programmation de systèmes informatiques. Le succès d'une aide visuelle dépendra de la cohérence de la solution proposée. La première partie de cet article décrit les aspects formels du problème et présente un relevé des diffucultés rencontrées lors des étapes successives de l'éboration du système d'aide. La seconde partie décriot, en tenant compte des remarques formulées antérieurement, le Visual Speech Apparatus lui-même.
Les méthodes de modification décrites ici combinent des caractéristiques des méthodes basées sur le principe PSOLA et des algorithmes pour resynthétiser la parole basés uniquement sur le module de sa transformée de Fourier à court-terme. Le point de départ est une représentation de Fourier à court terme du signal. Pour effectuer des modifications de durée, des portions voisées correspondant à des périodes complètes sont supprimées ou insérées. En ce qui concerne les modifications de fréquence fondamentale, des périodes sont raccourcies ou ralongées et un certain nombre de périodes respectivement supprimées ou insérées. Comme il s'agit d'un outil important pour les modifications de durée et de fréquence fondamentale, la méthode de resynthèse de Griffin et Lim (1984) et Griffin et al. (1984), basée uniquement sur le module de la transformée de Fourier à court terme, est revue et adaptée. Des méthodes de modification de durée et de fréquence fondamentale sont présentées ainsi que leurs résultats.
Lors de la numérisation de la transmission des radiocommunication vocoles, les conditions exigées pour les différentes composantes du système sont assez rigoureuses. En particulier, il faut préter beaucoup d'attention au numérisateur de parole. Le debit binaire applique à la transmission vocale influence essentiellement la largeur des bandes de fréquences utilisées pour les voies de transmission vocale et, de ce fait, l'économie de fréquence réalisée pour le système dans son ensemble. Le débit binaire doit done être aussi faible que possible. De plus, les influences pertubatrices du canal radioélectrique sur l'intelligibilité doivent être compensées par des codages appropries en vue d'assurer une protection contre les erreurs. Ces deux exigences entraînent des structures de codeurs complexes, composées de blocs fonctionnels diférents qui se complètent. La structure ici discutée réunit un algorithme de codage de source optimal donné par la Quantification de Vecteurs (VQ), avec un procédé multi-impulsionnel modifié. Il est montré dans quels eas la VQ est utilisée pour la quantification de différents paramètres. En particulier, on discute l'application de la VQ à des fonctions d'aire divisées en groupes.
Dans cet article nous présentons une revue de certains effets d'écoulement intervenant lors de la production des plosives bilabiales. Comme support pour une analyse ultérieure, nous décrivons tout d'abord un dispositif expérimental destiné à la mesure in vivo. L'ordre de grandeur de paramètres aérodynamiques ou géométriques est alors présenté. Différents modèles théoriques d'écoulement sont ensuite discutés et évalués par rapport aux mesures obtenues sur des maquettes de lèvres ou par simulation numérique.
Cet article s'intéresse à la cartographie automatique des fonds marins en imagerie sonar haute résolution. De nombreuses méthodes d'analyse de textures ont été développées jusqu'à présent, utilisant des approches statistiques, géométriques ou spectrales [14, 45, 7, 44]. Cependant, peu d'entre elles fournissent des attributs caractéristiques robustes vis-à-vis des rotations d'images. Cette propriété est pourtant essentielle dans le cadre de l'étude proposée : elle a pour objectif de faciliter et d'améliorer l'apprentissage du classifieur. Nous présentons dans cet article cinq méthodes de caractérisation, robustes vis-à-vis des rotations d'images. La première méthode est une version étendue de la modélisation AutoRégressive (AR) circulaire initialement proposée par Kashyap et Khotanzad [19], en vue d'en extraire directement un nombre restreint de paramètres caractéristiques significatifs invariants en rotation. Les quatre autres méthodes résultent d'une approche originale qui consiste à appliquer une méthode de traitement d'images à un ensemble de paramètres décrivant une texture, afin de le rendre robuste vis-à-vis des rotations d'images. Les deux premières de ces méthodes consistent à appliquer la Transformation Log-Polaire respectivement aux paramètres issus d'une modélisation autorégressive 2D non- causale et aux paramètres de corrélation associés (nommés paramètres COR). Quant aux deux dernières méthodes, elles consistent en l'application de la méthode des moments de Zernike respectivement à ces deux ensembles de descripteurs. Des résultats de classification expérimentaux obtenus sur images réelles et sur images tournées artificiellement, ainsi que sur des textures issues de l'album de Brodatz, sont fournis pour souligner les performances de chacune des méthodes.
Nous présentons une architecture d'Hidden Control Neural Network (HCNN-CDF) dépendant du contexte pour la reconnaissance de la parole continue, basée sur les phonémes et les mots fonctionnels. Le système peut être considéré comme une large extension du vocabulaire du système HCNN basé sur les mots, proposé par Levin. Initialement, nous avons analysé les principes de modélisation de HCNN sous une forme indépendante du contexte, dans le cadre du système de reconnaissance de la parole Linked Predictive Neural Networks (LPNN) et avons trouvé qu'il aboutit à une augmentation de 6% dans la précision de reconnaissance de la parole à un degré de perplexité 402. Comparé à LPNN, nous avons pu obtenir des réductions significatives dans les exigences de ressources et les charges computationnelles grâce à notre implémentation HCNN. Dans des expériences de reconnaissance dépendant du locuteur, avec un degré de perplexité 111, les versions actuelles des systèmes LPNN et HCNN-CDF obtiennent respectivement une précision de reconnaissance de mots de 60% et 75%.
Entre la fin de la chaine des méthodes de codage de forme d'onde qui s'étend de la PCM linéaire jusqu'au codage adaptif et prédictif (APC) et celle des “vocoders” (en particulier : LPC), il existe un “trou de codage” de 32-2.4 kbit/s. Cet espace définit actuellement le domaine des codeurs à “vitesse moyenne”. Il est démontré, comment leuts faiblesses pourraient étre surmontées par des méthodes prédictives améliorées comme Les idées et les problèmes fondamentaux de la quantification vectorielle (VQ) sont résumés brièvement. Des combinaisons de méthodes VQ et d'autres ainsi que diverses combinaisons sont également discutées.
On sait que l'amplitude de crête négative est en forte corrélation avec le niveau de pression accoustique (SPL) de la parole. Ainsi, la fonction entre d peak et SPL a été conventionnellement modelée en une seule ligne. Dans cette étude, la linéarité de la fonction entre d peak et SPL est reverifiée en analysant les flux glottaux obtenus par filtrage inverse à partir de sons de parole d'une large gamme de différentes intensités. On peut voir que les courbes d peak et SPL sont obtenues de manière bien plus précises en utilisant deux fonctions linéaires, la première pour les modèles de phonation douce, la seconde représentant les sons de parole normale et forte. Pour toutes les courbes d peak et SPL analysées, l'inclinaison de la ligne modelée correspondant aux phonations douces est plus prononcée que celle de la ligne des sons de parole normale et forte. Ce résultat suuggère que l'intensité vocale n'est pas seulement affectée par la valeur du domaine d'amplitude de la source vocale, d peak, mais aussi par la forme du flux glottal différentié à l'approche de la crête négative.
Cet article est consacré à l'emphase particle ou “prominence” de segments de la phrase japonaise. Quatre groupes de 48 phrases lues par deux locuteurs et qui renferment différents types de prominences sont analysés. Cette analyse, qui porte ainsi sur un total de 172 phrases, montre que dans 88% des phrases la “prominence” est générée par l'élévation de F 0 et l'augmentation de l'énergie. Sauf dans certains cas exceptionnels, aucun exemple d'allongement des phonèmes n'a été observé sur les parties prominentes des phrases. Une exception concerne l'allongement accompagné d'une pause insérée comme marque de prominence, une autre concerne le ralentissement du débit global. Les caractéristiques prosodiques du discours lu naturellement sont ensuite utilisées pour élaborer des règles à partir desquelles les phrases de référence seront modifiées afin de générer un effet de prominence pour une synthèse de discours basé sur des règles. D'après les résultats des tests d'écoute sur 10 sujets, la différence d'expressibilité entre une prominence synthétisée par des règl;es (pourcentage d'expressions correctes : 76,9%) et une prominence de discours naturel (79,9%) est non significative. Pour augmenter l'expressibilité de prominence, on utilise des tests d'écoute sur 10 sujets afin de mettre en évidence dans quelles conditions l'expression de prominence est à son niveau optimal. Ces tests ont montré que les paramètres de contrôle prosodique accroissent l'expressibilité d'environ 20%. Finalement, les caractéristiques prosodiques du discours conversationnel spontané sont analysées et comparées à celle du discours de phrases lues. Il apparait que sur les parties qui renferment une prominence, le ralentissement du débit est d'avantage évidente dans le cas d'un discours conversationnel spontané.
La variabilité interlocuteurs dans la coarticulation des voyelles /a,i,u/ a été examinée dans des mots artificiels contenant les consonnes /p,t,k,d,s,m,n,r/. Ces mots ont été lus en isolation par 15 locuteurs néerlandais (m). Les formants F 1–3 (en Barks) ont été extraits de la partie stable de chaque voyelle /a,i,u/. La coarticulation dans chacune des 1200 réalisations des voyelles a été mesurée en F 1–3 en fonction du contexte consonantique, par une mesure statistique, nommée COART. L'effect de coarticulation le plus grand a été trouvé sur /u/ : les consonnes nasales et alvéolaires en position C 1 y ont l'effect le plus grand sur les formants, plus spécifiquement sur F 2. La coarticulation sur /a,u/ s'avère être spécifique du locuteur. Pour ces voyelles, la variabilité par locuteur de la mesure COART était, généralement, la plus grande pour des valeurs de COART plus grandes. Dans le contexte d'une tâche d'identification de locuteurs, COART n'améliore les résultats d'identification que si trois conditions sont combinées : (a) COART est additionné aux mesures des F 1–3 ; (b) les valeurs de COART pour la voyelle sont grandes ; (c) tous les contextes de voyelles sont combinés dans une seule analyse. Les deux conclusions de cette expérience sont que le phénomène de coarticulation ne peut pas être étudié indépendamment de la variabilité interlocuteurs, et que COART peut contribuer à l'identification de locuteurs, mais seulement dans des conditions très restreintes.
Dans cet article, on s'intéresse au problème d'extraction de règles non redondantes sur un fond de sémantique basée sur la fermeture de connexion de Galois. Cette approche présente un fort intérêt pour un système de visualisation de règles. Les résultats des expérimentations menées sur des bases réelles montrent l'utilité de l'approche ainsi que de taux de réduction de la redondance fort intéressants.
Le bruit d'environnement dégrade de façon significative les performances de la plupart des systèmes actuels de reconnaissance automatique de la parole. Cette dégradation provient principalement des différences entre les environnements d'apprentissage et d'utilisation d'un système. Ces dernières années, de nombreux travaux ont porté sur la réduction de ces différences. Une synthèse des résultats de ces recherches est présentée dans cet article, selon trois grandes catégories : les paramétrages résistant au bruit et les mesures de similarité, le débruitage de la parole, et la compensation des modèles en présence de bruit. L'article met en évidence les points essentiels en reconnaissance de parole bruitée, à savoir l'utilisation des corrélations en temps et en fréquence du signal, l'augmentation de l'importance des portions du signal ayant un rapport S/B élevé lors de la décision, la prise en compte de connaissances spécifiques à la tâche sur le signal et sur le bruit, la mise en oeuvre de traitements dépendant des classes d'événements de la parole, et enfin l'utilisation des modèles auditifs.
On propose dans cet article une unité rythmique alternative à la syllabe : le groupe interperceptual-center (GIPC). Ce groupe est délimité par des événements qui peuvent être caractérisés par des corrélats purement acoustiques parallèlement au décodage acoustico-phonétique (Pompino-Marschall, 1989). Les patrons rythmiques du français sont ainsi décrits : la réalisation de l'accent est graduelle au long du groupe accentuel et cet allongement progressif de la durée est nécessaire à la perception.
Dans une série d'expériences d'identification, les effets de phase et d'amplitude sur la perception de consonnes plosives en environnement vocalique ont été étudiés. Pour la première expérience ont été produits, à partir de stimuli VCV (voyelle, consonne, voyelle), trois types de stimuli : (1) les “Swapped” stimuli, qui ont le spectre d'amplitude d'un signal VCV et le spectre de phase d'un autre signal VCV ; (2) les “Phase-only” stimuli ; (3) les “Amplitude-only” stimuli. Les expériences révèlent que la perception de consonnes plosives, en environnement vocalique, passe de la dominance d'amplitude à la dominance de la phase quand la taille de la fenêtre de l'analyse Fourier croı̂t. Le passage de l'une à l'autre apparait pour des longueurs de fenêtres situées entre 192ms et 256ms. Dans la deuxième expérience, on a examiné l'effet de phase pour des tailles de fenêtre plus petites. Cette expérience montre qu'à partir d'un même spectre d'amplitude, mais avec spectres de phase différents, on peut construire différents sons. Donc le spectre d'amplitude obtenu avec une fenêtre d'analyse très petite ne permet pas toujours l'identification d'une consonne plosive. Selon les deux expériences, la perception d'une plosive sonore semble dépendre fortement de l'information de phase, celle du lieu d'articulation semble dépendre surtout de l'information d'amplitude.
On présente un système de transmission de la parole à faible débit (environ 1000 bit/s), fondé sur le principe suivant ; le signal est analysé par prédiction linéaire, et on code séparément pour chaque fenêtre d'une part l'entrée (énergie, pitch, détection voisé/non-voisé), d'autre part les coefficients du filtre. C'est sur ce dernier point que les études ont porte : on a comparé plusieurs espaces de représentation de ces coefficients (autocorrélation, cepstre, avant et aprés préaccentuation) afin de choisir celui qui se prête le mieux à une quantification vectorielle. Celle-ci a été ensuite réalise par un algorithme simple, que nous avons comparé à la méthode “LBG”. Nous montrons que dans les conditions expérimentales décrites, la simplicité de notre algorithme n'est pas pénalisante et qu'il présente de grands avantages pour constituer le dictionnaire de codage. Une seconde partie de l'étude porte sur l'utilisation du dictionnaire ainsi obtenu ; il est calculé sur plusieurs locuteurs, pour un total d'environ 30000 fenêtres de parole (soit environ 6 minutes), et comporte plus de 1500 éléments. Nous avons étudié une technique permettant d'obtenir un codage rapide d'un vecteur inconnu, en perdant l'optimalité du codage par rapport au dictionnaire. Cependant, nous montrons que l'on augmente très peu la distorsion moyenne en utilisant une technique d'accès hiérarchique (obtenue par classification automatique descendante) : ceci permet de coder très rapidement un vecteur inconnu. En conclusion, une méthode simple de construction du dictionnaire (associée à un bon choix de l'espace des vecteurs à quantifier), et une technique d'accès rapide à ce dictionnaire conduisent à un système aux performances peu dégradées par rapport aux références classiques en codage du spectre par quantification vectorielle.
Dans ce papier nous proposons une nouvelle technique de codage dans un espace transformé appelée “Transform Trellis Coded Quantization” (TTCQ). Cette technique se base sur la quantification en codage par treillis proposée récemment où les treillis de modulation d'amplitude d'Ungerboeck et les idées de partition d'ensembles sont utilisés pour effectuer le codage de source.
Le gestionnaire d'appel (`CallManager') de Bellcore est un prototype expérimental de filtrage d'appels et de transfert d'appels ou numéro unique (`follow-me anywhere') qui utilise un gestionnaire de calendrier personnel et un répertoire téléphonique personnel (qui peuvent être accédés à partir de la ligne téléphonique de l'abonné ou de sa ligne radiotéléphonique ou cellulaire) pour déterminer où se trouve l'abonné au moment de l'accès et l'importance de chaque appelant pour l'abonné. C'est un exemple d'une classe future de services centralisés qui utilisent des traitements de la parole avancés et des données spécifiques à l'abonné pour améliorer la valeur du réseau téléphonique auprès des abonnés. De tels services permettent que les appels importants atteignent l'usager tout en filtrant les appels non désirés ou non importants. Ces services peuvent potentiellement donner proactivement des informations à l'abonné `telles qu'elles arrivent' quelque soit l'endroit où l'abonné se trouve.
L'article s'intéresse à la façon dont Jean Lemaire de Belges développe une réflexion sur les enjeux de la pratique poétique et sur le rôle de l'auteur, à une période qui impose de prendre position face à l'héritage médiéval, qu'il s'agisse de celui de la poésie courtoise ou de l'ensemble des connaissances transmises par le Moyen Âge depuis l'Antiquité. Dans les Épîtres de l'Amant vert, le rapport de dépendance qui lie le poète et sa protectrice le porte à aborder le poids de ces traditions sous la forme parodique de l'autodérision. La portée politique et morale des Illustrations de Gaule et singularitez de Troye donne lieu à un questionnement sur la légitimité du discours poétique et de sa rhétorique affectés par leurs attaches avec la thématique amoureuse. La Concorde des deux langages ouvre sur l'hypothèse d'une conciliation possible dans la persona de l'auteur, entre le poète, armé de la séduction de son éloquence, et le lettré soumis aux exigences du « labeur historien » .
Nous décrivons un modèle du processus de codage des mouvements de la membrane basilaire en activité nerveuse dans les fibres du nerf auditif. Le modèle est constitué de deux parties : un modèle unidimensionnel des mouvements de la membrane basilaire et un modèle des récepteurs sensitifs. La première partie est un modèle fonctionnel linéaire qui donne une image électrique des déplacements de la membrane basilaire. La seconde partie est un modèle physique non linéaire qui repose essentiellement sur l'hypothése d'interaction électrique entre les informations issues des deux types de récepteurs sensitifs (cellules celiées). On montre que le modéle est capable de reproduire l'excitation des fibres isolées du nerf auditif en réponse à des stimulations simples (entree mono- et bi-tonale) ou à des déplacements trapézoïdaux de la membrane basilaire. Une deuxième série d'expériences est décrite pour montrer l'intérêt d'un tel modèle dans l'étude du codage des sons complexes. Nous présentons des résultats pour un signal d'entrée de type parole, à un formant, avec une attention toute particulière au codage de la fréquence fondamentale dans les réponses de nos fibres simulées.
Nous présentons dans ce papier une illustration d'une tendance forte du traitement d'image actuel, qui, comptetenu des puissances de calculs disponibles, tend d'une part à privilégier les approches non-paramétriques sur les approches paramétriques, pour proposer des modèles moins contraints, plus souples, plus expressifs et, d'autre part, s'éloignant des descriptions linéarisées, essaie de replacer les objets d'études dans leurs structures géométriques naturelles. Nous montrons comment la géométrisation du problème de l'appariement comme recherche d'un chemin optimal de déformation d'un objet source vers un objet but, permet de lier le problème de l'estimation d'un appariement à celui d'une géodésique dans un espace de formes.
Cet article présente les recherches récentes sur la reconnaissance de la parole aux Laboratoires de NTT (Nippon Telegraph and Telephone Corporation), depuis le traitement acoustique jusqu'au traitement linguistique. Elles comprennent la proposition de paramètres hièrarchiques Δcepstraux et de paramètres ΔLSP, une nouvelle méthode d'utilisation de l'information apportée par la fréquence fondamentale, des techniques d'adaptation automatique au locuteur, de robustes modèles markoviens au niveau du phonème, de nouveaux algorithmes d'apprentissage pour réseaux neuronaux, un traitement linguistique utilisant des connaissances syntactiques et sémantiques, l'implémentation de systèmes prototypes de reconnaissance de la parole continue et un algorithme de reconnaissance du locuteur efficace et indépendant du texte.
Nous présentons une méthode géométrique utilisant l'orientation du gradient pour la détection de la signalisation verticale dans des images fixes, indépendamment de leur position et de leur orientation. La détection est réalisée par une transformation de type accumulateur de Hough bivariée, fondée sur l'utilisation de paires de points avec des contraintes sur leurs gradients. Les panneaux circulaires et polygonaux (non triangulaires) sont détectés par la transformation chinoise bilatérale TCB. Cette transformation est rapide et ne fait pas de distinction entre les cercles et les polygones 4 côtés ou plus. Les performances de la TCB et de la TSB sont estimées sur plusieurs bases d'images de scènes urbaines.
La plate-forme utilise simultanément un ensemble de méthodes de visualisation et d'apprentissage automatique permettant de découvrir de manière intuitive, interactive et rétroactive des connaissances. La tâche de fouille est exprimée sous la forme d'un flot graphique de données où une méthode est représentée par un composant graphique de JavaBeans, la communication entre les méthodes se base sur un bus de données. L'utilisateur peut créer et contrôler totalement le processus d'extraction de connaissances sans aucune programmation. Notre plate-forme de programmation visuelle permet d'une part de réduire la complexité d'une tâche de fouille de données et, d'autre part, d'améliorer la qualité et la compréhensibilité des résultats obtenus.
Ce papier décrit une méthode à base de règles, guidée par les données, qui est destinée à modéliser les variations de prononciation en reconnaissance automatique de la parole (RAP). Les différentes phases de cette méthode guidée par les données sont les suivantes. Premièrement, les éventuelles variantes de prononciation sont générées en considérant que chaque phone de la transcription canonique peut être omis. Ensuite, nous effectuons une reconnaissance forcée afin de déterminer quelle variante correspond la mieux au signal acoustique. Enfin, les régles sont dérivées en alignant la meilleure variante avec la transcription canonique qui lui correspond. Une analyse des erreurs commises est effectuée afin de mieux comprendre le processus de modèlisation de prononciation. Cette analyse montre que, bien que cette modélisation apporte des améliorations, elle introduit également des détériations. Une forte corrélation entre le nombre d'améliorations et le nombre de détériations par régle a été trouveé. Ce résultat indique qu'il n'est pas possible d'améliorer les performances de la RAP en élimant les règles qui détériorent la reconnaissance pour certains candidats, étant donné que ces mêmes règles améliorent la reconnaissance de beaucoup d'autres candidats. Enfin, nous avons comparé trois critères visant à sélectionner les meilleures règles. La “fréquence absolute d'application d'une règle (F abs)” est apparue comme le meilleur critère. Pour la meilleure condition de test, nous avons obtenu une réduction du taux d'erreur par mot statistiquement significative de 1.4% (taux absolu) ou de 8% (taux relatif).
Les Contemplations sur les sept heures de la Passion, rédigées par Jean Miélot en 1454 pour Philippe le Bon, duc de Bourgogne, sont conservées dans un manuscrit unique (Paris, BnF, fr. 12441) ; la source principale de Miélot est la Meditatio de passione Christi per septem diei horas d'un auteur anonyme. La comparaison du texte français et de sa source permet de reconnaître les modifications que Miélot a introduites en adaptant son modèle pour un lecteur laïc.
Nous présentons, dans cet article, la conception et le développement du workbench MATE, un programme pour l'annotation de la parole et des textes écrits. Il facilite la visualisation et l'édition flexibles de telles annotations, et permet des requêtes complexes sur un corpus résultant. Le workbench offre une approche plus souple que la plupart des outils d'annotation, qui ont souvent été conçus pour un jeu d'étiquettes spécifique. Le workbench MATE permet le traitement de tout jeu d'étiquettes pourvu que ce dernier puisse s'exprimer en format XML (rattaché au signal vocal, si disponible, en utilisant certaines conventions). Le workbench utilise un langage de transformation pour définir les éditeurs spécialisés qui sont optimalisés pour des tâches d'annotation particulières avec des visualisations appropriées et des actions permises conçues en fonction de la tâche. Le workbench est écrit dans le langage Java, ce qui le permet d'être indépendant de la plateforme. Cet article décrit l'architecture du logiciel du workbench et le compare à d'autres outils d'annotation.
Une experience en deux parties sur les mouvements de protrusion de la lèvre inférieure pour la voyelle [u] a été menée afin d'étudier : (1) la production de 'creux' (diminution de la protrusion labiale devant la consome intervocalique dans des énoncés [uCu] ; (2) la fixation temporelle (début de mouvement à un intervalle fixe avant le début du voisement de [u] quel que soit le nombre de consonnes neutres dans des énoncés [Vnon arrondieC n u]). Deux locuteurs français, un locuteur espagnol et deux locuteurs anglais ont produit des ensembles similaires d'énoncés dépourvus de sens. Un bloc dentaire a été utilisé pour éliminer les mouvements mandibulaires, sources des mouvements de la lèvre inférieure. Un examen détaillé a été conduit sur les relations etre les données à la fois sur le plan du mouvement et sur celui du signal pour tous les énoncés-tests. Les résultats suggérent que la production des creux peut être due partiellement à des cibles articulatoires spécifiques pour les consonnes intervocaliques [s] et [t]. Des cibles consonantiques spécifiques empêchent l'investigation directe de la fixation temporelle. Des limitations expérimentales préviennent des conclusions fermes mais la nature des résultats suggère qu'un ensemble de facteurs, incluant la coproduction des segments adjacents et des ajustements de cibles articulatoires dépendant du contexte, peuvent sous-tendre les variations observées dans le comportement articulatoire.
Cet article rend compte d'une série d'études sur quelques traits phonétiques de l'anglais américain représentés dans la base de données TIMIT. D'abord nous décrivons certaines caractéristiques pertinentes de TIMIT, et comment nous utilisons les fichiers d'étiquetage du CD TIMIT avec une base de données commerciale. Puis, nous décrivons deux études : l'une n'utilise que les informations non-audio de TIMIT (les transcriptions et durées segmentales et l'information sur les locuteurs), l'autre utilise le signal audio pour une analyse acoustique. Les résultats de ce type d'étude sont utiles non seulement pour la phonétique linguistique mais aussi pour l'élaboration de lexiques pour la reconnaissance de la parole et la synthèse à partir du texte des systèmes de traduction texte-parole.
Nous présentons dans cet article un système de reconnaissance de caractères multifontes utilisant plusieurs classifieurs. Chaque classifieur fournit une réponse puis le résultat final est obtenu par vote majoritaire. Les classifieurs sont de deux types : stochastique et plus proche voisin. Les classifieurs stochastiques sont des modèles de Markov cachés du premier et du second ordre. La reconnaissance des caractères est suivie d'un module de vérification lexicale qui utilise un modèle de Markov caché pour les mots dont les paramètres sont déterminés à partir de statistiques sur la langue et d'un dictionnaire.
Dans cet exposé sur la modification de la structure temporelle du signal de parole, nous opterons pour l'utilisation des représentations temps–fréquence du signal, plutôt que pour des représentations par modèles. Nous examinerons une méthode itérative permettant de reconstruire une fonction de phase pour spectrogrammes d'amplitude modifiés. La recherche d'une bonne condition initiale pour démarrer l'itération nous ammènera aux méthodes de recouvrement-addition synchronisées et notamment à WSOLA, une technique basée sur un critère de ressemblance entre formes d'ondes.
Les émotions complexes dans des contextes réels ont encore été peu étudiées. Dans ce papier, nous explorons comment représenter et automatiquement détecter le comportement émotionnel de sujets dans le contexte d'interactions orales Homme-Homme. Par rapport aux nombreuses études précédentes conduites sur des données artificielles, ce papier montre les défis auxquels on doit faire face lorsqu'on étudie des émotions non basiques présentes dans des données réelles. Des dialogues enregistrés dans des centres d'appels ont révélé la présence de nombreuses émotions mixtes. Un vecteur d'émotions pondérées sert à représenter les émotions. Cette représentation permet d'obtenir une annotation plus fiable et de sélectionner la partie du corpus sans émotions mixtes conflictuelles pour l'apprentissage des modèles. Un taux de détection correcte de 80 % entre émotions Négative et Neutre a été obtenu avec des modèles SVMs et des arbres de décision, en utilisant des indices paralinguistiques sur un corpus de 20 heures enregistrées dans un centre d'appel médical.
Cet article décrit une méthode de gestion de pare-feux à partir de mise en œuvre de règles. On analyse d'abord l'architecture de réseautique à base de règles (pbn) proposée par le groupe « Policy Framework » de l'ietf qui comporte des protocoles de communication, des langages de spécification de politique et la modélisation de l'information nécessaire. On présente ensuite un état de l'art de l'application des langages de spécification de règles à l'architecturepbn en détaillant particulièrement la spécification des règles de sécurité avec le langagespsl. Le protocolecops et sa variantecops-pr utilisés pour transporter l'information sur les règles sont également présentés. La dernière partie de l'article est consacrée à l'application de l'architecturepbn à la gestion de pare-feux. L'architecture proposée est alors analysée au travers de quelques exemples. L'article se conclut en évaluant l'approche à base de règles dans la gestion des pare-feux.
Pour améliorer la perception des consonnes, on propose dans cet article une technique de traitement de la parole qui amplifie certaines parties du signal contenant une forte concentration d'indices acoustiques responsables de contrastes phonémiques. La deuxième série de tests porte des phrases dépourvues de sens et traitées de la même façon. Les énoncés (mots et phrases) ont été présentés aux sujets avec du bruit de fond. Ces résultats montrent qu'il est avantageux d'exploiter la connaissance des indices acoustiques dans le développement de techniques de traitement de la parole visant à améliorer la perception de la parole dans le bruit.
Cette étude met en lumière un trope de la littérature apocalyptique musulmane resté jusque-là négligé, selon lequel, dans une région connue sous le nom d'al-Ṭālaqān, un grand trésor attendrait le futur Mahdī, trésor grâce auquel il s'assurerait une armée puissante qui l'aiderait à mener la bataille finale contre le Mal. En faisant remonter ce trope à l'apocalyptisme zoroastrien et à sa dissémination ultérieure dans un large éventail de traditions apocalyptiques musulmanes, cet article soutient que ce trope apocalyptique fut finalement intégré au sein de l'apocalyptisme musulman, en particulier dans sa variante chiite, au cours d'une révolte zaydite menée par le Ḥasanide Yaḥyā b. ʿAbd Allāh contre les Abbassides en 176/792. Nous explorons alors comment ladite révolte forgea la fonction du trope des « trésors d'al-Ṭālaqān » dans l'apocalyptisme musulman et comment la personnalité de Yaḥyā ainsi que la révolte qu'il inspira laissèrent une empreinte indélébile sur l'apocalyptisme imamite par la suite.
Le développement des objets datifs chez les enfants apprenant l'hébreu a été étudié. Un grand corpus constitué des informations présentes dans le discours maternel a été examiné, et la catégorie du verbe datif s'est révélée extrêmement bancale par sa fréquence et variée du point de vue sémantique. A travers l'analyse de 30 observations longitudinales le développement des enfants a été exploré. Les tout premiers verbes produits avec un complément au datif étaient en effet des verbes noyaux. La facilitation sémantique a démontré un apprentissage fondé sur le transfert. Les effets de fréquence d'entrée des données et leur caractère obligatoire étaient beaucoup plus faibles pour la deuxième vague de verbes appris. Les résultats montrent que deux processus ordonnés de façon séquentielle interviennent dans le développement d'une catégorie syntaxique qui recrée immédiatement sa structure : l'établissement du noyau et l'apprentissage- transfert de la périphérie basé sur la similarité.
Dans de nombreuses applications, où les données X E A3 à analyser représentent des objets auxquels sont affectés aléatoirement des labels binaires Y E {-1, +1}, l'enjeu de l'apprentissage statistique ne se borne pas à déterminer comment affecter le label le plus probable à un objet donné mais consiste à ranger l'ensemble des objets x E A dans le même ordre que celui induit par la probabilité a posteriori y (x) = P {Y = +1 | X = x}, les règles d'ordonnancement étant évaluées à l'aune de la courbe COR. Contrairement à la plupart des approches utilisées en pratique, reposant sur une estimation préalable de la fonction y (x), les résultats récents décrits dans cet article permettent d'étendre la notion d'arbre de décision au problème de l'ordonnancement statistique et d'ajuster/combiner des règles de ce type de façon à optimiser la courbe COR directement.
Combinant les propriétés de la théorie des probabilités et de la théorie des graphes, les réseaux bayésiens ont acquis une popularité certaine durant la dernière décennie. La détermination de la structure d'un modèle à partir d'une base de cas demeure cependant un problème délicat. Nous avons développé un algorithme génétique déterminant une structure tout en s'affranchissant des limitations fréquemment imposées (nombre limité de parents par variable, connaissance d'un ordre total sur les variables). L'algorithme parcourt l'espace des graphes orientés sans circuit et repère un ensemble d'op- tima locaux pour renvoyer le meilleur optimum local trouvé.
Cet article présente une nouvelle approche de l'analyse et de la synthèse paramétriques de la parole basée sur l'élaboration d'un modèle du résidu du filtre inverse de la prédiction linéaire dans le domaine fréquentiel. Ce modèle fait intervenir la recherche d'une structure harmonique et de la période fondamentale, l'analyse en sous-bandes du signal pour la détermination de « proportions de voisement » de sorte à rendre la décision voisé-non voisé progressive et fonction de la fréquence. Cette représentation paramétrique du signal résiduel est associée aux paramètres LPC habituels pour la transmission ou la mémorisation. Le système ainsi créé présente la souplesse des systèmes paramétriques et est bien adapté aux problèmes de connexion entre trames intervenant dans les applications de synthèse à partir du texte.
Dans cet article, on décrit et on analyse des algorithmes pour la téléphonie mains-libres, qui utilisent un annuleur d'écho acoustique combiné avec un filtre RIF complémentaire dans la voie d'émission. Nous décrivons deux méthodes différentes pour adapter le filtre complémentaire (appelé “filtre de mise en forme de l'écho”) ; ces deux méthodes sont très efficaces et faciles à mettre en oeuvre. Nous montrons que les algorithmes proposés permettent de réduire significativement l'ordre de l'annuleur d'écho tout en apportant une atténuation élevée de l'écho et une faible distorsion de la parole locale pendant les phases de double parole.
Cet article présente les enjeux de l'ingénierie des connaissances dans le domaine des sciences du vivant et, à titre d'illustration, un système d'intégration de données thématiques ouvert sur le web, appelé ONDINE (Ontology based Data INtEgration). Ce système propose un processus complet d'acquisition, d'annotation sémantique et d'interrogation de données à partir de tableaux trouvés dans des documents scientifiques issus du web. Nous présentons le modèle de la RTO, la méthode d'annotation semi-automatique de tableaux de données guidée par cette RTO, puis le logiciel @Web (Annotating Tables from the Web) d'annotation sémantique de tableaux.
SIGNAL est un langage en cours de définition à l'IRISA dans le cadre d'un projet d'aide à l'implantation d'algorithmes en traitement temps réel du signal. Les caractéristiques générales du langage sont inspirées des principes flots de données ; un programme SIGNAL décrit un réseau de processus (opérateurs arithmétiques ou temporels) interconnectés à travers des ports orientés, sur lesquels circulent des signaux. Ces réseaux sont construits progressivement à l'aide d'opérations permettant d'établir des liaisons entre les ports. SIGNAL permet la description et l'exécution de tout algorithme temps réel synchrone mettant en œuvre éventuellement plusieurs horloges pour rythmer différents signaux. La présentation est illustrée par la description d'un algorithme de prédiction linéaire en treillis.
Dans un témoignage unique, Apollonius Dyscole soutient que certains mots simples seraient formés à partir de mots composés privatifs, par suppression de l'ἀ privatif (ἀέκητι → ἕκητι). L'examen de ce procédé par Apollonius s'avère paradoxal. En effet, le grammairien assimile cette formation à un pathos (une altération formelle) ; or une forme altérée, de l'aveu même d'Apollonius, doit toujours garder le sens de la forme de base, tandis qu'un mot simple signifie forcément le contraire de son composé privatif. Cet article vise à montrer ce que cette position inattendue d'Apollonius, qui remet en cause le principe même de la pathologie, nous apprend du statut particulier du composé privatif et de sa place dans la théorie grammaticale ancienne.
La plupart d'entre eux ne fonctionnent bien que lorsque les séquences de parole de référence et de test sont enregistrées dans des conditions identiques d'ambiance non bruyante. Le but de cette étude est de développer un système de vérification du locuteur basé sur un modèle de prédiction linéaire orthogonal, suivant une approche approche et n'utilisant qu'un jeu de paramètres de référence sans se préoccuper de savoir si le signal à tester est de haute qualité ou bruité. Des seuils sont ensuite calculés pour déterminer les paramètres orthogonaux à prendre en compte dans le calcul de la distance et l'ordre du modèle pour un rapport S/B donné.
Notre travail a eu pour but d'étudier les effets de longuer de registre fini dans un système de reconnaissance de la parole par modèle caché de Markov (HMM). Un modèle statistique a été employé pour la distribution approximative des différences entre des scores. L'étendue des erreurs de reconnaissance attribuables à des erreurs de quantification des paramèters du HMM a été calculée au moyen de ce modèle statistique. La relation entre le taux de reconnaissance et l'erreur de quantification est ensuite calculée. Ceci détermine la longueur de registre nécessaire pour la réalisation matérielle du système de reconnaissance par HMM.
Dans cet article nous présentons un nouveau système de reconnaissance de textes manuscrits scripts en mode omni-scripteur. Ce système utilise un lexique français de très grande taille (200 000 mots), qui couvre de nombreux champs d'application. Le processus de reconnaissance repose sur le modèle d'activation- vérification proposé en psychologie perceptive. Un ensemble d'experts code le signal d'entrée et extrait des informations probabilistes à différents niveaux d'abstraction (géométrique, morphologique). Nous avons expérimenté plusieurs stratégies d'adaptation non supervisée au scripteur. La meilleure, appelée « adaptation non-supervisée dynamique » agit en continu sur les paramètres du système. Elle permet d'atteindre des performances proches de l'une adaptation supervisée. Les performances, évaluées sur une base de données comportant 90 textes (5400 mots) écrits par 38 utilisateurs différents, sont très encourageantes car elles atteignent un taux de reconnaissance de 90%.
Ce papier décrit les résultats récents en modélisation de l'onde glottique pour la synthèse de parole. Nous décrivons plus spécifiquement deux méthodes de modélisation de l'onde glottique, que nous appliquons á des problèmes de conversion de voix. Un des modèles utilise une modélisation polynomiale (pour modéliser la dérivée de l'onde de débit à l'intérieur d'une période fondamentale). Les coefficients de ce polynome forment un vecteur qui est ensuite utilisé pour apprendre un dictionnaire de formes de références d'excitation glottiques, comprenant 32 entrées (pour les segments voisés). Ce dictionnaire est appris sur deux phrases, prononcées par des locuteurs différents. L'excitation dans les segments non-voisés est représentée à l'aide d'un dictionnaire de formes d'onde de bruit comprenant 256 références. Nous décrivons dans cette contribution les techniques d'analyse pour apprendre les deux dictionnaires. Le synthétiseur GELP permet d'obtenir une très bonne qualité de parole. Elle permet au chercheur de disposer d'un système simple, aux qualités et aux défauts universellement reconnus, capables de reproduire tous les sons du signal de parole, et disposant d'une excitation paramétrique directement reliée á la dérivée de l'onde de débit glottique et à l'intégrale du résidu de prédiction. Nous proposons aussi une autre approche fondée sur l'utilisation du modèle de Liljencrants-Fant (LF) d'onde glottique pour modéliser les caractéristiques de différents modes de phonation (tendu, chuchotté,…). Nous proposons de transformer le mode de phonation en utilisant le synthétiseur GELP, en altérant l'onde de débit glottique sans modifier les caractéristiques du filtre de synthèse.
L'authentification automatique du locuteur a été le sujet d'actives recherches durant de nombreuses années, et malgrés ces efforts et des résultats prometteurs en laboratoire, le niveau de performance sur le réseau téléphonique reste inférieur au niveau requis pour de nombreuses applications. L'étude expérimentale, dont les principaux résultats sont présentés dans cette article, avait pour objectif de quantifier en dehors de toute application l'influence de facteurs plus ou moins reconnus pour leur effet sur les performances des systèmes d'authentification du locuteur. Les questions addressées sont : le choix du modèle (mélange de gaussiennes ou modèle phonétique) ; la connaissance ou non du texte prononcé par le locuteur ; l'importance de la quantité et de la nature des données d'apprentissage et d'authentification, en particulier l'influence du contenu linguistique des énoncés sur le niveau de performance pour des textes lus et de la parole spontanée ; la dégradation des résultats due au vieillisssement des modèles et la manière de le compenser avec des techniques d'adaptation. Les résultats experimentaux ont été obtenus sur un corpus téléphonique conçu et enregistré pour cette étude qui comprend plus de 250 heures de parole pour un total de 100 locuteurs abonnés et 1000 imposteurs. Sur ces données le taux d'égale erreur est de l'ordre de 1% dans le mode dépendant du texte lorsque deux essais sont autorisés par tentative d'authentification avec une durée minimale de 1,5 s par essai.
Les réseaux bayésiens de modélisation de la croyance constituent un outil efficace pour combiner différentes sources d'information ayant différents degrés d'incertitude. Ils sont rigoureux mathématiquement et peuvent être implémentés de façon efficace. Ils sont malheureusement peu utilisés en traitement de la parole. Cet article montre comment ils peuvent être appliqués à ce domaine. Nous donnons aussi un algorithme, inspiré de l'algorithme EM, qui permet l'apprentissage de matrices de liens à partir d'exemples. A l'aide de ces extensions, nous construisons un modèle de langage à base “context-free” pour la reconnaissance de la parole, dans lequel les phrases sont analysées localement, en segments judicieusement choisis, au lieu d'être analysées dans leur totalité. Ce modèle a été évalué sur une base de données textuelles. Sa performance, mesurée par l'entropie de l'ensemble de test, est au minimum égale à celle des modèles bi-ou tri-grammes ; nous avons aussi constaté une bonne capacité de généralisation des données d'apprentissage vers les données de test.
Nous proposons dans cet article une approche de fusion probabiliste reposant sur des critères entropiques dont le but est de réduire l'espace de combinaison en représentant explicitement les notions de redondance et de complémentarité des sources d'information. Ce type de modélisation est en particulier intéressant pour optimiser le choix des mesures, issues des sources d'information, à combiner dans un système de fusion. Il est en accord avec le souci de rapidité de traitement et de minimisation des ressources matérielles qui se pose en fusion d'informations. Pour repondre à cela, nous avons réalisé une étude de la parallélisation de l'algorithme de fusion entropique développé en vue de son implantation parallèle dans le cadre d'une application en robotique mobile. La spécification de l'algorithme faisant apparaître du parallélisme potentiel est ensuite implantée sur un réseau de stations de travail fonctionnant en mode MIMD-NORMA à l'aide des environnements de programmation SynDEx, qui supporte la méthodologie AA-A, et PVM, qui est de type CSP de Hoare.
Inspirés par des observations neurobiologiques et psychoacoustiques, nous avons construit un réseau de neurones pour la reconnaissance de mots isolés. Un prétraitement du signal de parole biologiquement motivé transforme la fréquence en bandes critiques et la puissance en sonie, contraste les spectrogrammes et extrait les indices temporels et spectraux. Nous montrons que les différentes étapes du prétraitement augmentent le taux de reconnaissance d'une manière significative et sont essentielles pour réaliser une reconnaissance sans erreurs d'un petit vocabulaire. De plus, le réseau est capable, sans aucune modification de l'architecture du système, de reconnaître des mots prononcés simultanément. Ceci représente une nouvelle approche pour résoudre l'un des problèmes les plus difficiles, celui de la séparation du signal de parole du fond sans utiliser des techniques conventionnelles telles la séparation directionelle de la parole enregistrée en stéréophonie ou le suivi de la fréquence fondamentale.
Dans ce papier, nous présentons la problématique de la reconnaissance d'images détériorées et plus particulièrement l'étape de sélection de primitives au sein d'un traitement de classification supervisée. Cette étape de sélection a lieu après que la segmentation et l'extraction des descripteurs statistiques sur des images documentaires aient été réalisées. Nous exposons en détail l'utilisation d'un arbre de décision, afin de l'harmoniser puis la comparer avec une approche moins étudiée utilisant un treillis de Galois.
Cet article décrit l'approche d'IBM pour la transcription des nouvelles du journal télévisé. Les problèmes caractéristiques de cette tâche sont la segmentation, la classification automatique, la modélisation acoustique, l'estimation de modèles de langage et l'adaptation des modèles acoustiques. Cet article présente de nouveaux algorithmes pour chacun de ces problèmes. Parmi les idées clés, on peut citer le critère d'information Bayesien (pour la segmentation, la classification automatique et la modélisation acoustique) et l'apprentissage adapté pour chaque locuteur/classe de locuteurs.
On a enseigné à des enfants aphasiques ayant des déficits de langage sérieux, à communiquer par l'intermédiare du système de symboles visuels mis au point par D. Premack pour les chimpanzés. Les sujets, qui ne possedaient pas de langage normal, ont rapidement pu de cette façon exprimer plusieurs fonctions du langage (mot, phrase, concept de classe, intérrogation, négation). On peut s'intérroger sur le statut linguistique du 'système Premack' dont on se rend sans doute mieux compte comme d'un système de communication. En conséquence, il est possible alors de penser que les enfants aphasiques manquent d'une capacité spécifiquement linguistique.
Dans cet article, nous appliquons une méthode générale d'apprentissage par renforcement pour la mise au point automatique de comportements de personnages non joueurs d'un jeu vidéo de tir à la première personne, Counter-Strike©. Le résultat de l'apprentissage est un ensemble d'arbres de décision représentant de façon lisible un modèle du problème et la politique de décision des personnages. Enfin, nous discutons de la portée de notre méthode pour la réalisation d'architectures de décision pour les personnages non joueurs de jeux vidéo.
Quand il rencontre un “mot inconnu”, c'est-à-dire absent de son répertoire, un système traditionnel de synthèse de parole à partir du texte active des règles de transcription orthographigue-phonétiques contextuelles pour produire une prononciation. Une hypothese proposée par les sciences psychologiques est que le locuteur humain prononce les mots inconnus sans utiliser de règles explicites, mais plutôt par analogie avec des correspondances lettres-phonèmes dans des mots qu'ils connaît déjà. Dans cet article, on présente un système de synthèse par analogie, qui est donc également un modèle de la prononciation des mots inconnus par un locuteur humain. L'usage de l'analogie est proposé aussi bien au niveau orthographique que phonétique, et s'applique ici à la prononciation de mots inconnus en Anglais et en Allemand. Le développement du système a permis de rencontrer certains points de détail auxquels la théorie de l'analogie ne s'est pas révélée pour le moment capable de répondre. C'est pourquoi une grande partie de ce travail traite des conséquences des choix d'implémentation sur les performances, c'est-à-dire la capacité du système à produire des prononciations conformes à celles données par les humains. Il faut aussi prendre en compte la taille et le contenu de la base de donnée lexicale sur laquelle tout système par analogie doit s'appuyer. Les meilleures des implémentations ont fourni des résultats utiles pour les deux langues citées. Mais les meilleurs résultats ont été obtenu pour chaque langue avec des implémentations assez différentes.
Dans cet article, nous analysons la possibilité de réduire le nombre de niveaux de lissage d'un filtre LUM (lower-upper-middle) adaptatif 3-D basé sur un contrôle par seuils fixes (FTC = fixed threshold control). Outre son excellente capacité d'atténuation du bruit tout en assurant la conservation des détails, le filtre LUM FTC avec une fenêtre de taille N, est caractérisé par une structure relativement complexe, où l'estimation de la valeur de sortie est faite en fonction de (N + 1)/2 règles de décision. Ceci peut entraver l'implémentation matérielle de tels filtres dans des applications vidéo temps réel. Afin de simplifier la complexité du filtre tout en gardant ses excellentes performances, nous proposons deux approches qui sont la réduction linéaire du nombre de niveaux de lissage et la réduction optimale basée sur un algorithme génétique.
Bien que la plupart des paramètres dans un système de reconnaissance de la parole soient estimés à partie des données en utilisant une fonction objective, l'inventaire des unités acoustiques et le lexique sont généralement créés à la main, et donc susceptibles de ne pas être optimeux. Cette étude propose une solution conjointe aux problèmes interdépendants que sont l'apprentissage à partir des données d'un inventaire des unités acoustiques et du lexique correspondant. Nous avons testé l'algorithme proposé sur des échantillons lus, en reconnaissance indépendantes du locuteur avec un vocabulaire de 1k : il surpassé les systèmes phonétiques en faible ou forte complexité.
Nous proposons une nouvelle méthode formulée au niveau région pour la segmentation texturale d'images sonar haute résolution. Nous caractérisons les différents types de fonds marins par des descripteurs de texture sous forme de distributions de leurs réponses à un ensemble de filtres, estimées sur la globalité des régions et nous définissons une nouvelle mesure de similarité adaptée à la discrimination entre fonds marins dans l'espace de ces descripteurs. Notre mesure de similarité est une somme doublement pondérée de divergences de Kullback-Leibler entre les descripteurs de textures : la première pondération permet la sélection des filtres les plus pertinents pour la discrimination entre textures et la deuxième pondération est angulaire et elle permet de tenir compte de la variation des descripteurs de texture en fonction des angles d'incidence. Le premier est un terme qui évalue l'homogénéité des régions selon la mesure de similarité pondérée entre les statistiques estimées sur les différentes régions de l'image et les prototypes relatifs aux différents types de fonds marins. Le deuxième terme contraint la régularité des frontières entre régions. La minimisation de la fonctionnelle est effectuée par descente du gradient et exploite les outils de dérivation de forme et la méthode est implantée selon la technique des ensembles de niveaux.
Un modèle de Markov caché (HMM) à maximum de vraisemblance pour la reconnaissance de mots isolés peut être traité comme un réseau neuronal récurrent. Les unités dans la boucle de récurrence sont linéaires mais les observations entrent dans la boucle via une multiplication. L'apprentissage peut utiliser la rétro-propagation des dérivées partielles pour maximiser une mesure de la discrimination entre les mots. La rétro-propagation a exactement la même forme que la 'Backward Pass' de l'algorithme de Baum-Welch (EM) pour l'apprentissage des HMM à maximum de vraisemblance. Il est intéressant d'observer que l'utilisation d'un critère particulier d'erreur basé sur l'entropie relative (équivalent au critère d'information mutuelle utilisé pour l'apprentissage discriminant des HMM) peut mener à des dérivées qui sont liées aux réestimations selon l'algorithme de Baum-Welch et à l'apprentissage correctif.
Nous proposons une méthode morphologique de segmentation d'images couleur de cytologie. Cette méthode est basée sur la ligne de partage des eaux utilisant une fonction de potentiel couleur combinant informations locale et globale. Cette méthode de segmentation utilise des informations a priori pour élaborer l'utilisation de la méthode. L'article s'articule autour de trois parties. Dans une première partie, nous rappellerons tout d'abord la structure d'une segmentation morphologique couleur. Dans une dernière partie nous verrons une illustration de la méthode de segmentation sur des images de la cytologie des séreuses.
Le domaine d'application du système de reconnaissance de parole et de dialogue EVAR est celui des renseignements sur les horaires de train. Nous avons constaté que dans les dialogues réels de personne à personne, la personne qui cherche une information interrompt souvent l'agent lorsque celui-ci communique l'information. La plupart de ces interruptions sont des répétitions des horaires indiqués par l'agent. Le rôle fonctionnel de ces interruptions n'est souvent déterminé que par des indices prosodiques. Un résultat essentiel des expériences réalisées avec des personnes naïves est qu'il leur est difficile de suivre les informations horaires données par EVAR lorsque celles-ci sont délivrées en synthèse de parole. Il est alors encore plus important que l'usager puisse intervenir lors de la réponse. Nous avons donc élargi le module de dialogue pour donner à l'usager la possibilité de répéter les horaires et nous avons ajouté un module prosodique qui commande la poursuite du dialogue en analysant l'intonation de cet énoncé de l'usager.
Les modèles markoviens (HMM) sont devenus l'approche prédominante dans les systèmes de reconnaissance de la parole. SPHINX est un exemple d'un tel système ; développé à CMU, il offre les caractéristiques suivantes : vaste vocabulaire, indépendance du locuteur et parole continue. Dans cet article, nous présentons les techniques de modélisation des HMM, nous analysons les raisons de leurs succès et nous décrivons quelques améliorations par rapport aux HMM standards utilisés dans SPHINX.
Nous avons analysé des phrases produites spontanément au cours d'interviews semi-standardisées par dix patients souffrant d'une démence sénile modérée de type Alzheimer, cinq aphasiques de Wernicke et cinq sujets contrôles âgés mais sans atteinte cérébrale. L'analyse a révélé chez les deux groupes de patients une réduction de la longueur des phrases, mais l'absence de symptomes paragrammaticaux systématiques chez les déments séniles. Dans les productions des deux types de patients, l'usage des noms était dénoncée de façon relativement sélective, alors que la capacité de trouver les mots était étonnamment préservée chez les Alzheimer. Les deux groupes ont montré des déficits marqués, mais des comportements pathologiques différents, dans leurs réponses aux questions de l'examinateur. Les résultats sont interprétés dans le cadre d'un modèle neurolinguistique de production du langage. Nous pensons que le processus de formulation peut être préservé chez les déments séniles, mais qu'il est atteint dans l'aphasie. Les désordres du langage observés chez les déments séniles résulteraient de troubles pré-linguistiques dans la formation de la structure conceptuelle de l'acte de parole.
Les modèles articulatoires de la production de la parole sont, en général, contrôles par des paramètres cinématiques qui gouvernent les positions et les mouvements des tissues et de l'air. Nous presentons afin de complèter cette approche un modèle de la glotte à quatre paramètres d'un type similaire. Les paramètres sont des quotients sans dimension qui contrôlent la forme statique et dynamique de la glotte. Le modèle peut simuler simultanément avec les mêmes paramétres, la vitesse volumique, l'aire glottique et la surface de contact entre les cordes vocales. Les propriétés de ces formes d'ondes sont diccutées en termes de configuration glottique sous-jacente à leur production. En particulier, une description détaillée de la forme d'onde de la surface de contact est donnée. Le modéle est destiné à être appliqué à l'imagerie du mouvement des cordes vocales reposant sur des signaux captés de maniére non invasive à la surface du corps. Dans le contexte de la synthèse, le modèle constitute une alternative à la modélisation du bébit parce qu'il inclut l'interaction entre la source et le conduit sans réclamer beaucoup plus de calcul.
Les psycholinguistes s'efforcent de construire un modèle du traitement de langage humain en général. Mais ceci n'implique pas qu'ils doivent limiter leurs recherches aux aspects universels de la structure linguistique et éviter les recherches sur les phénomènes spécifiques à telle ou telle langue. Tout d'abord, mêmes les caractéristiques universelles de la structure du langage ne peuvent être observées de façon précise qu'en étudiant plusieurs langues. Ce point est illustré dans cet article par des travaux sur le rôle de la syllabe dans la reconnaissance de mots parlés, sur le traitement perceptif des voyelles par rapport aux consonnes et sur la contribution des phénomènes d'assimilation phonétique à l'identification des phonèmes. Dans chaque cas, ce n'est qu'en étudiant les phénomènes de façon comparative entre les langues que l'on peut en comprendre le principe général. D'autre part, les traitements spécifiques à chaque langue peuvent certainement aider à identifier un modèle universel de la compréhension du langage. On illustre ici ce second point par des études sur l'exploitation de l'harmonie vocalique dans le segmentation lexicale en Finois, sur la reconnaissance de mots en Néerlandais avec et sans épenthèse et sur la contribution des différents types de structure prosodique lexicale (ton, accent intonatif, accent lexical) à 1'activation initiale des mots candidats dans l'accès au lexique. Dans chaque cas, les aspects du modèle universel de traitement sont révélés par l'analyse d'effets spécifiques à chaque langue. En résumé, l'étude du traitement du langage parlé par l'être humain requiert des comparaisons inter-langues.
Cette recherche a évalué deux explications alternatives des déficits de la compréhension syntaxique chez les aphasiques agrammatiques : l'explication par une perte syntaxique (Grodzinsky 1986) et l'hypothèse d'une déterioration de la mémoire de travail (Kolk et van Grunsven 1985). Quatre patients aphasiques présentant différentes formes de déterioration morphologique et structurelle de la production ont été examinés. Des tâchcs de compréhension ont comparé la performance sur des phrases passives entiéres ou tronquées. L'hypothèse de perte syntaxique prédisait un moins bon résultant avec les phrases passives tronquées qu'avec les passives entières alors que l'hypothèse du déficit de mémoire active prédisait l'inverse. Aucune des deux hypothéses ne fut vérifée car les résultats obtenus par les patients étaient les mêmes sur ces deux types de phrases passives. En outre, il y avait peu de rapport entre les indicateurs de production des patients et leur niveau de compréhension. Ces résultats vont à l'encontre de toute théorie globale de l'agrammatisme qui tenterait d'attribuer la même origine au discours agrammatique et aux déficits de compréhension qui peuvent l'accompagner.
Dans cet article nous présentons une étude des mesures objectives de qualité pour une vaste gamme de systèmes de codage. Ces mesures prennent en compte les distorsions linéaires et non linéaires des codeurs. Une analyse de corrélation a été effectuée afin de repérer les mesures qui prédisent le mieux les indices perceptifs de la qualité de la parole. Finalement, nous décrivons le signal test que nous avons utilisé dans notre étude.
Cet article rentre dans le cadre de la recherche d'information (RI) flexible. Une technique de reformulation de requête par réinjection de pertinence graduelle est présentée. L'utilisateur donne des préférences graduelles aux documents préalablement sélectionnés par le système. Ainsi il pourra formuler son jugement par « tel document est moyennement pertinent » ou « très pertinent » .
Lors de la conception de systèmes interactifs multimodaux le concepteur se trouve confronté au problème du choix des modalités pour favoriser l'utilisabilité du système. En s'appuyant sur une modélisation à un haut niveau d'abstraction, nous proposons une évaluation en phase de conception sur un principe multicritère. L'évaluation s'intéresse simultanément à plusieurs points de vue, pondérés en fonction de l'environnement et de la nature de la tâche. Elle repose sur des mesures estimant des adéquations entre les éléments impliqués dans l'interaction. Ces mesures sont rendues possibles notamment par une décomposition fine des modalités d'interaction.
Nous discutons de la normalisation du ton et de son application à des données sur la fréquence fondamentale de sept locuteurs parlant une variété du chinois Wu. Nous dérivons une représentation phonétique en vue d'une comparaison avec d'autres variétés du chinois.
L'annulation d'écho acoustique utilisant un filtre adaptatif transverse et l'algorithme de l'erreur carrée moyenne minimale (LMS) est la plus efficace pour réduire les échos acoustiques d'un téléphone mains libres. Cependant, il est nécessaire d'utiliser un filtre d'ordre très élevé pour chaque microphone, ce qui induit des problèmes de convergence et d'implantation matérielle. Nous étudions dans cet article les performances des filtres adaptatifs de longueur finie. Nous établissons une formule reliant l'annulation d'écho à la taille du filtre. Une analyse détaillée montre que les performances d'un filtre de longueur finie sont meilleures sur de la parole que sur du bruit blanc.
L'emploi des méthodes du deuxième ordre de traitement du signal pour l'analyse spatiale est limité par la corrélation existante entre les sources. Celles-ci doivent rayonner des signaux indépendants afin de satisfaire les exigences de ces méthodes et permettre un haut pouvoir résolvant. La méthode proposée ici, parvient à augmenter le rang d'une matrice contenant les vecteurs susceptibles de reformer la base du sous-espace formé par les sources. Ceci agit comme une décorrélation des sources. L'avantage de cette méthode est qu'elle continue à séparer les sources totalement corrélées avec un haut pouvoir résolvant contrairement à la populaire diversité d'espace. Cet article montre comment l'algorithme DEESE se sert de l'invariance en translation puis, de l'invariance en direction dans le but de récupérer une base orthonormale du sous-espace source. Des simulations réalistes sont aussi présentées pour confirmer la bonne estimation de la position des sources et la conservation du pouvoir résolvant.
Cet article rend compte d'une comparaison des performances de deux techniques récentes de codage de la parole : le codeur excité par impulsions régulièrement espacées et à boucle de prédiction à long terme (RPE-LTP) et le codeur à prédiction linéare excité par code (CELP) dans le cas d'un canal de transmission bruité, dans des conditions d'erreurs aléatoires et en rafales. En simulation, le flux de bits généré par chaque codeur est altéré par des suites d''erreurs provenant d'un modèle d'erreurs en rafales. Le modèle d'erreurs est composé de deux parties : un générateur de l'envelope des évanouissements (fading) de Rayleigh et un modèle de réceptuer à modulation de phase différentielle à M états dans lequel le niveau du signal varie suivant l'enveloppe de fading de Rayleigh. Les performances de chaque codeur sont évaluées à l'aide de tests objectifs et subjectifs. Le résultat des simulations indique que le codeur RPE-LTP offre des performances plus stables dans un environnement de transmission en rafales. Quatre techniques de codage du canal spécifique au codeur CELP sont également comparées.
Il n'y a pas de contradiction majeure entre le grand plaidoyer d'Henri Ey pour un « corps psychique » ou un « devenir conscient » et ce que peuvent déployer comme efforts, en ce moment, les théoriciens cognitivistes. L'organodynamisme pourrait aussi bien parrainer ces tentatives que ces dernières s'en réclament. Cela peut présenter des avantages et enrichir les deux domaines, en maintenant tendu le fil de l'histoire.
Des données précises sur les caractéristiques de la source glottique sont importantes pour analyser et synthétiser la parole. On a utilisé ici une méthode temporelle de filtrage inverse pour analyser les voix de 4 hommes et de 4 femmes. 14 mono-syllabes ont été prononcées par chacun des locuteurs, (10 avec une voix normale, 2 avec une voix soufflée, 2 avec une voix laryngalisée) puis filtrées par un ensemble de zéros correspondant aux formants. On a effectué des mesures temporelles et fréquentielles de l'onde de débit différenciée ainsi obtenue : près du début du voisement, du centre de la voyelle et de la fin du voisement. Bien qu'on ait constaté de la variabilité parmi les sujets du même sexe, les femmes ont des quotients de fermeture plus courts et des périodes plus longues entre le maximum de l'excitation et le minimum du débit. Dans le domaine spectral, on a trouvé moins d'énergie pour les femmes que pour les hommes dans les hautes fréquences près du centre de la voyelle. Ces différences hommes-femmes sont comparables à celle s observées pour les différences entre voix laryngalisées et normales et entre voix soufflées et normales. Ces différences qualitatives peuvent être liées à une combinaison de facteurs biologiques, sociaux et acoustiques.
L'article présente un type de réseaux neuro-mimétiques appelé « réseaux d'yprels » . Après avoir rappelé quelques caractéristiques essentielles de ces réseaux, on précise la méthode d'apprentissage incrémental permettant d'améliorer les performances par reprise des erreurs de classification. Les résultats obtenus pour un problème de reconnaissance de caractères sont alors présentés.
Dans la volumineuse correspondance de Timothée I, Catholicos de l'Église orientale, deux lettres renvoient à sa collaboration à la traduction des Topiques d'Aristote en syriaque et en arabe, commandée par le Calife al-Mahdī. On trouvera ici la traduction annotée en anglais de ces deux lettres.
Dans cet article nous présentons un modèle permettant de caractériser les gestes à l'aide d'une série de paramètres d'expressivité, puis de générer des gestes expressifs pour les Agents Conversationnels Animés, l'objectif étant d'augmenter la crédibilité des agents et le naturel de leurs comportements. Nous présentons ensuite deux tests perceptifs destinés à évaluer expérimentalement notre modèle. De plus, il apparaît nécessaire d'étudier de manière plus approfondie les effets d'interaction entre paramètres.
L'objet de cet article est de proposer une synthèse des applications musicales du traitement de signal, des problématiques de recherche qui leur sont liées et des directions prospectives qui se dégagent sur la base de travaux récents dans ce domaine. Après l'exposé de notions préliminaires, relatives au système technique musical et à l'analyse des différentes représentations numériques des informations musicales, cette synthèse se concentre sur trois types de fonctions principales : la synthèse et le traitement des sons musicaux, la spatialisation sonore et les technologies d'indexation et d'accès.
Le Perceval imprimé en 1530, qui réunit sous un titre unique la réfection en prose de cinq œuvres rattachées au Conte du Graal de Chrétien de Troyes, est fondé sur un manuscrit aujourd'hui perdu. Le but de cet article est de vérifier, à partir d'un sondage mené sur la totalité du texte, les rapports avec l'un ou l'autre des manuscrits conservés des romans en vers. Si aucun de ceux-ci ne constitue « la » source du prosateur, l'adaptation de 1530 peut apporter des lumières sur la tradition des poèmes, voire offrir des leçons qui pourraient remonter aux « originaux » .
Cet article propose de dresser un panorama des outils et techniques mis en place pour la reconnaissance d'images de documents.
L'expérience a démontré que la mise en oeuvre d'une gestion efficace des connaissances passe par la mise en place d'une cartographie des connaissances. Ainsi, la cartographie des connaissances est un moyen de navigation « cognitif » pour accéder aux ressources d'un patrimoine de connaissances d'une organisation, qu'il soit implicite ou explicite. De plus, elle permet d'avoir une compréhension fine, par une analyse de criticité, des domaines de connaissances sur lesquels des efforts doivent être faits en terme de capitalisation, partage ou innovation. Nous présentons dans cet article une méthodologie et des outils mis en œuvre pour bâtir une telle cartographie.
Cet article décrit une procédure de segmentation automatique de bases de données de mots isolés, du type de celles utilisées classiquement pour la synthèse de la parole. Les unités phonémiques issues de la transcription sont représentées par des modèles de Markov spécifiques et la segmentation est obtenue en alignant le signal de parole avec la séquence des modèles de Markov représentant la transcription phonétique des mots. L'avantage spécifique de la méthode présentée ici est qu'elle ne doit pas recourir à une base de donnée segmentée manuellement pour initialiser l'apprentissage des modèles de Markov. Dès lors, cette procédure peut être considérée comme une amélioration d'une technique connue pour la segmentation automatique. Le problème de l'initialisation des modèles de Markov en l'absence de matériel acoustique préalablement segmenté à la main est résolu ici par une approche hiérarchique en trois étapes. La première réalise une segmentation en grandes classes phonétiques, de façon à obtenir des points d'ancrage pour la deuxième étape qui consiste en une quantification vectorielle avec contrainte de séquence. Cette deuxième étape poursuit le travail en segmentant chaque grande classe phonétique suivant les phonèmes qui la composent. Le résultat est une segmentation phonétique grossière qui est à son tour utilisée pour initialiser les modèles de Markov. Le réglage fin des modèles de Markov est achevé au moyen d'estimations Baum-Welch. La segmentation définitive est obtenue au moyen d'un alignement Viterbi des signaux de parole avec les modèles de Markov.
La représentation générique d'un ensemble de données que nous utilisons ici est un treillis de Galois, c'est-à-dire un treillis correspondant aupartitionnement des termes d'un langage en classes d'équivalence relativement à leur extension (l'extension d'un terme est la partie d'un ensemble d'instances qui satisfait ce terme). Pour réduire la taille du treillis, nous proposons ici de simplifier la représentation des données, tout en conservant la structure formelle de treillis de Galois. Pour cela nous utilisons une partition préliminaire des données correspondant à l'association d'un type à chaque instance. En redéfinissant la notion d'extension d'un terme de manière à tenir compte, à un certain degré a, de cette partition, nous aboutissons à des treillis de Galois particuliers appelés treillis de Galois Alpha.
Dans cet article, nous présentons une solution au problème de l'estimation spectrale nonlinéaire pour la restauration de la qualité d'un signal vocal bruité. La méthode est fondée sur un simple modèle statistique pour l'estimation spectrale court-terme de la parole et du bruit. La génération des données empiriques et l'emploi de méthodes d'approximation de courbes permettent de dériver des expressions (explicites et simples) de la relation entre le niveau d'entrée de l'estimateur MMSE et les paramètres du modèle pour chaque fréquence. Le principal avantage de notre technique est qu'elle a une bonne fondation théorique, qu'elle est générale par le choix de ses paramètres et qu'elle est presque aussi simple que la soustraction spectrale classique. De plus, l'emploi d'un réseau de neurones pour l'approximation de fonctions (qui s'avère être la meilleure méthode pour notre problème d'approximation de courbes) permet de réaliser d'autres estimateurs MMSE basés sur des modèles statistiques avec l'approche proposée.
Nous évaluons ici les performances d'un estimateur de la L2-mesure de dépendance probabiliste en vue de la réduction de dimension bidimensionnelle linéaire dans le cas multiclasse. Nous comparons l'algorithme proposé d'une part, à l'analyse discriminante linéaire introduite par Fisher et, d'autre part, à une version généralisée au cas multiclasse se basant sur l'extracteur linéaire récursif de la L2-mesure de dépendance probabiliste. Dans le cas non gaussien, cette évaluation sera faite au sens de l'erreur des к plus proches voisins. L'estimateur à noyau des densités de probabilité est calculé dans le contexte du paramètre de lissage optimisé au sens de la moyenne quadratique intégrée. Ce dernier servira à l'estimation de la probabilité d'erreur de classification des mélanges de vecteurs gaussiens. Nous montrons sur un exemple de bases d'images de visages l'intérêt du réducteur de dimension proposé relativement aux méthodes conventionnelles.
La plupart des biologistes et certains cognitivistes sont arrivés indépendamment à la conclusion que l'apprentissage, au sens instructiviste et traditionnel du terme, n'existait pas. Cette thèse peut sembler extrémiste, mais je la défend ici à la lumière de données et de théories provenant d'une part de la biologie, en particulier de la théorie de l'évolution et de l'immunologie, et d'autre part, de la grammaire générative moderne. Je souligne également que la chute de l'apprentissage est incontestée dans les sciences biologiques, alors qu'un consensus similaire n'a pas encore été atteint en psychologie ni en linguistique. Puisque de nombreux arguments offerts à l'heure actuelle en faveur de l'apprentissage et d'une capacité d' “intelligence générale” s'appuient souvent sur une image déformée de l'évolution humaine, je dévouc quelques sections de cet article à une critique de l' “adaptationnisme”, en donnant également les éléments d'une meilleure théorie de l'évolution (fondée sur i' “exaptation”). De plus, certains arguments en psychologie et en intelligence artificielle présentés aujourd'hui comme indubitables sont en fait une réplique exacte des anciens arguments en faveur de l'instruction et contre la sélection en biologie ; je m'appuie sur ces erreurs du passé en tirant des leçons pour le présent et le futur.
Dans cet article, nous proposons deux formes d'hybridation entre une métaheuristique (Optimisation par Colonie de Fourmis ou Algorithme Génétique) et une méthode exacte (Programmation Linéaire en Nombres Entiers) pour la résolution du problème d'ordonnancement de voitures. Nous examinons dans quelles mesures ce type d'hybridation peut améliorer la qualité des solutions obtenues par rapport à ce que l'on pourrait obtenir avec une métaheuristique utilisant une procédure de recherche locale. Les résultats obtenus montrent que l'utilisation d'approches hybrides apporte une amélioration significative de la performance et que l'efficacité de l'heuristique ou de la métaheuristique sur laquelle se base l'hybridation influence aussi grandement la qualité des solutions. Nous concluons que les mécanismes de diversification d'une métaheuristique à base de populations jouent un rôle important dans l'hybridation.
La description phonético-acoustique de la diphtongue s'appuie encore de nos jours (1) sur les deux plus basses fréquences de résonance (ou formants F 1 et F 2) du conduit vocal, considérées individuellement ou conjointement dans le plan F 1−F 2, et (2) sur une représentation très éparse du contour de ces fréquences. S'il est vrai que cette approche de longue date a facilité la caractérisation des voyelles initiale et finale de la diphtongue, l'état de la recherche semble avoir très peu évolué au-delà de l'espace planaire F 1−F 2, en tant que cadre paramétrique permettant l'élucidation de la nature dynamique de la transition vocalique. En revanche, nous avons pu obtenir, à l'aide d'un échantillonnage temporel détaillé des trois formants F 1, F 2 et F 3, une description spectro-temporelle plus précise d'un sous-ensemble des diphtongues de l'anglais australien (). Il en ressort surtout la mise en évidence de certains traits de non-linéarité du contour de F 3, qui semblent avoir été jusqu'ici inconnus ou considérés sans conséquence pour la spécification de la diphtongue. Cette découverte permet de dégager, dans l'espace tridimensionel F 1−F 2−F 3, une perspective nouvelle sur la nature acoustique de la transition vocalique propre à la diphtongue.
Dans l'histoire des théories énonciatives du XX e siècle, Charles Bally est l'auteur de la première « théorie générale de l'énonciation » , bien que son nom ait été rarement évoqué par les théoriciens de ce champ. Dans le cadre de la réflexion sur l'articulation entre représentations et opérations chez plusieurs linguistes de l'énonciation, dans un rapport plus ou moins étroit avec une image saussurienne, nous envisageons d'éclairer les points les plus révélateurs qui ont conduit Bally de la stylistique à la théorie de l'énonciation, en poursuivant un fil qui va de la distinction entre « impressions » et « idées pures » (Précis 1905) à l'opposition affectif/intellectuel (Traité 1909), puis au traitement de l'expressivité linguistique en tant que mécanisme (Le langage et la vie 1926) pour arriver à la théorie de l'énonciation, où il définit la modalité. Dans ce parcours, nous évoquons son interprétation originale de concepts et de conceptualités saussuriennes, ainsi que la position de Saussure à l'égard du statut de l'affectif dans la linguistique.
On rend compte de l'évolution de l'accentuation des mots dissyllabiques en anglais - accentuation de type trochaïque (fort-faible) en ce qui concerne les noms et de type iambique (faible-fort) et en ce qui concerne les verbes. Deux théses sous-tendent l'explication proposée : (1) Les utilisateurs du langage, dans leur choix d'un type d'accentuation, cherchentáalterner les accents forts et faibles (principe d'alternance rythmique) ; (2) les noms et les verbes tendentáapparaître dans des contextes rythmiques différents, de sorte que les verbes ont plus de chance que les noms de recevoir une accentuation iambique. Il est apparu,ál'analyse d'échantillons d'anglais parléetécrit, que les verbes dissyllabiques ont plus de chances que les noms dissyllabiques de recevoir une inflection qui ajoute une syllabe au mot. De telles syllabesétant faiblement accentuées, il y a alternance rythmique si le mot dissyllabique reçoit l'accent sur la seconde syllabe (par ex. “suggesting”) plutoˆt que sur la premiére (“promising”). Deux expériences ont montréque l'accentuation de pseudomots dépend de la nature syllabique des inflexions ajoutées au mot. En outre, les analyses de texte et les expériences peuvent rendre compte de sous-types d'accentuation particuliersál'intérieur de l'asymétrie générale noms/verbes, aussi bien que de cette asymétrie générale elle-meˆme. La discussion porte à la fois sur les implications de ces faits pour les théories de l'accent et, de façon plus générale, sur la possibilitéde comprendre le changement linguistique en le rapportant aux opérations cognitives du locuteur/auditeur individuel.
Un codeur de parole à 16 kbit/s avec une faible complexité et un faible retard de signaux est présenté, qui est une version spéciale de l'algorithme d'excitation à impulsions régulières et de prédiction LPC (RPE-LPC). Cette proposition forme la base du standard de codeurs qui sera utilisé dans le futur système de téléphone mobile à couverture européenne. Un modèle expérimental est décrit.
Une façon de réduire le débit des codeurs CELP consiste à rallonger la taille des trames d'analyse de l'excitation. Pour améliorer la qualité de la parole codée, il est souhaitable de restituer l'excitation CELP avec des pics plus marqués. Sur la base de cette observation, on propose une nouvelle source adaptative dans laquelle un prédicteur de fréquence fondamentale à deux coefficients permet d'attribuer aux échantillons différents gains suivant leur amplitude. Les résultats de simulation montrent que les impulsions pointues de début de voisement sont clairement reconstruites, ainsi que l'explosion des plosives.
On détermine un algorithme récursif (sur l'ordre du modèle) d'estimation des coefficients d'un modèle autorégressif au sens du maximum de vraisemblance. Les coefficients ainsi estimés servent alors à estimer les densités spectrales des sources par la méthode du maximum d'entropie. Enfin, on présente des résultats de simulation permettant de comparer cet algorithme avec l'algorithme de Durbin-Levinson.
Jusqu'ici, l'estimation des fractions d'abondance a toujours été réalisée dans un second temps, par résolution d'un problème inverse généralement. Dans cet article, nous montrons que les techniques géométriques d'extraction des composants purs de la littérature permettent d'estimer conjointement les fractions d'abondance, pour un coût calculatoire supplémentaire négligeable. Pour ce faire, un socle commun d'interprétations géométriques du problème est proposé, que l'on peut décliner pour mieux l'adapter à la technique d'extraction de composants purs retenue. Le caractère géométrique de l'approche lui confère une flexibilité très appréciable dans le cadre de techniques de démélange géométrique, illustrée ici avec N- Findr, SGA, VCA, OSP et ICE. Une extension non linéaire est proposée, en utilisant des techniques de réduction de dimensionnalité par apprentissage de variétés, illustrée avec les algorithmes MDS, LLE et ISOMAP. Une telle approche permet de maintenir inchangés les algorithmes géométriques d'identification des composants purs et d'estimation de la proportion de ces derniers dans le mélange. La pertinence de cette approche est illustrée par des expérimentations sur des données synthétisées et réelles
Cet article présente deux stratégies d'échantillonnage dans le contexte de l'apprentissage par renforcement en mode “batch”. La première stratégie repose sur l'idée que les expériences susceptibles de mener à une modification de la politique de décision courante sont particulièrement informatives. Etant donné a priori un algorithme d'inférence de politiques de décision ainsi qu'un modèle prédictif du système, une expérience est réalisée si, étant donné le modèle prédictif, cette expérience mène à l'apprentissage d'une politique de décision différente. La deuxième stratégie exploite des résultats récemment publiés pour calculer des bornes sur le retour des politiques de décision de manière à sélectionner des expériences améliorant la précision des bornes afin de discriminer les politiques non-optimales. Ces deux stratégies sont illustrées sur des problèmes élémentaires et les résultats obtenus sont prometteurs.
Une technique TDNN à deux niveaux a été développée pour reconnaître les finales (voyelles) de syllabes en Chinois Mandarin. Le premier niveau discrimine le groupe “voyelle”, basé sur (a, e, i, o, u, v) et le groupe “nasal”, basé sur des terminaisons nasales (-n, -ng, -autres). Le discriminateur de groupe “nasal” est ensuite utilisé pour partitionner de nouveau le large groupe “voyelle” produit par le discriminateur de groupe “voyelle”. Les 2 regroupements du premier niveau produisent 8 sous-groupes au deuxième niveau. Des discriminations supplémentaires au deuxième niveau permettent d'identifier chacune des 35 finales du Chinois Mandarin. Cette technique a été testée de façon approfondie en utilisant 8 séries de 1265 syllabes isolées en Pinyin Hanyu, 6 séries étant utilisées pour l'apprentissage et 2 pour le test. Les résultats globaux montrent que l'on peut atteindre un taux de reconnaissance de 99.4% sur les données d'apprentissage et de 95.6% sur les données de test. Le taux de bonne reconnaissance parmi les 4 meilleurs candidats atteint 99.1% sur la base de données de test.
Dans cette article nous développons plusieurs modèles autour du paradigme “multi-stream” de la RAP (Reconnaissance Automatique de la Parole) robuste, et nous discutons de leurs relations avec la perception naturelle de parole. Fortement inspirée par la règle “produit des erreurs” de Fletcher, issue de la psychoacoustique, la reconnaissance “multi-bande” se veut être robuste à l'inadéquation des données par rapport aux conditions d'apprentissage, en exploitant la redondance spectrale, tout en faisant un minimum d'hypothèses sur la nature du bruit. Des études précédentes en RAP ont montré que le traitement indépendant des sous bandes peut diminuer le taux de reconnaissance en parole propre. Nous avons surmonté ce problème en considérant toutes les combinaisons de sous bandes comme des flux indépendants de données. Après un état de l'art sur la RAP multi-bandes, nous formalisons cette approche “full-combination” dans le contexte de la RAP HMM/ANN, en introduisant une variable latente qui spécifie à chaque trame de signal la combinaison de sous bandes la plus adéquate. Ceci nous permet de décomposer la probabilité a posteriori pour chaque phonème en une somme pondérée, sur toutes les positions possibles des données propres. Cette approche est prometteuse pour l'adaptation aux bruits imprévisibles et variant rapidement.
Quand plusieurs caractéristiques acoustiques différentes contribuent à la perception d'une distinction phonétique, on peut montrer l'existence d'une relation compensatoire lors de l'identification de stimuli de parole lorsque ceux-ci sont phonétiquement ambigus. Les expériences présentes essayent d'observer si ces relations compensatoires existent également avec des stimuli non-ambigus, au moyen d'une tâche de discrimination AX avec des stimuli, soit proches de la limite entre deux catégories phonétiques, soit à l'intérieur d'une catégorie. Les résultats suggèrent que parmi les cinq relations compensatoires, quatre sont liées à la perception des contrastes phonétiques ; elles disparaissent ou s'inversent à l'intérieur des catégories. L'unique exception prévue représente une relation compensatoire supposée tirer son origine du niveau psychoacoustique. Ces données limitent strictement les explications psychoacoustiques pour les relations compensatoires et suggérent également que la discrimination à l'intérieur des catégories n'est pas réalisée dans un mode phonétique de perception, affirmant ainsi que le discrimination de la parole peut être traitée de deux façons ; phonétique et psychoacoustique.
Le Perceptron MultiCouche (PMC) est un des réseaux de neurones les plus utilisés actuellement, pour la classification supervisée notamment. On fait dans un premier temps une synthèse des résultats acquis en matière de capacités de représentation dont jouit potentiellement l'architecture PMC, indépendamment de tout algorithme d'apprentissage. Puis on montre pourquoi la minimisation d'une erreur quadratique sur la base d'apprentissage semble être un critère mal approprié, bien que certaines propriétés asymptotiques soient aussi exhibées. Dans un second temps, l'approche bayesienne est analysée lorsqu'on ne dispose que d'une base d'apprentissage de taille finie. A l'aide de certains estimateurs de densité, dont les propriétés remarquables sont résumées, il est possible de construire un réseau de neurones stratifié réalisant la classification bayesienne. Cette technique de discrimination directe semble être supérieure au PMC classique à tous points de vue en dépit de la similarité des architectures.
Le travail de recherche dans le domaine du traitement de la parole date de plus de soixante ans, mais c'est seulement depuis quelques années que l'on commence à s'apercevoir de l'impact de ces années de travail dans les systèmes de télécommunication modernes. Pratiquement tous les domaines issus du traitement de la parole, qui comprennent en particulier le codage de la parole, la synthèse de la parole, la reconnaissance de la parole, et même, dans une moindre mesure, la vérification d'identité par la parole, ont quitté le laboratoire de recherche et apparaissent aujourd'hui dans des produits et des services qui sont utilisés journellement sur le marché, souvent par des millions d'utilisateurs. Cette révolution du traitement de la parole pour les télécommunications est attisée par les progrès des algorithmes (qui améliorent la qualité des systèmes de traitement de la parole), par les progrès des matériels (qui permettent une grande capacité de calcul et de mémoire à bas prix), ainsi que par les progrès des réseaux (qui fournissent des accès à haute capacité vers les habitations, les lieux de travail, et à travers l'ensemble du réseau de télécommunications). Dans cet article, nous illustrons l'impact du traitement de la parole sur les télécommunications modernes en montrant comment le codage de la parole, la synthèse de la parole, la reconnaissance de la parole, et la vérification d'identité par la parole se sont intégrés dans de nouveaux produits et services.
Cet article présente un dispositif qui définit des moyens opérationnels pour repérer, acquérir et valoriser des connaissances liées au traitement d'images de document. Notre démarche pragmatique, a consisté à utiliser une approche terminologique basée sur des expertises pour extraire des unités de connaissance. Cette analyse linguistique nous a mené à l'élaboration d'un modèle consensuel de scénario et au développement d'une interface. Ensuite nous proposons une interaction dynamique, pour faire l'acquisition et l'historisation des connaissances des traiteurs d'images dans une base de scénarios. Enfin, une exploitation des scénarios déjà joués, est faite par les naïfs qui naviguent dans cette base de façon intuitive, et extraient les connaissances qui sont nécessaires à la résolution d'un problème. La navigation suivant différents points de vue se fait grâce à un graphe hyperbolique.
La modélisation de la sortie du conduit vocal nécessite que soient connues les relations qu'entretiennent les dimensions de la géométrie des lèvres : • - de face : l'écartement, la séparation, l'aire ; • - de profil : les protrusions supérieure, inférieure, du coin ; l'aperture du pavillon et sa profondeur. Le corpus utilisé explore l'espace maximum de manoeuvre sur les lévres du française (5 locuteurs), avec des consonnes qui requièrent naturellement un contrôle précis de la mandibule (contextes [s] et [∫], et qui, par leur influence fermante, maximisent les mouvements propres aux lèvres. Ainsi les propositions tendant à calculer l'aire avec une seule de ces mesures ne peuvent être retenues. De profil, les protrusions sont naturellement très corrélées ; et il en va de même pour la profondeur du pavillon avec la protrusion du coin de la fente labiale. Nous pouvons donc choisir ce coin comme un pivot de la modélisation de profil. Mais le plus crucial pour la modélisation de tout le pavillon est sans doute la corrélation inverse que nous avons pu observer entre l'écartement et la protrusion (à condition de bien choisir la protrusion du coin).
Cet article donne une vue d'ensemble d'un système à large vocabulaire et basé sur le phonème pour la reconnaisssance de la parole continue. Il constitue le module de reconnaissance, dépendant du locuteur, du système spicos conçu pour reconnaître, compredre et répondre à des questions d'une bangue de données formulées en allemand. Il s'ensuit que le problème de la reconnaissance se transforme en une recherche efficiente dans un très grand espace des phases de manière à ce que les décisions purement locales puissent être évitées au profit de décisions globalement optimales. La taille de cet espace des phases dépend principalement du modèle de langage employé. Trois types de modèles sont étudiés ici : un modèle sans aucune contrainte, un réseau à nombre d'états fini et un modéle stochastique trigramme basé sur les probabilités des différentes catégories de mots. Pour chacun de ces trois modèles, des expériences de reconnaissance ont été menées pour 4 locuteurs sur un vocabulaire de 917 mots. Pour chaque locuteur, 200 phrases totalisant 1391 mots devaient être reconnues.
Nous présentons dans cet article les avancées réalisées au LIMSI sur la reconnaissance de parole continue de grand vocabulaire, indépendante du locuteur dans une application de dictée de textes. Le système utilise des modèles de Markov cachés à densités continues au niveau acoustique, et des modèles de langage n-grammes au niveau syntaxique. La modélisation acoustique repose sur une analyse cepstrale du signal vocal, des modèles de phones en contexte (inter-et intramot) dépendant du genre du locuteur, et des modèles de durée phonémique. Nous avons utilisé, pour la langue anglaise, le corpus de parole continue ARPA-WSJ contenant des enregistrements de textes lus extraits du Wall Street Journal, et, pour la langue française, le corpus BREF contenant des enregistrements de textes lus extraits du journal Le Monde. Les performances du système de reconnaissance, mesurées au niveau phonétique et au niveau mot sont données sur ces deux corpus pour des vocabulaires contenant jusqu'à 20.000 mots. Nous donnons également pour référence les résultats obtenus sur le corpus ARPA-RM qui a été très largement utilisé pour évaluer et comparer des systèmes de reconnaissance de parole.
Pour obtenir le volume désiré dans un vocodeur à Prédiction Linéaire (LP) on utilise souvent la méthode de l'énergie du signal d'erreur. De grandes erreurs de gain se présentent tout de même, quand un formant à basse fréquence est en résonance avec les impulsions d'excitation voísée. Dans cet article, on donne une évaluation des erreurs et on discute leurs causes fondamentales. On démontre que les grandes erreurs sont dues aussi bien à la suppression excessive d'une raie spectrale du signal LP d'erreurs, qu'à l'incompatibilité des fenêtres d'analyse et l'excitation continue pendant la synthèse. Pour terminer, une amélioration réalisée est discutée dans ce contexte.
Nous présentons une nouvelle méthode d'analyse de séquences d'images adaptée à l'extraction automatique en temps réel de mouvements localisés dans des scènes naturelles. Nous montrons comment extraire ces mouvements sous la forme de voisinages de points formés dans un espace de très grande dimension par le plongement temporel des variations de niveaux de gris des pixels d'une même enveloppe. Nous présentons tout d'abord notre méthode d'extraction rapide des voisinages dans cet espace multidimensionnel. L'application est un détecteur des feux de forêts capable de faire la distinction entre des enveloppes causées par une source de fumée ou par tout autre phénomène dynamique pouvant apparaître localement dans un paysage. Nous généralisons ensuite les perspectives d'utilisation de la méthode du plongement fractal en envisageant d'autres types d'applications par l'extraction de caractéristiques autres que des mouvements.
Cet article tente de dégager la structure spatio-temporelle des informations acoustiques le long de la cochlée et, corrélativement, l'importance de l'effet de la phase dans l'oreille. On s'appuie sur les résultats obtenus par un modèle de l'audition périphérique. Ce modèle est décomposé fonctionnellement en parties indépendantes : de l'oreille externe aux fibres nerveuses. Il est décrit par un ensemble d'équations portant sur la propagation des ondes acoustiques, la vibration mécanique de la membrane basilaire et la transduction mécano-électrique des cellules ciliées et des fibres nerveuses. La représentation des informations circulant dans la cochlée est un probléme important quand on cherche à extraire des indices acoustiques pertinents en vue de l'analyse de la parole. De plus, en synthèse de la parole, on s'aperçoit que la phase joue un rôle non négligeable pour une meilleure qualité perceptive. Il est donc nécessaire de visualiser ces phénomènes échantillon par échantillon, tout en gardant cependant l'intérêt du sonagramme, c'est-à-dire une relation avec l'évolution de l'intensité.
La morphologie mathématique repose sur la notion d'ordonnancement. Pour le traitement d'images couleur, l'écriture d'une relation d'ordre valide nécessite l'utilisation de distances couleur normalisées issues des espaces CIELAB ou CIELUV. Depuis les premières recommandations de la CIE (Commission internationale de l'éclairage), plusieurs distances couleur ont été proposées. Le but de cet article est d'étudier l'impact de ces formules de distance couleur dans le contexte de la morphologie mathématique couleur. Les résultats sont développés pour une nouvelle construction des opérateurs morphologiques couleur basée sur la distance dans l'espace CIELAB. Un critère de comparaison des méthodes d'ordonnancement couleur est ensuite proposé pour comparer les principales approches en morphologie mathématique avec celles basées sur une fonction de distance.
Les analyseurs syntaxiques à ilôts de confiance ont des applications potentielles intéressantes en Reconnaissance Automatique de la Parole. La plupart des systèmes récemment développés sont fondés sur l'association d'un Module Acoustique et d'un Module Linguistique. Le premier calcule la probabilité a priori des données acoustiques, étant donnée une interprétation linguistique. Le second calcule la probabilité de cette interprétation linguistique. Cet article décrit des travaux de généralisation des analyseurs syntaxiques à ilôts de confiance aux grammaires hors-contextes stochastiques. Celles-ci pourraient alors être utilisées comme modèles par le module linguistique pour calculer la probabilité d'une interprétation linguistique.
L'intelligibilité de consonnes initiales et finales dans des suites monosyllabes CVC a été mesurée pour une parole synthétisée par règles (concaténation dyadique). Afin d'évaluer les résultats d'intelligibilité, deux conditions supplémentaires ont été testées : une parole en codage PCM (12 bits, échantillonnage à 10 kHz) et une parole resynthétisée par LPC (12 coefficients). L'ensemble des stimuli se compose de toutes les consonnes initiales et finales possibles dans neuf contextes CVC différents, c'est-à-dire avec trois voyelles /i, u, O/ et trois consonnes non-voisines /p, t, k/. Les sujets devaient identifier la consonne initiale ou finale de chaque mot et pouvaient choisir n'importe quelle consonne comme réponse. Les scores généraux de pourcentages de bonnes réponses pour 33 sujets, pour les consonnes initiales et finales étaient de 93% et de 92.8% pour la parole codée PCM, de 86.7% et de 85.4% pour la synthèse LPC, et de 58.2% et de 73.5% pour la synthèse par règles. Ces résultats mis à part, les confusions notées sont discutées en détail. Plus importante que les taux d'intelligibilité dans ce test particulier de la synthèse par règles améliorée, est l'expérience acquise dans l'évaluation et l'amélioration de tels systèmes.
Ce papier présente un nouvel algorithme qui génére des trajectoires tri-dimensionnelles de points de visage à partir d'un fichier de parole, avec ou sans son texte. Ce dictionnaire contient les caractéristiques acoustiques et visuelles. L'acoustique est représentée par les coefficients LSF (line spectral frequencies), et les points du visage sont représentées par leurs composantes principales (PC). Dans l'étape de synthèse, l'entrée parole est comparée aux entrées du dictionnaire. Sur base de cette similarité, on assigne un coefficient de pondération à chaque entrée du dictionnaire. Si l'information phonétique de la phrase test est disponible, celle-ci est utilisée pour limiter la recherche dans le dictionnaire aux entrées qui sont les plus proches du phonème courant (en utilisant une matrice de similarité). Ces pondérations sont alors utilisées pour synthétiser les composantes principales de la trajectoire des points du visage. Les performances de l'algorithme sont testés sur des données séparées, et on montre que la trajectoire synthétique a une corrélation de 0.73 avec la trajectoire réelle.
Nous proposons dans cet article une voie à suivre pour tenter d'apporter une solution au problème complexe qu'est la définition d'un facteur de forme adapté au problème de la vérification automatique des signatures manuscrites. Le codage de la signature obtenu de la projection locale du tracé sur les segments d'un motif M($ {\gamma }$) est un compromis entre les approches globales où la silhouette de la signature est considérée comme un tout, et les approches locales où des mesures sont effectuées sur des portions spécifiques du tracé. Inspiré de ces deux familles d'approches, l'ESC est en fait une approche mixte qui permet d'effectuer des mesures locales sur la forme sans la segmenter en primitives élémentaires, une tâche très difficile en pratique. Ce travail porte principalement sur l'étude de l'influence de la résolution des motifs utilisés pour le codage de la signature (par la projection locale du tracé), et sur la définition d'un système de type multi- classifieurs pour tenter de rendre plus robuste la performance des systèmes de vérification de signatures.
Dans cet article nous proposons une structure multibande à plusieurs capteurs qui utilise un mécanisme d'adaptation intermittente. La convergence de cette méthode est comparée avec celle de la méthode dés moindres carrés appliquée dans le domaine temporel et fréquentiel. Des résultats préliminaires concernant l'influence de l'ordre des filtres dans chaque bande sont aussi présentés.
L'analyse des paramètres acoustiques pour la caractérisation et l'identification des phonèmes de la langue à étudier représente la première étape du décodage acoustique-phonétique, indépendamment de la méthode utilisée. On trouve malgré tout très peu d'analyses acoustico-phonétiques de la langue espagnole. Le travail présenté ici traite de la discrimination des occlusives espagnoles. Rechercher un ensemble réduit de paramètres robustes pour identifier le lieu d'articulation des occlusives sourdes a constitué notre premier objectif. A partir de cet ensemble de paramètres, on a ensuite élaboré et évalué deux algorithmes de classification et de reconnaissance automatique. Après une étape de localisation automatique de l'explosion (“burst”), seules les caractéristiques acoustiques de ce segment sont prises en compte pour l'estimation des paramètres. On a mesuré aussi bien les caractéristiques temporelles que fréquentielles sur un corpus de syllables CV prononcées par 6 locuteurs. On a conçu, dans le premier cas, un système procédural à base de règles, pour reconnaître le lieu d'articulation. Pour le traitement des paramètres fréquentiels, on a mis au point un classifieur statistique, développé à partir d'une analyse discriminante préalable des paramètres d'entrée. Un corpus de syllables CV prononcées par 40 nouveaux locuteurs, non utilisé pour la définition et l'analyse des paramètres, a permis d'évaluer les deux systèmes qui ont tous deux conduit à de bons résultats d'identification.
L'algorithme calcule le taux de vraisemblance brut pour chaque mot du lexique en utilisant les probabilités d'observation des spectres et de l'information sur les durées des unités de reconnaissance. Avec cette méthode, nous avons pu réduire l'effort de calcul de 74% en tolérant une légère dégradation du taux de reconnaissance dans un système à 1160 mots qui utilise la modélisation de phonèmes par des modèles de Markov cachés. Aussi, nous avons observé que le calcul du taux de vraisemblance brut est un bon estimateur du même taux calculé par l'algorithme de Viterbi.
Les microperturbations de la période fondamentale permettent de discriminer entre locuteurs normaux et dysphoniques. Deux études comparées ont été menées à bien. Les différences inter-voyelles significatives ont pu être reliées au comportement idiosyncratique des différentes méthodes de prétraitement du signal par rapport à la qualité phonétique de la voyelle. Les différences inter-voyelles intrinsèques sont compensées par une normalisation des microperturbations à l'aide de la moyenne de la période fondamentale. En règle générale, le prétraitement a été d`autant plus la distance en fréquence entre F 0 et F 1 était élevée. Lors d`une deuxième expérience, des obteunus à partir de phrases isolées n`ont pas mieux séparé locuteurs normaux et dysphoniques que des mesures basées sur des voyelles soutenues. En ce qui concerne nos corpus, aucune supériorité intrinsèque de la parole continue n`a pu ětre mise en évidence au niveau des performances de discrimination. Par contre, lors des transition entre segments et lors de l`établissement et de l`extinction du voisement les valeurs des microperturbations sont appareus plus importantes en valeur absolue.
Cet article présente une approche de l'apprentissage et de l'adaptation du modèle acoustique, appelée normalisation des environnements, appliquée au modèle stochastique des mélanges de trajectoires. L'approche proposée étend la technique connue de normalisation des environnements — utilisée pour l'adaptation des HMM — aux modèles fondés sur les segments. De plus, l'approche proposée donne une nouvelle méthode de représentation et de combinaison des différentes sources de la variabilité de la parole. Dans notre approche, la normalisation et l'adaptation sont effectuées en utilisant des transformations linéaires. Les résultats des expériences de l'adaptation au locuteur montrent que l'approche proposée conduit à une amélioration du taux de reconnaissance jusqu'à 34% par rapport au modèle non adapté. Les résultats des expériences de l'adaptation au bruit montrent que pour certaines configurations de test la technique proposée donne même de meilleurs résultats que le modèle dépendant de l'environnement. Nous avons également observé que l'apprentissage par la normalisation des environnements et l'adaptation sont plus performants que l'apprentissage classique et l'adaptation par régression linéaire (MLLR).
En commande des systèmes, l'anticipation pure apparaît comme la meilleure solution mathématique au problème de l'asservissement des sorties aux consignes, que celles-ci soient connues a priori (cas des systèmes de régulation) ou pas (cas des systèmes de poursuite de trajectoire). D'un point de vue formel, cela est obtenu en mettant le système à asservir en cascade avec son système inverse. Cette solution n'est toutefois pas réalisable physiquement, car le modèle du système n'est que rarement complet. De plus, le système inverse est souvent instable. Enfin, les perturbations observées, soit en sortie, soit en entrée, rendent difficile l'accès à une solution satisfaisante. Dernier aspect : pour être exploitable, l'anticipation doit se faire en temps réel. La méthode présentée ici tente d'apporter une solution rapide et robuste au problème de prédiction. Elle utilise à la fois les propriétés géométriques du signal à prédire à l'instant considéré (procédure locale), ainsi qu'une base d'apprentissage constituée d'observations passées (procédure globale). Les performances du prédicteur sont évaluées par quelques exemples significatifs et comparées aux performances d'autres prédicteurs.
Dans ce papier, nous évaluons en détail l'influence du canal de transmission téléphonique sur les performances de systèmes de reconnaissance automatique de la parole (RAP). Un simulateur temps-réel est décrit et mis en œuvre, permettant une génération flexible et contrôlée des différentes perturbations habituellement rencontrées dans les réseaux téléphoniques, aussi bien traditionnels (fixes) que mobiles et IP. Le modèle utilisé est basé sur un ensemble de paramètres d'entrée qui sont connus des concepteurs de réseaux ; il est donc applicable sans devoir mesurer explicitement les caractéristiques du réseau. Ce modèle peut donc être utilisé pour mesurer analytiquement l'impact des perturbations du réseau sur les performances de la RAP, pour produire des données d'entraı̂nement correspondant à des caractéristiques de transmission déterminées, ou encore pour tester des systèmes vocaux interactifs dans des conditions de réseau réalistes et multiples. Dans ce papier, nous nous focalisons avant tout sur le premier point. La robustesse de deux systèmes de RAP, intégrés dans une application de recherche d'informations basée sur un dialogue vocal, est évaluée en fonction de la dégradation (contrôlée) du canal de transmission. Les dégradations résultantes du système de RAP sont ensuite comparées à celles observées dans le cas de la communication homme-homme. Il est alors intéressant de noter que les conclusions dépendent fortement du type de perturbations (résultant souvent en différents comportements). Ces conclusions sont pertinentes aussi bien dans le cadre de la conception des réseaux que lors du développement de technologies vocales.
Des résultats sont présentés qui indiquent que les performances d'une technique à fréquence de trames variable et basée sur des triphones peuvent être meilleures que celles obteneus en utilisant des triphones et la fréquence de trames maximale. La technique à fréquence variable requiert un temps de calcul très inférieur.
Un problème inverse du conduit vocal est analysé du point de vue de la théorie des problèmes incorrects. On propose la méthode, utilisant la régularisation variée avec des restrictions pour surmonter des difficultés liés à la dissemblance et à l'instabilité. Le fonctionnement des organes d'articulation est utilisé comme un régulateur et comme un critère d'optimum pour une résolution approximative recherchée. Des paramètres acoustiques mesurés servent des restrictions extérieures tandis que la géométrie du conduit vocal, les mécanismes d'articulation et les particularités phonétiques de la langue servent des restrictions intérieures. Une méthode effective numérique de la réalisation d'un approche proposé est basée sur une approximation linéaire d'une image “articulation – acoustique”. Une méthode euristique nommée “une méthode des courbes calibrées” a été utilisée pour évaluer la précision des résolutions approximatives obtenues. On fait voire que dans les certains cas une faute dans la résolution d'une tâche inverse ne dépend que très faiblement des fautes des mesures des fréquences des formantes. Formes du conduit vocal évaluées à l'aide d'une méthode proposée ressemblent beaucoup aux formes mesurées au cours des expériences radiographiques.
Le cliquetis dans les moteurs à allumage commandé demeure un problème pour les motoristes. La détection du cliquetis doit en effet permettre de réaliser un compromis entre l'optimisation du rendement du moteur, la consommation de la voiture et le respect des normes en matière de dépollution. Souvent l'allumage est réglé avec une marge de sécurité qui garantit l'absence de cliquetis même en cas de variations de la qualité du carburant. L'enjeu de l'élaboration d'une méthode de détection de cliquetis est de se rapprocher le plus possible des conditions limites de cliquetis tout en évitant son apparition. L'objectif de l'étude présentée consiste à évaluer l'intensité du cliquetis produit dans la chambre de combustion à partir d'un enregistrement fourni par un accéléromètre placé sur le bloc moteur. Son but est de reconnaître trois types de cliquetis : l'absence de cliquetis, le cliquetis naissant et le cliquetis violent. L'approche envisagée pour mener à bien cette détection fait appel aux techniques du diagnostic par reconnaissance des formes floue. La méthode, mise au point à l'aide d'un ensemble d'apprentissage, conduit à la réalisation de plusieurs processus de diagnostic qui coopèrent.
La présente contribution examine les impacts de la standardisation et de la véhicularisation sur la diversité linguistique. Nous démontrons à la lumière du tɔŋúgbe, parlé dans le sudest du Ghana, et du peul véhiculaire dans le nord du Cameroun que les langues sont des objets sociaux dynamiques pouvant être institutionnellement et / ou socialement soumis à une promotion ou à une rétrogradation. Sur une base de données empirique et authentique, nous montrons par exemple que le tɔŋúgbe, l'un des dialectes de la langue éwé, comporte des propriétés linguistiques exceptionnelles qui ont échappé à la documentation de l'éwé standard. Pourtant ces propriétés, à l'instar de celle de la détermination du syntagme nominal par l'article défini, sont essentielles à la compréhension et à l'étude non seulement de l'éwé, mais également de l'ensemble du groupe Gbe. Dans la deuxième partie, nous soutenons que la véhicularisation, comme pour le cas du peul Adamawa, se révèle être une arme à double tranchant qui, d'une part, promeut une variété de peul vis à vis d'autres et, d'autre part, implique le recul d'autres langues et variétés minoritaires.
Le codage optimal d'un synthétïseur à formants a été déterminé. L'optimisation des paramètres de commande est basée sur des critères statistiques et subjectifs. Le synthétiseur est du type parallèle et est capable de faire une synthèse de très haute qualité de sons voisés ou non voisés. Les phrases choisies pour l'expérimentation sont des logatomes CVCV représentant des groupes français licites. Le premier groupe comprend les occlusives /b, d, g/ et les voyelles /a, u, i/ alors que le second utilise des consonnes fricatives /З, z/ et les mm̂mes voyelles. La procédure comprend 4 étapes. La première consiste en une étude statistique sur les paramètres de commande afin de déterminer pour chacun d'eux la gamme de leur dynamique effective. Dans un deuxième temps, on détermine le nombre minimum de bits nécessaires pour la quantification de chacun des paramètres indépendamment (sans dégradation perceptive notable). La troisième étape permet de trouver le nombre minimum de bits nécessaires lorsque tous les paramètres sont quantifiés simultanément. On opère par regroupement de paramètres en sous-groupes et recherche du nombre minimum de bits de quantification pour tous les paramètres d'un sous-groupe. Puis nous regroupons les sous-groupes pour trouver le nombre optimal de bits pour tous les paramètres simultanés. L'étape finale détermine la période d'échantillonnage de chacun des intervalles d'un logatome. Un échantillonnage variable est proposé selon la nature des événements sonores.
Les applications embarquées dans les appareils portables tels que téléphones ou PDAs et qui interagissent avec leur utilisateur, doivent prendre en compte la disponibilité de celui-ci. Une approche de livraison de messages, dynamique et dépendante du contexte de l'utilisateur, est ici proposée. Cette approche est illustrée en utilisant Scatterbox, une application pervasive qui permet la fusion d'information afin de déterminer le contexte dans lequel se trouve l'utilisateur. En fonction du niveau de disponibilité de celui-ci, Scatterbox rend prioritaires certains messages et les envoie sur son téléphone portable. Nous tirons ces conclusions après une évaluation préliminaire du système.
Cet article passe en revue plusieurs domaines d'applications du critère de classification « K-produits » introduit dans [10]. Ce critère est appliqué à l'estimation de mélange de lois, à l'extraction de lignes droites dans des images binaires et à l'estimation aveugle de canal en radiocommunications. Plusieurs algorithmes d'optimisation du critère sont présentés et des comparaisons avec d'autres approches sont conduites.
Parmi un certain nombre de représentations paramétriques équivalentes de la prédection linéaire, la représentation par coefficients du cepstre est reconnue comme fournissant les meilleures performances en reconaissance de la parole. Comme les coefficients cepstraux d'un filtre tout pôle sont inversement proportionnels à leurs quéfréquences, ces coefficients sont multipliés par leur quéfréquence respective. Les coefficients cepstraux pondérés en quéfréquence sont étudiés en fonction de leur eficacité dans une expérience de reconnaissance de voyelles.
Notre projet de recherche vise à élaborer des Webs Sémantiques d'Organisation (WSOs) hybrides, réalisant un couplage fort entre une Base de Connaissances (BC) et une Base de Documents (BDoc). Les connaissances capitalisées sont ainsi réparties à la fois dans la BC et la BDoc. L'intérêt de modéliser des connaissances est de permettre au WSO de raisonner sur ces connaissances pour assister les utilisateurs dans leurs tâches de gestion des connaissances. En contrepartie, la distribution des connaissances dans des sources hétérogènes complique leur accès. Pour pallier ces difficultés, nous proposons, d'une part, d'introduire un modèle de l'information contenue dans le WSO, en faisant abstraction de son mode de spécification et, d'autre part, de coupler ce modèle à un mécanisme de génération dynamique de présentations d'informations ciblées dont le contenu est adapté à l'utilisateur. Dans cet article, nousprésentons une vue d'ensemble de cette approche.
On a réalisé des simulations aérodynamiques de séquences /aCa/ à l'aide d'un modèle basse-fréquence pour l'écoulement de l'air dans la partie supérieure du conduit vocal et d'un modèle à deux masses pour la source. Ces simulations nous ont permis de mieux comprendre les résultats d'une étude empirique sur l'écoulement lors de la parole continue. On a examiné la contribution des diverses sources d'écoulement, y compris la compliance des parois, à l'écoulement buccal global. Le modèle à deux masses a été modifié pour permettre un écoulement glottique plus naturel pendant l'abduction et l'adduction. Malgré ces modifications, le modèle à deux masses s'est avéré insuffisant pour modéliser les variations de source en parole continue.
Par une technique de diversité d'espace consistant à utiliser plusieurs sous-réseaux identiques (par exemple appartenant à un seul réseau rectiligne de capteurs équidistants), il est possible d'extraire le propagateur à partir d'une seule épreuve de courte durée et, par suite, de procéder à la goniométrie de sources lointaines. De la sorte peuvent être traités le cas de situations non stationnaires ou celui de fronts d'onde incidents totalement cohérents, puisqu'on exploite seulement le vecteur des signaux reçus et non pas leur matrice interspectrale. La méthode exige un rapport signal à bruit par source au moins égal à OdB ; toutefois, s'il existe une certaine cohérence temporelle des sources sur une durée correspondant à trois ou quatre dizaines d'épreuves, la robustesse vis-à-vis du bruit peut être grandement accrue en employant une technique de mémoire consistant à appliquer un facteur d'oubli au vecteur des signaux reçus. Il s'agit d'une méthode superdirective qui a la propriété de fournir la phase des fronts d'onde incident, ce qui permet éventuellement des mesures de Doppler.
La base de données et les tests NOISEX-92 sont décrits et commentés. NOISEX-92 spécifie des tests sur des données bruitées artificiellement en évaluant les performances dans le cadre de la reconnaissance de chiffres et une gamme relativement large de rapports signal sur bruit. Des examples de scores de reconnaissances sont présentés.
Les recherches sur les langues parlées ont montréque la durée des pauses silencieuses d'une phrase est fortement liéeàla structure syntaxique de cette phrase. Une analyse du meˆme type sur un passage de la Langue des Signes Américaine permet de voir que les suites de signes sontégalement entrecoupées par des pauses (arreˆts entre les signes) de longueurs variables : les pauses longues semblent indiquer la fin des phrases, les pauses courtes marquent la frontière entre des phrases coordonnées et les pauses très courtes indiquent les frontières de constituants internes. L'analyse des pauses est un guide pour la segmentation des phrases dans la Langue des Signes Américaine.
Dans cet article nous décrivons une technique permettant d'améliorer la qualité de signaux de parole dégradés par du bruit additif non stationnaire. Cette technique est évaluée dans le cadre d'un système de reconnaissance de chiffres connectés perturbés par des bruits représentatifs d'environnements militaires. L'algorithme développé utilise une estimation de l'amplitude spectrale du signal de parole étant donnée une représentation paramétrique par état des modèles de la parole et du bruit. L'analyse spectrale est réalisée par un banc de filtres avec interpolation fréquentielle dont les paramètres sont sélectionnés en fonction de la nature du bruit. Les modèles sont des modèles ergodiques de Markov cachés appris sur du bruit et de la parole qui ont des distributions gaussiennes multivariées.
Ce dispositif permet de transformer certains paramètres de la voix d'un locuteur source de façon à approcher les caractéristiques acoustiques de la voix d'un locuteur cible. Nous nous intéressons ici particulièrement à la transformation du spectre à court-terme. Dans cette contribution, nous utilisons comme paramètre les formants, connus pour représenter de façon satisfaisante les caractéristiques acoustiques du conduit vocal. Notre méthode de transformation comprend deux phases distinctes : une phase d'analyse, dans laquelle nous extrayons les paramètres formantiques, et une phase d'apprentissage dans laquelle nous apprenons les transformations à l'aide d'un réseau de neurones. Les formants transformés sont ensuite utilisés, lors de la synthèse, dans un synthétiseur à formants.
Cette contribution décrit l'adaptation à l'analyse de l'intonation en allemand du modèle quantitatif proposé par Fujisaki et son application à la synthèse de F 0 par règles. Les valeurs paramétriques du modèle sont déterminées par une approximation automatique des contours de F 0 produits en langage naturel. Les sources potentielles de la variation des valeurs paramétriques sont examinées à l'aide de méthodes statistiques. Sur la base de ces analyses est formulé un ensemble de reègles qui exprime des traits linguistiques aussi bien que relatifs aux locuteurs individuels. Les règles produisent des contours d'intonation artificiels qui peuvent être interprétés relativement à des traits linguistiques, comme par exemple la modalité de phrase ou l'accent du mot. L'acceptabilité des patrons intonatifs produits sur la base des règles ainsi que le modèle adéquat des traits prosodiques sont évalués perceptuellement par des auditeurs professionnls (phonéticiens) et des auditeurs “naïfs”. En général, les énoncés resynthétisés avec des contours de F 0 produits par les règles sont jugés très acceptables et naturels par les deux groupes d'auditeurs.
La représentation en fréquence sur base d'un “line spectrum pair” a été proposée en tant que variante de la représentation paramétrique par prédiction linéaire. Dans le contexte du codage du signal de parole, la structure LSP possède de meilleures propriétes de quantification que les représentations LPC plus classiques. Dans cet article, la présentation LSP est étudiée dans le contexte de la reconnaissance automatique de la parole. Plusieurs mesures de distance sur base d'un modèle LSP sont étudiées dans le cadre d'une tâche de reconnaissance de voyelles soutenues. La mesure LSP pondérée s'avère être la meilleure. Elle a été comparée à d'autres mesures de distances mieux connues (c'est-à-dire les distances d'Itakura, cepstrale, cepstrale pondérée, de racine-puissance-somme, du rapport logarithmique d'aires et des coefficients de réflexion). La distance LSP pondérée permet un meilleur taux de reconnaissance que les autres mesures indiquées.
Les méthodes de classification non supervisée sont des outils de fouille de données qui visent à identifier des groupes d'objets similaires par rapport aux valeurs qu'ils prennent sur différentes variables. Les méthodes dites conceptuelles adjoignent à la partition une interprétation des classes en fonction des valeurs des variables présentes dans chacune des classes. Une telle structuration peut être décrite par un couple de partitions liées, appelé bipartition, constitué d'une partition des objets et d'une partition des modalités de variables. Cet article présente une étude de l'utilisation de méthodes de recherche locale pour la construction de bipartitions maximisant un critère de qualité défini par Goodman et Kruskal [GOO 54, GOO 59]. Nous proposons un algorithme basé sur le parcours stochastique d'une structure de voisinage sur l'espace de recherche des bipartitions possibles. Le critère d'arrêt est redéfini de manière statistique, ce qui permet de borner statistiquement la qualité de la solution obtenue. Enfin, une étude variationnelle de la fonction à optimiser permet de réduire la complexité du calcul.
Cette contribution vise à évaluer l'utilisation des variantes de prononciation pour différentes configurations de système, différentes langues et différents types d'élocution. Pour évaluer le besoin de variantes nous avons défini le taux de variant2+ qui correspond au pourcentage de mots du corpus qui ne sont pas alignés avec la meilleure transcription phonémique. Ce taux peut être considéré comme indicatif d'un éventuel besoin de variantes de prononciation dans le système de reconnaissance. Différents lexiques de prononciation ont été créés automatiquement générant différents types et quantités de variantes (avec surgénération). En particulier des lexiques avec des variantes parallèles et séquentielles ont été distingués afin d'évaluer la précision de la modélisation spectrale et temporelle. Dans une première étape nous avons montré le lien entre le besoin de variantes de prononciation et la qualité des modèles acoustiques. Nous avons ensuite comparé différents phénomènes de variantes pour l'anglais et le français sur des grands corpus de parole lue (WSJ et BREF). Une comparaison entre parole spontanée et parole lue est présentée. Cette étude montre que le besoin de variantes diminue avec la précision des modèles acoustiques. Pour le français, elle permet de révéler l'importance des variantes séquentielles, en particulier du e-muet.
L'auditeur réussit assez bien à identifier des paires de voyelles, et cela même lorsque les deux voyelles commencent et se terminent en même temps, sont présentées en monaurale, ont la même fréquence fondamentale (f 0) et ont approximativement la même intersité. La sensation décrite par l'auditeur est la suivante : une voyelle dominante “teintée” d'une seconde non-dominante. Une petite différence dans la f 0 améliore la performance et procure au sujet une sensation typique résultant de l'utilisation de deux sources de voix plutôt que d'une seule teintée d'une autre. La dominance pourrait refléter une stratégie de “décision” cognitive s'ajoutant au masquage spectral au niveau auditif périphérique.
Nous proposons, dans ce papier, un algorithme d'estimation automatique du rapport signal à bruit (signal-to-noise ratio – SNR) dans le cas d'un signal de parole bruité. Le choix de la technique d'extration des paramètres acoustiques est motivée par des propriétés neurophysiologiques du processus de modulation d'amplitude aux niveaux supérieurs du système auditif des mammifières. Celui-ci semblant analyser l'information à la fois en sous-bandes de fréquences et en terme de modulation de l'amplitude du signal entrant. Cette information peut-être représentée par un spectrogramme de modulation d'amplitude (amplitude modulation spectrogram – AMS). Un réseau de neurones est alors entraı̂né sur un grand nombre d'exemples d'AMS générés à partir de signaux de parole bruités. Une fois entraı̂né, le réseau de neurones est capable de produire une estimation du SNR lorsque des AMS de sources sonores inconnues sont présentées à son entrée. Des expériences de classification démontrent une estimation relativement précise du SNR dans des trames d'analyse indépentantes de 32 ms.
L'écriture manuscrite, comme la plupart des productions de l'activité humaine, présente une étonnante variabilité. Nous étudions cette variabilité afin d'obtenir, préalablement à sa reconnaissance, un premier degré de caractérisation de l'écriture manuscrite. Sur des écrits possédant peu de mots, ce premier degré de caractérisation peut être déterminé, au niveau de chaque mot, par un petit nombre d'observations largement indépendantes de leur contenu sémantique, et, par suite, propres à la main du scripteur. Une étude statistique portant sur 980 montants littéraux de chèques montre que ces observations sont peu corrélées entre elles : elles définissent un espace de variabilité inégalement dense, laissant ainsi apparaître la possibilité d'un regroupement des écritures en familles.
Cet article présente une nouvelle variante des Modèles de Markov cachés (HMM) “à Quantification Vectorielle Multiple” (MVQHMM). Sa caractéristique principale est d'utiliser un dictionnaire différent pour chaque modèle. On décrit les algorithmes d'apprentissage et de reconnaissance pour ces modèles. La procédure de reconnaissance combine le calcul de l'erreur de quantification de la séquence de vecteurs avec celui de la probabilité de sa génération par le HMM. De plus, les MVQHMM apparaissent plus robustes à la variabilité interlocuteur que les modèles discrets et semi-continus.
Nous proposons dans cet article une méthode originale pour rechercher, dans des séquences vidéo, des sous-séquences similaires. En introduisant de la flexibilité temporelle dans la caractérisation des sous-séquences, cette méthode permet d'éviter l'utilisation de mesures de distance flexibles (telles que le Dynamic Time Warping) qui ont l'inconvénient d'être lentes. La méthode proposée permet donc de rechercher, en temps réel, des sous-séquences vidéo similaires parmi plusieurs centaines de milliers d'exemples. La méthode proposée est adaptative ; un algorithme d'apprentissage rapide est présenté. Les performances ont été évaluées avec succès sur un ensemble de 1 707 clips vidéo (> 800 000 sous-séquences). A terme, notre objectif est de proposer un système de génération d'alertes et/ou de préconisations, en temps réel, dans le cadre de l'aide à la chirurgie sous contrôle vidéo.
La connaissance du langage repose-t-elle sur la représentation mentale de règles ? Rumelhart et McClelland ont développé un modèle connectioniste (parallel distributed processing, PDP) de l'acquisition du passé anglais qui parvient à produire la forme passé d'un certain nombre de verbes, à la fois réguliers (walk/walked) et irréguliers (go/went), à partir de leurs racines, et qui semble commettre certaines des erreurs et passer par certains des étapes de développement des enfants qui apprennent le passé anglais. Pourtant, le modèle ne contient pas de règles explicites ; il est exclusivement constitué d'un ensemble d'unités qui représentent des trigrammes de traits phonétiques de la racine, d'un ensemble d'unités qui représentent des trigrammes de traits phonétiques de la forme passée de la racine, et d'un réseau de connections entre les deux ensembles d'unités, connections dont la force varie en fonction de l'apprentissage. La conclusion de Rumelhart & McClelland est que les règles linguistiques ne sont peut-eˆtre en fait que des approximations pratiques et que les processus causaux réels de l'utilisation et de l'acquisition du langage doivent eˆtre caractérisés en termes de transfert de niveaux d'activation entre unités et de modification du poids de leurs connections. Nous avons analysé en détail les hypothèses linguistiques et de développement qui sous-tendent leur modèle et avons découvert que (1) le modèle ne peut pas représenter certains mots, (2) il ne peut pas apprendre beaucoup de règles, (3) il peut apprendre des règles que l'on ne rencontre dans aucune langue humaine, (4) il ne peut pas expliquer certaines régularités morphologiques et phonologiques, (5) il ne peut pas expliquer les différences entre formes régulières et irrégulières, (6) il ne parvient pas à accomplir la taˆche qui lui a été assigné, à savoir apprendre le passé anglais, (7) il explique incorrectement deux phénomènes de développement : les étapes de sur-régularisation de formes irrégulières comme bringed, et l'apparition de formes doublement marquées comme ated, enfin, (8) il donne une explication de deux autres phénomènes (la surrégularisation peu fréquente des verbes qui se terminent en t/d, et l'ordre d'acquisition des différentes sous-classes irrégulières) qui est indifférenciable de celle fournie par des théories utilisant des règles. En outre, nous montrons que c'est l'architecture connectioniste du modèle qui est responsable de ses nombreux défauts. Notre conclusion est que les affirmations des connectionistes quant à l'inutilité des règles dans les explications doivent eˆtre rejetées et que, bien au contraire, toutes les données militent en faveur de l'existence de telles règles.
L'A. critique plusieurs contributions grammaticales récentes qui tentent d'expliquer la fonction syntaxique de la forme wayyiqtol (dit » Impf. conséc. « ), en tant que marqueur de la narration : B. K. Waltke/M. O'Connor et P. Joüon/T. Muraoka, d'une part, et A. Niccacci, d'autre part). Il considère en particulier les paradigmes/modèles linguistiques qui sous-tendent selon lui ces contributions ( » philologie comparative « et » linguistique textuelle « ). Il critique l'explication étymologique de Waltke/O'Connor, mais modifie en même temps le modèle de linguistique textuelle proposé par Niccacci. En conclusion, l'A. signale l'erreur qui consiste(rait) à utiliser en priorité la construction paratactique des récits-LXX pour les traductions modernes de la Bible. Il faudrait par conséquent rendre, le plus souvent possible, les séries » monotones « de propositions débutant par wayyiqtol par la même disposition des phrases dans les langues-cibles modernes.
Cet article porte sur l'extension de la problématique classique de la découverte de règles de type « si a alors presque b » à la recherche de règles généralisées de type R^> R' où les prémisses R et les conclusions R' peuvent être elles-mêmes des règles. Dans le cadre de l'analyse statistique implicative développée initialement par Gras [GRA 79], [GRA 96], une première formalisation basée sur la notion de « hiérarchie orientée » a été récemment proposée [GRA 01]. Inspirée fortement par la classification ascendante hiérarchique, la démarche consiste à « agréger » des règles entre elles selon un mécanisme incrémental. Nous proposons ici une nouvelle formalisation du modèle qui met plus nettement en évidence les structures en jeu. Et, nous justifions l'emploi du terme hiérarchie, jusqu'alors utilisé métaphoriquement, en montrant que la mesure construite pour l'indicer vérifie les propriétés d'une ultramétrique. La démarche est illustrée sur un corpus de données réelles issu d'une enquête auprès d'enseignants de mathématiques du secondaire sur les objectifs assignés à leur enseignement.
Cet article décrit un système de récupération de documents oraux (Spoken Document Retrieval, SDR) pour des Emissions d'Informations (télévisées ou radio) britanniques et nord-américaines. Le système est basé sur un reconnaisseur de la parole à large vocabulaire connecté à un système de recherche probabiliste. Nous discutons le développement d'un reconnaisseur vocal en temps réel des Emissions d'Informations télévisées ou radio ainsi que son intégration au sein du système SDR. Pour cela, nous avons améliore deux approches a ce problème : la segmentation automatique et l'expansion statistique de la récupération des données en utilisant un corpus secondaire.
L'une des étapes les plus importantes de la compréhension du langage parlé est la segmentation du signal de parole en mots. Quand les conditions d'écoute sont mauvaises, les locuteurs peuvent aider ceux qui les écoutent en articulant bien, c'est-à-dire en produisant une “parole claire”. Nous avons examiné, au cours de quatre expériences, la production des frontières de mots dans la parole claire. Un rapport précédent a montré que les locuteurs qui articulent très soigneusement essaient effectivement de souligner les frontières de mots en effectuant une pause aux frontières et en allongeant les syllables qui les précèdent. De plus, ils appliquent particulièrement ces stratégies aux frontières qui précèdent les syllabes faibles. Les anglophonesemploient en effet une stratégie de segmentation telle qu'ils repèrent plus aisément les frontières de mots précédant les syllabes fortes ou accentuées ; le soulignement des frontières de mots précédant les syllabes faibles dans la parole claire permet de marquer les frontières qui seraient difficiles à percevoir. Le présent article décrit des données supplémentaires : les analyses prosodiques des syllabes qui suivent une frontière critique. Dans la parole claire, la durée est plus allongée et l'intensité davantage renforcée dans les syllabes faibles que dans les syllabes fortes. La fréquence fondamentale moyenne augmente aussi davantage dans les syllabes faibles que dans les syllabes fortes. Au contraire, le mouvement du ton augmente plus dans les syllabes fortes que dans les syllabes faibles. Ces effets sont toutefois très petits comparés aux allongements, observés auparavant, de la durée des syllabes précédent les frontières de mots et de celle des pauses à la frontière.
Au cours d' une conversation, les interlocuteurs travaillent ensemble pour construire une référence définie. Dans le modèle proposè, le locuteur initie le processus en présentant un syntagme nominal. Avant de passer à la contribution suivante, les participants, si cela est nécessaire, corrigent, développent ou remplacent ce syntagme nominal au cours d'un processus itératif jusqu'a ce que soit atteinte une version que tout deux acceptent. En faisant cela ils essaient de minimiser l'effort conjoint. La procedure préférée consiste pour le locuteur à présenter un syntagme nominal simple et pour l'allocuteur d'accepter ce syntagme en donnant le feu vert pour l'échange suivant. Nous décrivons une tache de communication an cours de laquelle deux personnes discutent l'agencement de figures complexes et nous montrons comment le modele proposé rend compte de nombreux traits des références produites. Le modéle découle, selon notre suggestion, de la responsabilité mutuelle que les participants prennent pour que soit compris chaque énoncé durant la conversation.
Quand ils parlent à des systèmes interactifs, les utilisateurs “sur-articulent” parfois, ou bien adoptent un type d'élocution, se voulant didactique, qui a été associé à une augmentation des erreurs de reconnaissance. Les buts de cette étude étaient les suivants (1) établir une méthode de simulation flexible pour étudier les réactions des utilisateurs aux erreurs des systèmes, (2) analyser le type et l'ampleur des adaptations linguistiques lors des résolutions d'erreurs entre l'homme et la machine, (3) fournir un modèle théorique unifié pour prédire et interpréter les adaptations de la parole de l'utilisateur au cours du traitement des erreurs de la machine, et (4) souligner les implications pour le développement de systèmes interactifs plus robustes. Une méthode de simulation semi-automatique permettant de générer de nouvelles erreurs a été développée pour comparer la parole de l'utilisateur juste avant et juste après l'apparition d'erreurs de reconnaissance de la part du système, et pour divers taux d'erreur de base. Les paires de phrases “originale versus répétée” ont ensuite été analysées du point de vue du type et de l'ampleur de l'adaptation linguistique. Il est apparu que, quand ils veulent corriger des erreurs de la machine, les utilisateurs modifient activement leur parole sur un axe d'hyper-articulation, réaction prédictible à leur identification de la machine avec un auditeur “à risques”. Tant pour des taux d'erreurs bas que élevés, les modifications de durée étaient manifestes et concernaient aussi bien l'allongement des segments de parole qu'une augmentation relative importante du nombre et de la durée des silences. En cas de taux d'erreurs élevés, la parole étaient également modifiée, incluant plus de traits phonologiques “hyper-clairs”, moins d'hésitations, et une fréquence fondamentale modifiée. Un modèle à deux niveaux, appelé CHAM (Computer-elicited Hyperarticulate Adaptation Model : modèle automatique d'adaptation hyper-articulée) est proposé pour rendre compte de ces modifications de la parole de l'utilisateur lors de résolution interactive d'erreurs.
Dans le cadre de la théorie de l'évidence ou théorie de Dempster-Shafer, la fusion de données est basée sur la construction d'une masse de croyance unique résultant de la combinaison de plusieurs fonctions de masse issues de sources d'information distinctes. Cette combinaison, appelée règle de combinaison de Dempster, ou somme orthogonale, possède différentes propriétés mathématiques intéressantes telle que la commutativité ou l'associativité. Cependant, cette combinaison, à cause de l'étape de normalisation, gère mal le conflit existant entre différentes sources d'information. La gestion du conflit n'est pas mineure, particulièrement lorsqu'il s'agit de fusionner de nombreuses sources d'information. En effet, le conflit a tendance à croître avec le nombre de sources d'information à fusionner. C'est pourquoi une stratégie de redistribution de ce conflit est indispensable. L'idée de cet article est de définir un formalisme permettant de décrire une famille d'opérateurs de combinaison. Pour cela, nous proposons un cadre générique afin d'unifier plusieurs opérateurs. Nous présentons, au sein de ce cadre de travail, les opérateurs de combinaison classiques utilisés dans le cadre de la théorie de l'évidence. Nous proposons ensuite d'autres opérateurs permettant une redistribution moins arbitraire de la masse conflictuelle sur les propositions. Ces opérateurs seront testés et comparés aux opérateurs classiques sur des fonctions de croyance synthétiques et des données réelles.
L'article étudie l'émergence des qualifications langue morte et langue vivante en France au XVII e siècle. Il s'appuie sur un dépouillement de sources métalinguistiques (grammaires, dictionnaires, recueils de remarques, traités divers). Une première partie traite de l'évolution des termes pour qualifier le latin et montre comment on est passé du motif de l'altération et de la corruption, présent depuis le XVI e siècle, vers celui de langue morte. Une deuxième partie montre comment le développement des théories de l'usage est concomitant de la valorisation nouvelle des langues vivantes. Une troisième partie montre comment les dictionnaires de la fin du siècle enregistrent l'opposition langue vivante / langue morte, ouvrant la voie à une manière d'organiser la représentation des langues qui se diffusera dans le contexte scolaire. Au travers de l'étude de ce paradigme émergent, c'est la question de la représentation des langues comme dotées de grammaires réglées ou comme vecteurs changeants de l'expression humaine qui est abordée.
Des mesures locales de distortions spectrales sont souvent utilisées pour évaluer la similitude (ou la distance) entre deux spectres à court terme. Dans cette étude, nous comparons différences mesures de distortion spectrale, entre autres la mesure de distorsion d'Itakura-Saito (IS), celle par quotient de vraisemblance logarithmique, la mesure de distortion par quotient de vraisemblance (LR), la mesure de distorsion cepstrale (CEP) et deux mesures de distortion basées sur la perception—le quotient de vraisemblance pondéré (WLR) et la métrique à pente pondérée (WSM). On souhaite déterminer leur effet sur les performances d'un système de reconnaissance de mots isolés par programmation dynamique (DTW). Deux modifications de la version de base de chaque mesure ont été également examinées—une distortion en fréquences selon une échelle en Bark et l'incorporation d'une information suprasegmentale—. Toutes ces mesures et leurs mldifications ont été testées sur une base de données multi-locuteurs (4) enregistrés par téléphone. Les résultats peuvent être résumés ainsi : (1) toutes les mesures de distorsion sur base LPC ont fourni des résultats satisfaisants. Les mesures de distorsion par quotient de vraisemblance logarithmique et par métrique à pente pondérée ont donné lieu aux meilleures performances de reconnaissance, tandis que la mesure d'Itakura-Saito a réalisé les performances les plus faibles ; (2) l'utilisation d'une information suprasegmentale a amélioré la reconnaissance, tandis que l'utilisation du grain et de la force sonore a dégradé les performances ; (3) la distorsion spectrale sur une échelle en Bark s'est révélée moins performante que son équivalent libre de toute distorsion, du moins sur notre base de données caractérisée par une largeur de bande limitée ; (4) la puissance du quotient de vraisemblance logarithmique pondérée est apparue réduite par rapport à son équivalent non pondéré.
La protéomique offre une approche puissante et complémentaire à la génomique. Elle permet de répertorier et caractériser les protéines, de comparer leur niveau d'expression entre un état physiologique sain et malade par exemple. En effet, le bruit du détecteur, le bruit électronique et chimique, la présence de peu de matériel protéique et enfin le bruit de la réduction des spectres (mauvais filtrage et/ou seuillage), tous ces bruits peuvent induire des Pics de Masses Parasites (PMP) et/ou supprimer des Pics de Masses Utiles (PMU) de faible intensité. La conséquence immédiate est que la présence des PMP et l'absence des PMU seront utilisées au dépens de la qualité d'identification de la protéine. Dans cet article, nous proposons un algorithme original éliminant les PMP, détectant et amplifiant ceux utiles. Le principe du pré-traitement utilise une Analyse Multirésolution (AM) couplée à un seuillage basé sur la logique floue (seuillage flou multi-échelle), une amplification locale des PMU, et enfin une correction adaptative de la Ligne de Base (LB). Le principe consiste à découper la bande passante fréquentielle de chaque spectre de masses en deux sous-bandes, une Basse Fréquence (BF), l'autre Haute Fréquence (HF), ensuite chaque sous-bande est à son tour découpée en deux sous-bandes etc. Les sous-bandes HF sont seuillées selon le critère de minimisation de l'entropie floue de Shannon et amplifiées localement, la ligne de base est calculée automatiquement et soustraite du spectre reconstruit. Pour évaluer la qualité de cet algorithme, nous présentons une comparaison des résultats obtenus par notre algorithme, et ceux fournis par le spectromètre MALDI-TOF (Matrix Assisted Laser Desorption/Ionisation-Time Of Flight), qui utilise le logiciel « DataExplorer » comme logiciel de réduction.
Les énoncés d'un discours peuvent varier selon deux dimensions essentielles : (i) leur position vis-à-vis de la hiérarchie des unités du discours, (ii) leur contenu, en termes d'actes du discours. L'amélioration des systèmes de dialogue oral peut donc être substantielle s'il est convenablement tenu compte des caractéristiques structurelles du discours et de l'intention d'un énoncé. Une question importante concerne donc la détection de ces éléments structurels. L'analyse de monologues et de dialogues homme-homme montre que la prosodie est un indicateur fidèle de ces facteurs. Cet article étudie dans une application de renseignements pour voyages touristiques ou d'affaires si les locuteurs utilisent la prosodie, pour souligner la structure du discours. Plus particulièrement, il explore si les locuteurs indiquent (i) un changement de thème en marquant prosodiquement le premier énoncé d'une partie du discours, et (ii) si un énoncé donné exprime une demande d'information ou une correction dans un sous-dialogue. Cette étude montre qu'en situation de dialogue homme-machine, la segmentation du discours et l'intention d'un énoncé peuvent être spécifiquement corrélées à des indices prosodiques, bien que les locuteurs puissent également avoir recours au choix d'une phraséologie particulière. L'intégration d'indices prosodiques dans les systèmes de dialogue oral semble donc être une issue prometteuse.
Dans cet article deux méthodes qui permettent d'obtenir des critères pour l'évaluation perceptive de détecteurs de voisement ont été testées et comparées. La première expérience consiste dans une tâche de “scanning perceptif” ; les sujets ont été priés de catégoriser les segments de parole de 30 ms comme “voisés”. Les jugements obtenus dans cette tâche s'avèrent très fiables, bien que la confiance des jugements sur la fin des segments soit moins grande que celle des jugements sur le début. Dans la seconde expérience, des versions différentes de parole resynthétisée ont été présentés à des auditeurs, qui ont été priés d'en apprécier la qualité relative ; les versions ne diffèrent que dans la position des transitions de voisement. La qualité de la parole dans laquelle les segments voisés ont été déterminés par le détecteur de mélodie SIFT, mais raccourcis de 20 millisecondes des deux côtés, est considérée comme la plus acceptable. On a constaté que l'acceptabilité des versions dans lesquelles les transitions de voisement ont été déterminées par les auditeurs à l'aide du “scanning perceptif” était à peine inférieure à celle dy “SIFT raccourci”.
Au début des années 90, la disponibilité du corpus TIMIT de transcription phonétique de parole dictée conduisit les chercheurs de AT&T à travailler sur l'inférence automatique des variations de prononciation. Ce travail, brièvement résumé ici, utilisa des arbres de décision construit à partir de traits phonétiques et linguistiques, et fut appliqué à la reconaissance de la parole dictée dans le domaine du DARPA North American Business News. Plus récemment, le corpus ICSI de transcription phonétique de parole spontanée fut mis au point à l'occasion des ateliers de travails d'été à l'université Johns Hopkins (WS) en 1996 et 1997. Un groupe de travail du WS97 mit l'accent sur l'inférence de la prononciation à partir de ce corpus afin de l'utiliser dans le domaine de la parole spontanée téléphonique DoD Switchboard. Nous décrivons plusieurs approches suivies à cette occasion. Ces approches incluent (1) une approche analogue à celle de AT&T, (2) une autre approche inspirée par le travail accompli à WS96 et à CMU qui nécessite l'addition de variantes de prononciation d'une séquence d'un ou plusieurs mots du corpus (`multimots', avec des probabilités extraites de ce corpus) au dictionnaire de prononciation du système de reconnaissance de la parole, et (1+2) une approche hybride où un model d'arbres de décision est utilisé pour déterminer automatiquement la transcription phonétique d'un corpus bien plus long que celui d'ICSI, et où l'approche multimots est utilisée pour construire un dictionnaire de prononciation pour la reconnaissance automatique de la parole.
Nous présentons ici un problème de conception de circuit à demande maximale, qui met en jeu des demandes de routages élastiques aux temps de parcours et qui est dérivé d'un problème général de synthèse de réseaux de transports publics. Ce problème implique la gestion sur un domaine de structure très irrégulière, d'une quantité induisant des temps de calcul très lourds. Afin de gérer à la fois la problématique classique des optima locaux et celle particulière de ces coûts de calcul, nous proposons un schéma métaheuristique dit de poursuite, fondé sur l'utilisation d'un processus de réécriture polymorphe du problème initial. Nous discutons diverses interprétations de ce schéma et présentons des expérimentations numériques.
Une analyse théorique du contrôle des composantes segmentales de la parole est proposée, qui s'appuie sur un certain nombre de résultats expérimentaux. La mise en évidence de phénomènes d'équivalence motrice entre deux constrictions, dont les variations se compensent pour préserver la même fonction de transfert du conduit vocal, est interprétée comme une première corroboration de l'hypothèse selon laquelle le contrôle segmental est orienté vers des objectifs acoustiques ou audio-perceptifs. Nous proposons que ces objectifs soient partiellement déterminés par des relations quantiques (appelées “effets de saturation”) entre les commandes motrices et les mouvements articulatoires, et entre l'articulation et le son. Considérant que les temps de traitement qui seraient nécessaires à l'exploitation en boucle fermée du feedback auditif seraient trop longs, nous proposons que la réalisation des objectifs acoustiques soit assurée via un contrôle mettant en jeu un “modèle interne” robuste, qui serait appris par le locuteur au cours de la phase d'apprentissage de la parole, et qui rendrait compte des relations entre l'articulation et le son. Des études menées sur des patients équipés d'implants cochléaires ou souffrant de neurinomes acoustiques bilatéraux ont fourni un certain nombre d'évidences en faveur d'un double rôle du feedback auditif chez l'adulte : (1) préserver et actualiser le modèle interne ; (2) prendre en compte l'environnement acoustique pour contribuer à assurer l'intelligibilité de la parole, en guidant des ajustements rapides des paramètres posturaux agissant sur le niveau sonore moyen de la parole, le débit d'élocution, et les inflexions de F0 et de niveau sonore associées à des facteurs prosodiques.
Dans cet article, nous proposons une nouvelle méthode de lissage des paramètres dans le cadre d'une architecture hybride pour la reconnaissance de la parole associant un réseau neuronal à délai TDNN et un modéle de Markov HMM. Dans cette architecture, le réseau TDNN et le module HMM sont combinés en utilisant les activations fournies par la deuxième couche cachée du TDNN comme entrées du quantificateur vectoriel flou (FVQ). L'algorithme HMM est adapté pour pouvoir traiter ces sorties FVQ. Pour améliorer les performances de l'architecture hybride, une nouvelle méthode de lissage des paramètres est proposée. Les valeurs moyennes des vecteurs d'activation de la deuxième couche cachée du TDNN modulaire sont utilisées pour générer une matrice de lissage dont sont extraites les probabilités p pondérées d'observation des symboles. Avec cette approche, les résultats de simulation sur une base de données de mots isolés en Coréen, en mode indépendant du locuteur, montrent une réduction du taux d'erreur de 44.9% par rapport à une Méthode de lissage classique.
Cet article décrit une méthode dont le but est d'adapter un système de reconnaissance basé sur des HMM à densité continue (appris sur des paramètres cepstraux représentant de la parole normale) pour rendre le système plus robuste en présence de bruit. Cette méthode, fondée sur la combinaison de modèles parallèles, permet de combiner les états appariés de bruit et de parole pour fournier un ensemble de paramères compensés. Ceci est une amélioration par rapport à des méthodes de compensation de la moyenne cepstrale car cette méthode permet aussi d'adapter les variances, ce qui permit de prendre en compte des rapports signal sur bruit beaucoup plus faibles. Nous montrons qu'elle donne de bons résultats pour un rapport signal sur bruit de 0 dB ou inférieur dans le cadre de bruits stationnaires et non-stationnaires. De plus, pour des conditions de bruit relativement constantes, cette méthode n'ajoute aucun temps de calcul en phase de test.
Dans cet article, nous présentons une méthode générique d'extraction et de reconnaissance de champs numériques (numéro de téléphone, code postal, etc.) dans des courriers manuscrits non contraints. La méthode d'extraction exploite la syntaxe des champs comme information a priori pour les localiser. Un analyseur syntaxique à base de modèles de Markov filtre les séquences de composantes qui respectent la syntaxe d'un type de champ connu du système. Nous montrons l'efficacité de la méthode sur une base de courriers manuscrits réels de type courrier entrant.
Dans cet article, nous présentons une étude exhaustive de la reconnaissance de la parole continue en espagnol. Nous avons dévéloppé un modèle semi-continu et contextuel dependant des classes des phones. En utilisant quatre phones, nous avons obtenu des réductions du taux des erreurs de reconnaissance qui sont approximativement équivalent à l'augmentation par pourcentage du nombre des paramètres, comparé avec le modèle semi-continu et contextuel qui sert de point de comparaison. Nous montrons également que l'utilisation de la pause dans le système d'entraı̂nement et les prononciations multiples dans le vocabulaire contribuent à améliorer le taux de reconnaissance considérablement. Les pauses actuelles des phrases d'entraı̂nement et le considération des effets d'assimilation améliorent la transcription dans des unitées qui dependent du contexte. Des multiples possibilités de prononciation sont générées en utilisant des règles générales qui s'appliquent facilement à n'importe quel vocabulaire espagnol. À l'aide de ces idées, nous avons réduit le taux des erreurs du système de base en plus du 30% dans un travail qui est parallèle à DARPA-RM, traduit à l'espagnol avec un vocabulaire de 979 mots. Notre base de données contient quatre locuteurs avec 600 phrases d'entraı̂nement et 100 phrases de test par locuteur. Toutes les expériences ont été réalisées avec une perplexité de 979 et même avec une perplexité un peu plus haute dans le cas des prononciations multiples pour pouvoir étudier la force du modèle en acoustique des systèmes sans contraintes grammaticales.
La reconnaissance de langue non-maternelle est un sujet qui prend de plus en plus d'importance dans les systèmes de reconnaissance automatique de la parole. La majorité des systèmes existants sont spécialisés dans la reconnaissance de langue maternelle et par conséquent les résultats de reconnaissance sont insuffisants. Une possibilité pour approcher ce problème est d'adapter les models acoustiques au nouvel orateur. Un autre moyen important est de prendre en considération les variations de prononciation non-maternelle dans le dictionnaire du système. La difficulté ici est la génération de variations de prononciation étrangère, plus particulièrement dans le cas oú plusieurs différents accents seraient à prendre en considération. Les approches traditionnelles pour modeler la prononciation ont besoin soit de connaissance phonétique soit de banques de données de parole volumineuses en langue non-maternelle. Ces deux méthodes sont trop coteuses particulièrement si une modélisation flexible de plusieurs accents est désirée. Nous proposons donc l'utilisation de banque de données de parole en langue maternelle uniquement pour la génération de variations de prononciation en langue non-maternelle. Nous avons combiné cette méthode avec la méthode d'adaptation de l'orateur MLLR. Nos expériences ont montré que l'utilisation d'un dictionnaire étendu par les variantes produites par cette méthode peut améliorer les resultats de 5.2% word error rate. En combinaison nous avons atteinds une amélioration de 18.2% en comparaison avec le dictionnaire normal.
Les terminologies métier sont au cœur de nombreuses applications : mémoire d'entreprise, gestion des savoir-faire et des compétences, veille technologique, recherche documentaire. La construction de terminologies est une tâche difficile pour laquelle il n 'existe pas de méthode générale unanimement acceptée. Nous verrons dans le cadre de cet article que le modèle ontologique pour la représentation et la signification des termes permet de garantir de telles propriétés. Elle définie une « Terminologie Ontologique » entre la « Terminologie Textuelle » et la « Terminologie Conceptuelle » .
Nous présentons un cadre unificateur pour l'inférence exacte et approchée dans les réseaux bayésiens. Ce cadre est utilisé dans “ProBT”, un moteur d'inférence généraliste permettant d'automatiser le raisonnement probabiliste et de faciliter la construction incrémentale des modèles. Cet article n 'a pas pour objectif de présenter ProBT, mais de décrire ses algorithmes sous-jacents et principalement l'algorithme “Successive Restrictions Algorithm ” (SRA) pour l'inférence exacte et l'algorithme “Monte Carlo Simultaneous Estimation and Maximization ” (MCSEM) pour l'inférence approchée. Ces expressions peuvent être “exactes ” ou bien “approchées ” et sont utilisées comme briques de base pour la construction incrémentale de modèles probabi- listes plus complexes.
Nous décrivons dans cet article une nouvelle méthode de classification d'images de télédétection. Ces images contiennent des données volumineuses et complexes : les informations sont parfois bruitées, parfois erronées. Avec notre approche, des règles de classification sont découvertes par un algorithme évolutif au lieu d'appliquer un algorithme de classification choisi a priori. Durant le processus évolutif de découverte, les règles de classification sont créées en utilisant des images de télédétection brutes, une expertise contenue dans des images classifiées, et des statistiques sur les concepts thématiques à découvrir. Les règles découvertes sont simples à interpréter, efficaces, robustes et résistantes au bruit. Nous détaillons dans l'article l'algorithme évolutif conçu, ainsi que des validations sur des images de télédétection qui couvrent non seulement la zone urbaine de Strasbourg, mais aussi une zone de végétation dans la lagune de Venise.
La qualité segmentale reste un des domaines les plus importants à étudier et à améliorer et nous avons évalué régulièrement cet aspect. Un test basé sur des VCV (voyelle-conspnne-voyelle) avec la consonne dans un contexte vocalique symétrique a été choisi. Toutes les consonnes du suédois peuvent se trouver dans cette position. Comme nous utilisons une réponse ouverte et des mots sans signification, toutes les confusions sont possibles. Dans le système le plus récent, de nouvelles stratégies de contrôle des paramètres ont été explorées. Auparavant, la plupart des paramètres de notre système avaient été spécifiés par des fonctions échelons lissées. Dans le nouveau système, l'algorithme général de lissage a ét'e remplacé par un algorithme d'interpolation linéaire. Le développement du nouveau système a nécessité une révision importante de l'ancien ensemble de règles. Le taux d'erreurs a progressivement diminué : 41,7% (1983), 26,1% (1987) et 12,8% (1989). Néanmoins, un effort important sur certaines consonnes est encore nécessaire pour améliorer davantage le système.
L'introduction d'une modélisation statistique par champs de Markov a récemment permis des avancées importantes dans nombre de problèmes classiques en analyse d'images. Ces modèles sont généralement associés à des algorithmes d'optimisation globale par relaxation qui restent coûteux en temps de calcul dans certaines applications. Or les techniques multigrilles, par ailleurs classiques en analyse numérique, peuvent conduire à des gains importants sur ce point. Pour l'heure il n'existe cependant pas réellement de support théorique permettant d'associer de façon simple et efficace stratégie multigrille et modélisation markovienne. Nous présentons dans cet article une approche multiéchelle de la modélisation markovienne qui est à la fois mathématiquement cohérente et facilement implantable. Nous détaillons son application sur deux exemples d'analyse du mouvement dans une séquence d'images : la détection du mouvement et la mesure du mouvement. Cela permet de mettre en évidence les apports de l'approche : accélération de la convergence et amélioration de l'estimée par rapport aux techniques markoviennes multirésolutions classiques.
Une méthode de recalage d'images multimodales 2D/3D entre Imagerie par Résonance Magnétique (3D) et à l'angiographie par rayons X (2D) est appliquée à la planification dosimétrique en radiochirurgie. Cependant, l'utilisation d'algorithmes de recalage dans la phase de planification permet de simplifier les procédures d'imagerie en diminuant l'usage du cadre sans contraindre la planification. Nous proposons ici les résultats préliminaires de l'application du recalage dans un contexte radiochirurgical par comparaison avec la méthode basée sur un repérage stéréotaxique qui constitue le gold standard. Les résultats préliminaires obtenus lors de cette première phase de validation permettent de conclure sur la compatibilité de certaines séquences d'images IRM avec le recalage d'images tomographique et de projection.
Au jour d'aujourd'hui, il est possible de développer des systèmes de reconnaissance de la parole exhibant de très bonnes performances pour différentes tâches et langues. Ceci résulte surtout de l'utilisation de puissantes approches statistiques de reconnaissance de formes, couplées avec la disponibilité de très grandes bases de données contenant des exemples de parole et de grammaire spécifiques à la tâche étudiée. Il est cependant également connu que ces bonnes performances de reconnaissance ne peuvent être préservées lorsque les données de test ne “ressemblent” pas aux données d'entraı̂nement. Une déformation du signal de parole apparait généralement comme une combinaison de variations acoustiques diverses, mais la forme exacte de cette distorsion est souvent inconnue et difficile à modéliser. Une façon de réduire ces différences acoustiques consiste à ajuster les paramètres caractéristiques du signal de parole selon des modéles de la distorsion. Une autre solution consiste à adapter les paramètres des modèles statistiques, par exemple les modèles de Markov cachès, de façon à ce que les modèles modifiés caractérisent mieux les caractéristiques du signal perturbé. Dépendant des connaissances utilisées, cette famille de méthodes de compensation des vecteurs caractéristiques et des paramètres des modèles peut se subdiviser en trois classes, à savoir : (1) compensation basée sur 1′ entraı̂nement, (2) compensation aveugle, et (3) compensation basée sur la structure. Cet article présente un aperçu des possibilités et limitations des approches de compensation et illustre leurs similarités et différences. La relation entre adaptation et compensation sera également discutée.
La gamme des produits à base terminologique nécessaires pour répondre aux nouveaux besoins en matière de gestion de connaissances et de documents s'élargit considérablement. Dans cet article, nous défendons l'idée que chaque type d'application passe par la mise au point de produits spécifiques à partir de textes et autres ressources du domaine. Nous proposons alors un cadre méthodologique unificateur et un ensemble de logiciels dont l'utilisation ciblée facilite le recueil de connaissances et la modélisation de ressources adaptées. Nous évoquons en parallèle les problèmes fondamentaux qui se posent et, lorsqu'elles existent, les solutions, techniques ou théoriques qui peuvent être envisagées. Nous nous appuyons pour cela sur trois études de cas de construction de ressources terminologiques à partir de textes pour des applications très différentes.
Dans ce contexte, les noyaux sur graphes fournissent une approche intéressante en combinant les méthodes d'apprentissage automatique et la représentation naturelle des molécules par graphes. Parmi les méthodes basées sur les noyaux sur graphes, la décomposition du graphe en sous-structures représente une importante famille de noyau. Dans cet article, nous présentons deux extensions d'un noyau précédemment basé sur les sous-structures non étiquetées à l'énumération de sous structures étiquetées et à la prise en compte de l'information cyclique des molécules. Nous proposons également des méthodes de sélection de variables permettant de pondérer un ensemble de sous-structures afin d'améliorer la précision de la prédiction.
On rend compte d'expériences de vérification du locuteur sur des chiffres isolés, de qualité téléphonique, utilisant des modèles de Markov cachés, discrets et semi-continus.
Une combinaison linéaire finie de variables aléatoires indépendantes de même loi non gaussienne ne peut être gaussienne. Dans le cas d'une combinaison linéaire infinie, il est d'usage de conclure à la normalité par application systématique du théorème de la limite centrale. La sortie des filtres Autorégressifs (AR) ou Autorégressifs à Moyenne Ajustée (ARMA) s'exprime sous la forme d'une somme infinie d'échantillons de l'entrée du modèle. Nous étudions dans cet article la loi de la sortie de ces filtres et plus particulièrement leur « proximité » avec la loi gaussienne.
Cet article traite du problème de l'évaluation des systèmes de vérification du locuteur. Son objectif est de présenter une façon concise et pertinente de caractériser ces systèmes. Il suggère l'emploi d'un “profil de performance” prenant en compte les aspects importants d'un système en test : le taux réel de vérification, la capacité mémoire demandée, la ressemblance des locuteurs dans l'ensemble de test, la qualité de la parole et la durée des données de parole en phase d'apprentissage et de test. Il présente des résultats montrant comment cet ensemble de mesures peut s'utiliser pour donner une représentation significative d'un système donné. Il ne s'agit pas dans cet article d'imposer une méthode particulière d'évaluation, mais de souligner quelles sont les solutions avancées. Il est en général nécessaire de préciser strictement les définitions de certains termes d'emploi courant avant de pouvoir comparer deux systèmes de vérification du locuteur de manière rigoureuse. Un consensus sur l'adoption d'un ensemble de mesures standardisées, dans la ligne de celui proposé ici, permettrait d'augmenter significativement la validité de telles comparaisons.
Jean Miélot joue un rôle important dans le renouvellement de la connaissance de l'Antiquité à la fin du Moyen Âge, en relayant à la cour de Bourgogne plusieurs textes de l'humanisme italien et en traduisant Cicéron. Il semblait donc opportun de s'intéresser tout spécialement au vocabulaire qu'il utilise pour traiter de l'ancienne Rome. Conformément à une conception utilitaire de la traduction, moins le texte est explicitement historique, plus les transpositions sont nombreuses. Le corpus ne dévoile aucune intention de créer ou d'améliorer le vocabulaire français en usage. Tout au contraire, Miélot s'inscrit dans la tradition d'illustres prédécesseurs comme Simon de Hesdin et Nicolas de Gonesse.
Parmi les données utilisées en identification juridique les empreintes digitales et les données génétiques semblent présenter un degré de fiabilité élevé. Il n'en n'est rien : un enregistrement de parole n'est pas une trace laissée sur une surface au contact d'une partie du corps d'un individu, ni un prélèvement direct opéré sur celui-ci. on comprend tout l'intérêt que pourraient offrir des techniques fiables d'identification du locuteur. En France il n'existe pas d'experts auprès de tribunaux répertoriés comme spécialistes d'identification vocale. Et pourtant certains “experts” prétendent identifier de façon certaine la voix d'un suspect et certains magistrats accordent, en France, beaucoup d'importance à ces analyses. L'auteur précise les conditions dans lesquelles sont faites, en France, les expertises vocales dans le cadre d'une procédure pénale ; tente de cerner les limites de ce protocole, les difficultés (et impossibilités) d'une évaluation probabiliste ; présente un rappel historique des discussions et prises de position de la communauté parole française depuis 1990 ; avance enfin des éléments de réflexion et des propositions qui pourraient être discutées par les spécialistes de parole en collaboration avec la police, la gendarmerie et la magistrature, au niveau national, européen (et international) pour faire avancer la recherche de preuve dans un cadre scientifique et aboutir à des protocoles bien balisés.
Cet article présente l'approche suivie dans le projet ANR StaRAC et en résume les résultats principaux. L'objectif était de reconsidérer le concept de stationnarité dans le but de lui donner une forme opérationnelle, se prêtant à une interprétation relative à une échelle d'observation et permettant de le tester dans un sens statistique précis grâce à l'emploi de substituts temps-fréquence, ainsi que d'en fournir diverses extensions, en particulier au-delà de l'invariance en translation.
Les besoins en codage de parole à débit variable existent pour un nombre sans cesse croissant d'applications telles que la visioconférence, l'audioconférence, les systèmes à multiplication de paquets (PCMS) et les communications avec les mobiles. Cet article étend le concept des codes imbriqués au codage CELP et VSELP à débit variable. Les gains orthogonalisés résultant permettent de déduire un nouvel algorithme d'optimisation des dictionnaires successifs dans le cas du codage CELP/VSELP multi-étages à codes imbriqués. Finalement les résultats subjectifs présentés montrent que les codeurs CELP/VSELP à codes imbriqués fournissent, aux débits de 24 et 32 kbit/s, une parole codée en bande élargie équivalente à celle du SB/ADPCM G722 à codes imbriqués fonctionnant à 56 et 64 kbit/s.
Cet article passe en revue et évalue trois modèles récents de l'apprentissage de la lecture par stades successifs (Marsh, Friedman, Welch, & Desberg ; Frith : Seymour). Il discute également des liens entre la “conscience phonologique” et la lecture, en particulier de la direction d'un éventuel lien causal. Les données d'une étude longitudinale de l'acquisition de la lecture sont exposées. Cette étude comprend des évaluations des capacités phonologiques des enfants avant qu'ils apprennent à lire. Les résultats suggèrent que (a) même si on se représente l'apprentissage de la lecture comme des stades successifs, tous les enfants ne passent pas par la même succession de stades ; (b) la “conscience phonologique” et l'apprentissage de la lecture entretiennent des relations causales réciproques et interactives, et non par une relation unidirectionnelle ; et (c) chez les enfants qui possèdent les meilleures capacités phonologiques. ces dernières peuvent jouer un rôle dans le tout premier stade de l'acquisition de la lecture. En conséquence, il est d'avancer que le premier stade dans l'apprentissage de la lecture implique toujours des procédures non-phonologiques telles que le traitement dit “logographique”.
Le but de ce travail est de définir un cadre commun incluant un ensemble de critères d'apprentissage discriminant et de méthodes d'optimisation pour la reconnaissance de la parole continue. Nous introduisons un critère discriminant fondé sur le rapport entre la vraissemblance des modèles corrects et concurrents. Ce critère général conduit à définir des critères spécifiques par le choix des séquences de mots en concurrence et par celui de la méthode de lissage. Des comparaisons analytiques et expérimentales sont menées pour les critères d'information mutuelle maximale (MMI) et d'erreur de classification minimum (MCE) ainsi que pour leur optimisation par la déscente de gradient (GD) et l'algorithme Baum étendu (EB). Une méthode de reconnaissance restrictive fondée sur une recherche arborescente est proposée pour réduire la complexité de l'apprentissage discriminant pour les grands vocabulaires. De plus une méthode efficace a été introduite dans l'apprentissage MCE, utilisant des graphes de mots pour le calcul des statistiques discriminantes. Des expériences de reconnaissance de parole continue ont été menées sur le corpus ARPA Wall Street Journal (WSJ) (vocabulaire de 5k mots) ainsi que pour la reconnaissance de chiffres connectés sur les corpus TI digit string (anglais américain) et Sie Till (allemand par téléphone). Les résultats analytiques et expérimentaux n'ont pas mis en évidence des différences significatives entre les méthodes d'optimisation EB et GD pour le critère MMI. Pour des modèles acoustiques de faible complexité, l'apprentissage MCE a fourni des résultats significativement meilleurs que l'apprentissage MMI. Les résultats de reconnaissance pour l'apprentissage MMI avec un grand vocabulaire sur le corpus WSJ montrent une forte dépendance à la taille du contexte pour le modèle de langage utilisé pendant l'apprentissage. Les meilleurs résultats ont été obtenus pour un modèle de langage unigramme avec l'apprentissage MMI. Aucune corrélation significative n'a été observée entre le choix du modèle de langage pour l'apprentissage et celui pour la reconnaissance.
Dans ce but, des demi-syllables ont été utilisées comme unités de segmentation et les suites de consonnes contenues dans celles-ci comme unités de décision pour la classification. Comparée au grandd nombre de demi-syllabes différences, l'utilisation de suites de consonnes réduit considérablement l'inventaire des classes. Trois expériences utilisant des mots allemands prononcés isolément ont été réalisées pour tester cette méthode. Dans la troisiéme expérience, un systéme complet de reconnaissance de 1000 mots a été développé, lequel réalise la segmentation, la classification de suites de consonnes et de voyelles ainsi que la correction d'erreurs de reconnaissance à l'aide d'un dictionnaire phonétique. La segmentation en demi-syllables s'est avérée appropriée en particulier pour le traitment d'un dictionnaire d'un grand vocabulaire.
De nombreux problèmes de traitement automatique des langues (TAL) se ramènent à des problèmes de classification. La complexité de la langue naturelle fait qu'il est difficile d'isoler les attributs discriminants pour une tâche donnée, que la fiabilité des valeurs associées à ces attributs est souvent faible et varie sur des corpus de domaines différents. Cet article défend l'idée que le formalisme des réseaux bayésiens est adapté à la classification de données décrites par de tels attributs. Nous avons estimé le bénéfice apporté par un classifieur bayésien sur une application réelle du TAL : la reconnaissance des pronoms anglais 'it' impersonnels et anaphoriques.
Ce texte, effectuant une synthèse de divers travaux de l'auteur, présente une méthodologie de modélisation des signaux non stationnaires, au moyen d'une classe de modèles autorégressifs à moyenne ajustée (ARMA). La non-stationnarité du signal y est caractérisée par l'évolution temporelle des coefficients du modèle : ceux-ci s'expriment comme combinaisons linéaires d'une famille de fonctions connues, suivant en cela les idées dues à Rao, Mendel, puis Liporace. Il sera montré que cette hypothèse conduit à un ensemble d'estimateurs dont on détaillera plusieurs variantes, pour les modèles autorégressifs, puis les modèles à moyenne ajustée, enfin pour les filtres en treillis, et leur paramétrisation en terme de fonctions d'aire logarithmiques. La synthèse de parole est une des applications où de tels modèles s'avèrent performants et une description de cette application concluera l'article.
Ce papier décrit le serveur téléphonique interactif à commande vocale MAIRIEVOX, développé par le CNET. Enfin, les développements industriels français dérivés de ce système sont rapidement décrits.
Nous présentons les définitions et synthèses de processus stochastiques respectant des lois d'échelles voilées, qui s'écartent de façon contrôlée d'un comportement en loi de puissance. Nous définissons des bruit, mouvement et marche aléatoire issus de cascades infiniment divisibles (IDC) voilées. Nous étudions analytiquement le comportement des moments des accroissements de ces processus à travers les échelles. Ces résultats théoriques sont illustrés sur l'exemple d'une cascade log-Normale voilée. Les algorithmes de synthèse et les fonctions Matlab utilisés sont disponibles sur nos pages web.
Les formes participiales des temps composés font l'objet d'un traitement particulier chez les grammairiens des différentes langues romanes depuis la Renaissance. Les formes participiales posent en effet un problème assez spécifique, dès lors que dans ces vernaculaires elles présentent des propriétés incompatibles avec la classe du participe telle que la définit la tradition latine. Certains proposent de recatégoriser ces formes en leur affectant une désignation ou une nouvelle classe avec des propriétés plus adaptées. La mise en série des options théoriques relevées dans un corpus étendu (XV e-XVIII e s.) tend à souligner l'importance de cette manière d'appréhender les données qui mettent à l'épreuve le modèle descriptif latin. Par ailleurs, la récurrence et la commensurabilité des solutions théoriques dans diverses traditions montrent l'intérêt de sortir du cadre des histoires nationales.
Nous présentons une évaluation de la durée des simulations de la machine de Boltzmann synchrone en phase de relaxation sur des stations de travail usuelles et des supercalculateurs vectoriels. Nous étudions l'impact des paramètres les plus importants : la topologie du réseau, la nature des connexions entre couches, le codage des états, la précision des calculs et l'architecture des machines utilisées. Nous proposons une méthode pour prédire l'ordre de grandeur des performances des différentes machines. Enfin nous montrons que ces performances permettent d'envisager à court terme l'utilisation d'une machine de Boltzmann de taille moyenne dans des applications pratiques.
Leséchecs de compréhension des aphasiques agrammatiques ainsi que leurs difficultésáconstruire des phrases ontétéattribuésáun déficit sous-jacent impliquant la recherche de la structure syntaxique. Dans cetteétude les performances de quatre sujets agrammatiques dans une taˆche de jugements grammaticaux montrent que ces sujets font preuve d'une remarquable sensibilitépour l'information structurell. Ces résultats indiquent que la connaissance syntaxique n'est pas atteinte chez l'agrammatique et suggérent que les troubles de compréhension de phrase ne reflétent pas une perte dans la capacitéàretrouver la structure syntaxique. L'interprétation selon laquelle les déficits seraient dusàunéchec dans l'utilisation de l'information transmise par la classe fermée (mots foncteurs) du vocabulaire est remise en cause. D'autres interprétations sont proposées pour rendre compte des problémes de comprehension des agrammatiques.
Cette contribution présente quatre tests visant à évaluer le module de génération de parole utilisé dans le système de dialogue vocal INSPIRE. Ce système a pour objectif le contrôle vocal des appareils domestiques d'une maison “intelligente”, soit sur place, par un ensemble de microphones, soit à distance, par téléphone. Le but des expériences est de quantifier l'impact de trois classes de facteurs sur la qualité du système : la première classe caractérise le comportement du système (sa voix et sa “personnalité”), la deuxième porte sur l'environnement physique (interface acoustique, bruit de fond, voie de transmission) et la troisième est liée à la tâche effectuée par l'utilisateur (situation d'écoute ou d'interaction, effet des tâches parallèles). Les résultats obtenus montrent que l'impact des deux premières classes de facteurs est important, mais pas celui de la troisième. Les raisons de cette observation sont discutées et prises en compte pour la finalisation du prototype du système.
Le langage de programmation Prolog III est une extension de Prolog au niveau de ce qu'il a de plus fondamental, le mécanisme d'unification. Il intègre dans ce mécanisme un traitement fin des arbres et des listes, un traitement numérique et un traitement du calcul propositionnel complet. Puis il illustre les possibilités accrues du langage à travers des exemples variés.
Cet article propose une présentation des systèmes de classeurs qui sont des outils destinés à l'apprentissage d'interactions. Il en existe de nombreuses variantes qui sont présentées par le biais d'une approche chronologique introduisant les nouveaux défis ou concepts abordés par chaque modèle. Nous décrivons les concepts de base que sont les algorithmes génétiques et l'apprentissage par renforcement. L'article présente ensuite les systèmes de base tels que le ZCS ou le XCS, les systèmes à anticipation, ainsi que les classeurs hiérarchiques ou hétérogènes.
Dans cet article, nous suggérons que des modèles de production de la parole fortement structurés pourront contribuer significativement à la réussite future des modèles de reconnaissance automatique de la parole, limités en ce moment par les faiblesses de la base théorique de la technologie actuelle. Nous suggérons en conclusion que l'interaction entre les domaines de la production et de la reconnaissance de la parole peut être particulièrement efficace si l'on intègre les modèles de production dans la stratégie d'analyse-synthèse probabiliste, utilisée déjà depuis longtemps en reconnaissance de la parole.
Cette recherche porte sur les changements temporels survenant dans la chaîne parlée lorsqu'un lecteur réalise un accent d'insistance (accent didactique) sur des mots-cibles inclus dans le texte, et analyse les formes prosodiques structurées qui en résultent. Les trois expériences présentées tentent de répondre aux questions suivantes : (1) Les changements temporels sont-ils limités à l'entourage immédiat des cibles (dernière syllabe et pause précédant la cible, durée d'énonciation de la cible, pause suivant la cible) ? (2) Ces divers changements temporels sont-ils corrélés ? (3) La nature même des marques typographiques permettant de repérer les cibles produit-elle un effet sur les modifications temporelles réalisées ? (4) L'accent didactique produit varie-t-il avec l'importance relative de la cible dans la signification du texte ? Deux locuteurs ont lu 16 textes différents présentés chacun deux fois, avec et sans mots-cibles signalés par un changement de typographie. Les valeurs des indices mesurés sur et avant la cible sont inter-corrélés, mais la valeur de la pause suivant la cible est indépendante. Les deux locuteurs sont insensibles aux déterminants typographiques et sémantiques. Les résultats témoignent des contraintes cognitives qui pèsent sur les décisions du locuteur lors de la lecture continue de textes.
L'objet de cet article consiste en un état de l'art des réseaux de neurones temporels et d'une comparaison de trois réseaux de neurones récurrents les plus représentatifs pour des applications de surveillance dynamique et de pronostic. Les critères de sélection de ces réseaux se situent à deux niveaux : temporel et architectural. Suite à l'application de ces critères, trois réseaux récurrents se distinguent : le RRBF, le R2BF et le DGNN. Des tests utilisant un benchmark de surveillance dynamique et un benchmark de pronostic nous permettent d'évaluer les performances des trois réseaux temporels en termes de temps de calcul et de capacité de traitement.
Différents niveaux d'affects sont exprimés dans différents niveaux du traitement de la parole : les expressions des émotions, relevant d'un contrôle déclenché involontairement, les expressions des attitudes et des intentions du locuteur et les stratégies expressives métalinguistiques. C-Clone (Communicative Clone) est présenté comme une architecture cognitive interactive de la communication expressive. Un sous-ensemble auto-annoté d'expressions émotionnelles a permis de valider la modélisation de la prosodie affective en contours gradients. Des expériences perceptives indiquent en outre qu 'aucune dimension acoustique prosodique n 'est spécifique à une valeur d'émotion.
Ce papier présente un formalisme relationnel pour la classification topographique de données qualitatives (ou catégorielles), se présentant sous forme d'une matrice binaire ou d'une somme de matrices binaires. L'algorithme de classification relationnelle topographique proposé s'inspire du modèle de Kohonen (conservation de l'ordre topologique) et utilise le formalisme de l'analyse relationnelle en optimisant un critère défini à partir du critère de Condorcet. Il s'agit d'un algorithme hybride « Batch-CRT » , qui se comporte linéairement par rapport à la taille des données, et permet simultanément une classification des données et une visualisation des classes découvertes sur une grille bidimensionnelle en préservant l'ordre topologique a priori des données. L'approche proposée a été validée sur plusieurs bases de données et les résultats expérimentaux ont montré des performances très prometteuses.
Le traitement dynamique de la parole dans le système auditif s'effectue apparemment par analyse de la forme spectrale et détection en parallèle du changement spectral. Cette formulation inspirée de Chistovich et al. (1982), constitue une hypothèse de base à partir de laquelle nous examinons le rôle auditif des diphtongues en tant qu'exemple de changement temporel du spectre. Il y a un désaccord très net dans la littérature en ce qui concerne les poids perceptifs relatifs des différents éléments d'une diphtongue. L'auditeur prête-t-il attention aux points extrêmes d'une diphtongue ou à son taux de changement spectral ? Cet article fournit des données supplémentaires pour essayer de résoudre ce conflit. Nos résultats montrent qu'un simple modéle cumulatif du traitement auditif du signal de parole est inadéquat. Il en va de même pour les modèles qui utilisent la vitesse de changement spectral comme déclencheur du processus de comparaison spectrale. Par contre, le rôle du changement spectral dans les diphtongues semble consister en (1) un drapeau qui commande un accrïssement supplémentaire de pondération perceptive en vertu du fait précisément qu'un certain changement intervient (2) un repère pour localiser les régions temporelles adjacentes qui sont importantes et qui devraient être échantillonnées de manière plus dense.
Cet article décrit un modèle pôle-zéro (ARMA) de la parole utilisant un algorithme de filtrage transversal rapide (FTF) basé sur les moindres carrés récursifs (RLS). Cet algorithme ARMA FTF permet d'estimer un signal d'excitation inconnu, et utilise celui-ci pour déterminer les paramètres du modèle pôle-zéro. L'algorithme est obtenu au moyen de projections géométriques. Cette approche permet d'accéder au fonctionnement de l'algorithme et d'interpréter utilement les différents filtres qui le composent. Nous donnons une évaluation des performances de l'algorithme en l'appliquant à l'estimation du spectre de signaux de parole synthétiques et naturels. L'algorithme est capable de représenter avec précision les pics et les vallées du spectre du signal de parole et nécessite moins de temps de calcul que les filtres maillés RLS et que l'algorithme ARMA FTF développé par Ardalan et Faber (1988). De plus, l'algorithme peut également être utilisé pour d'autres problèmes de traitement de signal pour lesquels le signal d'entrée est inconnu.
DragonDictate est un système de reconnaissance de la parole développé par Dragon Systems. Pour l'entraînement d'un tel système, une approche efficace consiste à utiliser des “phonèmes-en-contexte”, c.à.d. des triphones accompagnés d'un code concernant leur allongement éventuel devant une pause (PIC). A son tour, chaque PIC est représenté comme une suite de 1 à 6 élément phonétiques (PEL). Pour chaque phonème, il peut y avoir des milliers de PIC différent, mais les PEL sont tout au plus au nombre de 63. Initialement, tous les PIC et PEL sont entraînés à partir d'une base de données d'environ 16.000 mots enregistrés. Quand un nouveau locuteur utilise le système de reconnaissance, chaque mot reconnu sert immédiatement à adapter les PEL dans sa chaîne de Markov cachée. Après la reconnaissance d'environ 1.000 mots, la plupart des PEL se trouvent adaptés au nouveau locuteur. Ainsi, même les modèles de mots qu'il n'a jamais prononcés sont adaptés au locuteur. Nous avons essayé le système de reconnaissance avec 2 textes, qui diffèrent beaucoup sur le plan du vocabulaire et du style. Ils ont été lus par 3 locuteurs : un locuteur de référence, un nouveau locuteur masculin et un nouveau locuteur féminin. Après une phase d'adaptation d'approximativement 1.500 mots, le rendement pour les trois était meilleur que celui obtenu par le locuteur de référence avec des modèles non adaptés. Avec un vocabulaire actif de 25.000 mots, 86% des mots étaient reconnus correctement ; en plus 8% des mots figurant sur une liste de choix de 8 mots.
Dans cet article, des outils issus de la théorie de l'estimation sont proposés pour permettre l'évaluation des performances et le dimensionnement de systèmes expérimentaux. Ceux-ci ont été appliqués au système WACS (Whales Anti Collision System), système de localisation passive des cachalots vocalisants ou non afin de contribuer à réduire les collisions avec les navires. Basée sur des outils théoriques, l'approche proposée s'attache à se rapprocher au mieux de la réalité par les hypothèses effectuées. Sans monitorage de l'environnement acoustique, il est démontré que WACS est un bon outil pour le biologiste mais pourraît ne pas être assez précis pour être inséré au sein d'un réseau anti-collision.
Dans cet article une nouvelle approche de commande prédictive non linéaire est proposée pour un robot marcheur bipède à cinq segments sous actionné. La caractéristique principale dans la stratégie proposée est d'utiliser l'optimisation en-ligne pour mettre à jour les trajectoires à poursuivre sur les variables complètement commandables (coordonnées actionnées) dans le but d'améliorer le comportement et la stabilité des variables indirectement commandées (coordonnées non actionnés). L'approche proposée est illustrée à travers différents scénarios de simulations. La robustesse, quant à elle, est analysée par rapport à des incertitudes dans le modèle du robot, et des irrégularités dans le sol.
Nous passons en revue l'utilisation de l'algorithme “Time-Domain Pitch Synchronous OverLap-Add (TD-PSOLA)” dans le cadre de la synthèse à partir du texte. Nous en établissons les inconvénients et en déduisons trois conditions sur la base de données de parole. Afin de mieux y satisfaire, nous développons plus avant une technique de re-synthèse de haute qualité qui tire parti du modèle “Multi-Band Excited (MBE)”. Un des effets importants de cette opération est de rendre automatique l'operation de marquage de pitch. Elle permet également d'introduire un bloc d'interpolation temporelle dans la chaîne de traitement PSOLA. La technique de synthèse finale, appelée “Multi-Band Re-synthesis Pitch Synchronous OverLap Add (MBR-PSOLA)”, est ainsi pourvue de réelles possibilités de concaténation entre segments, sans que cela ne nuise à la simplicité initiale de l'algorithme TD-PSOLA.
Cet article présente le développement de modèles de Markov cachés à densités continues partagées (SC-HMM) précis pour la modélisation acoustique d'un système de reconnaissance de parole continue de grand vocabulaire, indépendante du locuteur. Deux méthodes sont décrites afin d'améliorer substantiellement l'efficacité du calcul des probabilités d'émission pour les SC-HMM. En premier lieu, on a créé des SC-HMM réduits, pour lesquels chaque état ne partage pas toutes les densités gaussiennes, mais seulement celles qui sont importantes pour cet état. Il se trouve que le nombre moyen de gaussiennes utilisées par état peut être réduit jusqu'a 70, sur un ensemble de 10 000 gaussiennes. Ensuite, un nouvel algorithme de sélection scalaire est présenté, qui réduit – sans détérioration des performances de reconnaissance – à 5% le nombre de gaussiennes qui doivent être calculées sur l'ensemble des 10 000 gaussiennes. Par ailleurs, le concept de modélisation dépendante du contexte avec regroupement d'état basé sur des arbres de décision phonétiques est adapté pour les SC-HMM. Plus précisément, un critère de division de nœud compatible avec les SC-HMM est introduit qui est basé sur une mesure de distance entre les mélanges de fonctions pdfs gaussiennes utilisés pour la modélisation des états des SC-HMM. Ceci contraste avec d'autres critères proposés dans la littérature qui se basent sur des fonctions pdfs simplifiées pour résoudre la complexité des calculs. Pour la tâche ARPA Resource Management, l'utilisation de notre critère offre une réduction relative des taux d'erreur de 8% par rapport à deux critères basés sur des fonctions pdfs simplifiées.
Les réseaux neuronaux sont de bons instruments pour la reconnaissance automatique de la parole non seulement parce qu'ils fournissent un mode de reconnaissance non linéaire mais aussi parce que leur architecture permet d'incorporer et d'exploiter notre connaissance actuelle de la parole. Dans la lère partie, nous soulignons que la définition du problème de la reconnaissance de la parole implique que la connaissance préalable de méthodes d'analyse linguistique est essentielle à sa résolution et suggère que la faible exploitation actuelle de cette connaissance est une conséquence des architectures contemporaines de reconnaissance des formes. Nous critiquons l'accent mis sur les algorithmes de reconnaissance des formes syntaxiques opérant au niveau du segment phonétique. La 2e partie démontre qu'une architecture en réseau pour le lexique fournit un mécanisme qui incorpore et exploite une gamme d'analyses phonologiques. De plus, par une séparation explicite entre les représentations phonologiques et phonétiques, il est possible de construire une conmposante phonétique d'entrée sur la base de principes relevant purement de la reconnaissance des formes. Par la normalisation du locuteur et de l'environnement, la composante phonétique peut être interfacée au réseau lexical pour aboutir à une architecture complète de reconnaissance qui évite les compromis lors de l'exploitation de la connaissance sur la parole.
Cet article présente la méthodologie sous-jacente à la conception de la procédure de vérification en virgule flottante du codeur de parole prédictif excité par codes à faible retard (LD-CELP), récemment retenu par le CCITT (recommandation G.728). Cette procédure est basée sur une spécification nun définie au bit près, ce qui diffère des procédures de vérification utilisées jusqu'ici pour les codeurs de parole au CCITT. Cette approche autorise one plus grande liberté pour implanter l'algorithme, et permettra des réalisations plus efficaces sur des matériels variés. Cependant, cette flexibilité entra^ine aussi que des implantations différentes produiront des réponses légèrement différentes aux séquences de test. Pour remédier à cet inconvénient, des mesures explicites et objectives de ces variations sont utilisées dann la procédure de vérification. Ces mesures sont de simples rapports signal à bruit (RSB), pondérés ou non. En plus de ces mesures objectives, un certain nombre de restrictions ont dû ^etre introduites dann la conception de séquences de test. Cependant, en dépit de ces restrictions sur ces entrées, un ensemble de séquences de test assurant one couverture satisfaisante de l'algorithme LD-CELP et de l'espace des états associé a pu être trouvé par des résultats expérimentaux. Des expériences de validation décrites ici montrent que ces séquences possèdent one capacité satisfaisante de détection des erreurs. La discussion finale conclut que la procédure de vérification proposée constitue un outil réaliste pour l'implanteur.
La caractérisation est une tâche supervisée de fouille de données qui permet de résumer de manière succincte et concise un ensemble de données. Cette tâche est intéressante dans la mesure où elle ne nécessite pas de contre exemples. Nous proposons un cadre général pour la caractérisation d'un ensemble d'objets, appelé ensemble "cible", en nous basant non seulement sur leurs propriétés propres mais aussi sur les propriétés des objets qui leur sont liés. Selon le type des objets considérés, différents liens peuvent être envisagés. Dans le cas de bases de données géographiques, ce sont les relations spatiales qui expriment des liens entre objets géoréférencés. Nous proposons des algorithmes d'extraction de règles de caractérisation et nous montrons comment nous les avons appliqués à des données géographiques réelles fournies par le BRGM.
Un court siècle a transformé la France urbaine. Un nouveau genre de spectacles, la revue théâtrale locale, a accompagné cette mutation d'environ 1855 à 1930. D'anciens citadins ne reconnaissaient plus un cadre de vie que découvraient simultanément de jeunes ruraux. Le développement d'une industrie du spectacle facilita sans doute l'intégration culturelle. Rire - ou sourire - en ville contribua à une coexistence qui devint identité, sans pour autant faire oublier les différences sociales.
Nous proposons un modèle de représentation statistique de la structure conceptuelle d'un sous-ensemble parlé du langage naturel. Le modèle est utilisé pour segmenter une phrase en propositions et pour étiqueter celles-ci avec des relations de concepts (ou cas). Le modèle est entraîné au moyen d'un corpus de phrases dont la transcription est annotée. Un système de compréhension est construit sur base de ce modèle permettant une entrée vocale sans contraintes dans le cadre d'une tâche de consultation de banque de données. Le but de cet article est de donner des détails et des résultats concernant le nouveau modèle de représentation du langage. Dans ce but, le modèle a été implémenté et testé avec un texte en entrée. Les paramètres du modèle ayant été estimés par l'intermédiaire de 547 phrases d'entraînement, les résultats d'un test effectué sur 148 phrases ont montré que presque 97% des concepts ont été correctement détectés et étiquetés par la procédure automatique d'étiquetage de concepts ; finalement, 65% des phrases ont été correctement comprises.
Plusieurs études ont récemment été menées sur l'attribution de compétences cognitives et de caractéristiques psychologiques à des agents artificiels. Cependant ces études reposent sur des approches procédurales, difficiles à analyser, et elles se focalisent sur des phénomènes particuliers au lieu de couvrir une partie significative du domaine psychologique des humains. Nous présentons ici une approche systématique de l'implémentation du principe stipulant que les traits de personnalité ont une influence potentielle et effective sur le processus de décision rationnelle d'agents cognitifs.
L'étude de la parole et de l'émotion, partie du stade de la recherche exploratrice, en arrive maintenant au stade qui est celui d'applications importantes, notamment dans l'interaction homme–machine. Le progrès en ce domaine dépend étroitment du développement de bases de données appropriées. Cet article aborde quatre points principaux qui méritent notre attention à ce sujet : l'étendue, l'authenticité, le contexte et les termes de description. L'article montre comment trois récents projets importants (celui de Reading–Leeds, celui de Belfast, et celui de CREST–ESP) ont relevé le défi posé par la construction de bases de données appropriées. A partir de ces trois projets, ainsi que d'autres travaux, les auteurs présentment un bilan des outils et méthodes utilisés, identifient les problèmes qui y sont associés, et indiquent la direction dans laquelle devraient s'orienter les recherches à venir.
Cet article traite du problème de la reconnaissance en temps-réel de la parole en milieu bruyant. Les nombreux travaux qui ont été effectués dans ce domaine n'ont pour l'instant abouti qu'à des succès limités. La raison essentielle en est que les performances des algorithmes de reconnaissance sont prédites à partir d'hypothèses sur les conditions d'environnement pour lesquelles les algorithmes sont conçus et implémentés. Ce système prend en compte à la fois les effets du bruit additif sur le signal de parole émis et les effets sur le système de production de parole lui-même. Les évaluations montrent une amélioration moyenne du taux de reconnaissance de +17.28% dans 11 conditions d'émission de parole en milieu bruyant.
En reconnaissance de la parole, le signal est habituellement représenté par un ensemble de séquences temporelles de paramètres spectraux (TSSPs) qui modélisent l'évolution temporelle, trame par trame, de l'enveloppe spectrale. Ces séquences sont ensuite filtrées soit pour les rendre plus robustes aux conditions de l'environnement ou pour calculer des paramètres différentiels (indices dynamiques) qui améliorent la discrimination. Dans cet article, nous appliquons une analyse fréquentielle aux TSSPs afin de fournir un cadre d'interprétation pour les divers types de filtres de paramètres utilisés jusqu'à présent. Ainsi, l'analyse du spectre moyen à long-terme des séquences correctement filtrées révèle un effet combiné de l'égalisation et de la sélection de bande qui fournit des informations intéressantes sur le filtrage TSSP. Nous montrons également que, quand des paramètres différentiels supplémentaires ne sont pas utilisés, le taux de reconnaissance peut être amélioré même pour de la parole non bruitée, juste en filtrant les TSSPs de manière appropriée. Pour confirmer cette assertion, un certain nombre de résultats expérimentaux sont fournis, en utilisant tant des modèles de mots que des modèles phonétiques. Les filtres empiriquement optimaux atténuent la bande des basses fréquences et accentuent celle des hautes fréquences, de sorte que le pic du spectre moyen à long-terme de la sortie de ces filtres se situe aux alentours de la vitesse syllabique moyenne de la base de données utilisée (3 Hz, environ).
À ces deux types d'erreurs peuvent être associés deux types de rejet : le rejet d'ambiguïté et le rejet d'ignorance. Par contre, les approches qui agissent par modélisation sont par nature mieux adaptées à ce second type de rejet, mais ne s'avèrent que peu discriminantes. Ainsi, nous proposons de combiner les deux types d'approche au sein d'un système de classification à deux niveaux de décision. Au premier niveau, une approche par modélisation sera utilisée pour rejeter les données aberrantes et pré-estimer les probabilités a posteriori. En outre, cette combinaison présente l'avantage de réduire la complexité de calcul associée à la prise de décision des SVM. Ainsi, les résultats obtenus sur un problème classique de reconnaissance d'images de chiffres manuscrits isolés ont montré qu'il est possible de maintenir les performances associées aux SVM, tout en réduisant la complexité d'un facteur 8.7 et en permettant de filtrer efficacement les données aberrantes.
On propose une méthode utilisant des techniques de traitement optique pour l'analyse et la reconnaissance de la parole. Elle est mise en oeuvre sous la forme d'un processeur optique comportant un laser HeNe, des lentilles optiques, des plaques photographiques et des diffuseurs. Un calculateur personnel permet de traiter les données expérimentales produites par l'ensemble du système de traitement optique. Cette méthode de traitement optique a l'avantage intrinsèque de permettre un traitement parallèle et à haute vitesse de signaux bi-dimensionnels : par suite, les évolutions temps-fréquence d'un signal mono-dimensionnel peuvent être obtenues sans déplacer de fenêtre le long de l'axe temporel et la comparaison de formes pour la reconnaissance de parole peut être réalisée sur les périodes courtes. Des productions de voyelles et de syllabes ont été analysées à l'aide de ce processeur : les résultats montrent une concordance forte avec ceux obtenus par simulation informatique. On montre que la déformation nonlinéaire de l'axe temporel, indispensable en reconnaissance de mots, est réalisée par le contrôle de la fonction de transfert de la plaque de fenêtrage. La comparaison de formes sur les voyelles donne une reconnaissance correcte des cinq voyelles. Ces résultats montrent la validité du processeur optique. L'utilisation de cristaux liquides est aussi proposée pour la plaque de fenêtrage : une expérience a été menée concernant l'analyse des voyelles. Une comparaison de formes, quasi temps-réel et avec déformation temporelle nonlinéaire est rendue possible par le contrôle électrique de la plaque à cristaux liquides en utilisant, comme signal de rétro-action, le résultat de la comparaison précédente.
Pour différents signaux de parole voisée, l'instant de la fermeture de la glotte a été déterminé en utilisant la pseudo-distribution de Wigner-Ville lissée et la méthode de Wong. Les deux méthodes donnent des résultats équivalents quand cette détermination est facile. Quand la détermination devient difficile, la pseudo-distribution de Wigner-Ville lissée peut être encore employée dans certains cas où la méthode de Wong cesse d'être utilisable.
Nous nous intéressons à l'utilisation de dispositifs mobiles pour l'apprentissage informel en musée. De nombreux travaux s'appuient sur une représentation sémantique des œuvres, pour la présentation d'informations en mobilité. Cependant, ces travaux prennent peu en compte le caractère situé de la visite. Nous proposons dans cet article le modèle CALM (ContextuAlized Learning through Mobility) qui associe à la représentation sémantique des œuvres des informations contextuelles sur l'utilisateur et sur sa situation.
Les scores retournés par les séparateurs à vaste marge sont souvent utilisés comme mesures de confiance pour la classification de nouveaux exemples. Cependant, il n'y a pas de fondement théorique à cette pratique. C'est pourquoi, lorsque l'incertitude de classification doit être estimée, il est plus sûr de recourir à des classifieurs qui estiment les probabilités conditionnelles des classes. Ici, nous nous concentrons sur l'ambiguïté à proximité de la frontière de décision. Nous proposons une adaptation de l'estimation par maximum de vraisemblance. Le critère proposé vise à estimer les probabilités conditionnelles, de manière précise à l'intérieur d'un intervalle défini par l'utilisateur, et moins précise ailleurs. Le modèle est aussi parcimonieux, dans le sens où peu d'exemples contribuent à la solution. Nous appliquons ce critère à la régression logistique. Ce modèle de régression logistique parcimonieuse sera ensuite validé par le jeu de données Forest Covertype de l'UCI.
L'acquisition des savoir-faire de parole par l'être humain comprend l'apprentissage “simultané” de sa perception et de sa production, dans un environnement de locuteurs ayant déjà assimilé ces savoir-faire. En revanche, quand la parole est traitée par des machines, la reconnaissance et la synthèse de la parole sont étudiées et implémentées séparément (et l'on a développé des méthodes différentes pour chacune). Le présent article propose une structure d'acquisition de la parole par des machines dans laquelle l'apprentissage de la reconnaissance et de la synthèse se fait simultanément à partir de parole naturelle. La structure consiste en une chaîne de synthèse dans laquelle un synthétiseur est contrôlé par un réseau de neurones artificiels à partir d'un vecteur d'état de synthèse, et d'une chaîne de reconnaissance comprenant un réseau de neurones de reconnaissance qui produit un vecteur d'état de reconnaissance Le système de reconnaissance reçoit successivement de la parole naturelle pour l'apprentissage et de la parole synthétique. Une minimisation couplée est mise en œuvre pour entraîner le système de reconnaissance à classifier ou à reconnaître de la parole naturelle, et le synthétiseur à produire de la parole synthétique qui peut être reconnue comme appartenant à la même classe que la parole naturelle. Une démonstration de l'algorithme est faite pour l'acquisition de voyelles et de mots simples isolés.
Cet article aborde le problème de la prise de décision décentralisée dans les colonies de robots autonomes et coopératifs. Toutefois, ils ne proposent qu'une modélisation restreinte du temps et des actions et ne permettent pas la prise en compte de certaines propriétés des colonies de robots autonomes. Afin d'étendre l'applicabilité des DEC-MDPs à la robotique collective, nous proposons un modèle, nommé OC-DEC-MDP, basé sur les DEC-MDPs qui permette une modélisation plus adéquate du temps et une gestion des contraintes sur l'exécution des tâches. Nous décrivons également un algorithme de faible complexité permettant une résolution approchée des problèmes formalisés sous forme d'OC-DEC-MDP. L'approche présentée permet ainsi de résoudre les problèmes de décision rencontrés dans les colonies de robots autonomes.
Le cliquetis dans les moteurs à allumage commandé demeure un problème pour les motoristes. La détection du cliquetis doit en effet permettre de réaliser un compromis entre l'optimisation du rendement du moteur, la consommation de la voiture et le respect des normes en matière de dépollution. Souvent l'allumage est réglé avec une marge de sécurité qui garantit l'absence de cliquetis même en cas de variations de la qualité du carburant. L'enjeu de l'élaboration d'une méthode de détection de cliquetis est de se rapprocher le plus possible des conditions limites de cliquetis tout en évitant son apparition. L'objectif de l'étude présentée consiste à évaluer l'intensité du cliquetis produit dans la chambre de combustion à partir d'un enregistrement fourni par un accéléromètre placé sur le bloc moteur. Son but est de reconnaître trois types de cliquetis : l'absence de cliquetis, le cliquetis naissant et le cliquetis violent. L'approche envisagée pour mener à bien cette détection fait appel aux techniques du diagnostic par reconnaissance des formes floue. La méthode, mise au point à l'aide d'un ensemble d'apprentissage, conduit à la réalisation de plusieurs processus de diagnostic qui coopèrent.
Le présent article introduit le système informatique ALTO conçu afin de favoriser le développement et l'expérimentation d'algorithmes de génération de tournées pour des véhicules de transport. Ce système repose principalement sur une “heuristique générale”, soit un ensemble de modèles qui sont instancies par un utilisateur expert à l'aide de ses propres formules afin de créer des algorithmes spécifiques. Il devient dès lors possible de reproduire de nombreux algorithmes classiques décrits dans la littérature ou encore de concevoir de nouvelles approches de résolution face aux problèmes rencontrés. Une application concrète dans le domaine de la collecte du courrier est d'ailleurs présentée à la fin de l'article afin de souligner l'intéret d'un tel système.
Cet article présente une adaptation du boosting à l'inférence grammaticale. Notre but est d'améliorer les performances d'un algorithme à base de fusion d'états, en présence de données bruitées. Cette information est une évaluation de la confiance en l'étiquette d'un exemple. Nous montrons que la règle de mise à jour des poids conserve les propriétés théoriques du boosting. Nous décrivons enfin une étude expérimentale sur l'algorithme à base de fusions d'états RPNI*, dont les performances sont significativement améliorées.
Nous proposons une reformalisation de l'analyse spectrale autorégressive régularisée dans le cadre de l'approche varia- tionnelle en considérant le polynôme autorégressif comme une transformation du cercle complexe unité en une courbe paramétrique fermée et orientée dans le plan complexe (théorie globale des courbes planes fermées : classe d'équivalences d'immersions du cercle complexe unité dans le plan Euclidien). Nous montrons que l'Equation d'Euler-Lagrange associée nous ramène à la solution par moindres carrés régularisés classique. Nous posons ensuite le problème sous une forme géométrique intrinsèque pour laquelle la solution est définie comme une géodésique minimale particulière dont la métrique dépend explicitement du terme d'adéquation aux données. Le calcul des variations alors, en redéfinissant la notion de courbure d'une fonction complexe, une équation aux dérivées partielles (EDP) de type « flot de courbure moyenne » . La discrétisation du problème via la transformée en Z aboutit à une EDP agissant sur le vecteur des paramètres autorégressifs. Cette seconde approche permet de s'affranchir de l'optimisation de l'hyperparamètre de régularisation intervenant dans l'approche de Tikhonov classique, en stoppant l'EDP dès que sa vitesse d'évolution est ralentie. Le second avantage réside dans la formalisation EDP qui permet naturellement l'estimation continue, en ligne, du spectre au rythme du flot des données. L'extension de cette formalisation au Cepstre, dont la distance induite ainsi que celle du retard de groupe sont très utilisées en signal, fait apparaître le cepstre différentiel comme la transformation de Hopf-Cole du polynôme autorégressif et induit donc une évolution associée selon l'équation de Burgers conditionnellement aux données. Nous concluons en utilisant l'interprétation de l'intégration complexe par Polya en terme de flux et de travail d'un champ de vecteurs pour montrer que la régularisation tend à rendre non-divergent et irrotationnel le champ de vecteurs autorégressifs conjugués sur le cercle complexe unité.
Cette étude vise à déterminer l'effet de l'orientation du cahier des charges comme une aide aux concepteurs pour réaliser des sites web plus faciles d'utilisation. En effet, aussi bien les professionnels que les débutants confrontés au CCU prennent en compte oralement et respectent, dans leurs maquettes, un nombre important de contraintes liées à l'utilisateur sans pour autant que cela nuise à la prise en compte de contraintes liées au commanditaire. Cela n 'est pas le cas pour les concepteurs confrontés au CCM. Bien que les résultats soient encourageants, les maquettes réalisées comportent encore un nombre important de problèmes ergonomiques. Nous concluons par la présentation d'études et de pistes de recherche pour aider les concepteurs à réaliser des sites plus simples d'utilisation.
Dans cette contribution, nous décrivons une méthode de transformation du locuteur par interpolation de formes de références à l'aide de réseaux de fonctions à symétries radiales (Radial Basis Function ou RBF). L'intérêt principal de cette méthode d'interpolation réside dans le fait qu'elle reste exploitable même lorsque le nombre de données disponibles pour apprendre la transformation est limité. Les fonctions d'interpolation de différents ordres sont pondérées et additionnées, en utilisant les coefficients de pondération donnés par le réseau RBF. Un certain nombre d'expériences ont été conduites dans une tâche prototype de transformation (4 locuteurs). Dans une deuxième expérience, l'ensemble d'apprentissage est composé de 10 mots ; la transformation par interpolation de fonctions multiples permet d'atteindre 48% de réduction.
Cet article présente une étude en apprentissage automatique semi-supervisé asymétrique, où seules des données positives et non étiquetées sont disponibles, ainsi qu 'une application à un problème bio-informatique. Nous montrons que sous des hypothèses faibles, le classi- fieur naïf de Bayes peut être identifié à partir de données positives et non étiquetées. Nous en déduisons des algorithmes que nous étudions sur des données artificielles. Enfin, nous présentons une application de ces travaux au problème de l'extraction d'affinités locales dans les protéines pour la prédiction des ponts disulfures.
Nous nous plaçons dans le cadre de la classification automatique. Nous abordons le problème de l'estimation du nombre de classes et des paramètres qui leurs sont associés. Nous proposons une méthode utilisant l'hypothèse contextuelle inhérente aux images pour discriminer les différentes classes. Cette méthode est validée à la fois sur le plan théorique et sur des images de synthèse et des images réelles. Nous montrons, en outre, que la méthode proposée a un domaine de validité plus étendu que les méthodes fondées sur une analyse des modes de ('histogramme. Nous discutons ensuite de la forme du potentiel d'attache aux données dérivé de cette classification dans le cadre d'une segmentation markovienne. Les résultats sont obtenus avec deux modèles a priori différents : le modèle de Potts et le chien-modèle.
Cet article présente un ensemble de mesures pour la reconnaissance du locuteur. Ces mesures reposent sur des tests statistiques du second ordre, et peuvent être exprimées sous un formalisme commun. Différentes expressions de ces mesures sont proposées et leurs propriétés mathématiques sont étudiées. Dans leur forme la plus simple, ces mesures ne sont pas symétriques, mais elles peuvent être symétrisées de différentes façons. Toutes les mesures sont testées dans le cadre de l'identification du locuteur indépendante du texte en ensemble fermé, sur 3 versions de la base de données TIMIT (630 locuteurs) : TIMIT (parole de très bonne qualité), FTIMIT (version filtrée de TIMIT) et NTIMIT (qualité téléphonique). Des performances remarquables sont obtenues sur TIMIT, mais les résultats se dégradent naturellement avec FTIMIT et NTIMIT. La symétrisation apparaît comme un facteur d'amélioration, plus particulièrement lorsque l'on dispose de peu de parole. Il est finalement suggéré, comme conclusion à ce travail, d'utiliser certaines mesures proposées comme méthodes de référence pour évaluer la complexité intrinsèque d'une base de données quelconque, sous un protocole donné.
Nous présentons dans cet article une application complète des « Support Vector Machine » au contrôle qualité par vision artificielle de pièces à géométrie complexe. Nous précisons le cadre pratique dans lequel s'effectuent les opérations, la nature des défauts à détecter ainsi que les techniques d'extraction des paramètres discriminants. Nous présentons ensuite les trois méthodes de classification utilisées. Nous définissons le protocole d'apprentissage, ainsi que la méthode de recherche des paramètres optimum du classifieur. Nous comparons les résultats obtenus à partir d'un espace de description défini a priori ainsi que ceux issus d'une sélection de paramètres via un algorithme séquentiel.
Cette contribution aborde la façon dont Bar Hebræus a emprunté au grammairien arabe Zamaḫšarī la notion de transitivité et comment il l'a reformulée dans le cadre de sa grammaire du syriaque. Je procède en traduisant et commentant son texte et en comparant avec celui de Zamaḫšarī. Son chapitre s'organise en quatre sections : 1. Première section : à propos d'exemples de verbes intransitifs et transitifs ; 2. Deuxième section : des causes de la transitivité ; 3. Troisième section : à propos de l'échec des causes de la transitivité ; 4. Quatrième section : à propos des verbes qui sont à la fois transitifs et intransitifs. C'est dans ces deux dernières sections que se manifeste le mieux la différence entre les deux grammairiens ; et il apparaît que si Bar Hebræus a emprunté le concept de transitivité à Zamaḫšarī, il en a donné un traitement qui dépasse largement sa source. En effet, la seule préoccupation du grammairien arabe est d'assurer que tous les compléments sont bien à l'accusatif et d'identifier les causes de la transitivité. Enfin Bar Hebræus étudie en détail les verbes labiles qui sont à la fois transitifs et intransitifs.
Cet article examine les formes d'écoulement d'air lors des transitions voyelle-consonne et consonne-voyelle. L'écoulement d'air buccal a été enregistré chez 6 locuteurs anglais-américains répétant des énoncés. Un filtrage inverse du signal a été effectué pour obtenir une estimation des impulsions glottiques. On a mesuré les écoulements maximum et minimum, le quotient d'ouverture, la zone des impulsions et la fréquence fondamentale. Les résultats montrent de grandes variations dans les caractéristiques des impulsions à la transition entre voyelles et consonnes sourdes. En particulier, la source est caractérisée par un mode de phonation rauque. Cette raucité est associée à de larges variations de l'écoulement et à une valeur du quotient d'ouverture proche de 1. Les variations observées peuvent être dues aux ajustement laryngés effectués pour les consonnes sourdes, en particulier le mouvement d'ouverture de la glotte et sa relation de phase avec les événements articulatoires buccaux. Les différences individuelles observées suggèrent que les locuteurs diffèrent dans leur façon d'utiliser la tension longitudinale des cordes vocales pour contrôler le non-voisement.
L'article présente une nouvelle formulation matricielle des concepts qui sont à la base des modèles markoviens discrets (HMM — Hidden Markov Models). En utilisant cette formulation, nous montrons que les probabilités d'états et de symbolés sont des fonctions exponentielles de la matrice de transition du modèle. Ensuite, nous dérivons une expression fermée entre les valeurs propres de la matrice de transition et les probabilités des symboles à des instants différents. La formulation matricielle fournit un outil qui est utile à l'interprétation physique du processus d'apprentissage et de décision à l'aide d'HMM. Elle apporte une aide à la compréhension et elle fournit des outils pour un modèle qui possède des caractéristiques d'apprentissage améliorées.
D'autre part, nous utilisons un ensemble de connaissances linguistiques sous forme de modèles réduits issues de modèles linguistiques de textes. Dans ce contexte, nous cherchons à évaluer si l'utilisation de connaissances et de traitements linguistiques peut améliorer les performances d'un système de filtrage. En effet, nous utilisons, au-delà des caractéristiques lexicales, un ensemble d'indicateurs sur le message portant sur la structure et le contenu. Ces connaissances sont indépendantes du domaine d'application et la fiabilité repose sur l'opération d'apprentissage. Pour tenter de statuer sur la faisabilité de notre approche et d'évaluer son efficacité, nous l'avons expérimenté sur un corpus de 1 200 messages. Nous présentons les résultats d'un ensemble d'expériences d'évaluation.
Cet article présente quelques développements dans l'expansion de requête et la représentation des documents de notre système de recherche documentaire et montre comment les diverses techniques de recherche affectent la performance pour différents ensembles de transcriptions dérivées d'une source de parole commune. Des modifications de la représentation des documents sont effectuées, qui combinent plusieurs techniques pour l'expansion de requête, fondées sur des connaissances d'une part et sur des statistiques d'autre part. Utilisées conjointement, ces techniques peuvent améliorer la Précision Moyenne de plus de 19%, relativement à un système semblable à celui que nous avons présenté à TREC-7. Ces nouvelles expérimentations ont également confirmé que la dégradation de la Précision Moyenne due à un Taux d'Erreur de Mot (WER) de 25% est vraiment faible (3,7% relatif) et peut être réduite à une quantité négligeable (0,2% relatif). L'amélioration globale du système de recherche documentaire peut aussi être observée pour sept ensembles différents de transcriptions provenant de différents systèmes de reconnaissance ayant un WER variant de 24,8% à 61,5%. Nous espérons reproduire ces expérimentations, lorsque de plus grandes collections de documents parlés seront disponibles, afin d'évaluer le comportement de ces techniques sur de plus gros volumes de données.
Cet article porte sur le traitement de l'information visuelle apre`s la cre´ation des premie`res repre´sentations. La capacite´de de´terminer visuellement les proprie´te´s formelles absraites et les relations spatiales esl un pre´requisa`ce niveau. Cette capacite´joue un role majeur dans la reconnaissance d'objet, dans les manipulations guide´es par la vision ainsi que dans la pense´e visuelle plus abstraite. Pour le syste`me visuel humain, la perception des proprie´te´s spatiales et des relations complexes au point de vue calcui apparait trompeusement imme´diate et facile. La perception des propriete´s de forme abstraite et des relations spatiales soule`ve des difficulte´es fondamentales avec des conse´quences importantes pour le traitement ge´ne´ral de l'information visuelle. Les auteurs de´fendent l'ide´e que le calcul des relations spatiales se´pare l'analyse de l'infformation visuelle en deux stades principaux. Au cours du premier se cre´ent, de bas en haut, certaines repre´sentations de l'environnement visible. Au cours du second des processus dits 'routines visuelles' s'appliquent aux repre´sentations issues du premier stade. Ces routines peuvent reve`ler des proprie´te´s et des relations qui n'e´taient pas repre´sente´es de façon explicite dans les repre´sentations initiales. Les routines visuelles sont compose´es de se´quences d'ope´rationse´le´mentaires conjointes pour les diffe´rentes proprie´te´s et relations. En utilisant une se´rie fixe d'ope´rations de base, le syste`me visuel peut assembler diffe´rentes routines pour extraire une suite illimite´e de proprie´te´s de forme et de relations spatiales. Les auteurs posent le proble`me de l'assemblage de ces ope´rationse´le´mentaires en routines visuelles signifiantes.
L'état actuel de la recherche sur l'effet des émotions d'un locuteur sur la voix et la parole est décrit et des approches prometteuses pour le futur identifiées. En particulier, le modèle de perception de Brunswik (dit “de la lentille” est proposé) comme paradigme pour la recherche sur la communication vocale des émotions. Ce modèle permet la modélisation du processus complet, de l'encodage (expression) par la transmission au décodage (impression). La conceptualisation et l'opérationalization des éléments centraux du modèle (l'état émotionnel du locuteur, l'inférence de cet état par l'auditeur, et les indices auditifs) sont discuté en détail. De plus, en analysant des exemples de la recherche dans le domaine, les avantages et désavantages de différentes méthodes pour l'induction et l'observation de l'expression émotionnelle dans la voix et la parole et pour la manipulation expérimentale de différents indices vocaux sont évoqués.
Il propose un formalisme original, l'interac-DEC-POMDP inspiré des modèles markoviens au sein duquel les agents peuvent interagir directement et localement entre eux. A partir de ce formalisme, cet article propose un algorithme d'apprentissage décentralisé fondé sur une répartition heuristique des gains des agents au cours des interactions. Une démarche expérimentale valide sa capacité à produire automatiquement des comportements collectifs. Les techniques présentées pourraient alors constituer des moyens permettant aux agents de décider automatiquement et de manière décentralisée comment s'organiser avec les autres pour résoudre un problème donné.
L'estimation du mouvement à partir de séquences d'images bidimensionnelles s'appuie sur deux hypothèses de base : l'hypothèse de conservation de la luminance des objets au cours de leurs mouvements et l'hypothèse de continuité spatiale, temporelle ou spatio-temporelle, du champ de vitesses apparentes. Cette dernière hypothèse est valable localement, « à l'intérieur » des objets, mais elle provoque un lissage indésirable au voisinage des frontières entre les projections, dans le plan image, des objets animés de mouvements différents. Ces frontières sont appelées discontinuités de mouvement. Le sujet principal de cet article est la revue des techniques visant à estimer le champ de vitesses apparentes en évitant de lisser les discontinuités de mouvement. La première partie de l'article présente les méthodes s'appuyant sur l'hypothèse selon laquelle les discontinuités de mouvement coïncident spatialement avec certaines frontières photométriques. La deuxième partie rapporte les méthodes de segmentation du champ estimé courant en régions homogènes au sens du mouvement. Cette inhibition peut être obtenue par introduction d'un « processus de ligne » binaire, grâce à l'utilisation d'un « estimateur robuste » , ou dans un schéma de diffusion anisotrope. La dernière partie est consacrée à la gestion des occultations. Les estimations obtenues dans les zones d'occultation sont erronées à cause de la violation des deux hypothèses de base : conservation des propriétés photométriques et continuité.
L'intérêt de séparer les impulsions en fonction de l'émetteur est de procéder ensuite à l'analyse des lois qui régissent les paramètres décrivant ces impulsions. Cependant, en raison d'innombrables perturbations et de la complexité des lois d'évolution des paramètres des impulsions, la tâche s'avère fort délicate. Nous montrons que les méthodes de Monte-Carlo séquentielles sont susceptibles d'apporter une réponse adaptée à ce problème d'extraction, que l'on peut également formuler comme une problématique d'association de données. La fusion des différents paramètres, à condition que cette dernière s'effectue en tenant compte des spécificités du modèle, permet d'étendre le domaine d'application de l'algorithme à des densités d'impulsions importantes.
La voix soufflée est utilisée pour former des contrastes linguistiques dans certaines langues, mais elle peut également caractériser les locuteurs en tant qu'individus et, dans une certaine mesure, le sexe. Henton et Bladon (1985) prétendaient que la présence de souffle dans les voix diminue l'intelligibilité. Dans les expériences décrites dans cet article, de la parole synthétique a été employée pour déterminer les effets de l'ajout d'une source de bruit à une source de voix modale ainsi que l'effet des différents corrélats acoustiques de la voix soufflée sur l'intelligibilité de mots isolés. Aucun effet significatif n'a été trouvé.
Cette communication présente les principaux problèmes liés à la recherche d'information dans la blogosphère. Recourant au modèle vectoriel tf idf, ainsi qu'à trois approches probabilistes et un modèle de langue, cet article évalue leur performance sur un corpus TREC extrait de la blogosphère et comprenant 100 requêtes. Basés sur deux mesures de performance, nous démontrons que l'absence d'enracineur s'avère plus efficace que d'autres approches (enracineur léger ou celui de Porter). Imposer la présence côte à côte de deux mots recherchés dans la réponse fournie permet d'accroître significativement la performance obtenue.
Cet article, basé sur les trois exposés effectués en 1998 lors de la conférence RLA2C à Avignon, présente les méthodes de métrologie de la reconnaissance du locuteur. Pour cela nous utiliserons des detection error trade-off (DET) curves. Ces courbes ont l'avantage de montrer le compromis entre erreur et fausse alarme et l'effet sur les performances des conditions d'entrainement, de la durée des segments de tests, du sexe du locuteur ou du type de combiné. Nous avons découvert que plusieurs facteurs influençaient fortement les performances des systèmes, comme par exemple la tonalité de la voix, le type de combiné utilisé ou le bruit ambiant. Nous concluerons avec un historique des techniques de reconnaissance du locuteur et avec quelques projections de ce domaine dans l'avenir
Dans cet article, nous définissons un critère de fidélité pour quantifier le degré de distorsion introduite par un codeur de parole. Un signal vocal original et sa version codée sont transformés du domaine temporel dans le domaine perceptuel utilisant un modèle auditif (cochléaire). Cette représentation dans le domaine perceptuel fournit une information liée aux probabilités de décharges dans les canaux neuronaux. La mesure de discrimination cochléaire introduite ici compare ces probabilités de décharges au sens de la théorie de l'information. En essence, elle évalue l'entropie croisée des décharges neuronales pour la parole codée par rapport à celle de la parole originale. La performance de cette mesure objective est comparée à des résultats d'évaluation subjective. Finalement, nous fournissons une analyse débit-distorsion en calculant la fonction débit-distorsion pour le codage de la parole en utilisant l'algorithme de Blahut. Quatre codeurs de parole performants avec des débits allant de 4.8 kbit/s (CELP) à 32 kbit/s (ADPCM) sont étudiés du point de vue leurs performances (telles qu'évaluées par la mesure de discrimination cochléaire) par rapport aux limites débit-distorsion.
Cinquante ans se sont écoulés depuis que Stuart Piggott a fouillé le complexe préhistorique de Cairnpapple. A cette époque-là on n' avait exploré que peu de sites parallèles en Ecosse, et, inévitablement, leur interprétation reposait essentiellement sur les sites déblayés dans le sud de la Grande-Bretagne. Beaucoup plus de données appropriées à la région sont désormais disponibles et la séquence de Cairnpapple peut maintenant être réévaluée dans son contexte régional. Piggott avait identifié cinq périodes, avec au commencement un agencement de pierres, 'un cromlech', et un cimetière à incinération datant de la fin du néolithique, vers environ 2500 av. J.-C. La période II consistait en un monument avec enceinte, comprenant un 'cercle' de pierres dressées avec inhumations cérémoniales associées, entouré par un fossé accompagné d'un talus du côté extérieur – 'de l'époque des peuples à vase, probablement vers 1700 av. J.-C.'. La période III comprenait le cairn primaire, contenant deux inhumations avec dalles de pierre 'datant du milieu de l'âge du bronze, probablement vers 1500 av. J.-C. Pendant la période IV la taille du cairn a doublé, avec deux crémations dans des urnes à incinérations retournées. De la période finale de l'âge du bronze moyen ou de la fin de l'âge du bronze régional, probablement autour de 1000 av. J.-C. La période V comprenait quatre tombes 'mais peut être du début de l'âge du fer, au cours des deux premiers siècles ap. J.-C. La présente étude, utilisant des matériaux comparables provenant d'autres endroits en Ecosse, argumente en faveur d' une révision des différentes phases : la phase 1 comprend un dépôt de tessons de bols non décorés et de fragments de têtes de haches du début du néolithique associé à une suite de foyers. On peut comparer ceci à des dépôts structurés répertoriés sur d'autres sites de cette période. La phase 2 comprend la construction de l'enceinte – un ensemble de 24 verticaux –probablement en bois plutôt qu'en pierre, probablement suivi par la construction du fossé et du talus tout autour. Le 'cromlech' est analysé dans le contexte de structures comparables en Ecosse. La phase 3 a vu la construction d'une série de tombes, y compris la monumentale North Grave, tombe nordique, qui était probablement enchâssée dans un cairn. Le cairn qui correspond à la période III de Piggott fut alors construit, suivi par le cairn de la 'période IV'. Il semble probable que les inhumations à urnes aient été introduites dans la surface de ce tertre, qui recouvrait peut-être une inhumation (perturbée depuis) en haut du tertre de la 'période III', ou en était peut-être une monumentalisation délibérée. Il semble plus probable que les quatre tombes identifiées par Piggott comme appartenant à l'âge du fer datent en réalité du début de l'ère chrétienne. La réévaluation du rapport de Piggott insiste sur la valeur que représente un compte-rendu dont l'écriture est claire et le contenu suffisamment détaillé. Tandis qu'aucun rapport ne peut être totalement objectif, on constate que les efforts d'objectivité fournis par Piggott l'ont amené à écrire un article dont la valeur subsiste.
Nous proposons dans cet article une approche de fusion probabiliste reposant sur des critères entropiques dont le but est de réduire l'espace de combinaison en représentant explicitement les notions de redondance et de complémentarité des sources d'information. Ce type de modélisation est en particulier intéressant pour optimiser le choix des mesures, issues des sources d'information, à combiner dans un système de fusion. Il est en accord avec le souci de rapidité de traitement et de minimisation des ressources matérielles qui se pose en fusion d'informations. Pour repondre à cela, nous avons réalisé une étude de la parallélisation de l'algorithme de fusion entropique développé en vue de son implantation parallèle dans le cadre d'une application en robotique mobile. La spécification de l'algorithme faisant apparaître du parallélisme potentiel est ensuite implantée sur un réseau de stations de travail fonctionnant en mode MIMD-NORMA à l'aide des environnements de programmation SynDEx, qui supporte la méthodologie AA-A, et PVM, qui est de type CSP de Hoare.
Cet article étudie dans quelle mesure la reconnaissance des mots est influencée par le contexte lexical, syntaxique et sémantique, cela afin de comparer les prédictions faites par des théories modulaires et interactives de l'architecture du systéme de compréhension du langage. Notre conclusion est que les données montrent clairement qu'il existe des effets du contexte lexical, moins clairement qu'il existe des effets du contexte sémantique, et qu'il y a peu de données en faveur d'effets du contexte syntaxique. Selon nous, les effets de feedback “de haut en bas” dans la compréhension apparaissent essentiellement dans des situations où il existe une relation partie-ensemble claire entre les deux niveaux, et où l'ensemble des unités de niveau inférieur qui peuvent recevoir un feedback du niveau supérieur est restreint.
Nous présentons un système de classification de phonèmes indépendant du locuteur et appliqué aux voyelles. L'architecture du classificateur de voyelles est basée surun modèle d'oreille suivi d'un ensemble de réseaux neuronaux à plusieurs couches (MLNN). Les MLNNs apprennent à reconnaître les traits articulatoires, par exemple le lieu et le mode d'articulation en relation avec la position de la langue. Des expériences ont été effectuées sur 10 voyelles anglaises et montrent un taux de reconnaissance supérieur à 95% sur de nouveaux locuteurs. Lorsque les traits sont utilisés pour la reconnaissance, des résultats comparables sont obtenus pour des voyelles et des dihthongues qui n'ont pas été utilisées lors de l'apprentissage et prononcées par de nouveaux locuteurs. Ceci suggère que, pour des données calculées par un modèle d'oreille, les MLNNs présentent un bon pouvoir de généralisation pour de nouveaux locuteurs et de nouveaux sons.
Annoter des images selon un nombre fini de concepts fixés a priori est une tâche fondamentale permettant la recherche d'images par le contenu. En pratique, plusieurs modalités (visuelle, textuelle...) fournissent des informations sur le contenu des images. Notre intérêt porte ici sur les tags associés aux images, généralement issus d'une indexation personnelle, fournissant une information imparfaite et partiellement pertinente. Nous proposons deux modèles de tags pour pallier de telles imperfections, l'un modélisant le phénomène au moyen d'un seuil établi automatiquement selon la similarité sémantique avec les concepts visuels, et l'autre améliorant le schéma de codage des sacs-de-mots en s'inspirant de récents travaux effectués en classification d'images. L'ensemble de ces travaux est validé sur plusieurs bases d'images publiques et couramment utilisées dans le domaine de l'annotation d'images. Les résultats expérimentaux montrent que les méthodes proposées dépassent l'état de l'art tout en restant moins coûteuses en calculs que les travaux récents dans le domaine.
Cet article présente une méthode d'approximation pour les POMDP qui est basée sur une recherche en profondeur pour la planification dans un environnement temps-réel dynamique. L'idée de base de notre approche, appelée RTBSS, est d'éviter de calculer des politiques complètes pour des POMDP. Cette approche est spécialement utile pour des environnements temps-réel où l'espace d'états est trop grand pour que l'on puisse considérer les algorithmes de résolution hors lignes des POMDP. A cet effet, nous proposons une approche en ligne pour calculer à chaque cycle, l'action qui maximise l'utilité espérée de l'agent. Nous commençons par présenter tout le formalisme à la base de notre méthode. Par la suite, nous présentons les résultats expérimentaux obtenus sur trois environnements. Mentionnons par ailleurs que cette approche a été implémentée avec succès pour la compétition mondiale de la RoboCupRescue en 2004 où nous nous sommes classés en deuxième position.
Dans cet article, un système de reconnaissance de la parole basé sur la gńération synthétique de prototypes de références est décrit. Le vocabulaire et la grammaire sont décrits dans un réseau de phonèmes à l'état fini. Dans les transformations des représentations symboliques en représentations spectrales, des règles de réduction modifient les valeurs cibles du phonème initial et un modèle de la coarticulation insère des états de transition interpolés aux frontières de phonèmes. Les gabarits de phonèmes sont spécifiés en terme de paramètres de contrôle d'un synthétiseur à formants en série. A chaque état, une section spectrale est calculée à partir des paramètres de synthèse. Le processus de reconnaissance utilise une technique de programmation dynamique et synchronisée pour trouver le chemin dans le réseau qui minimise la distance spectrale cumulée par rapport à la phrase de départ. Une méthode dynamique d'adaptation au spectre de la source vocale du locuteur est employée pendant la phase de reconnaissance. Sans adaptation, le taux de reconnaissance moyen est de 88% pour 10 locuteurs masculins dans une tâche de reconnaissance de mots isolés utilisant un vocabulaire de 26 mots. L'ajout d'une adaptation à la source vocale fait monter la performance jusqu'à 96%. Sur un vocabulaire de séquences de 3 chiffres connectés, le tauc de reconnaissance pour six locuteurs masculins augmente de 88.7%, à 92.8% grâce à la technique d'adaptation. L'amélioration est plus grande pour les sujets qui ont u taux de reconnaissance initial faible, ce qui montre le bénéfice de la technique d'adaptation à la source vocale pour certaines voix. En changeant le modèle de source vocale et en optimisant l'adaptation, la constante de temps fait monter le taux de reconnaissance jusqu'à plus de 96,1%. Les travaux en cours étudient l'adaptation du locutuer aux paramètres phonèmiques et la modélisation de la variabilité de la dynamique des paramètres aux frontières de phonème.
Les effets du VOT, de la tenue voisée (la période entre la fermeture orale et l'arrèt de voix), de la durée et de l'étendue de la transition des formants et de l'intensité du bruit de friction sur la perception de voisement dans des séquences de deux obstruentes néerlandaises (C 1 C 2) ont ét'e testés dans quatre expériences séparées à l'aide de stimuli synthétiques Les résultats montrent que le VOT et la tenue voisée sont des indices importants pour la perception de voisement dans C 1 C 2, et que l'intensité du bruit de friction constitue un indice plus faible. Les transitions des formants n'ont pas eu d'effet significatif. En outre, les données concernant le VOT et la tenue voisée montrent que des indices qui proviennent de parties du signal acoustique qui se trouvent à des distances temporelles assez éloignées, sont intégrés dans une unité perceptive, et qu'un indice particulier a un effet semblable sur le caractère de voisement perçu des deux consonnes qui constituent la séquence.
Cet article décrit deux expériences portant d'une part sur le rappel stimulé de phrases présentées dans un contexte particulier, et d'autre part le rappel non-stimulé de ces mêmes phrases. Certains mots clef de ces phrases ont été introduits de façon à posséder le même sens supérficiel tout en appartenant à des catégories syntactiques et des fonctions sémantiques indépendantes. Pour les phrases dans lesquelles la fonction sémantique d'acteur et de recepteur coincidaient respectivement avec la fonction syntactique de sujet et d'objet profond, le rappel stimulé était meilleur que pour les phrases qui ne manifestaient pas cette coincidence normale sémantico/syntactique. Le rappel non-stimulé était identique dans les deux cas. Les deux genres d'information normalement utilisés dans le langage courant apparaitraient donc indispensables dans le traitement de phrases modèle.
Dans cette communication, nous appliquons un modèle de recherche d'information pour la tâche d'identification du scripteur. Les requêtes sont des images de documents qui sont tout d'abord projetées dans un espace de caractéristiques. La base de documents manuscrits est indexée selon le principe du modèle vectoriel de recherche d'information textuelle. L'approche exploite donc à la fois la représentation mixte image et textuelle spécifique d'un document manuscrit. Les documents identifiés à l'issue de cette étape font ensuite l'objet d'une analyse complémentaire pour vérifier les hypothèses émises. Nous proposons d'utiliser un critère d'information mutuelle pour vérifier que chacun des documents identifiés peut avoir été produit par le scripteur de la requête. Nous utilisons un test d'hypothèse à cet effet. L'approche est testée sur deux bases d'écritures différentes et montre une grande robustesse aux différentes écritures. L'approche semble donc très intéressante pour des applications à plus grande échelle nécessitant d'interroger des bases de documents manuscrits.
Nous proposons une nouvelle méthode de calcul d'une politique approchée d'un Dec-POMDP qui surpasse les approches de l'état de l'art dont PBDP et MBDP. Notre approche est fondée sur une estimation de la distribution de probabilité des croyances atteignables pour un horizon donné. Cette estimation est faite en simulant l'exécution d'une politique heuristique du Dec-POMDP considéré. Cette distribution de probabilité des croyances est ensuite utilisée pour choisir les arbres de politique candidats à l'horizon considéré grâce à un critère simple qui cherche à minimiser l'erreur induite par l'élagage.
Un nouvel algorithme de modélisation acoustique est proposé qui génère des unités de type Modèles de Markov Cachés (MMCs) non-uniformes pour prendre en compte les variations spectrales de la parole continue. L'algorithme est conçu pour la génération automatique et itérative d'unités de longue durée dans le cadre d'une modélisation non-uniforme. Cet algorithme est fondé sur un critère de réduction d'entropie, qui utilise des données textuelles ainsi qu'un critère de probabilité maximum qui utilise des données orales. L'efficacité des modelès d'unités non-unifomes est confirmée en comparant des probabilités entre les unités MMCs de longue durée et les unités MMCs basées sur le modèle conventionnel des unités phonémiques.
Dans les descriptions de la grammaire du tibétain, il est courant de traiter -las et -nas comme des marques casuelles similaires, en signalant simplement que -las peut former des comparaisons alors que -nas ne le peut pas. De même, la plupart des descriptions n'opèrent aucune distinction entre les suffixes -bas et -las en ce qui concerne la comparaison. Nous montrons à travers divers exemples illustrant l'emploi de ces trois morphèmes qu'ils ont des fonctions syntactiques distinctes et présentent également des différences sémantiques.
Cet article décrit un système de dialogue oral en cours de développement, TARSAN, pour guider des personnes en voyager. TARSAN utilise comme source de connaissance des guides commercialisés sous la forme de CD-ROMs qui comportent une grande quantité d'informations touristiques. Pour manipuler une telle quantité d'informations, le système de reconnaissance doit pouvoir accepter un très large vocabulaire sans réduire ses performances. Dans ce but, nous proposons deux étages de contrôle des mots actifs/non-actifs : (1) une stratégie de prédiction des mots/de la grammaire, et (2) un algorithme de ré-estimation des mots inconnus. La stratégie de prédiction mot/grammaire modifie de façon dynamique le réseau de reconnaissance en fonction de l'état de la conversation en utilisant les résultats retrouvés à partir des CD-ROMs. Cette stratégie permet aux utilisateurs d'accéder à quasiment toutes les informations du CD-ROM en utilisant un système de reconnaissance de petit vocabulaire. Cet algorithme améliore l'efficacité de la prédiction mot/grammaire. Dans les expériences sans modèles poubelle, 80.9% des énoncés étaient correctement reconnus. Dans l'expérience utilisant les modèles poubelles pour la ré-estimation des mots inconnus, 86.4% étaient correctement ré-estimés, pour un taux de fausse-alarme de 5%.
Nous combinons pour l'exploration Monte-Carlo d'arbres de l'apprentissage artificiel à 4 échelles de temps : regret en ligne, via l'utilisation d'algorithmes de bandit et d'estimateurs Monte-Carlo ; de l'apprentissage transient, via l'utilisation d'estimateurs rapides de Q-fonction (RAVE, pour Rapid Action Value Estimate) qui sont appris en ligne et utilisés pour accélérer l'exploration mais sont ensuite peu à peu laissés de côté à mesure que des informations plus fines sont disponibles ; apprentissage hors-ligne, par fouille de données de jeux ; utilisation de connaissances expertes comme information a priori. L'algorithme obtenu est plus fort que chaque élément séparément. Nous mettons en évidence par ailleurs un dilemme exploration-exploitation dans l'exploration Monte-Carlo d'arbres et obtenons une très forte amélioration par calage des paramètres correspondants.
La recherche dans le domaine de la reconnaissance de grands vocabulaires s'est développée de façon intensive, au niveau international ces dernières années, stimulées par les progrés dans les domaines de l'algorithmique, des architectures et des matériels. Aux Etats-Unis, la communauté DARPA a orienté ses efforts sur l'étude de diverses tâches de reconnaissance de parole continue, dont la gestion de ressources navales (Ressource Management : une tâche de 991 mots), un système d'information sur les transports aériens (ATIS, une tâche de compréhension de parole avec un vocabulaire ouvert (en pratique, plusieurs milliers de mots) et une composante de traitement de langage naturel) et le Wall Street Journal (WSJ : une tâche de dictée vocale avec un vocabulaire de l'ordre de 20 000 mots). Bien que nous ayons beaucoup appris sur la façon de construire et d'implémenter efficacement des systèmes de reconnaissance de grands vocabulaires, il reste toutes une série de questions fondamentales pour lesquelles nous n'avons pas de réponses définitives.
Des stimuli consistant en des trains alternés d'impulsions à un et deux formants, et des stimuli à deux formants à rapport A 1/A 2 variable, on été utilisés pour des expériences d'identification vocalique. Deux faits essentiels ont été relevés : 1) l'augmentation en proportion d'impulsion à un formant dans le train d'impulsions et l'augmentation en amplitude du formant correspondant dans le stimulus à deux formants affectent l'identification exactement de la même manière. 2) de fortes variations dans la différence d'amplitude entre les impulsions à un et à deux formants dans le train d'impulsions n'ont pas d'effet sur l'identification. Ni l'hypothèse de classification phonémique courante. ni l'hypotèse de spectre moyen ne sont compatibles avec l'ensemble de ces deux faits. Il se pourrait que des patterns simples “à une crête” et “à deux crêtes” soient utilisés comme composantes pour l'analyse de la forme spectrale.
Au cours d'une serie d'expériences les sujets décrivent des scènes visuelles simples soit avec des phrases soit avec des mots. Des données appuient les positions suivantes sur les processus de lexicalisation (recherche de mots) ; 1) les mots utilisés pour dénomer dans des phrases sont selectionnés suivant deux processus séquentiels. le premier travaille sur les items prephonologiques abstraits (items L1), Le second ajoute la forme phonologique (items L2). 2) La sélection des items L1 dans un énoncé de plusieurs mots peut être simultanée. 3) Un dispositif de contrôle (moniteur) vérifie à la sortie de la lexicalisation L1 l'accord avec les contraintes sur le format de l'énoncé. 4) La recherche de l'item L2 correspondant à un item L1 donné ne commence qu'après la vérification de L1 par le moniteur et qu'après que tous les L1 nécessaires à la construction de l'énoncé soient disponibles. Une image cohérente des processus de lexicalisation commence à emerger lorsqu'on réunit ces points et les résultats expérimentaux obtenus avec les travaux sur la dénomination et le production de phrases, e.g., temps de réaction à la dénomination d'images (Seymour, 1979), erreurs (Garrett, 1980) ou préférences sur l'ordre des mots (Bock, 1982).
Le diagnostic précoce est le moyen le plus efficace de lutte contre le cancer. Parmi toutes les techniques possibles, les méthodes optiques (photodiagnostic du proche UV au proche IR) présentent des caractéristiques importantes recherchées par les médecins : grande sensibilité, radiations non ionisantes et mesures atraumatiques. Elles sont particulièrement bien adaptées à la détection des cancers des organes creux, par nature superficiels et difficilement décelables en endoscopie classique. Cet article décrit une approche méthodologique fondée sur l'exploitation de l'autofluorescence tissulaire, applicable en endoscopie clinique, et conduisant à l'élaboration d'indicateurs diagnostiques issus des paramètres spectraux. Après un état de l'art sur les méthodes spectroscopiques (LIFS) et d'imagerie endoscopique d'autofluorescence, nous montrons l'efficacité de la LIFS fibrée en terme de sensibilité et de spécificité pour le diagnostic de lésions cancéreuses de l'œsophage (étude clinique sur 25 patients). Nous présentons ensuite les caractéristiques technologiques et le calibrage du prototype d'imageur endoscopique d'autofluorescence développé. Une seconde partie traite du pré-traitement, du recalage et du mosaïquage des images endoscopiques appliqués à la construction automatique d'une image panoramique (cartographie) à partir de séquences vidéos des zones explorées de l'organe. Finalement, en exploitant les informations de fluorescence fournies par l'imageur, la faisabilité d'une superposition des informations spatiale et spectrale est validée sur fantôme.
On présente ici un ensemble de règles permettant de fournir à des systèmes de synthèse du français les durèes des phonèmes en contexte. Les règles utilisent, pour chaque phonème, des durées intrinsèques qui sont considèrées comme des données indépendantes du locuteur. Ainsi, cet ensemble de régles permet de prédire des durées segmentales différentes pour imiter au mieux des locuteurs varés. La validité du modele a été testd sur 2 locuteurs. Sur les corpus de test utilisés, les écarts moyens entre durées prédites et mesurées sont inférieurs à 18 ms.
L'ancienne écriture zhuang - un terme qui désigne actuellement les langues tai parlées au Guangxi, dans le sud de la Chine - est empruntée au chinois. La typologie présentée ici a des implications considérables pour l'étude des systèmes d'écriture et de l'écriture chinoise en particulier.
Dans la conception des algorithmes de codage de la parole à bas-debit la variabilité de langue est souvent considérée avec une importance secondaire en comparaison avec les autres facteurs opérationnels, tels que la variabilité d'interlocuteur et le bruit. Etant donné que les langues sont largement différentes au niveau de composition de l'enveloppe spectrale et que l'enveloppe spectrale de la parole représente une partie importante de la répartition des bits dans le codage de la parole, il est surprenant de trouver qu'aucune étude complète n'a jamais été effectuée sûr le rôle des langues en la quantification spectrale. Dans cette étude, nous adressons ce déficit a travers d'une série d'enquêtes sur la performance de quantification spectrale effectué pour un ensemble de familles de langage typique de la telecommunication mobile planétaire. Dans cette étude, nous considérons certains facteurs de conception de la quantification tel que la taille et structure des dictionnaires de code, et la quantité des donnes monolingue utilisées dans la conception des dictionnaires de code. Cette évaluation indique que la distorsion de quantification n'est pas uniforme à travers des différents langages. Il est montré qu'une différence importante existe dans le comportement de la quantification spectrale à travers des langages, en particulier celle des points écarte de haute distorsion. Une analyse détaille des donnes de la distorsion spectrale sur un niveau phonétique a révélé que la nature de la distribution de l'énergie spectrale des phonèmes influence le comportement des dictionnaires de code monolingue. Nous présentons quelques explications pour la performance des dictionnaires de code ainsi qu'un ensemble de recommandations pour la conception des dictionnaires de code destine aux environnants multilingues.
L'oeuvre d'Othon de Grandson, qui fait aujourd'hui l'objet d'une réévaluation globale, met à contribution différents types de mythologies.
L'évaluation de la qualité de la parole codée et synthétisée est étroitement liée à la perception auditive des sons complexes. Une compréhension de la perception des sons complexes est donc nécessaire pour améliorer la qualité des sons après traitement. L'étude perceptuelle des sons de parole est abordée dans ce papier sous l'aspect du masquage auditif. Contrairement à la plupart des autres travaux analogues, nous avons pris comme cibles des signaux de bruit à bande étroite et comme masqueurs des sons harmoniques complexes à large bande. Nous montrons que la détection des cibles à basses fréquences est surtout fonction des propriétés spectrales des masqueurs. Pour les hautes fréquences, la détection des cibles est préférentiellement déterminée par le comportement temporel des masqueurs. Les contributions relatives des analyses spectrale et temporelle dépendent fortement de la fréquence fondamentale du masqueur. Une meilleure résolution temporelle correspond à un plus haut niveau de masquage.
Une prothèse auditive a été développée qui permet d'estimer en temps réel la fréquence et l'amplitude des formants. Ces paramètres peuvent être utilisés pour améliorer le signal de sortie en renforçant les pics formantiques et en ajustant les amplitudes des formants à la dynamique d'amplitude de l'audition pour chaque fréquence ou en resynthétisant le signal de parole qui convient aux caractéristiques auditives de l'auditeur. Cette aide auditive peut aussi être utilisée dans un mode “adaption à la courbe de réponse en fréquence”, similaire à celui utilisé dans les aides auditives conventionnelles. Les premières évaluations du fonctionnement en mode “renforcement des pics spectraux” font apparaitre de légères améliorations de la perception de parole pour 3 groupes de sujets : (a) Cinq déficients auditifs (de “sévère” à “profond”) ont donné des scores améliorés de 7% en utilisant la prothèse “à formant” combinée avec un implant cochléaire multi-électrodes, par rapport à la combinaison de leur implant et de leur prothèse conventionnelle ; (b) un déficient auditif présentant une perte auditive importante fournit un score amélioré de 11% avec le signal “à pics spectraux renforcés” par rapport à l'utilisation de sa prothèse auditive conventionelle ; (c) 4 auditeurs bien-entendants montrent, en présence de bruit, une amélioration moyenne de 19% de leur perception des voyelles et une diminution de 5% de celle des consonnes quand le signal est pré-traité par la nouvelle prothèse. Ces résultats préliminaires illustrent certains effets potentiels d'un traitement formantique.
Cet article présente une nouvelle approche du codage sinusoïdal de la parole ne nécessitant pas de détecteur de voisement. Le modèle propose de représenter le signal de parole comme une somme de sinusoïdes et de signaux aléatoires passe-bande ; il est appelé “modèle hybride harmonique”. L'utilisation d'ensembles variés de fonctions de base permet d'augmenter la robustesse du modèle, puisqu'il n'est plus nécessaire d'alterner des méthodes adaptées à une classe particulière de signaux. Prendre pour base des fonctions sinusoïdales aux fréquences réglées harmoniquement autorise une représentation précise de la structure quasi-pérodique de la parole voisée, mais n'est pas adéquat pour celle des sons non-voisés. Par contre, les signaux aléatoires passe-bande permettent une représentation excellente des sons de parole non voisés car leur largeur de bande est supérieure à celle d'une sinusoïde. On réalise, simultanément, l'estimation des amplitudes de ces deux ensembles de fonctions de base par un algorithme des moindres carrés ; le signal de parole résultant est synthétisé dans le domaine temporel par la superposition de toutes les fonctions de base, en proportion de leur amplitude. Les tests expérimentaux confirment que le modèle hybride, pour le codage de signaux de parole bruités, surclasse les modèles sinusoïdaux classiques qui sont sensibles à la décision voisé/non-voisé. Pour finir, on décrit l'implémentation et le test de l'intégralité de ce codeur hybride à 4.8 Kbit/s.
Cet article propose une méthode d'extraction de l'impact émotionnel des images à partir de descripteurs bas niveau. Nous avons émis l'hypothèse que la précision de ces derniers encoderait des informations haut niveau intéressantes voire discriminantes pour les émotions. Plus ce temps est long plus l'interprétation sémantique de l'image prend le dessus sur l'émotion « primaire » . A ces descripteurs nous avons associé deux classifieurs performants, particulièrement adaptés à des discriminations d'informations complexes. Nous avons, à cet effet, effectué nos tests sur une base diversifiée de 350 images, construite à partir d'images à faible contenu sémantique. Nous avons défini trois classes d'émotions.
La reconnaissance d'un mot parlé consiste en deux étapes principales. Lors de l'étape pré-lexicale, l'information présente dans le signal de parole est analysée, et la représentation abstraite de l'énoncé ainsi générée est utilisée lors de l'accès au lexique mental. Cet article présente des données indiquant que les informations segmentales et suprasegmentales présentes dans le signal de parole peuvent jouer un rôle positif ou négatif lors de ce processus de compétition selon que ces informations sont compatibles ou incompatibles avec la représentation lexicale des candidats. De plus, nous discutons l'existence d'un “feedback” du lexique vers le niveau pré-lexicale qui s'ajouterait ainsi au flux d'information nécessaire entre le niveau pré-lexicale et le lexique. Lors de deux experiences de catégorisation phonétique, conduites en néerlandais, les auditeurs avaient pour tâche de décider de l'identité d'une fricative ambiguë présente au début ou à la fin d'une séquence qui correspondait, selon l'identité attribuée à cette fricative, soit à un mot, soit ou un nonmot (e.g., une fricative ambiguë entre [f] et [s] placée dans une séquence mot–nonmot, maf–mas, ou dans une séquence nonmot–mot, jaf–jas). Ce biais lexical était, cependant, plus faible lorsque les temps de réaction lors de la catégorisation étaient lents, même lorsque les auditeurs étaient encouragés à répondre le plus vite possible. Ces résultats sont problématiques pour les modèles dans lesquels l'analyse pré-lexicale du signal sonore est modulée par un “feedback” opérant systématiquement, toutes les fois où un mot est perçu.
L'amincissement est assurément un descripteur de forme majeur pour l'analyse d'image et la reconnaissance de forme. Le rehaussement est aussi un outil essentiel pour faciliter l'interprétation visuelle et la compréhension des images de documents notamment celles qui sont bruitées et floues. Nous décrivons dans cet article une méthode d'amincissement et de rehaussement utilisant un filtre de chocs dérivant de celui introduit par Remaki et Cheriet pour le rehaussement. Ce nouveau filtre utilise un champ de diffusion spécifique initial. L'utilisation de tels champs apporte un nouveau degré de liberté aux filtres de chocs, puisque ceux-ci sont spécifiques aux applications (amincissement, rehaussement) et permettent ainsi au même filtre d'être utilisé pour différentes applications. Nous illustrons la performance de notre méthode par des résultats probants obtenus sur des images manuscrites.
L'association chez Saussure et ses prédécesseurs immédiats d'un héritage empiriste et d'une approche combinatoire des faits linguistiques a rendu difficile l'édification d'une théorie satisfaisante de la signification (Bedeutung), le plus souvent comprise comme résultant d'un empilement de représentations mentales (Vorstellungen). Une difficulté face à laquelle le signe saussurien fait plutôt figure d'échappatoire. Certains contemporains ont toutefois privilégié une autre approche, centrée sur la Darstellung (soit la « représentation » , entendue cette fois comme technique de figuration et non plus comme phénomène cognitif). Si différents qu'aient été les objets grammaticaux ainsi traités, ces tentatives ont pour point commun de postuler l'existence de propriétés organisationnelles spécifiques au représentant lui-même, et d'argumenter par là en faveur de la motivation du signe. Elles partagent toutefois avec les théories centrées sur la Vorstellung une orientation essentiellement sémantique, ce qui circonscrit de facto leur sémiotique.
Ce travail s'inscrit par le cadre du développement méthodologique d'une architecture multi spécialistes, appelée MESSIE, pour l'interprétation d'images. Nous présentons, dans cet article, les spécifications du système pour l'interprétation d'objets, en particulier ceux faits de main d'homme dans l'imagerie aérienne. La principale difficulté de ce problème est l'expression des connaissances nécessaires à l'interprétation : les connaissances liées aux Objets, à la Stratégie et à la Scène. L'architecture MESSIE (1), de type tableau noir, est organisée sur ces quatre types de bases de connaissances, qui schématiquement se décomposent en deux niveaux. Le premier niveau correspond à la connaissance liée à la Scène et à la Stratégie et le deuxième correspond aux spécialistes (un par type d'objet). Chaque niveau n'accède qu'à certains des points de vue.
Les erreurs rencontrées dans le discours des enfants montrent que certains enfants formulent d'aboard la transformation affixe et l'inversion sujet-auxiliaire comme copie sans effacement. D'autres erreurs suggèrent que certains enfants peuvent formuler d'autres règles de mouvement comme l'effacement sans copie. En se fondant sur l'analyse de ces erreurs on fait une proposition sur le mécanisme de l'acquisition du langage : ce mécanisme d'acquisition du langage formule les hypothèses sur les transformations en terme d'opérations fondamentales.
Melyador de Jean Froissart s'inscrit dans la lignée du roman de chevalerie courtoise. En digne héritier, il met en scène quatre grands tournois, autour desquels s'articulent l'architecture de l'œuvre et les intrigues amoureuses de l'histoire. L'examen de ces morceaux convenus permet de voir qu'ils reproduisent et assument la part de stéréotypie inhérente au thème, mais non sans la transcender et en faire un mode de renouvellement esthétique. La stéréotypie de l'épisode de tournoi se trouve en effet à la fois généralisée et ramenée à son essence, tout en étant très stylisée au point de conférer une dimension lyrique et une circularité à l'épisode. Dans Melyador, le temps du spectacle chevaleresque rejoint ainsi, de manière originale, la dimension poétique de l'œuvre.
Les réseaux de neurones ont été utilisés dans une large gamme d'applications. En particulier, des résultats satisfaisants ont été observés dans le domaine de la reconnaissance de formes. Toutefois, dans le contexte de la reconnaissance de la parole, l'utilisation des réseaux de neurones est difficile vue l'absence du paramètre temps dans leur structure. D'un autre point de vue, dans une application de reconnaissance de la parole, un mot peut être reconnu et bien classé ou reconnu et mal classé, il est donc impératif de pouvoir expliquer le raisonnement qui a conduit à cette décision. Dans cet article, nous considérons deux insuffisances des réseaux de neurones artificiels : le manque de connaissances explicites du domaine d'application et l'absence de l'aspect temps dans la structure des réseaux. À cet effet, nous proposons un modèle de neurone temporel et spécialisé, que nous appelons STN (pour specilized temporal neuron). Ce modèle est ensuite utilisé comme élément de base dans un réseau neuro-symbolique pour la reconnaissance de la parole.
L'utilisation des processeurs de signaux n'est pas encore très courante, en dépit des avantages qu'ils procurent. Nous présentons ici un certain nombre de réflexions menées dans le sens d'une plus grande facilité d'utilisation de ces processeurs. Ces réflexions ont été concrétisées dans l'élaboration d'une architecture de processeur, à la fois optimisée et d'utilisation aisée.
Le travail présenté dans cette correspondance s'appuie sur l'idée que le développement d'algorithmes pour la reconnaissance automatique de la parole nécessite des connaissances variées qui doivent coopérer. Afin d'aider au développement de tels algorithmes, appelés algorithmes hybrides, et de façon plus générale pour le traitement automatique de la parole, des architectures avancées et des environnements intégrés sont souhaitables. Il est aussi souvent nécessaire de représenter les connaissances du domaine parole étudié par l'intermédiaire de structures abstraites, de manipuler des bases de données importantes, et de modéliser, simuler, et évaluer des systèmes de reconnaissance automatique de la parole. Afin de prendre en compte ces différents aspects, nous proposons dans cette correspondance le nouveau concept de laboratoire artificiel pour le traitement automatique de la parole. Un tel système simule un laboratoire réel et permet de manipuler des données. Il fournit aussi à l'utilisateur un ensemble de fonctions préprogrammées qui facilitent la modélisation et la simulation d'algorithmes de traitement automatique de la parole. Dans cette correspondance nous décrivons brièvement les principaux concepts du prototype de laboratoire artificiel en cours de développement.
Les méthodes d'ensemble ont été utilisées avec succès comme schéma de classification. Les algorithmes d'élagage d'ensembles de classifieurs sont apparus afin de réduire la complexité de ce paradigme populaire d'apprentissage. Cet article présente une nouvelle méthode efficace d'élagage d'ensembles qui, non seulement réduit de manière significative la complexité des méthodes d'ensemble, mais permet aussi une meilleure précision de classification que la version sans élagage. Cet algorithme consiste à ordonner tous les classifieurs de base par rapport à leur entropie qui exploite une nouvelle version de la marge des méthodes d'ensemble. La confrontation de cette méthode avec l'approche naïve d'élagage aléatoire des classifieurs de base et avec un autre algorithme d'élagage par ordonnancement a permis de montrer sa supériorité à travers une analyse empirique conséquente.
Dans des expériences précédentes, il a été montré que la perception du voisement dans les séquences consonantiques de deux obstruentes en Néerlandais (C1C2) était affectée par les paramètres suivants : la durée de la fermeture de la deuxième consonne dans la séquence, le VOT, la tenue voisée (VTT - l'intervalle entre la fermeture orale et l'arrêt de voix), la durée de la résonance de la voyelle précédente, la position de l'accent et l'intensité du bruit de friction. L'objectif de l'expérience présentée ici vise à déterminer si les effets des six indices sont additifs ou interactifs, et à établir l'importance relative des six indices dans la perception. Les résultats (mesurés en termes de réponses voisée-voisée, non voisee-voisée, non voisée-non voisée et voisée-non voisée) montrent que les effets des paramètres sont additifs et que — bien que la présence/absence de périodicité (VOT et VTT) soit le facteur primordial dans la perception de “voix” — la perception est influencée de façon considérable par la durée de la “C2” et la durée de la “voyelle précédente”
Les langues moyen-indiennes appartiennent à la même famille linguistique que le sanskrit, mais leurs grammaires présentent une situation contrastée : les prakrits littéraires sont décrits par des grammairiens qui utilisent le sanskrit, modèle normatif par excellence qu'elles étendent donc ; en revanche, le pali (langue des écritures du bouddhisme Theravāda), est décrit au moyen du pali. Cet article examine les raisons susceptibles d'expliquer cette différence surprenante, alors même que prakrits et pali présentent de nombreux points communs dans leurs évolutions phonétiques ou morphologiques. Le choix d'une langue distincte, le pali, est-il plus qu'une différence superficielle ? Inversement, le choix du sanskrit est-il un obstacle à prendre en compte les réalités des langues décrites ? On tente de répondre à ces questions à partir d'un cas exemplaire : le fonctionnement de la description du verbe et le traitement de la notion de racine. Comment les grammairiens négocient-ils entre le modèle sanskrit omnipotent et la réalité de conjugaisons qui, tendant à prendre pour forme de base le thème du présent, développent des paradigmes réguliers ?
Nous discutons les résultats de l'application à un problème réel simplifié de quatre techniques de classification - les plus proches voisins, méthode des mélanges, perceptron multi-couches et les réseaux auto-organisateurs de Kohonen. Le problème choisi est l'identification des mots anglais “yes” et “no” prononcés par plusieurs locuteurs et représentés par de simple vecteurs. Les résultats montrent que le perceptron multi-couches est supérieur aux autres méthodes et qu'il est d'une faible complexité à l'exécution.
Ce texte présente deux systèmes performants d'identification et de vérification du locuteur fondés sur la modélisation par mélange de gaussiennes, une caractérisation statistique robuste de l'identité d'un locuteur. La méthode d'identification est un classificateur à maximum de vraisemblance ; celle de vérification est un test de rapport de vraisemblance appuyé sur une normalisation des locuteurs. Les systèmes ont été évalués sur quatre bases de données publiques de parole : TIMIT, NTIMIT, Switchboard et YOHO. On y trouve une variabilité et des différences de qualité permettant d'évaluer les systèmes selon différents points de vue. Les contraintes y varient de l'élocution par mots isolés à la parole spontanée ; la qualité sonore va de la quasi-perfection à l'enregistrement téléphonique. L'identification dans un ensemble fermé de 630 locuteurs, pour TIMIT et NTIMIT, a atteint les taux respectifs de 99.5% et de 60.7%. Pour une population de 113 locuteurs extraits de Switchboard, le taux d'identification a été de 82.8%. Les taux globaux d'erreurs (à seuil égal) de 0.24%, 7.19%, 5.15% et 0.51% ont été obtenus dans les expériences de vérification sur les bases de données TIMIT, NTIMIT, Switchboard et YOHO.
Ce papier présente une nouvelle technique de réduction du nombre de canaux spectraux pour aider à la classification des images multispectrales en mode d'occupation du sol. Cette technique, basée sur des réseaux de neurones multicouches, propose une règle d'apprentissage de ces réseaux qui adapte le gradient conjugué à la méthode de rétropropagation ; permettant ainsi une convergence rapide au réseau.
Dans cet article, nous développons un modèle d'image qui fait appel aux champs aléatoires markoviens de Pickard dans le but de modéliser des notions contextuelles aussi vagues et imprécises que « l'uniformité d'une région » ou « la continuité du bord d'un objet » . Nous décrivons une méthode d'estimation par maximum de vraisemblance a posteriori obtenue par une généralisation simple d'une méthode largement utilisée dans le contexte unidimensionel de la reconnaissance de la parole.
Des liens sont nécessaires pour surmonter le fossé entre l 'analyse de la parole en tant qu'ensemble d'unités linguistiques discrétes, ordonnées mais atemporelles et les analyses de signaux acoustiques continúment variables dans le temps. Les dispositifs actuels de reconnaissance et de synthése usent mal de la structure imposée par les processus de production de la parole lors de l'application d'une séquence allophonique sur la pluralité des signaux de parole y associés. Nous avons développé en tant qu'aide à la description phonétique un cadre de réference articulatoire à la fois quantitatif et souple. Nous proposons des unités articulatoires pour quelques allophones de phonèmes anglais ainsi que des méthodes de liaison avec des allophones adjacents. Des spécifications préliminaires pour un sous-ensemble d'allophones sont proposèes qui sont basées sur des résultats déjà publiés. Les schèmes articulatoires sont organisés par rapport à des événements saillants E. Ces derniers peuvent concerner la coordination inter-articulateurs entre deux articulateurs différents et quasi autonomes ou concerner un seul articulateur maintenu dans un ètat statique. La coordination entre deux événements est exprimée à travers la durée D de l'intervalle temporel qui les sépare. Nous donnons six exemples de construction d'un plan articulatoire complet pour une séquence d'anglais. Ce plan forme le premier module d'un modèle numérique des processus articulatoires, aérodynamiques et acoustiques de la production de la parole. Le signal ainsi synthétisé est acoustiquement modifié afin de simuler les variations observables en parole naturelle et dues aux options des locuteurs, y compris les modifications du débit d'élocution. Ceci est obtenu en altérant une ou plusieurs valeurs D dans le plan temporel et en négligeant quelques actions optionnelles. La variabilité observée lors de multiples répétitions par un locuteur réel peut être simulée en perturbant les valeurs D. Le modéle réclame d'être confronté à des locuteurs réels afin d'évaluer le réalisme de sa simulation de la variation et de la variabilité des traits acoustiques parole naturelle ainsi que son degré de prédictabilité des covariations.
Cet article explore dans quelle mesure la qualité vocale d'un locuteur, définie comme le timbre perçu de la parole d'un individu, évolue en fonction de la variation mélodique. Les analyses sont fondées sur plusieurs productions de la voyelle `a' correspondant à différents patrons intonatifs. I1 apparaı̂t qu'en général la fréquence fondamentale covarie avec la `relation de force' entre les deux premiers harmoniques (H1–H2). Cette relation détermine dans une certaine mesure la qualité vocale et elle est souvent avancée comme le reflet du quotient d'ouverture. Cependant, la corrélation de la mesure de H1–H2 avec les paramétres du modéle LF ŕevéle que le quotient d'ouverture et l'asymétrie de l'impulsion glottique ont tous deux un impact sur la partie basse du spectre harmonique
Nous avons réalisé trois expériences dans le but d'examiner l'effet d'intégration temporelle sur la sonie dans des syllables CV. La voyelle du stimulus de référence [ta] utilisé dans les tests de perception a une durée de 250 ms et une intesité de 70 dB SPL. Les durés retenues pour la voyelle du stimulus variable [ta] sont : 75, 100, 150, 200 et 250 ms. L'intervalle entre les voyelles a été fixé à 200 ms, dans l'expérience I et à 600 ms, dans l'experience II. Pour ces deux expériences, nous avons employé une méthode d'adjustment pilotée par ordinateur. le niveau de différence mesuré en dB est fonction décroissante de la durée de la variable. Il est inférieur à 2 dB pour la durée la plus bréve et égal à 0.2 dB pour la durée la plus longue. Dans l'expérience III, nous avons employé la méthode 'Up-Down-Transformed-Response' et les mêmes stimulus que dans l'expérience II. Les valeurs du niveau de différence obtenues dans cette derniére expérience sont légèrement supérieures à celles mesurées dans les expériences I et II, mais elles définissent une courbe de même allure.
Un nouvel algorithme est décrit pour l'extraction de la fréquence fondamentale. La méthode est basée sur l'utilisation ittérative d'un filtre linéaire de phase nulle et réponse fréquencielle décroissante en fonction de la fréquence. Les résultats montrent que cette méthode est efficace et résistante à la présence de bruit.
Dans cet article, nous présentons une nouvelle approche dans le domaine de la fouille textuelle, dans le but de faciliter le développement d'interfaces intelligentes pour les utilisateurs de systèmes de recommandation et de recherche documentaire. En recherche documentaire, le principal problème pour les utilisateurs est de disposer de connaissances quasiment parfaites du domaine d'application et de sa terminologie. Notre approche vient atténuer cette nécessité en permettant d'encoder les connaissances de domaines d'application de manière à ce que les systèmes de recherche documentaire puissent transformer la terminologie (relative aux domaines) des utilisateurs en celle des experts des domaines respectifs. Cette transformation effectuée, les systèmes peuvent consulter leurs bases de données pour trouver les informations recherchées. La faisabilité de notre approche est démontrée par l'étude de cas d'un système de recommandation d'émissions de télévision.
L'engouement du grand public pour les applications multimédia sans fil ne cesse de croître depuis le développement d'Internet. Des contraintes d'hétérogénéité de canaux de transmission, de fiabilité, de qualité et de délai sont généralement exigées pour satisfaire les nouveaux besoins applicatifs entraînant ainsi des enjeux économiques importants. C'est dans ce cadre que s'inscrit le panorama présenté ici. Cet article présente d'une part un état de l'art sur les principales techniques de codage et de décodage conjoint développées dans la littérature pour des applications multimédia de type téléchargement et diffusion de contenu sur lien mobile IP. Sont tout d'abord rappelées des notions fondamentales des communications numériques à savoir le codage de source, le codage de canal ainsi que les théorèmes de Shannon et leurs principales limitations. Les techniques de codage décodage conjoint présentées dans cet article concernent essentiellement celles développées pour des schémas de codage de source faisant intervenir des codes à longueur variable (CLV) notamment les codes d'Huffman, arithmétiques et les codes entropiques universels de type Lempel-Ziv (LZ).
La biométrie, qui désigne la mesure d'attributs caractéristiques du corps humain, est très utile pour authentifier un individu, comme par exemple pour le contrôle d'accès. Le marché de l'authentification par des approches biométriques est favorisé par les récents progrès des technologies informatiques, et l'essor du commerce électronique et des objets de communication nomades (téléphones et ordinateurs portables, PDA, etc.), qui nécessitent d'identifier automatiquement une personne physique plutôt que d'utiliser un mot de passe ou une carte d'accès. Bien que chacune des techniques biométriques présente un intérêt particulier suivant l'application visée, nous constatons que les systèmes de reconnaissance basés sur l'iris sont parmi les plus fiables. Nous montrerons la faisabilité d'intégration de la technologie de l'iris sur les futurs terminaux mobiles, et plus particulièrement la portabilité de la chaîne algorithmique de traitement d'images d'iris sur une plate-forme multimédia embarquée basée sur le module-cœur ARM920T.
La suppression d'échos permet d'obtenir l'agrément d'une conversation à mains libres, le feedback et le guidage vocal rendent possible l'utilisation du téléphone dans les situations qui requiérent toute l'attention visuelle, enfin et surtout, la reconnaissance de la parole libère l'utilisateur de la manipulation du clavier pour composer le numéro d'appel. L'article présente de manière claire et accessible un appareil qui incorpore ces diverses technologies et qui a été réalisé comme une extension à la série des produits Philips pour la téléphonie mobile. L'accent est mis sur les algorithmes de reconnaissance de la parole. La robustesse aux changements d'environnement acoustique a été améliorée par l'estimation et la soustraction du spectre à long terme. Nous montrons que lorsque cette dernière opération est effectuée récursivement, elle est équivalente aux techniques de filtrage de type passe-haut de même qu'aux méthodes “RASTA” (approaches spectrales relatives) qui ont été récemment proposées dans la litérature.
La téléconférence par le RNIS, les services multi-média sur CD-ROM, la télévision haute définition créent de nouvelles applications et de nouveaux paris pour le codage large-bande des signaux et en particulier de la parole. Dans le codage de la parole large-bande, un point de repère important est le standard CCITT à 64 kbit/s pour la parole à 7 kHz. Des résultats de recherche récents mettent en avant de meilleures performances — une plus large bande à 64 kbit/s, ou une bande de 7 kHz pour des débits réduits à 32 ou 16 kbit/s. Le codage audio de signaux dans une bande de 20 kHz suscite une attention accrue, avec l'activité récente de l'ISO (International Standard Organisation), dans le but de stocker un canal audio monophonique de la qualité du Compact Disque à un débit n'excédant pas 128 kbit/s. Les chances d'y parvenir sont élevées. En contrepartie, les algorithmes qui apparaissent offriront une option très attirante à des débits tels que 96 et 64 kbit/s.
L'étude présentée ici s'interroge sur le contenu émotionnel perçu des “Affect Bursts” pour l'Allemand. Les Affect Bursts sont définis comme expressions courtes, émotionnelles et non-verbales. Cette étude démontre que les Affect Bursts, présentés sans contexte, peuvent transmettre un sens émotionnel clairement identifiable. L'influence de la structure ségmentale sur la reconnaissance des émotions, vis-à-vis de la prosodie et du timbre, est étudiée. Le degré d'accord entre les transcripteurs est utilisé comme critère expérimental pour distinguer entre les Affect Bursts Crus, réflexifs, et les Emblèmes Affectives conventionalisées. Un compte rendu détaillé de 28 classes d'Affect Bursts est présenté, comprenant l'émotion perçue et le taux de reconnaissance dans des tests de perception orale et écrite, ainsi qu'une transcription phonétique de la structure ségmentale, du timbre et de l'intonation.
En situant dans des contextes culturels et philosophiques les tentatives d'enseigner le langage à des espèces non humaines, les auteurs ont examiné les positions évolutionnistes de l'origine du langage ainsi que la thèse de Quine sur l'adéquation imparfaite de la traduction. L'opposition du langage naturel acquis par les humains et du langage artificiel enseigné aux non humains, les amènent à traiter l'esprit humain comme une combinaison d'apprentissage, de cablages et de cognition. Les auteurs discutent la nature de chacun de ces composants, suggèrent des interactions possibles et comparent le système humain à trois composants avec le système à deux composants des autres espèces.
Récemment, nous avons proposé un modèle entrée-sortie de l'impulsion glottique. Mathématiquement parlant, l'impulsion est décomposée en une excitation cosinusoïdale et deux formeurs non linéaires. L'impulsion est reconstituée lorsque la cosinusoïde est injectée dans les formeurs. Dans cet article, nous montrons que les cycles de l'onde glottique d'un locuteur peuvent être synthétisés à partir des formeurs d'un faible nombre de cycles de référence. En effet, les systèmes non linéaires ne sont pas caractérisés par une fonction de transfert. Par conséquent, on peut supposer que les formeurs non linéaires d'une impulsion glottique sont moins variables que la forme d'onde proprement dite. Deux expériences ont été réalisées afin de vérifier ces hypothèses. Dans la première, les formes d'onde statiques émises par un modèle à deux masses des cordes vocales ont été copiées. Dans la deuxième, le signal glottique obtenu pour un logatome [ama], produit par un locuteur masculin, a été analysé et synthétisé. Chaque impulsion a été caractérisée par son amplitude de crête, sa période et son facteur de forme. Dans les deux expériences, les indices de toutes les impulsions glottiques ont été copiés en calculant les coefficients des formeurs de deux cycles de référence et en ajustant les paramètres de contrôle de la cosinusoïde à l'entrée jusqu'à obtention des valeurs d'indices souhaitées à la sortie.
Ce texte porte sur un codeur d'analyse-synthèse encodant les objets plutôt que les blocs N × N constituant l'image. Les objets sont décrits par trois ensembles de paramètres décrivant leur trajectoire, leur forme et leur couleur. Ces ensembles sont obtenus par une analyse de l'image basée sur des modèles de source d'objets 2D ou 3D en mouvement. Des techniques de codage connues sont utilisés pouur encoder ces ensembles. Ce codage par objets introduit des distorsions géométriques au lieu d'erreurs de quantification. A l'aide des ensembles de paramètres transmis une image peut être reconstruite par synthèse basée sur modèle. Des résultats expérimentaux obtenus lors d'une première mise en oeuvre du codeur sont présentés et commentés.
Nous proposons une méthode statistique de modélisation du dialogue basée sur la théorie de l'information et la théorie des actes de langage. Le modèle du dialogue consiste en trigrammes d'énoncés classés en fonction de leurs actes de langage associés. Il peut être utilisé pour éliminer, à la sortie de l'étage de reconnaissance, les candidats erronés (syntaxiquement et sémantiquement corrects mais incorrects d'un point de vue contextuel) en examinant si ces énoncés candidats forment un discours local naturel du point de vue du séquencement des actes de langage. Comme ce modèle est basé sur la théorie de l'information, nous pouvons définir des mesures objectives de la qualité du modèle de dialogue, comme la perplexité du discours. Des expériences sur 100 dialogues au clavier, incluant 2722 énoncés et 38954 mots, montrent que ce modèle de dialogue peut prédire le type d'acte de langage de l'énoncé subséquent. En utilisant 90 dialogues pour l'apprentissage et les 10 autres dialogues pour le test, on obtient un score de prédiction correcte de 39.7% pour le premier candidat et de 61.7% pour les 3 premiers candidats. Nous montrons également que l'on peut améliorer le modèle de langage en combinant le modèle de dialogue avec le modèle de phrases. Calculée sur les 100 dialogues, la perplexité de mots des bigrammes de mots associés à des trigrammes d'actes de langage est de 7.27 alors que celle d'un simple bigramme de mots est de 1.16.
Pour construire un système robuste de traitement du langage naturel, on doit incorporer un module de gestion du dialogue. L'élaboration d'un tel module requiert une bonne compréhension des conversations homme-homme. Dans ce but, on propose ici une tentative de présentation de la notion de conversation comme collaboration. Les arguments justifiant le fait que la conversation est, de façon inhérente, une collaboration sont basés sur des phénomènes syntaxiques observés dans des conversations spontanées en Anglais. Dans cet article, “collaboration” signifie co-production simultanée d'une conversation par les participants et non pas seulement la construction de significations conversationnelles par des contributions ponctuelles, alternantes, des interlocuteurs. Les structures syntaxiques que l'on évoque pour soutenir ce point de vue sont des listes, des questions en écho, des réponses brèves, des productions associées et ce que nous appelons ici des “structures parallèles” et des “accomodations”. Des suggestions sont faites en ce qui concerne l'impact de cette approche sur l'analyse des conversations et l'élaboration d'interfaces homme-machine.
Cet article est consacré à l'évaluation statistique des descriptions de tables de contingence fournies par les arbres d'induction. On se limite au cas particulier de données catégorielles. Trois aspects sont successivement abordés. i) La nature de l'ajustement en apprentissage supervisé, où l'on souligne la distinction entre prédiction de valeurs individuelles et prédiction de leur représentation sous forme de table de contingence. ii) La description de tables fournies par les arbres d'induction que l'on compare notamment à la modélisation log-linéaire utilisée en statistique. iii) L'adaptation au cas des arbres d'induction des mesures et statistiques de qualité d'ajustement utilisées en modélisation log-linéaire. La discussion est complétée par une illustration sur les données du Titanic.
Une représentation du signal de parole comme somme de fonctions élémentaires permet de réaliser simplement des modifications spectro-temporelles, globales ou locales. Après avoir discuté de la modélisation du signal de parole en somme de fonctions élémentaires, un système automatique d'analyse-synthèse est présenté. Les paramètres du modèle sont estimés grâce à une analyse trame par trame : modélisation et segmentation spectrale en utilisant la transformée de Fourier à court terme et la prédiction linéare, filtrage adaptatif par transformée de Fourier à court terme suivant cette segmentation, détection et modélisation des formes d'ondes élémentaires dans chaque bande d'analyse. Les paramètres du modèle étant pertinents pour le modèle acoustique linéaire de production de la parole, leur manipulation autorise des traitements comme, par example, l'expansion/compression spectrale, la modification de la fréquence de voisement, des formants, du bruit de frication.
C'est dans ce dernier secteur que se situent l'appareil d'enseignement et l'Académie, simple institution spécialisée, y compris les textes (circulaires, programmes) qui expliquent cette action organisatrice. Dans les trois cas, l'État ne produit qu'indirectement et marginalement des normes de langue – en dépit de mythes tenaces. Tout cela souligne la composante idéologique, centrée sur le concept de légitimité – mais aussi consensus, norme-normalisation, insécurité, etc. Ces débats concernent la nature de l'État et la cohésion du corps politique.
Nous proposons, dans le présent papier, une approche originale dans un cadre statistique pour l'identification automatique des reins (sains et pathologiques) sur des images tomographiques bidimensionnelles (CT). Notre approche est constituée de deux phases : une phase de localisation suivie d'une phase de délimitation. La phase de localisation est guidée, d'une part, par un modèle a priori spatial et d'autre part, par un modèle a priori sur les niveaux de gris, statistiquement appris. La seconde phase consiste à utiliser les résultats de la localisation afin de délimiter la région du rein en utilisant un ensemble de règles. Cette approche est testée sur des images cliniquement acquises et des résultats satisfaisants sont obtenus.
On présente ici un bilan de certaines études récentes menées au KTH sur l'acoustique de la source vocale et sur l'analyse et la modélisation du flux glottique associé. On examine les aspects temporels et fréquentiels du processus de production dans le but de relier les paramètres du flux glottique obtenus par filtrage inverse et les fonctions de transfer du conduit vocal à l'amplitude et à la largeur de bande des formants. On propose de nouvelles méthodes de détermination de la constante de temps Ta = 1 (2πFa) dans la phase de retour de la dérivée du flux glottique après l'instant d'excitation, et donc de la pente globale du spectre glottique. Un filtrage inverse sélectif, ne conservant qu'un seul formant, semble être à cet égard une méthode prometteuse. L'influence des imprécisions dans la quantification des fonctions de transfert du conduit vocal est illustrée sur un exemple : on montre par calcul que l'introduction d'un effet fini d'atténuation de la tête ajoute une amplification supplémentaire haute-fréquence à l'amplification standard de 6 dB/octave. Une attention particulière a été apportée aux variations temporelles au sein d'un énoncé, telles que dérivées d'un filtrage inverse continu. On examine les questions de voisement bruité et de différences homme-femme dans la production de la voix. On démontre que, sur un énoncé produit par un locuteur masculin, le profil temporel de l'amplitude d'excitation E e (t) peut être approché par l'enveloppe de la partie négative du signal de parole.
Cet article présente une étude acoustique et perceptive des accents focal et postfocal dans les questions en italien de Naples. Dans cette variété de l'italien, les accents mélodiques des questions à reponse “oui/non” sont caractérisés par une montée suivie d'une descente avec un pic très marqué (L*+H). Lorsque la focalisation intentionelle est placée tôt, un accent postfocal aligné avec la dernière syllabe accentuée de la phrase intonative est produit ( !H*). Les résultats perceptifs suggerènt que l'accent postfocal ( !H*) n'est pas l'accent nucléaire de la phrase intonative, malgré sa position finale. La nature phonétique et phonologique des accents focal (L*+H) et postfocal ( !H*) sont aussi analysées en production à l'aide de questions “oui/non” caractérisées par types de focalisation différents. Les résultats défendent l'hypothèse que les accents focal et postfocal sont structurellement différents dans la mesure où l'accent postfocal est plus réduit. Finalement, nous avons étudié l'alignement temporel et les valeurs mélodiques de la montée initiale et de la chute finale pour des constituants focaliques de différentes tailles dans des questions où la focalisation est placée tôt. Les résultats suggèrent un effet de “répulsion tonale” (Silverman et Pierrehumbert, 1990) à la position temporelle du pic de l'accent L*+H, ainsi qu'un effet de “troncature apparente” de la chute finale, dans les constituants focaliques d'un seul mot.
Les simulations à base d'agents (MABS) ont été utilisées avec succès pour modéliser des systèmes complexes dans de nombreux domaines. Néanmoins, un problème des MABS est que leur complexité augmente avec le nombre d'agents et de types de comportements différents considérés dans les modèles. Pour des systèmes de taille moyenne à grande, il est impossible de valider, voire même d'observer simplement les trajectoires des agents individuels lors d'une simulation. Les approches de validation classiques, où seuls des indicateurs globaux sont calculés, sont trop simplistes pour permettre d'évaluer le modèle de simulation avec un degré de confiance suffisant. Il est alors nécessaire d'introduire des niveaux intermédiaires de validation et d'observation. Dans cet article, nous proposons l'utilisation de la classification automatique de données (clustering) combinée à la caractérisation automatisée de clusters pour construire, décrire et suivre l'évolution de groupes d'agents en simulation. La description de clusters est utilisée pour générer des profils d'agents qui sont réintroduits dans les simulations avec l'objectif d'étudier la stabilité des descriptions et des structures des clusters sur plusieurs simulations et de décider de leur capacité à décrire les phénomènes modélisés. Ces outils permettent au modélisateur d'avoir un point de vue intermédiaire sur l'évolution du modèle. Ils sont suffisammentflexibles pour être appliqués à la fois hors ligne et en ligne comme le montrent les analyses réalisées à la fois sur des simulations Netlogo et sur des logs de simulations.
Les modèles dominants de la reconnaissance des mots parlés font jouer un rôle essentiel au composant d'accès lexical dans l'identification des mots. Pour ces modèles, le processus de reconnaissance est une opération simple qui associe l'input à des représentations lexicales emmagasinéés en mémoire ou qui active directement ces représentations. Etant donnée cette caractérisation du problème, on voit mal comment la connaissance qu'a l'auditeur de la structure de sa langue pourrait faciliter la reconnaissance des mots. Et pourtant, il peut être nécessaire d'utiliser la connaissance grammaticale pour résoudre bien de problèmes considérés comme importants par les théories de la reconnaissance des mots : la segmentation, la variabilité de la réalisation acoustique des mots et la reconnaissance de mots nouveaux. Cet article prend au sérieux la possibilité que la connaissance grammaticale participe à la reconnaissance des mots. Il étudie quels types d'information pourraient servir à cette fin. Il essaye aussi d'esquisser quel type de systéme de reconnaissance des mots pourrait tirer profit des régularités que l'on rencontre dans les langues naturelles.
Nous présentons un environnement flexible pour la génération d'hypothéses lexicales en parole contibue. Aprés avoir décrit l'interface avec les autres modules de notre système de compréhension de la parole, un algorithme de vérification et de détection de mots baśe sur HMM est discuté. La génération des modèled de réfŕence pour la procédure de mise en correspondance est effectuée automatiquement en utilisant la prononciation standard du mot ainsi qu'un ensemble de règles phonologiques sur les phénomǹes d'assimilation internes au mot. Les prononciations possibles sont représentées par des graphes à extrémités libellées. Nous présentons quelques résultats obtenus par la procédure de mise en correspondance.
Une étude sur l'utilisation de l'apprentissage bayésien des paramètres de densités multigaussiennes a t́é effectuée. Dans le cadre des modèles markoviens cachés à densitiés d'observations continues (CDHMM), l'apprentissage bayésian est un outil très général applicable au lissage des paramètres, à l'adaptation au locuteur, à l'estimation de modèles par groupe de locuteurs et à l'apprentissage correctif. Le but est d'augmenter la robustesse des modèles d'un système de reconnaissance afin d'en améliorer les performances. Notre approche consiste a utiliser l'apprentissage bayésien pour incorporer une connaissance a priori dans le processus d'apprentissage sous forme de densités de probabilités des paramètres des modéles markoviens. La base théorique de cette procédure est présentéee, ansi que les résultats obtenus pour le lissage des paramètres, l'adaptation au locuteur, l'estimation de modèles propres à chaque sexe et l'apprentissage correctif.
Vingt locuteurs masculins néerlandais ont lu 47 mots-test présentés en liste et dans de courtes phrases. Ils ont également eu à énoncer un sous-ensemble de ces mots directement à partir de la présentation d'images. On a demandé à un groupe de vingt auditeurs d'identifier une voyelle non-accentuée dans chacun de ces mots-test. Les réponses des auditeurs ont été codées en deux grandes catégories : “voyelle complète” et “schwa”. Nos buts étaient (1) de trouver dans quelle mesure les auditeurs étaient capables de distinguer ces deux classes de façon non-ambigue, (2) d'étudier l'influence de la fréquence d'occurrence des mots sur la classification des voyelles test, (3) d'étudier l'influence des styles d'élocution sur cette classification en comparant les conditions “liste”, “images” et “phrases”. Les résultats expérimentaux montrent que (1) les auditeurs, souvent, ne peuvent pas classer de façon non-ambigue les voyelles test, en particulier quand elles apparaissent en position “interstress”, (2) le nombre des réponses “schwa” était beaucoup plus élevé pour les voyelles contenues dans des mots à fréquence d'occurrence élevé, (3) le nombre de réponses “schwa” augmentait dans le cas d'élocution plus relachée. Des mesures acoustiques sur les voyelles test montrent une relation claire entre les résultats perceptifs et les indices acoustiques. Bien que les pré-conditions du changement “voyelle complète → schwa” soient excellentes dans un certain nombre de mots en néerlandais, la réalisation concrète de ce changement est, de notre point de vue, bloqué dans une large mesure par la correspondance assez étroite en néerlandais entre les réalisations acoustiques des voyelles et leurs représentations orthographiques.
Récemment, des résultats quantitatifs ont été publiés sur les changements acoustiques observés dans la parole Lombard par rapport à la parole normale. Ces résultats montrent que le réflexe Lombard est très dépendant du locuteur. Dans cet article, nous examinons brièvement l'influence de l'environment acoustique sur la production de la parole et résumons les principales caractéristiques de l'effet Lombard. Nous présentons ensuite des résultats expérimentaux montrant comment le réflexe Lombard varie avec le sexe du locuteur, le langage et l'environnement (e.g. type de bruit). Enfin, nous discutons comment l'utilisation d'indices relationnels peut permettre de réduire l'influence du réflexe Lombard sur les systèmes automatiques de reconnaissance de parole.
Dans le présent article, nous utilisons les résultats d'une étude de la langue anglaise et l'appliquons dans un algorithme de syllabification. Notre système permet aussi l'identification automatique d'accents étrangers et peut etre utilisé avec des données générées de façon manuelle ou automatique. Les éléments de la structure syllabique sont definis selon leurs positions à l'intérieur des structures des syllables et des mots. Les éléments de la structure syllabique qui apparaissent uniquement à la bordure d'un morphème sont identifiés comme éléments périphériques ; ceux qui se présente à n'importe quel endroit de la morphologie du mot sont identifiés comme éléments centraux. Toutes les langues font potentiellement une distinction entre les éléments centraux et péripheriques de leur structure syllabique. Cependant, les formes que prennent ces structures syllabiques varient d'une langue à l'autre. En plus des problémes posés par les différences entre les inventaires de phonèmes, nous nous attendons à ce que les personnes avec de grandes différences structurelles entre la langue maternelle et étrangere sont celles qui ont les plus grandes difficultés dans la prononciation de la langue étrangère. Dans cet article, nous analysons deux accents étrangères de l'anglais australien : la première est basé sur l'arabe, dont la structure centrale et périphérique est similaire à l'anglais, et la seconde est fondé sur le vietnamien, dont la structure diffère au plus au degré de celle de l'anglais.
Nous proposons une approche nouvelle en reconnaissance de la parole continue fondée sur un décodage phonétique ; à chaque phonème doit être assocée une fonction temporelle : la plausibilité d'observer ce phonème. Nous présentons un critère de choix de la meillure phrase, lié à la somme des plausbilités des symboles qui la composent. En se fondant sur l'idée d'utiliser les régions de forte plausibilité pour réduire la complexité de calcul tout en préservant l'optimalité, notre méthode trouve les phrases les plus plausibles pour la parole en entrée, étant donnée la plausibilité μ a,n d'observer le phonème a à l'instant n. Deux procédures d'optimisation ont été défines pour traiter les deux problémes de recherche imbriqués suivants : (1) trouver le meilleur chemin joignant les pics de la fonction de plausibilité de deux symboles successifs, et (2) trouver l'instant de transition optimal entre deux pic donnés. On emploie dans les deux cas la programmation dynamique. La reconnaissance est très performante, car l'algorithme de recherche du meilleur chemin ne procède pas trame. Les résultats expérimentaux du système VINICS montrent que cette méthode produit la meilleure précision de reconnaissance et qu'elle demande environ 1/20 du temps de calcul méthodes traditionnelles de programmation dynamique. Le système expérimental a obtenu 95% de reconnaissance de phrases dans un test pluri-locuteur.
On présente un nouvel algorithme de recherche pour la reconnaissance de la parole continue á trés grand vocabulaire. La complexité de cet algorithme augmente de seulement dix fois en passant des mots isolés á la parole continue. On donne des résultats préliminaires obtenus en testant le systéme de reconnaissance sur des livres sur cassette utilisant un dictionnaire de 60 000 mots.
Cet article traite d'un système d'analyse-synthèse basé sur la méthode de covariance et qui est capable de manipuler indépendamment les fréquences des formants et leur largeuz de bande. L'analyse synchronisée de la fréquence fondamentale est faite sur la base du minimum local de l'erreur quadratique normalisée. Après avoir estimé les fréquences des formants et leur largeur de bande, on modifie les coefficients prédicteurs de manière à ce qu'ils soient la solution de la nouvelle équation polynominiale. Ce système peut être appliqué pour modifier la voix et comme moyen de recherche en perception de la parole sur la qualité vocale et la personnalité du locuteur.
Depuis de nombreuses années, l'analyse de réseaux neuronaux suit un essor fantastique. L'étude suivant cette approche des fonctions postulées dans le système nerveux requiert de puissants outils de simulation. En nous inspirant à la fois des caractéristiques générales en traitement des signaux et des tendances actuelles vers le parallélisme, en matière de structures de calculateurs, nous proposons une architecture d' « array » processeur performante pour l'étude de réseaux récursifs adaptatifs en particulier et pour l'analyse de données (signal, image) en général : c'est le processeur « CRASY » (Calculateur de Réseaux Adaptatifs SYstolique).
Nous présentons dans cet article un opérateur de classification rapide adapté au traitement d'images, ses performances en classification, ainsi que son intégration dans un circuit ASIC. Pour effectuer une segmentation ou un classement d'images en vue de la détection de défauts, il est souvent impossible de trouver un nombre réduit de paramètres caractéristiques pertinents qui permettent de discriminer les classes. Nous proposons une méthode de classification géométrique par apprentissage de polytopes de contraintes, qui autorise l'utilisation d'un grand nombre de paramètres et assure une vitesse de décision élevée. L'opérateur de décision associé à cette classification a été intégré sous forme de circuit précaractérisé dont la simplicité de mise en œuvre, la rapidité et la robustesse en classification sont des qualités qui lui permettent de rivaliser avec les opérateurs neuronaux.
Dans cet article, un algorithme de segmentation d'images basé sur une technique d'étiquetage crédibiliste est présenté. La contribution essentielle de ce travail réside dans la façon dont les images sont modélisées par des fonctions de croyance de façon à représenter l'incertitude inhérente à l'étiquetage d'un voxel à une classe. L'allocation de masse réalisée pour chaque voxel est construite à partir des caractéristiques intrinsèques des régions qui composent l'image. Afin de limiter cette incertitude dans la phase d'étiquetage, on diminue de façon progressive un seuil de décision tout au long d'un processus itératif jusqu'à sa stabilisation. Cet algorithme est appliqué à la segmentation de volumes d'intérêt sur des images TDM.
Cette étude explore l'héritage intellectuel laissé par le juriste koufien Muḥammad b. Sulaymān al-Kūfī (m. au début du iv e/x e siècle) qui s'établit au Yémen et appartint au cercle de lettrés dans l'entourage d'al-Hādī ilā l-Ḥaqq Yaḥyā b. al-Ḥusayn (m. 298/911). Elle propose une analyse de son œuvre la plus importante, le Kitāb al-Muntaḫab, à travers un examen singulier des pratiques rituelles qui se focalise sur l'emploi de la basmala dans la prière quotidienne. En conclusion, nous montrons la valeur du Muntaḫab comme voie d'accès possible à un courant de jurisprudence koufien qui n'a pas survécu à l'époque moderne.
Grâce aux progrès en technologie des transducteurs, en traitement du signal et en informatique, il est désormais possible de réaliser des saisies sonores de bonne qualité dans des zones spatiales données malgré des conditions acoustiques difficiles. Les techniques de formation de voie et de filtrage adapté sont appliquées à des antennes bi- ou tri-dimensionnelles de capteurs. La performance des antennes est évaluée de amnière préliminaire par la simulation informatique des salles et par une analyse des images de leur effet d'environnement. Les résultats incitent à penser que des signaux de bonne qualité peuvent être récupérés dans des zones spatialement localisées de milieux fermés fortement réverbérants. Réciproquement, on peut appliquer les mêmes techniques à la projection sonore spatialement sélective.
Les contraintes grammaticales et sémantiques jouent un rôle essentiel dans l'interprétation ou la compréhension des expressions linguistiques. Toutefois, elles semblent être inadéquates pour faire un choix parmi plusieurs candidats qui sont tous soit corrects, soit incorrects d'un point de vue grammatical ou sémantique. Il est clair que l'être humain interprète une expression linguistique d'une manière contextuelle, même s'il y a plusieurs interprétations possibles. Cette méthode calcule des scores de similarité entre expressions linguistiques et des probabilitiés pour sélectionner l'expression la plus adéquate. Elle tient compte de classifications de type morpho-syntaxique et de type force illocutoire, qui sont associées aux fréquences de séries d'expressions linguistiques voisines, stockées dans des bases de données d'exemples. Une unité expérimentale de traitement, effectuant ce type d'analyse du contexte local, a été implémentée dans un prototype de traduction bilatérale (anglais et japonais), prouvant son applicabilité à la sélection de candidats dépendants du contexte pour la traduction. Ce mécanisme d'analyse du contexte local peut être utilisé dans des systèmes de traduction conventionnels sans traitement contextuel pour augmenter la précision de la traduction.
Dans cet article, nous montrons comment le problème de l'acquisition des grammaires peut être ramené à un problème d'apprentissage inductif de règles heuristiques. Nous décrivons le système GASRIA (grammaire apprise par simulation répétée intelligemment et automatiquement) composé de : un module d'apprentissage inductif appelé SAGE, basé sur une méthode originale capable d'analyser des chaînes de caractères non analysables par les méthodes existantes, en l'occurrence l'algorithme de l'analyse partielle (AAP), développé et testé, un environnement de programmation en logique de premier ordre, une base de connaissances comprenant une base de règles avec variables.
Nous présentons une nouvelle méthode interactive de visualisation 3D de données multimédia (numériques, symboliques, sons, images, vidéos, sites Web) en réalité virtuelle. Nous utilisons un affichage 3D stéréoscopique permettant de représenter les données numériques. La navigation au sein des visualisations est effectuée grâce à l'utilisation d'un capteur 3D à six degrés de liberté qui simule une caméra virtuelle. Des requêtes interactives peuvent être posées à la machine par l'utilisation d'un gant de données reconnaissant les gestes. Nous montrons comment cet outil est appliqué sur un cas réel concernant l'étude de la peau humaine saine.
Dans cet article, on décrit un système mono-plaquette en ligne destiné à la reconnaissance d'un mot isolé et indépendant du locuteur. Le systéme est constitué, d'une part, d'un prétraitement câblé qui est un modèle simplifié du traitement auditif périphérique et, d'autre part, d'un microprocesseur. A l'aide de plusieurs tests, l'influence de la longueur du mot, de la gamme dynamique et de la configuration du filtre sur la performance de reconnaissance a été étudiée. Les résultats indiquent qu'une gamme dynamique de 30 dB semble adéquate et que trois ou quatre bits par canal sont suffisants pour encoder l'information d'amplitude. Enfin, on a examiné l'influence que pouvait avoir le fait de varier les paramètres du filtre.
Nous présentons une nouvelle méthode de reconnaissance de caractères manuscrits fondée sur le principe des modèles de Markov pseudo-2D ou planaires (PHMM). Cette méthode se situe dans la classe des techniques qui tentent de rétablir la forme prototype d'un caractère à partir d'une version déformée de celle-ci. Contrairement aux approches souvent proposées dans ce domaine, notre méthode ne repose sur aucune extraction de traits explicite et produit des scores de reconnaissance qui sont des estimations des probabilités bayesiennes. Elle se prête à un apprentissage automatique. Une de ses caractéristiques distinctive est l'utilisation d'un modèle probabiliste (réseau de Markov) réellement bi-dimensionnel mais causal pour estimer les probabilités. Enfin, on montre comment on peut engendrer des images synthétiques des caractères possibles et ce suivant leur probabilité estimée par le modèle.
Nous décrivons dans cet article des problèmes typiques rencontrés avec les équipements mains-libres dans le contexte de la radiotéléphonie GSM. Nous commencons par résumer les principales caractéristiques du bruit dans un véhicule en mouvement, et nous décrivons également le phénomène d'écho acoustique. Nous montrons que, pour assurer une qualité de parole suffisante, ces équipements mains-libres doivent introduire des dispositifs de réduction de bruit (NR) et de contrôle de l'écho acoustique (AEC). Nous présentons ensuite deux solutions techniques envisageables pour l'amélioration de la qualité du signal de parole dans un tel contexte. En conclusion, nous soulignons le fait que le choix d'une structure particulière parmi celles proposées est conditionné par l'algorithme d'adaptation du système de contrôle de l'écho acoustique considéré.
Une nouvelle approche de la modélisation adaptative du niveau sémantique du langage a récemment été proposée. La reconnaissance ou la compréhension sont envisagées comme une procédure de Transduction de Formats qui exploite l'ensemble des contraintes acoustiques et linguistiques qui ont été encodées dans les modèles appris pour entrer directement des signaux acoustiques bruts et sortir les messages sémantiques qui sont convoyés par ces signaux. Dans cet article, l'approche proposée est revue et de nouvelles améliorations sont présentées. Des résultats préliminaires sur de la parole continue avec un grand espace sémantique (nombres espagnols de l à l million) sont présentés.
Un système est décrit dans cet article qui ajoute à la parole synthétique des effets d'émotions simulées. Les paramêtres de contrôle d'un synthétiseur de parole sont contrôlés par des règles de facon à simuler les caractéristiques des émotions exprimées dans la voix humaine. Le système, qui simule six émotions vocales, a été testé sur les auditeurs naïfs. Les résultats montrent que le système reproduit des émotions vocales reconnaissables avec un taux de perception égal à celui de recherches antérieures sur la parole “expressive”. Ce système a été développé comme prothèse vocale pour les personnes muettes, mais on peut envisager son utilisation pour améliorer toute application de synthèse de parole par règles.
Cet article décrit un système de classification phonétique basé sur un réseau de neurones récurrent appliqué aux informations visuelle et auditive. On fournit les résultats de quelques expériences de reconnaissance phonétique, en modes dépendant et indépendant du locuteur, concernant les plosives en Italien.
Dans cet article, nous nous efforçons de présenter, de la façon la plus complète possible, une approche pour la conception de systèmes adaptatifs complexes, basée sur les systèmes multi-agents adaptatifs et l'émergence. Pour cela, nous décrivons tout d'abord la théorie des Amas (Adaptive Multi-Agent Systems). Cette théorie donne des critères locaux de conception des agents qui permet l'émergence d'une organisation au sein du système et donc également l'émergence de sa fonction globale. Puis, nous étudions une application en e-éducation utilisant cette théorie à travers son fonctionnement technique et des expérimentations qui sont ensuite discutées. D'autres applications (prévision de crues, e-commerce, routage téléphonique) sont aussi décrites, illustrant divers domaines où la théorie a également été appliquée avec succès. Finalement, nous caractérisons les phénomènes d'émergence dans ces applications et positionnons notre théorie par rapport à d'autres.
La modélisation statistique du signal de parole a été largement utilisée en reconnaissance automatique du locuteur. Les performances obtenues avec cette approche sont excellentes, en laboratoire. Cependant, une dégradation significative des performances est observée avec de la parole de qualité téléphonique ou bruitée. Pour palier ce problème, il est nécessaire de mieux comprendre la nature de l'information spécifique du locuteur exploitée par ces méthodes statistiques. Cette connaissance doit permettre de mieux prendre en compte l'information pertinente et/ou de mettre à contribution de nouvelles sources d'information. La première partie de cet article reporte des expériences visant à spécifier les événements acoustiques les plus utiles à la reconnaissance du locuteur. Enfin, la possibilité d'exploiter l'information dynamique contenue dans la relation entre une trame et les p suivantes est évaluée. Dans une seconde partie, les auteurs proposent une nouvelle procédure de sélection de l'information spécifique du locuteur. En effet, les méthodes conventionnelles de sélection de paramètres (sélection ascendante, méthode du knock-out) ne permettent d'évaluer la pertinence d'une source d'information que de façon globale et a posteriori. Cependant, certains locuteurs sont mieux caractérisés par une source d'information que d'autres. De plus, la pertinence des sources d'information dépend de la qualité de l'échantillon de test. Face à ce besoin de traitements spécifiques suivant le locuteur et d'adaptation à l'environnement, nous proposons un système permettant de sélectionner automatiquement les parties les plus discriminantes d'une portion de parole. L'architecture proposée divise le signal de test en blocs temps–fréquence. Le score de vraisemblance correspondant est calculé en sélectionnant dynamiquement les blocs temps–fréquence les plus pertinents. Une réduction significative du taux de mauvaise identification (jusqu'à 41% de réduction relative du taux de mauvaise identification sur TIMIT) est observée. Finalement, des expériences réalisées dans le cas d'un bruit simulé, montrent le potentiel de cette méthode pour traiter des signaux de parole partiellement dégradés.
Cette étude compare l'efficacité de trois types d'informations acoustiques pour compléter la lecture labiale : la sortie, filtrée passe-bas, d'un électroglottographe, un substitut sinusoïdal, de fréquence variable, pour la fréquence fondamentale (Fo) et un substitut sinusoïdal, de fréquence fixe, pour représenter le voisement. Les deux signaux sinusoïdaux ont été synthétisés avec une amplitude constante pendant les périodes de voisement. Ces signaux ont été préparés “off-line” en combinant des estimations automatiques et manuelles de contours de Fo extraits de phrases enregistrées en vidéo. Ces signaux ont ensuite été resynchronisés avec la partie audio des enregistrements. Pour 12 adultes bien entendants, on a pu observer que tant le signal électroglottographique que le substitut de Fo (sinusoïdal et de fréquence variable) augmentent de 30 et 35%, respectivement, le nombre de mots reconnus dans des phrases portant sur des sujets connus. L'ampleur de cet effet est plus importante pour des phrases longues mais est indépendante des capacités de base de lecture labiale. Le substitut de fréquence fixe fournit une amélioration de 13%, ce qui suggère que approximativement un tiers de l'effet d'amélioration de la lecture labiale du à Fo peut être attribué à la seule détection du voicement.
Dans cet article, nous présentons un cadre d'apprentissage général pour la classification supervisée. Ce cadre ne nécessite que la définition d'un opérateur de généralisation et fournit en particulier des méthodes d'ensemble. Pour les tâches de classification de séquences, nous montrons que l'inférence grammaticale, avec des objectifs différents, a déjà défini de tels apprenants pour certaines familles d'automates comme les réversibles ou les k-TSS. Nous proposons ensuite un opérateur de généralisation original pour la famille des boules de mots. Enfin, nous montrons au travers de différentes expérimentations que notre approche permet effectivement de résoudre des tâches de classification de séquences.
La majorité de la recherche publiée sur le sujet de l'adaptation se concentre sur l'adaptation au locuteur, ainsi qu'à l'adaptation aux canaux et environnements bruités. Dans cet article, nous présentons une étude sur l'adaptation à une tâche, qui fournit également des gains de performance significatifs. Nous explorons plusieurs questions qui n'ont pas été adressées auparavant sur le sujet de l'adaptation, et présentons de nouvelles solutions à ces problèmes. En particulier, nous montrons que l'adaptation peut conduire à un accroissement du taux d'erreur sur les phrases considérées non-grammaticales par le système. Nous présentons un algorithme automatisé d'ajustement des indices de confiance pour corriger ce problème. Nous montrons qu'adapter séparément chaque grammaire améliore la qualité de l'adaptation acoustique. Nous montrons également que l'adaptation acoustique concentrée sur des données considérées grammaticales par le système améliore les résultats de manière significative. Nous faisons l'étude de l'adaptation à une tâche au niveau acoustique ainsi qu'au niveau grammatical, et montrons que les gains obtenus sont additifs. Enfin, nous montrons que l'adaptation améliore aussi bien la vitesse que le taux d'erreur, alors que les études traditionnelles se sont plutôt concentrées sur le taux d'erreur uniquement. Nous étudions également les modes d'adaptation traditionnels tels que l'adaptation supervisée ou non-supervisée, l'utilisation de niveaux minimums de confiance pour l'adaptation non-supervisée, ainsi que l'influence de la quantité de données sur la performance.
L'objectif de la recherche rapportée dans cet article est d'identifier les causes qui peuvent expliquer la performance de différentes techniques de normalisation du canal de transmission. A cet effet nous avons comparé quatre techniques de normalisation de canal dans le contexte de reconnaissance de chiffres connectés sur ligne téléphonique : substraction de la moyenne cepstrale, la représentation cepstrale dynamique, ainsi que le filtrage RASTA et RASTA corrigé pour rotation de phase. Nous avons employé des Modèles de Markov dépendants et indépendants du contexte qui ont été entraı̂nés avec une grande variation de complexités des modèles. Les résultats de nos expériences de reconnaissance indiquent que chaque technique de normalisation doit conserver les fréquences de modulation entre 2 et 16 Hz dans le spectre du signal de parole. De plus, les composantes DC du spectre de modulation doivent être écartés. Dans les modèles indépendants du contexte, le filtre de normalisation du canal doit avoir une réponse de phase plate. Enfin, nous avons trouvé que la soustraction de la moyenne cepstrale et RASTA corrigé pour rotation de phase conduisent à des performances similaires pour les modèles dépendants et indépendants du contexte si l'on emploie des nombres égaux de paramètres de modèles.
En phonétique articulatoire, la parole est décrite comme étant une séquence de gestes articulatoires distincts, produisant un événement acoustique qui devrait se rapprocher d'une cible phonétique. Du fait du recouvrement des gestes, ces cibles phonétiques ne sont souvent atteintes qu'en partie. Atal (1983) a proposé une méthode permettant le codage de la parole, basée sur ce que l'on appelle la décomposition temporelle de la parole en une séquence de fonctions-cibles de recouvrement et de vecteurs-cibles correspondants. Les vecteurs-cibles peuvent être associés à de positions articulatoires idéales. Les fonctions-cibles décrivent l'évolution temporelle de ces cibles. Cette méthode ne requiert pas de connaissances articulatoires ou phonétiques particulières. Nous l'avons élargie et modifiée pour mieux déterminer le nombre et la position des fonctions-cibles ainsi que pour corriger les défauts de la méthode originelle. Grâce à ces améliorations, la décomposition temporelle est devenue un outil robuste pour l'analyse de la parole, dont pourraient bénéficier les chercheurs travaillant au codage, à la reconnaissance et à la synthèse de la parole.
Les compagnies de téléphone américaines reçoivent plus de six milliards d'appels de renseignement par jour. L'automatisation, ne serait-ce que d'une partie du service des appels téléphoniques, pourrait réduire considérablement le coût de ces services. Cet article explore deux facteurs affectant une automatisation réussie des renseignements téléphoniques : (a) l'impact de la taille de l'annuaire sur la reconnaissance de parole, et (b) la complexité des interactions des appels. Les performances du système de reconnaissance de parole pour un ensemble de 200 noms prononcés ont été mesurées pour des services de renseignement ayant entre deux cents et un million et demi de noms à une seule occurrence. Le taux de reconnaissance décroit de 82,5% pour des renseignements sur deux cents noms à 16,5% pour un corpus de 1,5 million de noms. Il est probable que la mise en pratique de l'automatisation de ces services se concentrera sur un petit pourcentage d'appels, demandant un vocabulaire plus petit, en partie parce que un taux très élevé de reconnaissance ne peut pas être obtenu pour des vocabulaires extrêmement vastes, hors contexte. Afin de maximiser les gains potentiels, le vocabulaire optimal est constitué des listes de noms les plus demandés. Afin d'identifier les questions critiques dans l'automatisation des demandes fréquentes aux services de renseignement, à peu près 13.000 appels de renseignement d'un bureau proche d'une grande ville des Etats-Unis ont été étudiés. Dans cet échantillon, 245 intitulés couvrent 10% du volume d'appels, 870 intitulés couvrent 20% du volume d'appels.
Cet article propose un cadre général pour la reconaissance de la parole continue sous contraintes grammaticales, dans lequel le développement du graphe syntaxique et l'analyse sont menés grâce aux mêmes opérations élémentaires simples, à savoir la multiplication et l'addition de matrices de vraisemblance. On montre que cette analyse syntaxique matricielle est une généralisation de la méthode CYK. De plus, elle autorise la prise en compte de la durée suprasegmentale pour toutes les catégories grammaticales. Les résultats préliminaires montrent que grâce à l'amélioration due à la prise en compte des durées des mores, les taux de reconnaissance au niveau de la phrase s'élèvent de 86.7% à 88.5%.
Une forme originale de débats poétiques en relation avec la lyrique courtoise s'élabore aux XIIé et XIIIè s. Appelés jeux-partis en langue d'oïl ils connaissent un certain succès dans le cadre urbain du puy d'Arras. Formulant une casuistique amoureuse, ils sont à la croisée de différentes formalisations : poétique, juridique et scolastique. L'enjeu du débat est exprimé sous le mode dilemmatique. L'argumentation mise en oeuvre se déploie autour de trois énoncés fondamentaux : sentences, proverbes et images. La sentence, inscrite dans le discours lyrique qu'elle érige en axiomatique de l'amour, occupe une fonction ambivalente : elle est l'énonce 'e que l'on se propose de discuter et al forme qu'adopte la démonstration. Se combinant avec une syntaxe de la démonstration, elle ne produit que l'illusion de la dialectique et révèle, en creux, le caractère tautologique du jeu-parti. Sur 120 poèmes, il n'y a pas moins de 80 expressions proverbiales qui s'articulent différemment sur le contexte — quoique majoritairement par des formules assertives — mais qui toutes rompent avec son isotopie, illustrant et énonçant en même temps la règle. La procédure d'exemplarisation, sous la forme d'énoncés imagés, opére d'autres déplacements. Si le proverbe, issu de l'univers empirique, universalise la situation à laquelle il se réfère, l'image procède à l'inverse : d'un thème général, elle offre l'exemple d'une ou de plusieurs situations anecdotiques, d'où surgit l'universalité de la règle. Or aucun de ces énonc'es n'entrent dans une logique démonstrative et proprement argumentative. Ils resten clos sur eux-mêmes. Les interlocuteurs ne reprennent pas ce qui vient d'être dit, sinon sous une forme brutale de réfutation. La véritable formalisation est polémique. Discours qui manipule l'ironie, frôle l'insulte et recherche l'effet plus que le raisonnement. Discours qui bâtit sa vérité - contradictoire - comme un jeu tourné vers un auditoire dont on saisit et quête les complicités. Car la vérité reste bien au coeur du débat et elle est sans cesse assertée. Comme elle l'est dans les disputes, ces combats des clercs. Disputes et ieux-partis mettent en scéne une logique de la controverse. Ils sont des “argumentations spectacles”. L'élaboration de la vérité se fait ailleurs, dans les sommes par exemple. Le jeu-parti est aporétique. S'il est une réponse á son questionnement, elle se lit dans le poéme d'amour dont la forme enferme le sic et non de la joy, joie et jeu d'amour.
L'utilisation de connaissances supplémentaires conjointement au signal de parole est une méthode classique pour améliorer les performances et la robustesse des systèmes de reconnaissance automatique de la parole (RAP). Ce papier décrit la méthode que nous avons développée pour l'intégration adaptative des informations acoustiques et visuelles dans un système de RAP. Chaque modalité est impliquée dans le processus de reconnaissance avec un poids différent ; celui-ci est adapté dynamiquement pendant le processus en fonction du rapport signal sur bruit et du contexte. Les systèmes que nous avons développés en utilisant les modèles de Markov cachés respectent successivement les trois modèles perceptifs suivants : intégration directe (DI), intégration séparée (SI) et intégration hybride (DI+SI). Les expériences réalisées avec différents niveaux de bruit ont montré que d'une part, de meilleures performances sont obtenues pour le système basé sur DI+SI que pour ceux basés sur DI ou SI, et que d'autre part les résultats des systèmes sont globalement améliorés en utilisant une pondération adaptative des deux modalités. De plus, ces résultats confirment l'importance d'utiliser une unité de décision spécifique pour la reconnaissance purement visuelle dans les systèmes basés sur SI ou DI+SI.
La résolution de problèmes à états et actions continus par l'optimisation de politiques paramétriques est un sujet d'intérêt récent en apprentissage par renforcement. Dans cet article, nous considérons PI2 en tant que membre de la famille plus vaste des méthodes qui optimisent une fonction de coût via une moyenne des valeurs des paramètres pondérée par les récompenses. Nous comparons PI2 à d'autres membres de la même famille – la « méthode de l'entropie croisée » et CMA-ES 1 – au niveau conceptuel et en termes de performance. La comparaison débouche sur la dérivation d'un nouvel algorithme que nous appelons PI2-CMA pour « Path Integral Policy Improvement with Covariance Matrix Adaptation » . Le principal avantage de PI2-CMA est qu'il détermine l'amplitude du bruit d'exploration automatiquement. Nous illustrons cet avantage sur un exemple non trivial de robotique simulée.
Ces dix dernières années de nombreuses recherches dans le domaine des contextes ont été menées, cependant, peu d'entre elles ont utilisé la logique comme sémantique. Cette théorie est étendue par les enregistrements à types dépendants - DTR - qui permettent la représentation de connaissances partielles et le raisonnement sur des données évolutives.
Cet article présente différentes approches pour la reconnaissance de parole en présence de bruit, intégrées à une Modélisation Stochastique des Trajectoires de parole (STM). Nous décrivons 4 méthodes : adaptation des modèles acoustiques par régression linéaire, transformation de l'espace acoustique de référence, combinaison de modèles stochastiques de parole et bruit, filtrage par état du signal bruité. L'évaluation des différentes approches est effectuée en mode dépendant du locuteur, sur une application de reconnaissance de parole continue comportant un vocabulaire de 1011 mots avec une grammaire de perplexité 28 (paire de mots). Les différentes approches sont évaluées sous des conditions de bruit additifs variées, comprenant différents types de bruit et différents rapports signal-à-bruit. Les expériences montrent que l'adaptation des modèles par régression linéaire conduit aux meilleurs résultats, pour tous les types de bruits testés, et pour des rapports signal-à-bruit modérés (de 6 à 24 dB). En présence d'un bruit Gaussien, pour un rapport signal-à-bruit variant de 6 à 24dB, l'adaptation par régression linéaire réduit le taux d'erreur de mots de 20% à 59% par rapport aux autres approches.
Cet article traite du problème de l'apprentissage des réseaux de neurones à fonctions radiales de base pour l'approximation de fonctions non linéaires L 2 de R d vers R. Pour ce type de problème, les algorithmes hybrides sont les plus utilisés. Ils font appel à des techniques d'apprentissage non supervisées pour l'estimation des centres et des paramètres d'échelle des fonctions radiales, et à des techniques d'apprentissage supervisées pour l'estimation des paramètres linéaires. Les méthodes d'apprentissage supervisées reposent généralement sur l'estimateur (ou le critère) des moindres carrées (MC). Cet estimateur est optimal dans le cas où le jeu de données d'apprentissage (z i,y i) i = 1, 2,.., q est constitué de sorties y i, i = l,..,q bruitées et d'entrées z, i = l,..,q exactes. Cependant lors de la collecte des données expérimentales il est rarement possible de mesurer l'entrée z i sans bruit. L'utilisation de l'estimateur des MC produit une estimation biaisée des paramètres linéaires dans le cas où le jeux de données d'apprentissage est à entrées et sorties bruitées, ce qui engendre une estimation erronée de la sortie. Cet article propose l'utilisation d'une procédure d'estimation fondée sur le modèle avec variables entachées d'erreurs pour l'estimation des paramètres linéaires (pour l'apprentissage supervisé) dans le cas où le jeux de données d'apprentissage est à entrées et sorties bruitées. L'interprétation géométrique du critère d'estimation proposé est établie afin de mettre en évidence son avantage relativement au critère des moindres carrés. L'amélioration des performances en terme d'approximation de fonctions non linéaires est illustrée sur un exemple.
Cet article porte sur la reconnaissance automatique de cibles partiellement immergées par imagerie IR. On dispose d'un ensemble d'images réelles acquises dans des conditions différentes (présence de bruits, plus ou moins contrastées). Très classiquement, en reconnaissance des formes, on procède à une étape de prétraitement avant la phase de décision (détection, éventuellement classification). Le prétraitement permet alors d'extraire des cibles dans des images très peu contrastées et bruitées. La phase de décision considérée ici est basée sur l'opération de corrélation c'est-à-dire d'un simple filtrage suivi d'un seuillage. Nous verrons que ces deux opérations peuvent être fusionnées en une seule.
Cet article propose un estimateur de l'espérance du retour de politiques de décision déterministes en boucle fermée à partir d'un échantillon de transitions d'un système dynamique. Cet estimateur, appelé en anglais Model-free Monte Carlo (MFMC) estimator, calcule une moyenne des retours d'un ensemble de « trajectoires artificielles » construites à partir de la politique à évaluer ainsi que de transitions du système disponibles dans un échantillon fixé dont l'acquisition s'est faite indépendamment de la politique à évaluer. Sous certaines hypothèses de continuité lipschitzienne de la dynamique du système, de la fonction de récompense et de la politique de décision à évaluer, on montre que le biais et la variance de l'estimateur proposé sont bornés par des termes qui dépendent des constantes de Lipschitz, du nombre de trajectoires artificielles, de la parcimonie de l'échantillon de transitions ainsi que de la variance « naturelle » du retour de la politique.
Le nombre nécessairement limité de données ne permet pas de distinguer sûrement entre les régularités réelles et les régularités accidentelles lorsque les données sont décrites par un grand nombre d'attributs. Cette méthode a été testée dans le cadre d'une application de classification de scènes naturelles. Une partie des images disponibles a été utilisée pour identifier I(X)0 motifs fréquents, grâce à un algorithme spécialement adapté.
L'objectif du travail présenté est, dans le cadre de l'apprentissage par renforcement, de guider l'agent grâce à de la connaissance a priori que l'on aurait sur un environnement donné. Nous proposons un formalisme procédural permettant d'introduire cette connaissance sous forme de programme. L'idée de base de notre méthode est de proposer à l'agent deux ensembles d'actions par état ; un ensemble réduit d'actions qui est utilisé au départ, et un autre ensemble moins contraint qui sera utilisé plus tard. Les contraintes initiales réduisent l'espace d'états et, par conséquent, réduisent le temps d'apprentissage. Mais, parce que les contraintes initiales peuvent être trop fortes, nous définissons un mécanisme de relaxation de contraintes qui permettra d'augmenter graduellement l'espace de recherche. Le fait de relâcher les contraintes initiales va nous permettre de prouver, pour une large classe de programmes, que la politique apprise par l'agent est aussi bonne que s'il n'y avait pas eu de contraintes.
Cette communication présente un projet de recherche consacré à la prosodie de la parole spontanée. Deux questions inaugurent ce projet. La première soulève le problème des différences entre la prosodie de la lecture en laboratoire et celle de la parole spontanée. Des données du suédois montrent à l'évidence que ces différences ne sont pas fondamentales. La seconde question concerne le rôle joué par la prosodie dans la structuration discursive de la parole spontanée. Une méthodologie a étéélaborée afin de mieux cerner ce rôle. Quatre analyses différentes sont ainsi appliquées : (1) une analyse discursive, (2) une analyse auditive, (3) une analyse acoustico-phonétique et (4) une analyse par synthèse. Certaines de ces analyses sont exemplifiées à l'aide d'un des monologues persuasifs produits au cours d'un débat entre deux politiciens français. L'accent focal et les contrastes de registre de voix semblent constituer des figures prosodiques typiques de la rhétorique politique.
Nous présentons un modèle d'apprentissage général pour la classification de documents structurés permettant de prendre en compte simultanément la structure et le contenu. Pour cela, nous définissons tout d'abord un modèle génératif de documents structurés à l'aide de réseaux Bayésiens. Nous transformons ensuite ce modèle génératif en un modèle discriminant en utilisant la méthode du noyau de Fisher. Nous détaillons enfin une instance de ce modèle dédié à la classification de pages HTML. Les expériences sur un corpus de référence montrent que la prise en compte de la structure permet un gain de performance par rapport aux modèles classiques de classification génératifs et discriminants.
Cette courte étude présente certaines caractéristiques de la phonétique acoustique qui reflètent et les caractéristiques de la voix et les mouvements articulatoires de 20 pré-adolescents (âgés de 6, 8 et 10 ans) et de 9 adults. Les caractéristiques de la phonétique acoustique examinées comprennent les valeurs de la fréquence des formants, la coarticulation, le chevauchement gesturel et les patrons temporels. Les caractéristiques vocales et les mouvements articulatoires nous révèlent des différences selon l'âge et le sexe, et des interactions entre l'âge et le sexe. En plus, il y avait d'importantes corrélations entre les fréquences des formants et la variation (ou bien les déviations) associée à ces fréquences. On a constaté également des différences individuelles quant aux modes de maturation que ne conformaient pas à l'âge strictement chronologique des sujets. Nous rapportons et discutons de ce données par rapport au dimorphisme sexuel de l'appareil vocal, du développement de caractéristiques vocales et du mécanisme de la parole et de son comportement.
La tolérance aux fautes informatique peut aujourd'hui s'appuyer sur presque trente ans de résultats théoriques et expérimentaux. Depuis le début des années quatre-vingt, un effort important a en particulier été porté sur l'intégration de mécanismes génériques pour la tolérance aux fautes dans des intergiciels répartis.
La présence oú l'absence d'un contexte phrastique permettait une estimation des effects inter-phrases sur les processus locaux et globaux.
Dans cette étude on présente deux expériences au cours desquelles les sujets doivent faire des décisions lexicales rapides sur des noms infléchis précédés d'adjectifs infléchis ou de pseudo adjectifs grammaticalement accordés ou non. Les adjectifs et les pseudo adjectifs affectent tous deux les temps de décision lexicale pour les noms suggérant que l'effet de facilitation des noms infléchis par des adjectifs infléchis se fait au niveau des inflections. Les pseudonoms infléchis cependant ne sont pas affectés de la même manière ce qui des facteurs lexicaux contribuent, avec les facteurs grammaticaux, à la facilitation. Cet exemple de facilitation grammaticale est interprété comme un effet post-lexical sur les produits relativement indépendants des processeurs lexicaux et syntaxiques.
Une synthèse des problèmes concernant l'utilisation des filtres de Volterra transverses (FVT) en détection, estimation et filtrage spatial d'antenne est présentée, que les données à traiter soient réelles ou complexes. Celle ci permet de couvrir simultanément des questions aussi variées que la maximisation du contraste à l'intérieur de l'espace de Hilbert des sorties des FVT, et l'estimation non linéaire en moyenne quadratique d'un processus aléatoire inconnu. Les FVT optimaux relatifs aux trois problèmes abordés sont obtenus comme solution d'un système unique d'équations normales généralisées. Des indications sont données à propos de l'identification adaptative, en temps réel, de ces FVT optimaux.
Cet article décrit une procédure d'anonymisation en plusieurs étapes qui a été développée sur des documents cliniques narratifs en français dans le domaine de la cardiologie. Notre approche se fonde sur la combinaison de plusieurs méthodes, une approche à base de règles suivie par l'application d'un système à base d'apprentissage. La combinaison des deux approches permet d'obtenir de meilleurs résultats (F-mesure de 0,881) que prises séparément, avec un rappel (0,912) plus important que la précision (0,851).
Nous présentons une extension de la notion de l'entropie conditionnelle de Shannon à une forme plus générale d'entropie conditionnelle qui formalise l'entropie conditionnelle de Shannon et une notion semblable liée à l'index de Gini. La famille proposée des entropies conditionnelles produit d'une collection de métriques sur l'ensemble de partitions des ensembles finis, qui peuvent être employées pour construire des arbres de décision. Les résultats expérimentaux suggèrent qu'en changeant le paramétre qui définit l'entropie il soit possible d'obtenir de plus petits arbres de décision pour certaines bases de données sans sacrifier l'exactitude de la classification.
Les méthodes d'analyse spatiale développées depuis 2 décennies reposent sur des hypothèses contraignantes qui ne sont généralement pas respectées en pratique et, par suite, donnent des résultats souvent décevants ; il s'agit notamment des hypothèses de non-corrélation entre sources, de planéité des fronts d'ondes et d'identité des capteurs. Classiquement, l'estimation des paramètres des sources est basée sur l'information contenue dans les valeurs et vecteurs propres de la matrice interspectrale des signaux captés. Partant des propriétés de cette matrice, on montre dans cet article qu'il existe une variante de la méthode des éléments propres, fondée sur la relation de dépendance linéaire existant entre les lignes de la matrice-sources. L'examen des diverses causes de perte de performance met en évidence l'intérêt d'une identification aussi complète que possible des fronts d'ondes distordus. Un nouvel algorithme est proposé in fine, permettant d'estimer les phases des éléments des vecteurs-sources, sous l'hypothèse de modules égaux.
La présente étude a pour objectif de définir les règles de détection des groupes consonantiques en français, fondées essentiellement sur le paramètre temporel. Les syllabes cibles CCV, VCC, CV et VC combinées avec les voyelles /i, a, ã/ ont été intégrées dans des mots bisyllabiques et trisyllabiques. Quatre corpus ont été constitués. L'ensemble des mots (603) a été lu à cinq reprises par dix locuteurs en chambre sourde. La durée des mots, des syllabes et des phonèmes a été mesurée avec un éditeur de signal. Ces paramètres ont été intégrés dans 17 règles de détection des groupes consonantiques, sept macro-classes ont été définies. Ces règles ont été testées sur le corpus GRECO BDSONS, elles ont permis un classement correct de 90.13% des groupes consonantiques.
Les algorithmes actuels d'apprentissage multiagent sont pour la plupart limités dans la mesure où ils sont incapables de gérer la multiplicité des équilibres de Nash et de converger vers l'équilibre Pareto optimal. Nous présentons des résultats expérimentaux montrant la convergence d'un tel algorithme. Nous étendons ensuite notre approche à un autre aspect essentiel des systèmes complexes qui est la non stationnarité des agents adverses et qui jusqu'ici a été peu étudiée. Finalement, nous abordons la question de la non-stationnarité dans les systèmes multiagents, et présentons des pistes qui nous semblent pertinentes pour améliorer les performances d'adaptation de notre algorithme à des agents non stationnaires.
Cet article décrit la recherche actuelle sur les systèmes connexionnistes pour des tâches de reconnaissance du locuteur. Nous considérons deux approches principales, la première est basée sur la classification directe et la seconde concerne la modélisation du locuteur. Le potentiel des modèles connexionnistes pour la reconnaissance du locuteur est d'abord discuté puis les principaux algorithmes des deux familles sont présentés. Nous discutons leurs possibilités et leurs performances respectives pour des tâches de reconnaissance du locuteur. Nous comparons ces techniques avec des méthodes conventionnelles comme la quantification vectorielle et les chaînes de Markov cachées. Le papier se termine avec quelques suggestions pour des recherches futures.
Toute approche réaliste du langage, se doit de rendre compte du passage de la communication par prélangage de l'enfant à l'utilisation de la langue à proprement parler. Pour cela, on peut montrer qu'il existe de nombreuses bases, préalables ou nécessaires aux traits organisationnels de la syntaxe, de la sémantique, de la pragmatique et même de la phonologie, dans les activités prélangagères des enfants. Des illustrations de ces bases préalables sont étudiées ici dans 4 domaines différents : le mode d'interprétation, par la mère des intentions de communication de l'enfant, le développement de la combinaison des référentiels, rendant le langage conforme à l'environnement, l'évolution de stratégies permettant l'utilisation de l'activité conjointe au langage, la transformation d'une organisation de type topic-comment à la prédication. En dernier lieu on propose la conjecture suivante : la connaissance, par l'enfant des besoins de l'action et de l'interaction peut elle fournir la base à l'élaboration initiale de la grammaire.
Utilisable par les internautes mais également par les webmestres, les plans de sites obtenus présentent la particularité de s'adapter aux capacités de mémorisation des personnes handicapées visuelles. Dans cet article nous présentons notre méthode de génération de plan qui utilise des fourmis artificielles afin de créer des regroupements de pages web sémantiquement proche, puis qui exécute l'algorithme de Prim sur chacun des regroupements réalisés par les fourmis artificielles.
Ces ouvrages sont les étapes d'un parcours qui, à travers l'emploi et la réélaboration qu'en font des humanistes comme Cristoforo Scarpa, Giovanni Tortelli, Nestore Avogadro, Niccolò Perotti, prélude à la création de la pratique lexicographique moderne. Cet article veut illustrer justement ce parcours à travers l'analyse de quelques mots latins, dont le traitement suggère un classement typologique reflétant les différentes manières dont la lexicographie monolingue médiévale et humaniste a conçu et réalisé le rapport entre grammaire et lexique.
Nous présentons quelques aspects des principaux thèmes de recherche étudiés en Australie dans le domaine de la parole et qui ne sont pas repris de manière adéquate dans ce numéro spéciale. Nous étudions également le développement d'outils et d'appareillages pour la recherche.
Pour les applications nécessitant une analyse par orientations, les fonctions de Gabor produisent une décomposition en ondelettes très utilisée. Cette décomposition par orientation est très lourde en temps de calcul, pour des filtres orientés de type passe-bande positionnés à basse fréquence et appliqués par convolution directe. Pour annuler ces modifications, des corrections adéquates doivent être prises en compte dès la génération du noyau de convolution. Deux exemples de décomposition pyramidale sont étudiés, à titre d'illustration et de comparaison.
L 'UMLS® (Unified Medical Language System®), que l'on pourrait traduire par « Système d'unification de la langue médicale » , est un produit terminologique extrêmement riche, construit de façon pragmatique, et que l'on peut appréhender de façon multiple. Nous donnons un aperçu de ce qu'est l'UMLS et mettons l'accent sur deux de ses aspects potentiellement antinomiques : sa relation aux ontologies et sa relation à la langue.
Nous confrontons une approche linguistique/psycholinguistique de l'organisation du lexique mental avec une approche mathématique/informatique de l'organisation « implicite » du lexique dans les dictionnaires considérés comme des graphes et dont la structure est de type « petit monde » .
Dans cet article, nous proposons un système complet d'analyse d'images comprenant toute la chaîne de traitements depuis le bas-niveau jusqu'à l'interprétation. Il utilise à la fois un réseau de neurones et un système à base de règles. Nous montrons que la mise en œuvre d'un système-expert fournit des informations précieuses pour la conception des réseaux. La réalisation mixte permet d'utiliser au mieux les spécificités de chacune des approches. Nous montrons également comment faire apprendre des configurations localement contradictoires à un réseau de neurones.
Cet article passe en revue des recherches sur le traitement moteur, perceptif et auditif de la parole, basées en particulier sur les études menées à l'Institut I.P. Pavlov de Physiologie de Léningrad par V. Kozhevnikov et L. Chistovich. L'accent a été mis sur l'emploi de réponses orales à des stimuli de parole, c'est-à-dire les réponses instantanées (shadowing) et l'imitation. Des versions antérieures d'une théorie motrice de la perception de la parole sont aussi présentées.
Nous étudions dans cet article une méthode de calcul approché de la Transformée de Fourier. Sous certaines conditions, que nous précisons, le calcul des différentes composantes du spectre ne nécessite aucune multiplication. Le calcul ainsi simplifié, peut s'effectuer en temps réel sur un micro-ordinateur non spécialisé. De plus, le calcul des différentes composantes du spectre s'effectue d'une manière indépendante les unes des autres. Nous avons vérifié la validité de cette méthode d'approximation sur un signal de spectre connu et sur un signal de parole réel. Le spectre approché est obtenu avec une précision de quelques pour cent à condition que le signal soit suréchantillonné.
Cet article présente un système de reconnaissance en ligne de lettres cursives isolées qui s'appuie sur une modélisation structurée et logique des lettres (amorce, corps, ligature,..,) par l'intermédiaire de modèles de Markov cachés. Après différents prétraitements spécifiques, on opère une segmentation dynamique des lettres en primitives locales représentatives de la trajectoire de la pointe du stylet (aspect gestuel), associées à des primitives de nature plus globale représentatives de la géométrie du tracé (aspect visuel). Une phase d'apprentissage est ensuite réalisée sur chaque modèle associé à chaque type de lettre. Lors de la reconnaissance, le système va estimer les probabilités de génération de la lettre à reconnaître pour chaque modèle. On effectue ainsi une classification basée sur un critère de ressemblance.
Deux types de Réseaux de Neurones Formels (ANN) ont été comparés, pour la classification de voyelles extraites de la parole continue, à un classificateur traditionnel à moyenne la plus proche, à un VQ et à un réseau de Kohonen. Les résultats montrent que les deux ANN offrent les meilleures performances et indiquent qu'un réseau auto-organisateur de Kohonen ne détériore pas l'information présentée à la seconde couche du réseau.
Cette investigation est la première dans une série qui a pour objet d'étudier a relation entre l'intelligibilité et la présence de différentes sortes d'erreurs dans la parole des sourds. Dans cet article, nous avons étudié le rôle es erreurs temporelles en comparant l'intelligibilité des phrases dites par des enfants sourds avec et sans corrections des diverses déviations temporelles. Dans un corpus de 30 phrases, énoncées par dix enfants sourds, âgés de 12 à 14 ans, la structure temporelle a été modifiée, après introduction des phrases dans la mémoire d'un ordinateur, à l'aide des programmes d'analyse et de (re)synthèse à base de L.P.C. Ainsi six versions ont été obtenues qui différaient surtout dans la mesure où leurs caractéristiques temporelles approchaient celles des mêmes phrases énoncées par deux enfants non sourds. L'intelligibilité de toutes les versions, y compris les phrases originales, a été déterminée par des expériences perceptives. Les données montrent que pour la plupart des phrases un accroissement modeste mais significatif de 4.5% à 6% est obtenu à la suite des corrections temporelles. L'élimination des pauses réduit généralement l'intelligibilité. Ces résultants sont opposés à ceux rapportés dans des recherches appliquant la méthode de corrélation qui suggèrent un plus grand effet des facteurs temporels. Ils correspondent davantage aux résultats d'une autre recherche (Osberger & Levitt, 1979) où l'on s'est servi de la même méthode que celle utilisée dans notre travail.
Ce travail présente une synthèse des méthodes de sous-espaces pour l'estimation de directions d'arrivée de sources ou pour l'estimation de fréquences pures noyées dans du bruit, qui ne requièrent pas de décomposition en éléments propres de la matrice de covariance des observations. Ces méthodes qualifiées de « linéaires » , par opposition à la méthode MUSIC, parce qu'elles n'utilisent que des opérations linéaires sur la matrice de covariance des observations, possèdent en effet un intérêt certain pour des applications en temps réel, du fait de leur faible coût calculatoire et du fait qu'elles peuvent être facilement rendues adaptatives. Au cours d'une présentation de ces méthodes, qui seront appelées dans la suite BEWE, la Méthode du Propagateur (MP) et SWEDE, nous établissons les liens qui existent entre ces méthodes et leurs différentes versions. La complexité de chacune de ces méthodes est étudiée et discutée. Il apparaît que BEWE est la moins complexe des méthodes linéaires. Les performances asymptotiques (pour un grand nombre d'observations) des méthodes BEWE et SWEDE ayant déjà été étudiées dans la littérature, nous proposons ici le calcul des performances asymptotiques d'une version de la MP, la Méthode du Propagateur avec élimination du bruit ou MPEB. Nous montrons que la MPEB est la plus performante des méthodes linéaires et que ses performances sont celles de MUSIC. Des simulations viennent confirmer les résultats théoriques présentés ici et illustrer la comparaison des différentes méthodes.
L'implémentation de tout algorithme adaptatif linéaire quadratique nécessite, au préalable, afin d'utiliser au mieux les informations a priori du processus observation, d'estimer l'importance relative des moments d'ordre trois par le calcul du skew et du kurtosis. Si ces moments sont nuls, c'est-à-dire pratiquement faibles, la structure adaptée de tout algorithme adaptatif LQ, LMS ou RLS, standard et rapide, est « découplée » , au sens où deux procédures stochastiques indépendantes, de pas et de gain différents, identifient récursivement et respectivement les noyaux linéaire et quadratique du filtre optimal. Si ces mêmes moments sont d'intensité non négligeable, la structure de ces algorithmes devient couplée : une seule procédure stochastique, caractérisée par un seul pas et un gain unique, rafraîchit simultanément et de façon conjointe les noyaux linéaire et quadratique. Ces considérations se déduisent de la façon dont s'interprète tout algorithme stochastique, à savoir comme estimée d'une procédure récursive déterministe du type gradient ou Newton-Raphson. Vu qu'un filtre de Volterra transverse reste une fonction linéaire des paramètres, les propriétés de l'algorithme LMSLQ demeurent très semblables, en dehors de la participation supplémentaire des moments d'ordre trois et quatre, à celles de l'algorithme LMS classique. En particulier, l'étude de la convergence fondée sur la théorie de la Mindépendance, introduite dans le contexte linéaire, s'étend sans difficulté. En présence de moments d'ordre trois, l'inadéquation de structure d'un algorithme LMSLQ, provenant d'une mauvaise utilisation des informations a priori, se modélise, commodément, par un bruit qui vient se superposer au bruit de modèle, appelé bruit « d'inadéquation » . La détermination de la variance de ce dernier montre à quel point ses effets s'avèrent néfastes sur le régime permanent de l'algorithme.
Nous décrivons un système de décodage acoustico-phonétique qui produit des treillis phonétiques en localisant et identifiant simultanément les unités au moyen de divers types de distances spectrales ajustées en fonction des phonèmes, du contexte et de certaines caractéristiques du locuteur. Les résultats obtenus — pour des mots isolés ou pour des énoncés continus — font apparaître tous les phonèmes effectivement énoncés avec un score d'identification particulièrement intéressant pour la sélection ascendante de cohortes d'items dans un lexique étendu.
Partant d'une comparaison entre le premier grand dictionnaire français de synonymes de Lafaye qui distingue les entrées lexicales sémantiquement proches en opposant des cooccurrences différentes au sein de phrases où ces entrées sont habituellement produites et se pose ainsi en précurseur des analyses du Lexique-grammaire initiées par Maurice Gross et le premier dictionnaire analogique de la langue française de Boissière qui permet de trouver des mots inconnus mais en écrasant les différences grammaticales et sémantiques des entrées lexicalement proches, l'auteur propose de calculer le degré d'analogie entre deux entrées par le biais d'une description analytique définitoire se référant à la matrice dont sont issus les énoncés définitoires des deux entrées comparées.
Dans cet article, nous proposons une nouvelle méthode de détermination de pondérations d'états discriminantes, basée sur la méthode de descente du gradient généralisée, en assumant que le score d'un énoncé est la somme pondérée des logarithmes des probabilités d'états des HMMs. Enfin, elle peut être appliquée à la reconnaissance de parole continue aussi bien qu'à la reconnaissance de mots isolés. Pour évaluer les performances du système de reconnaissance HMM à pondération d'états, des expériences ont été menées avec des pondérations d'états au niveau du phonème ou au niveau du mot, en utilisant diverses bases de données. Les résultats expérimentaux montrent que les systèmes de reconnaissance utilisant des pondérations d'états au niveau du phonème et du mot ont des taux d'erreur par mot réduits de 20% et de 50%, respectivement, pour des mots isolés, et de 5% pour de la parole continue. Notre méthode aboutit à des performance de reconnaissance similaires à celles obtenues avec d'autres approches pour la parole continue mais est beaucoup plus simple à implémenter.
De nos jours, l'ordinateur est en passe de changer de l'objet gros, gris et bruyant sur notre bureau à un objet petit, transportable et connecté que la plupart d'entre nous transporte. Cette nouvelle mobilité modifie notre façon de voir les ordinateurs et la manière dont nous travaillons avec eux. Lorsque nous pouvons interagir avec les autres n'importe où, n'importe quand, il est impératif que ce soit le système qui s'adapte à l'utilisateur et à la situation, et non l'inverse. Dans un deuxième temps, nous proposons une évaluation automatique d'une situation à partir d'un raisonnement à base de cas. Nous montrons finalement comment un système multi-agent peut fournir des services sensibles au contexte dans un environnement mobile.
Nous proposons une méthode d'apprentissage à partir d'exemples qui se situe à la jonction des méthodes statistiques et de celles basées sur des techniques d'intelligence artificielle. Notre modélisation se base sur la génération automatique de règles de classification et sur une utilisation originale du raisonnement approximatif. La méthode d'apprentissage proposée, basée sur une recherche de corrélations linéaires entre les composantes des vecteurs d'apprentissage est multi-attributs. L'incertitude des règles est gérée aussi bien dans la phase d'apprentissage que dans celle de la reconnaissance. Un système baptisé SUCRAGE a été implémenté et confronté à une application réelle dans le domaine du traitement d'images. Les résultats obtenus permettent de valider notre approche et nous autorisent à envisager d'autres domaines d'application. De plus, ces résultats confortent notre hypothèse des imperfections : le raisonnement approximatif ou une recherche de corrélations intraclasses peuvent sensiblement améliorer les résultats.
Un environnement bruité dégrade généralement l'intelligibilité d'un locuteur humain et les performances d'un système de reconnaissance de la parole. Ces dernières années, des efforts spécifiques ont été produits pour analyser et traiter l'effet Lombard dans le cadre de la reconnaissance automatique de la parole. L'objectif principal du travail présenté dans cet article concerne l'étude de tendances communes à certains paramètres acoustiques dans différentes unités phonétiques, liées à l'effet Lombard. Un autre objectif concerne l'étude de l'influence du sexe du locuteur sur la caractérisation des tendances recherchées. Des tests statistiques approfondis sont effectués pour chaque paramètre et chaque unité phonétique sur une large base de données de parole continue en Espagnol. Les résultats reportés confirment les changements produits sur la parole naturelle par l'effet Lombard. Quelques nouvelles tendances ont été observées suite aux tests statistiques effectués.
Nous présentons une théorie de la reconstruction des croyances, intégrable au modèle de communication d'un agent, qui rend compte de la persistance et de la révision des croyances. Nous analysons les théories de Cohen et Levesque (1990a) et de Perrault (1990), mettons en évidence des problèmes qu'elles ont et montrons que notre théorie ne souffre pas de ces problèmes. Son point de départ est ce que nous appelons le principe d'observation. Ce principe rend compte de la distinction entre ce qu'un agent observe d'un autre agent et l'action que ce dernier a réellement accomplie. La théorie est exprimée dans un cadre de logique autoépistémique utilisée objectivement, dans le sens de Levesque (1990). Appliquée au contexte de la communication, nous montrons que cette théorie prédit correctement les changements des croyances de l'observateur dans des cas tests tels que l'assertion sincère et le mensonge (détecté ou non). Ces cas mettent en évidence la capacité de la théorie à appréhender des situations de dialogue régulières, mais aussi celles où apparaissent des problèmes dus à une perception erronée, telle q'une mauvaise reconnaissance en communication par la parole.
Un enregistrement simultané de la vibration des cordes vocales et du signal de parole a été effectué sur trois sujets diplophoniques, grâce à un numériseur rapide d'images (développé par les auteurs). L'étude des sujets (le premier présentant une analyse unilatérale du nerf récurrent, deux autres une paralysie unilatérale de la branche externe du nerf laryngal supérieur) a montré dans tous les cas une différence dans la fréquence vibratoire entre la corde vocale gauche et droite. La différence de phase entre les cordes vocales varie dans le temps ; quand elle dépasse un certain seuil, elle est réinitialisée, ce qui replace les mouvements des cordes vocales en phase. Dans ce cas, la fermeture glottique est totale et l'excitation apparaît clairement dans le signal de parole, alors que dans le cas de déphasage des mouvements la fermeture glottique est incomplète et l'excitation est faible, ce qui se traduit par une vibration quasi-périodique dans le signal de parole.
Cet étude a pour but de déterminer les caractéristiques acoustiques des séquences voyelle-voyelle (hiatus) et semivoyelle-voyelle (diphtongue) en espagnol ainsi que d'observer les modifications de ces caractéristiques selon les proprietés du contexte de communication. Nous avons utilisé deux groupes des données : des échantillons provenant des dialogues entre deux locuteurs qui suivent la tâche de la carte géographique, où les items du corpus correspondent aux noms dans les cartes, et la lecture des mêmes séquences. La comparaison a été faite phonétiquement et phonologiquement : d′abord, les durées et la dynamique spectrale des diphthongues et des hiatus ont été analysées, et après, les processus phonétiques de réduction ont été inventoriés. Les résultats montrent que la séquence voyelle-voyelle est différente de la séquence semivoyelle-voyelle dans les domaines du temps et fréquence : les hiatus sont plus longs et ils ont une trajectoire de F2 plus courbée que les diphthongues. D′autre côté, les processus de réduction signalent la présence d′une ligne d′affaiblissement qui explique les prononciations des hiatus comme des diphthongues, et des diphthongues comme des voyelles. Il apparaı̂t que les hiatus et les diphthongues sont deux catégories phonétiques qui peuvent être décrites selon leurs caractéristiques acoustiques et qui suivent des processus de réduction, également à d′autres catégories phonétiques, quand ils apparaı̂ssent dans des contextes de prononciation relaxés.
Les techniques de synthèse du japonais fondées sur des unités multiphonémiques sont passées en revue. Le japonais est une langue à syllabation ouverte et son système phonologique ne comprend pas de groupes consonantiques. Dès lors, le japonais est structuré à l'aide de syllables du type CV-auxquelles il est fait largement appel dans la synthèse par règles plutôt que le recourir à des phonèmes. D'autres unités composites, telles que des séquences VCV ou CVC sont également utilisées pour tenir compte des effets de coarticulation. Dans cet article, on décrit une méthode préliminaire de synthèse utilisant des unités CVC et un codage de la forme d'onde résiduelle afin d'améliorer la qualité de la parole synthétique.
Dans les systèmes de dialogue oral Homme-Machine, la compréhension de la parole spontanée est un problème difficile qui requiert des méthodes d'analyse robustes. La plupart des systèmes sont destinés à des actions très spécifiques : la compréhension repose sur la détection de mots ou segments clefs pour remplir les différents champs de requêtes prédéterminées. LOGUS, le système de compréhension présenté dans cet article s'appuie sur des formalismes logiques, grammaires catégorielles et graphes conceptuels, hors du champ habituel de leur utilisation. L'analyse, incrémentielle, construit une formule logique par compositions progressives des concepts reconnus de l'énoncé. L'article décrit et compare les deux premières versions du système. Leurs évaluations donnent des résultats prometteurs : elles font apparaître la bonne robustesse de l'analyse et son assez bonne capacité à reconstituer le sens des énoncés. La prise en compte plus large du contexte et la gestion du dialogue feront l'objet de travaux futurs.
Les performances des systèmes de reconnaissance de mots isolés sont généralement mesurées en fonction du taux d'erreurs. L'Effective Vocabulary Capacity (EVC) est le vocabulaire maximum qu'un système de reconnaissance peut traiter pour un taux d'erreurs donné. Il se base sur des mesures relativement indépendantes du vocabulaire testé et ne demandant que quelques dizaines ou centaines d'énoncés-tests. L'algorithme EVC est testé sur des données synthétiques et réeles de systèmes de reconnaissance.
Les méthodes de visualisation souvent utilisées s'adaptent difficilement aux données ayant un grand nombre de dimensions.
Nous présentons ici un algorithme de segmentation en régions pouvant s'appliquer à des problèmes très variés car il ne tient compte d'aucune information a priori sur le type d'images traitées. C'est un algorithme de type division-fusion. Lors d'une première étape, l'image est découpée en fenêtres, selon une grille. L'algorithme de division travaille alors indépendamment sur chaque fenêtre, et utilise un critère d'homogénéité basé uniquement sur les niveaux de gris. La texture de chacune des régions ainsi obtenues est alors calculée. A chaque région sera associé un vecteur de caractéristiques comprenant des paramètres de luminance, et des paramètres de texture. Les régions ainsi définies jouent alors le rôle de sites élémentaires pour le processus de fusion. Celui-ci est fondé sur la modélisation des champs exploités (champ d'observations et champ d'étiquettes) par des champs de Markov.
Les relations entre émotions et indices multimodaux ont été peu étudiées dans le cadre d'émotions autres que les émotions de base jouées par des acteurs. Dans cet article nous présentons deux expériences permettant d'étudier ces relations par une démarche d'analyse-synthèse. Nous partons d'interviews télévisées montrant des comportements émotionnels naturels. Un protocole et un schéma de codage ont été définis pour les annoter à plusieurs niveaux (contexte, émotion, multimodalité). La première expérience manuelle a permis d'identifier les niveaux de représentation qui interviennent pour faire rejouer ces comportements par un agent expressif. La deuxième expérience fait intervenir une extraction automatique à partir des annotations multimodales. Une telle démarche permet d'apporter des connaissances sur les relations complexes entre émotions et multimodalité.
Les modéles de reconnaissance visuelle de mots différent selon les hypothéses sur l'utilisation de l'information phonologique et les processus qui la rendent accessible. L'anglais et le chinois ont des systémes structurés l'un selon l'alphabet, l'autre, la logographie. Deux études ont utilisé ces caractéristiques les résultats montrant qu'avec chacun des systémes d'écriture les mots trés fréquents sont reconnus sur une base visuelle sans médiation phonologique. La phonologie ne joue que pour le traitement de mots peu fréquents. Ainsi, bien que d'autres différences dans les systémes d'écriture peuvent influencer sur le traitement, les différences dans la maniére dont ces écritures représentent la phonologie ne sont pas pertinents pour la reconnaissance des mots usuels. Ces résultats sont compatibles avec un mode de reconnaissance des mots interactif et en paralléle dans lequel l'information orthographique et phonologique est activée á des latences différentes.
Comment choisir l'ensemble des variables pertinentes pour résoudre une tâche fixée ? La sélection de variables neuronale essaye de résoudre le problème pendant l'apprentissage du réseau de neurones. Parmi les méthodes utilisées avec les réseaux de neurones de type perceptron multicouches, certaines sont issues d'une technique d'élagage des poids, OBD (Optimal Brain Damage), proposée par LeCun et al. en 1990. Après avoir rappelé ces différentes méthodes, cet article montre comment essayer de les améliorer en suivant quelques principes simples. Une étude comparative situera ces différentes méthodes par rapport à d'autres techniques statistiques ou neuronales.
Nous expliquons dans un premier temps pourquoi il est nécessaire de séparer sur un signal les parties purement déterministes et les parties purement non déterministes. Après présentation de la méthode de Prony nous donnons des exemples d'applications sur des signaux avec traitement par microordinateur.
Lorsqu'on utilise des modèles de Markov cachés pour la reconnaissance de la parole, l'on fait habituellement l'hypothèse que la probabilité d'émission d'un vecteur acoustique ne dépend que de l'état courant et du vecteur acoustique actuellement observé. Dans cet article, nous envisageons une hypothèse moins restrictive : nous considérons qu'au sein d'un même état de la chaîne de Markov, les vecteurs acoustiques sont générés par un processus markovien continu. En effet, l'évolution temporelle du signal de parole est intrinsèquement continue, et l'échantillonnage n'est réalisé que pour les besoins de calculs numériques. Nous assignons une densité de probabilité à la trajectoire temporelle observée du vecteur acoustique, reflétant la probabilité que cette particulière a été générée par le processus markovien continu associé à l'état. Elle mesure “l'adéquation” de cette trajectoire observée par rapport à une trajectoire idéale, supposée générée par équation différentielle vectorielle linéaire. La segmentation la plus probable (au sens du maximum de vraisemblance) s'obtient en échantillonnant le processus continu, et en calculant le meilleur chemin à travers toutes les segmentations possibles et toutes les durées possibles par programmation dynamique.
Nous décrivons l'utilisation de transformations spectrales pour l'adaptation au locuteur de systèmes HMM de reconnaissance de mots isolés. Cet article expose et compare trois méthodes pour réaliser cette transformation ; la minimisation de l'erreur quadratique moyenne (MMSE), l'analyse canonique des corrélations (CCA) et l'emploi d'un perceptron multi-couches (MLP). Sur les mots isolés du corpus TI-46, les meilleurs résultats sont fournis par la méthode CCA. Nous comparons également trois stratégies d'apprentissage et d'adaptation des HMM. La technique “sans ré-apprentissage” calcule la transformation spectrale à partir d'une petite quantité de données d'adaptation : elle peut surtout être utilisée pour l'adaptation en ligne. La technique “d'apprentissage après adaptation” calcule la transformation avant l'apprentissage des HMM ; celui-ci doit être fait hors-ligne, mais les modèles obtenus sont de meilleure qualité. La troisième approche combine de manière originale les deux techniques précédentes en deux étapes ; elle réalise une adaptation à la fois rapide et de bonne qualité. Nos expériences montrent qu'une adaptation de ce type (à 2 étages et utilisant la méthode CCA de transformation spectrale) avec en moyenne seulement 10% des données d'apprentissage d'un nouveau locuteur permet d'obtenir un taux de reconnaissance meilleur que celui fourni par le modèle appris individuellement sur ce locuteur.
Cet article aborde la problématique de l'insertion de Jean Miélot et de ses œuvres dans le milieu de la cour de Bourgogne. On observe que, malgré la grande variété des textes que Miélot nous a laissée et leur grand intérêt, ils ne semblent pas avoir eu beaucoup de succès à son époque. Beaucoup de ses œuvres ne sont connues que par un ou deux manuscrits, et ses livres se trouvaient dans peu de bibliothèques. Deux questions s'imposent donc : tout d'abord, celle de savoir si l'on doit voir Jean Miélot comme un écrivain isolé ou bien comme un auteur bien inséré dans un milieu des artisans du livre à la cour de Bourgogne ; deuxièmement, si ses œuvres n'ont effectivement pas eu beaucoup de rayonnement ou si elles étaient par contre largement diffusées. Des recherches dans le domaine de l'écriture et de la décoration des manuscrits de Miélot confirment que le chanoine n'est pas un auteur isolé, mais qu'il est bien intégré dans un réseau de producteurs de livres pour la cour de Bourgogne. Des liens étroits avec David Aubert peuvent être supposés. D'autre part, un aperçu des possesseurs des manuscrits contenant des textes de Miélot au XVe siècle révèle que ses lecteurs étaient confinés au cercle très restreint de la famille ducale et de quelques membres de la haute noblesse à la cour de Bourgogne. Ses textes ne se sont pas, ou à peine, diffusés vers d'autres groupes sociaux ou vers d'autres aires géographiques. Jean Miélot est une figure originale et intéressante du XVe siècle. Une approche intégrant codicologie, paléographie et l'étude du texte et de l'image peut nous apporter un nouveau regard sur son rôle et sur ses œuvres.
Dans cet article, nous présentons un nouvel algorithme de transformation du timbre de la voix. Cette méthode présente deux particularités importantes. Premièrement, elle modifie les fréquences des formants et l'intensité spectrale en utilisant des règles de conversion “linéaires par morceaux”, permettant de contrôler les détails du spectre. La deuxième particularité est que l'algorithme prend en compte non seulement la fréquence et la bande passante des formants, mais aussi l'intensité spectrale (l'amplitude formantique). Ceci est obtenu au moyen d'une procédure itérative de modifications des pôles du filtre de synthèse. Des tests d'écoute ont démontré que cet algorithme transforme de façon efficace les caractéristiques individuelles du timbre du locuteur, tout en conservant une très bonne qualité de synthèse.
Cet article esquisse un cadre théorique pour la compréhension des bases neurales de la mémoire. Ce modèle réfuse l'existence d'un site anatomique unique pour l'intégration sensori-motrice et d'une mémoire unique gardant le sens d'entités ou d'événements. Le sens résulte de la rétrp-activation distribuée et synchrone de fragments. Seuls ces derniers atteignent le seuil du conscient.
Nous nous trouvons actuellement au milieu d'une révolution des moyens de communication qui promet de fournir un accès permanent aux services de communication multi-média. Pour y parvenir, cette révolution a besoin d'interfaces de haute-qualité, faciles d'usage et “sans couture” à offrir pour la communication large-bande entre les utilisateurs et les machines. Dans cet article, nous défendons l'idée que les interfaces en parole naturelle (SLIs) sont essentielles pour faire de cette vision une réalité. Nous présentons les applications potentielles des SLIs, les technologies qui les sous-tendent, les principes que nous avons développés pour les définir, ainsi que les domaines-clé de recherche future, tant en traitement de la parole naturelle qu'en interfaces personne–machine.
Ce papier présente des modèles de cartes auto-organisatrices de Kohonen (self-organizing map, som) hiérarchiques pour la classification phonémique. Cette méthode som hiérarchique utilise comme principe de base un apprentissage non supervisé et une organisation spatiale des données. Cette approche de classification étend la méthode de carte de Kohonen en introduisant le principe de vecteurs prototypes multiples, par l'intermédiaire de la méthode d'enrichissement de l'information auxiliaire dans une carte. L'étude de cas des modèles de classification som hiérarchiques porte sur la reconnaissance phonémique pour la parole continue, multilocuteur et indépendant du contexte. Les modèles som proposés servent comme des outils pour le développement des systèmes intelligents et poursuivant des applications de l'intelligence artificielle.
La question de savoir si les mots de la classe fermée et les mots de la classe ouverte suivaient la même voie d'accès au lexique a été récemment l'objet d'un vif débat. On a suggèré que les différences dans la sensibilité aux fréquences pouvaient indiquer des voies d'accès séparées. Nous n'avons pas trouvé de preuves à I'appui de l'hypothèse que les mots de la classe fermée ont une voie d'accès lexical différente ou spéciale. On ne trouve pour aucune des deux classes de mots d'effet de fréquence pour les fréquences de Kučera-Francis de 400 million ou plus et ceci aussi bien pour les temps de réaction que dansl'analyse des erreurs. Les mots de la classe ouverte donnent parfois lieu à des réponses plus rapides que les mots comparables de la classe fermée mais ceci pent etre en contradiction avec des interprétations sur l'effet de la classe des mots (Bradley et al 1980). En outre nos données montrent également quelles pourraient être les influences spécifiques aux mots sur les temps de décision lexicale — effets qui pourraient être impossibles à séparer de l'effet de la classe des mots en anglais. Pour interpréter la non sensibilité aux fréquences trouvée dans ces expériences on doit aménager les modèles d'accs̀ lexical basés sur le logogen et y inclure une limite inférieure pour les seuils de positionnements. Les modèles de résonnance (Gordon, 1983) prédisent dejà cette insensibilité aux fréquences. Il aurait du être possible de distinguer entre les deux modèles lors des tâches de décision lexicale avec masquage mais des effets inattendus inhérents aux mots nous ont empéché de le faire.
Le système apollonien peut être expliqué – nous semble-t-il – par sa conception du nom, censé signifier à la fois la substance et la qualité du référent et donc lié à la signification de l'hyparxis / ousía : le fait de nommer un référent en implique l'existence du moins au niveau linguistique.
Cet article consiste en un examen des tenants et des aboutissants de l'activité de relecture, considérée principalement sous l'angle de la temporalité. Après une brève étape de définition, y sont successivement abordées les tentatives de « programmation » textuelle de la relecture face aux relectures spontanées, les modalités mêmes de la relecture de textes fictionnels et non fictionnels, les motivations de la pratique de relecture. Ainsi se dégage une manière de bilan du phénomène de relecture dans son rapport au temps, implications comprises, sur le triple plan poétologique, pragmatique et anthropologique.
Cet article étudie le problèma de la reconnaissance des objects à partir de leur forme st propose une nouvelle approche, l'alignement des descriptions graphiques. La première partie de l'article passe en revue les approches générales de la reconnaissance visuelle des objets et divise ces approches en trois grandes catégories : méthodes des propriétés invariantes, méthodes de décomposition des objets et méthodes d'alignment. La seconde partie présente la méthode d'alignment. Dans cette approache le processus de reconnaissance est divisé en deux étapes. La première détermine la transformation dans l'escape nécessaire pour amener l'objet vu en alignement avec les modèles possibles d'objets. Cette étepa peut se dérouler sur la base d'une information minimale, telle que l'orientation dominante de l'objet, ou un petit nombre de traits communs entre l'objet et le modèle. La seconde étape détermine le modèle qui correspond le mieux avec l'objet vu. Au cours de cette étape, la recherche se fait sur tous les modèles d'objets possibles, mais pas sur l'ensemble des vues possibles de ces objets, étant donné que la transformation a déja été déterminée d'une manière unique au cours de l'étape d'alignment. La méthode d'alignment proposée utilise également des descriptions abstraites mais à la différence des méthodes de description structurelles, elle les utilise de manière graphique plutôt que sous la forme de descriptions structurelles symboliques.
Concevoir le comportement des personnages non joueurs (PNJ), dans un jeu vidéo de type jeu de rôles, est un problème difficile tant du point de vue de la réalisation informatique que de la modélisation du comportement lui-même. A ce moteur nous associons un mécanisme de sélection d'action basé sur les motivations. Ce mécanisme permet la définition de différents comportements de PNJ en jouant sur les paramètres des motivations et sans nouvelle programmation de code. Notre proposition constitue un moteur comportemental pour la modélisation de comportements de personnages situés. Par sa généricité, ce moteur peut être utilisé dans différents environnements (jeux) et pour différents agents en s'adaptant aux spécificités et capacités de chacun tout en proposant une diversité dans les comportements réalisables.
Deux modè;es de simulation du conduit vocal non-stationnaire à l'aide de filtres digitaux (WDF) sont décrits. Le premier modèle se limite à redéfinir périodiquement les coefficients du filtre WDF afin de simuler les changements d'aire. Le second modèle repose sur un filtre d'onde digital variable dans le temps qui permet une description physiquement cohérente du conduit vocal non-stationnaire. Dans le but de tester si le premier modèle suffit à la synthèse de la parole, les deux modèles sont comparés l'un à l'autre. De plus, trois modèles distincts de simulation de la source glottique sont décrits. Une première simulation est basée sur un filtre WDF variable dans le temps, une deuxième simulation est basée sur un filtre WDF ordinaire et une troisième simulation se fonde sur un modele dans lequel la glotte est supposée purement résistive. Les signaux produits par ces modèles et leurs interactions avec le conduit vocal sont comparés entre eux. Il apparaît que les différences entre les deux modèles du conduit sont très faibles en simulation de la parole et ne sont pas audibles dans des expériences d'audition. Les trois modèles de la source glottique produisent des différences plus importantes qui sont audibles. La simulation “simple” au moyen d'une source purement résistive produit des effets similaires aux autres modèles.
Dans les modèles autorégressifs de production de la parole, il est courant de modéliser l'excitation laryngienne ('glottal volume velocity') à l'aide de deux pôles réels. Cette communication discute des implications de ce procédé sur certaines caractéristiques temporelles fondamentales et conclut qu'une telle modélisation est physiologiquement irréaliste. Les conséquences sur les performances des algorithmes autorégressifs d'analyse et sur la qualité (perceptive) des voyelles ainsi produites sont discutées.
Cet article présente les performances d'un codec d'image bas debit pour le vidéophone et les applications RNIS concernant le canal B/2B. Au niveau du récepteur, les trames manquantes sont reconstruites à l'aide d'une interpolation linéaire qui utilise les trames codées et les vecteurs de mouvement associés. L'efficacité du codec est évaluée en utilisant deux séquences vidéo à l'entrée. Les séquences vidéo obtenues montrent que pour le vidéophone, la qualité est bonne. Par conséquent, ce codec peut être un bon candidat pour le vidéophone dans le réseau RNIS. Les considérations d'implémentation du codec sont également données.
Cet article résume les résultats d'études récentes sur le rôle de la mémoire à long-terme en perception de parole et en reconnaissance de mots. Ces expériences sur la variabilité des locuteurs, le débit de parole et l'apprentissage perceptif fournissent des preuves fortes en faveur de l'existence d'une mémoire implicite pour les détails perceptifs très fins de la parole. Apparemment, les auditeurs encodent des attributs spécifiques de la voix du locuteur et de son débit dans une mémoire à long-terme. La variabilité acoustico-phonétique ne semble pas être “perdue” à l'issue de l'analyse phonétique. Le processus de normalisation perceptive en oeuvre lors de la perception de parole semble donc comporter un encodage d'événements ou “épisodes” spécifiques du stimulus d'entrée et les opérations d'analyse perceptive. Ces opérations perceptives pourraient être effectuées au sein d'une “mémoire procédurale” pour chaque voix de locuteur donnée. Globalement, l'ensemble actuel d'observations est en accord avec les présentations non-analytiques de la perception, de la mémoire et de la cognition qui mettent l'accent sur la contribution d'un encodage épisodique ou “à base d'exemples” au processus de mémoire à long terme. Les résultats de ces études posent également la question des dissociations tradionnelles en phonétique entre les propriétés linguistiques et d'indexation de la parole. Les auditeurs retiennent apparemment, dans la mémoire à long-terme, des informations non-linguistiques sur le genre du locuteur, son dialecte, son débit de parole et son état émotionnel, attributs du signal de parole qui ne sont généralement pas considérés comme relevant des représentations phonétiques ou lexicales des mots. Ces propriétés influencent l'encodage perceptif initial et la rétention des mots parlés et doivent par conséquent jouer un rôle important dans les hypothèses théoriques concernant la façon dont le système nerveux associe les signaux de parole aux représentations linguistiques du lexique mental.
Dans cet article, nous présentons une solution multisensorielle temps réel pour la détection et le suivi d'obstacles sur route. Cette solution est basée sur l'utilisation d'un capteur mixte caméra vidéo/capteur de profondeur placé à l'avant d'un véhicule expérimental. Le capteur multisensoriel est décrit. Le calibrage permet l'alignement des données hétérogènes. Deux facultés du capteur sont développées : la perception dirigée permet l'acquisition d'une image de profondeur dans une zone définie dans l'image de luminance ; l'asservissement visuel réalise la focalisation du faisceau laser sur un point de l'image de luminance. De façon générale, ces facultés permettent un contrôle par rétroaction sur le mode d'acquisition du capteur en fonction de la situation dans laquelle se trouve le système de perception. La stratégie de perception est basée sur la sélection du capteur adéquat pour un objectif donné. La détection d'obstacle repose sur la segmentation et l'interprétation des données de profondeur qui sont d'une grande pertinence dans ce contexte. En revanche, la cadence d'acquisition de ces données n'est pas suffisante si l'on souhaite dériver les caractéristiques cinématiques des obstacles. En conséquence, le suivi des obstacles combine un traitement de l'image de luminance rapide avec un traitement de l'information 3D. Le premier permet de réactualiser la position de l'obstacle afin d'asservir le faisceau laser sur celui-ci et le second assure la connaissance de la taille du modèle de l'obstacle à chercher dans l'image. Cet algorithme de fusion de données hétérogènes accompagné d'un filtrage de Kalman permet d'inférer les caractéristiques cinématiques des obstacles dont la connaissance est indispensable pour aborder ceux-ci dans de bonnes conditions. Ces recherches sont menées dans le cadre du projet européen PROMETHEUS et sont validées en situation réelle à bord du véhicule expérimental Prolab.
Nous décrivons un corpus de monosyllabes servant à tester l'intelligibilité des consonnes en parole synthétique. Ce corpus se différencie de ceux utilisés pour d'autres tests en ce qu'il recouvre une large variété de sons de l'anglais et est utile pour le diagnostic et pour l'évaluation comparative. Les résultats obtenus avec certains tests “standards” d'intelligibilité utilisant un matériel phonétique restreint pourraient ne pas être représentatifs de l'intelligibilité d'un plus grand échantillon réellement représentatif de l'anglais. Pour illustrer ceci, nous présentons les résultats d'une comparaison effectuée sur une ligne téléphonique entre un synthétiseur de demi-syllabes actuellement en développment à Bellcore (“Orator”), un synthétiseur déjà commercialisé et basé sur les phonèmes et de la parole naturelle produite par deux locuteurs. Ces données de parole naturelle pourraient être utilisées par d'autres laboratoires désireux de comparer l'intelligibilité des consonnes d'autres systèmes de synthèse par rapport à la parole naturelle.
Le système VOICE (Voice Oriented Interactive Computing Environment) a été développé pour la langue hindie, dans le but de fournir un outil d'interaction visuelle et vocale. Le système de reconnaissance de 200 mots isolés s'applique dans une tâche de réservation ferroviaire ; il utilise des segments acoustico-phonétiques pour unités de base de reconnaissance. A chaque trame, une classification en grandes classes acoustico-phonétiques est réalisée grâce à un classificateur par maximum de vraisemblance ; la segmentation par classification hiérarchique des vecteurs des valeurs de vraisemblance associées aux trames est effectuée grâce à des semi-modèles de Makov cachés, qui utilisent expliticitement la durée. Une classification plus précise par réseaux connexionnistes est réalisée pour quelques classes (voyelles, barres de voisement et nasales dans une première étape). Un décodage de séquences par programmation dynamique permet l'accès lexical, c'est-à-dire le décodage comme des mots de la suite des symboles représentant les catégories phonétiques. Une implantation répartie des tâches permet de reconnaître un mot en quatre fois le temps réel. Un processeur linguistique lève les ambiguités entre les choix multiples fournis par le reconnaisseur à chaque mot, et corrige éventuellement des erreurs de reconnaissance au niveau acoustique. C'est le premier système de reconnaissance qui fonctionne sur la langue hindie ; le taux de reconnaissance des mots est de 85%. A fins de comparison, un système de reconnaissance de mots par Modèles de Markov cachés a également été développé. Les performances du système devraient encore s'accroître car il lui reste un large potential d'amélioration.
Plusieurs méthodes efficaces de collage de la parole à débit variable (VBR) adaptées aux techniques à falble retardà base de collage en arbre à decision différée (DDTC) et de CELP sont présentées dans vet article. Ces méthodes reposent sur la modification du (des) dictionnaire(s) existant(s) par des codes en blocs ou en treillis. Pour réaliser one réduction de débit du codeur DDTC, one technique nouvelle basée sur un code de parité est développée et s'est avérée apporter jusqu'à 2 dB d'amélioration du rapport signal sur bruit des méthodes conventionnelles. Pour one augmentation du debit do codeur LD-CELP, one approace basée sur un code en treillis est utilisée. Le dictionnaire en treillis modifié ou supplémentaire possède one structure géométrique (algébrique) permettant one procédure de recherche efficace pour one quantité minimum de mémoire supplémentaire. Les résultats des simulations de ces méthodes UBR pour un codeur DDTC à 16 kbit/s et pour le codeur LD-CELP à 16 kbit/s proposé pour la recommendation CCITT (G728) sont présentér.
Ce papier propose une méthode permettant d'identifier le scripteur d'un texte quelconque de quelques lignes en le comparant à des écritures de références. La comparaison est basée sur une mesure de mise en correspondance des distributions des allographes de lettres représentatifs des styles d'écriture. Un système automatique segmente le texte en lettres, puis classe chaque lettre de manière probabiliste parmi les prototypes disponibles pour cette lettre. Deux bases de complexité différentes sont utilisées pour valuer ce système. Cette méthode est développée sur de l'écriture en ligne.
Deux expériences utilisent une procédure développée par Carter et Bradshaw (Speech Communication, Vol. 3 (1984) pp. 347–360) pour examiner le rôle de la structure de la syllabe sur la production de la parole. Dans cette procédure, les sujets intervertissent des segments phonologiques dans des positions correspondantes d'une paire de mots ou de non-mots présentés visuellement et doivent produire les mots ou non-mots résultants aussi vite que possible. Carter et Bradshaw ont montré que les latences reflètent les fréquences des erreurs d'inversion dans la parole naturelle. La première expérience de la présente étude montre que les échanges de la consonne initiale sont favorisés par la similarité phonétique des consonnes échangées et reflètent un biais pour la production de mots réels. En contrôlant les influences, l'Expérience 2 réduplique et étend le résultat de Carter et Bradshaw selon lequel les échanges de la consonne initiale sont réalisés plus rapidement que ceux de la consonne finale. La discussion relie la différence de latence entre ces conditions à la difference de “cohésion” entre consonnes initiale et finale avee leur voyelle. En particulier, dans l'Expérience 2, plus d'un tiers des erreurs commises sur les échanges de consonne ou de voyelle finales sont des échanges de la syllabe rime entère (VC) alors que 10% seulement des erreurs commises sur la consonne ou voyelle initiales sont des échanges de la syllabe initiale (CV) du mot. Dans les Analyses menées a posteriori, diverses explications quant à la différence de cohésion sont examinées.
Cet article propose une revue de trente années de développement des algorithmes de démosaïçage utilisés dans les caméras numériques pour la reconstruction des images couleurs. La plupart des caméras numériques actuelles utilisent un seul capteur devant lequel est placée une matrice de filtres couleurs. Ce capteur échantillonne par conséquent une seule couleur par position spatiale et un algorithme d'interpolation est nécessaire pour la définition d'une image couleur avec trois composantes par position spatiale. Cet article montre que l'ensemble des techniques du traitement du signal et des images a été utilisé pour résoudre ce problème. Aussi, une nouvelle méthode proposée récemment par l'auteur et collaborateurs est décrite. Cette méthode, basée sur un modèle d'échantillonnage couleur par les cônes de la rétine, révèle la nature de l'échantillonnage spatio-chromatique dans les caméras couleur à un seul capteur.
Près de quatre décennies de recherches sur la perception de la parole ont échoué à démêler la relation entre son et phone. Ceci est-il dû fait que la discrimination des sons de la parole est à ce point complexe ou singulière qu'elle résiste à l'étude ? Ou parce que les bonnes questions n'ont pas été posées ? Cet article passe en revue certaines des recherches les plus récentes menées à l'Institut Pavlov de Léningrad qui suggèrent une réponse affirmative à la deuxième question. Cette nouvelle perspective provient d'un modèle original de la perception de la parole qui prend la forme d'une analyse de la modulation. Une considération plus étendue de cette approche basée sur la modulation pourrait fournir de réelles alternatives aux modèles spectraux développés en vue de la solution du problème de “l'invariance”. Après une introduction générale, le modèle est examiné dans le contexte d'expériences et de résultats représentatifs.
Dans cet article, nous proposons une étude de la Programmation Génétique (PG) du point de vue de la théorie de l'Apprentissage Statistique dans le cadre de la régression symbolique. En particulier, nous nous sommes intéressés à la consistence universelle en PG, c'est-à- dire la convergence presque sûre vers l'erreur bayésienne à mesure que le nombre d'exemples augmente, ainsi qu'au problème bien connu en PG de la croissance incontrôlée de la taille du code (i.e. le "bloat"). Les résultats que nous avons obtenus montrent d'une part que l'on peut identifier plusieurs types de bloat et d'autre part que la consistence universelle et l'absence de bloat peuvent être obtenues sous certaines conditions. Nous proposons finalement une méthode ad hoc évitant justement le bloat tout en garantissant la consistence universelle.
Nous introduisons une famille d'algorithmes adaptatifs permettant l'utilisation de réseaux de neurones comme filtres adaptatifs non linéaires, systèmes susceptibles de subir un apprentissage permanent à partir d'un nombre éventuellement infini d'exemples présentés dans un ordre déterminé.
Cet article présente les résultats expérimentaux obtenus avec une architecture originale permettant un apprentissage générique dans le cadre de processus décisionnels de Markov factorisés observables dans le désordre (PDMFOD). L'article décrit tout d'abord le cadre formel des PDMFOD puis le fonctionnement de l'algorithme, notamment le principe de parallélisation et l'attribution dynamique des récompenses. L'architecture est ensuite appliquée à deux problèmes de navigation, l'un dans un labyrinthe et l'autre dans un trafic routier (New York Driving). Les tests montrent que l'architecture permet effectivement d'apprendre une politique de décisions performante et générique malgré le nombre élevé de dimensions des espaces d'états des deux systèmes.
Dans cet article théorique, nous proposons de comparer les techniques “classiques” employées en inférence grammaticale de langages réguliers par exemples positifs avec celles employées pour l'inférence de grammaires catégorielles. Pour cela, nous commençons par étudier les traductions réciproques entre automates finis et grammaires catégorielles. Nous montrons ensuite que les opérateurs de généralisation utilisés dans chacun des domaines sont comparables, et que le résultat de leur application peut toujours se représenter à l'aide d'automates généralisés appelés “récursifs”. Les liens entre ces automates généralisés et les grammaires catégorielles sont étudiés en détail. Enfin, nous exhibons de nouvelles sous-classes apprenables de grammaires catégorielles pour lesquelles l'apprentissage à partir de textes n'est presque pas plus coûteux que l'apprentissage à partir de structures.
Les modéles connexionnistes des conduites linguistiques acquises qui ontétérécemment proposés, incorporent en fait des représentations linguistiques fondées sur un systéme de régles. Des modéles connexionnistes similaires pour l'acquisition du langage possédent de méme un appareillage et une architecture ad hoc qui leur fait mimer les effets des régles. Les modéles connexionnistes en général ne sont pas adéquats pour rendre compte de l'acquisition de connaissances structurelles : ils nécessitent des structures prédéterminées, méme pour simuler des faits linguistiquesélémentaires. De tels modéles sont plus appropriés pour décrire la formation d'associations complexes entre des structures qui sont déjáreprésentées de maniére indépendante. Ceci rend les modéles connexionnistes des outils potentiellement importants pourétudier les relations entre des conduites fréquentes et les structures qui sous-tendent les connaissances et les représentations. Ces modéles peuvent offrir de puissants moyens imformatiques pour démontrer les limites d'une description associationiste des conduites.
Le « Traité chinois des particules et des principaux termes de grammaire » , qui figure dans la Syntaxe nouvelle de la langue chinoise (1869) de Stanislas Julien, représente la première traduction de l'Explication des particules dans les Classiques et dans les commentaires (Jīngzhuàn shìcí 經傳釋詞, 1819) de Wáng Yǐnzhī dans une langue occidentale. Si l'ouvrage de Wáng peut être considéré comme le plus important répertoire de particules grammaticales de la tradition philologique chinoise, sa traduction constitue un exemple remarquable de présentation des méthodologies et de la terminologie linguistique chinoises pour un public européen. Cet article se propose de comparer les deux ouvrages, en analysant les modalités de traduction des lemmes et de transposition des catégories et de la terminologie linguistiques.
Dans cette étude, on a utilisé une base de données multi-locuteurs contenant des scores d'intelligibilité de 2000 phrases (20 locuteurs, 100 phrases) pour identifier les corrélats de l'intelligibilité qui sont dépendants du locuteur. Nous avons d'abord étudié des caractéristiques “globales” des locuteurs (genre, F0 et vitesse d'élocution). Il est apparu que les locutrices sont globalement plus intelligibles que les locuteurs. Nous avons également observé que l'ampleur du registre de F0 avait tendance à être corrélée positivement avec des scores d'intelligibilité plus élevés. Toutefois, la valeur moyenne de F0 et la vitesse d'élocution ne semblent pas être corrélées avec l'intelligibilité. Nous avons ensuite examiné d'autres corrélats de l'intelligibilité globale, plus fins au niveau des caractéristiques acoustico-phonétiques du locuteur. Nous avons observé que les locuteurs présentant des triangles vocaliques larges étaient généralement plus intelligibles que les locuteurs présentant des triangles vocaliques serrés. En étudiant deux cas d'erreurs d'écoute consistantes (destruction d'un segment et attribution à une syllabe), nous avons trouvé que ces erreurs perceptives pouvaient être dérivées directement des caractéristiques de timing détaillées du signal de parole. Les résultats suggèrent qu'une part substantielle de la variabilité de l'intelligibilité de la parole normale est attribuable aux caractéristiques acoustico-phonétiques spécifiques du locuteur. La connaissance de ces facteurs peut être utile pour améliorer la synthèse de la parole et les stratégies de reconnaissance, et pour des populations spécifiques (comme par exemple, les mal-entendants ou ceux qui apprennent une langue étrangère) qui sont particulièrement sensibles aux écarts d'intelligilibité entre locuteurs.
Le dévelopment d'un systéme de reconnaissance du locuteur à haute précision () et indépendant du texte est envisagé dans ce travail en deux étapes. La premiére phase traite de l'évaluation des caractéristiques sélectives du locuteur pour les différents ensembles de paramétres qui caractérisent le langage humain. Dans la seconde étape, on apparie deux à deux tous les ensembles de paramétres et on les combine logiquement pour obtenir une précision de reconnaissance plus élevée que celle qui pourrait être atteinte avec chaque ensemble isolé. Cet algorithme permet d'utiliser des phrases supplémentaires pour résoudre les décisions contradictoires résultant de l'application à la premiére phrase-test de la procédure à deux ensembles de paramètres. Pour completer la discussion, une bréve revue de la littérature pertinente est également présentée.
Un système à deux niveaux pour la reconnaissance du locuteur est proposé. Le premier classificateur est construit sur la base du réseau neuromimétique de Kohonen (SOM) et utilise les coefficients LPCC comme vecteurs d'entrée. Les résultats de la classification réalisée par les PDM servent d'entrées pour le classificateur de deuxième niveau. Ce classificateur est construit sur des réseaux neuromimétiques de type MLP, formés pour chaque locuteur. Le classificateur au premier niveau représente un pré-processeur pour le classificateur de deuxième niveau, qui réalise la classification finale. Le but du système proposé est de combiner les avantages des deux types de réseaux neuromimétiques afin d'effectuer une reconnaissance du locuteur plus précise. Les résultats expérimentaux montrent que ce système à deux niveaux améliore les performances surtout pour des signaux bruités (enregistrés par une ligne téléphonique).
La prescription peut inclure toute intervention dans le parler des autres. Depuis longtemps ignorée par les linguistes comme non scientifique, la prescription fait naturellement partie du comportement linguistique. Nous cherchons à mettre en lumière la logique et la méthode de la prescription à travers les manuels d'usage : leurs auteurs, leurs sources et le public visé ; le contexte social de ces ouvrages ; les catégories de « fautes » visées ; les prétendues raisons de la rectification ; la phraséologie de la prescription ; le rapport entre l'usage attesté et l'usage prescrit ; l'effet de la prescription. Nous regroupons dans notre corpus une trentaine de ces manuels de la tradition française. Nous espérons pouvoir créer une base de données permettant une étude comparative de ces aspects.
Un des thèmes importants de l'apprentissage par renforcement est l'approximation en ligne de la fonction de valeur. En plus de leur capacité à prendre en compte de grands espaces d'état, les algorithmes associés devraient présenter certaines caractéristiques comme un apprentissage rapide, la faculté de traquer la solution plutôt que de converger vers elle (particulièrement en raison de l'entrelacement entre contrôle et apprentissage) ou encore la gestion de l'incertitude relative aux estimations faites. Dans cette optique, nous introduisons un cadre de travail général inspiré du filtrage de Kalman que nous nommons différences temporelles de Kalman. Une forme d'apprentissage actif utilisant l'information d'incertitude est également introduite, et comparaison est faite à l'état de l'art sur des problèmes classiques.
L'élastographie dynamique par force de radiation ultrasonore est une technique d'imagerie des propriétés élastiques des tissus biologiques. D'un point de vue mécanique, nous supposons que ces milieux sont isotropes c'est-à-dire que leurs propriétés sont indépendantes du choix des axes de référence. Le tenseur élastique qui définit les constantes physiques de ce milieu s'exprime en fonction de deux constantes indépendantes, le module d'élasticité volumique K (qui intervient lors de la propagation des ondes de compression), et le module d'élasticité de cisaillement μ (qui intervient lors de la propagation des ondes de cisaillement). L'apparition de certains type de cancers entraîne de faibles variations du module d'élasticité volumique K, mais peut modifier considérablement le module d'élasticité de cisaillement μ. La mesure de ce paramètre μ peut ainsi aider au diagnostic de ce type de pathologie des tissus. Un moyen judicieux de mesurer ce paramètre est d'utiliser un effet non linéaire de force de radiation ultrasonore. Cette force est proportionnelle à l'atténuation et à l'intensité des ultrasons émis dans le tissu par le système d'imagerie. Cette source de contrainte génère principalement une onde de cisaillement qui se propage avec une vitesse de phase proportionnelle au module de cisaillement et une polarisation purement transversale en champ lointain (loin de la source de contrainte). La mesure des déplacements du milieu, induits par la propagation de cette onde, peut permettre par résolution du problème inverse de remonter au module de cisaillement. Nous avons réalisé ces mesures à partir des lignes radiofréquences (RF) obtenues par un transducteur d'imagerie ultrasonore. Ce travail décrit précisément le traitement que nous avons réalisé sur les lignes RF. Ce traitement est basé sur l'utilisation d'une méthode d'estimation des retards temporels entre les lignes radiofréquences obtenues pendant la propagation de l'onde de cisaillement. L'influence de différents paramètres (taille de la fenêtre glissante d'analyse, rapport signal sur bruit des lignes RF, fréquence d'échantillonnage, caractéristiques du transducteur ultrasonore…) sur la précision de mesure des déplacements a été étudiée. Nous présentons les courbes des déplacements en fonction du temps obtenus après optimisation des paramètres de traitement. Ces résultats expérimentaux ont été favorablement comparés à un modèle physique et nous ont permis de remonter au module de cisaillement du milieu.
Cette méthode consiste à calculer d'abord les histogrammes de projection obtenus pour différents angles, puis à déterminer la valeur maximale de la représentation temps-fréquence de la racine carrée de ces histogrammes. L'orientation du document est alors estimée par l'angle de projection fournissant la valeur maximale la plus élevée. La méthode proposée a été testée sur 864 documents inclinés avec 9 représentations temps-fréquence différentes. Les résultats sont présentés et analysés à la fin de cet article.
Une nouvelle méthode d'acquisition automatique des Fragments pour la compréhension du langage courant est désormais proposée. L'objectif de cette méthode est de générer une collection de Fragments, chacun représentant un ensemble de phrases similaires d'un point de vue syntaxique et sémantique. En premier lieu, les phrases fréquemment rencontrées dans le kit de formation sont sélectionnées en qualité de phrases candidates. Chaque phrase candidate présente trois répartitions de probabilité associées : contextes suivants, contextes précédents et actions sémantiques associées. La similitude entre les phrases candidates est mesurée en appliquant la distance Kullback–Leibler à ces trois répartitions de probabilité. Les phrases candidates proches des trois distances sont regroupées au sein d'un Fragment. Les séquences représentatives de ces Fragments sont ensuite acquises automatiquement, et exploitées par un module de compréhension du langage courant afin de classer les apples dans la tâche AT&T dénommée “How May I Help You ?” (“Comment puis-je vous aider ?”). Ces fragments nous permettent de généraliser les phrases non observées. Par exemple, ils ont permis de détecter 246 phrases présentes dans les kits de test et absentes des kits de formation. Ce résultat montre que les phrases qui n'ont pas été vues peuvent être découvertes automatiquement grâce à notre nouvelle méthode. Des résultats expérimentaux montrent une amélioration de 2,8% des performances de classification des types d'appels après la mise en place de ces Fragments.
A partir de l'information acoustique, il a été possible, avec un algorithme génétique, de retrouver des trajectoires articulatoires, en se servant d'un modèle dynamique de production de la parole. Des tests sur des logatomes simulés /əbæ/ et /ədæ/ montrent que cette méthode peut recouvrir la plûpart de trajectories originales ; cependant le traitement du timing précis pose des problèmes. Pour récupérer l'articulation, il est nécessaire de rajouter, aux trajectoires de fréquences formantiques, de l'information acoustique supplémentaire, comme l'amplitude RMS.
La distinction entre ce qui est prévu et ce qui est fait est bien connue. On oppose les tâches prescrite et effective, la logique de fonctionnement à la logique d'utilisation, la procédure à la pratique, etc. En fait, il existe une solution grâce à un formalisme qui permet une représentation uniforme des éléments de raisonnement et de contextes, appelé Graphes Contextuels. Nous proposons également une nouvelle notion de « modèle de tâche contextualisée » qui est un compromis opérationnel entre les tâches prescrite et effective. Le développement de tels modèles de tâches contextualisées permettrait d'établir des procédures plus robustes comme cela est montré à travers quatre applications.
Les sujets intègrent naturellement les informations auditives et visuelles en perception bimodale. Pour évaluer la robustesse de ce processus d'intégration, on a fait varier systématiquement les instants de déclenchement de sources auditives et visuelles. Dans la première expérience, des syllabes bimodales composées des versions auditives et visuelles des syllabes /ba/ et /da/ on été présentées avec cinq valeurs différentes d'asynchronie. La deuxième expérience dupliquait la première en utilisant les voyelles /i/ et /u/. Les résultats montrent que les sujets intègrent dans leur perception les deux sources d'information pour toutes les valeurs d'asynchronie. Les réponses groupées (par exemple /bda/ pour une source visuelle /ba/ et une source auditive /da/) apparaissent essentiellement pour les consonnes et non pour les voyelles. De plus, ces réponses groupées nécessitent que les informations visuelle et auditive soient, chacunes, raisonnablement compatibles avec les propriétés physiques d'une articulation de groupe consonantique. Tant pour les voyelles que pour les syllables consonnes-voyelles, l'information provenant des sources auditive et visuelle est continue, indépendante et combinée dans un processus de traitement des traits à trois niveaux : évaluation, intégration et décision.
Nous nous intéressons aux problèmes soulevés par les modifications des images couleur consécutives à des changements d'illuminant. Les images considérées dans cet article contiennent un seul objet placé sur un fond uniforme et éclairé avec un illuminant qui diffère d'une image à l'autre. Nous proposons de traiter ce problème, non pas en analysant les images de la base indépendamment les unes des autres, mais en analysant tous les couples constitués de l'image requête et de chacune des images candidates. Plus précisément, nous proposons d'analyser chaque couple d'histogrammes couleur pour comparer le contenu de chaque couple d'images. Pour cela, la procédure détermine un couple d'histogrammes couleur dits « spécifiques » à chaque couple d'histogrammes couleur considéré, de telle sorte que l'intersection entre ces histogrammes couleur spécifiques soit élevée uniquement lorsque les deux objets contenus dans les deux images sont similaires. Cette procédure est basée sur une nouvelle hypothèse sur les conséquences d'un changement d'illuminant qui ne porte pas directement sur les couleurs des pixels, mais sur les mesures de rang des pixels.
Cet article décrit une base de données élaborée dans le cadre d'une étude générale sur la parole spontanée sous stress du à un manque de sommeil. C'est un corpus de 216 dialogues orientés-tâche, à script non-écrits, produits par des adultes normaux au cours d'une large étude sur la privation de sommeil. L'étude elle-même examinait l'évolution continue de la performance, pendant les périodes normales, sans sommeil, et de récupération, obtenue par des groupes traités avec placébo ou avec l'une de deux drogues (Modafinil, d-amphétamine) réputées pour contrebalancer les effets du manque de sommeil. Les dialogues ont tous été produits sur la tâche de communication d'itinéraire utilisée dans le “HCRC Map Task Corpus”. Des paires de locuteurs collaboraient pour reproduire sur la carte du partenaire l'itinéraire imprimé sur la carte de l'autre. Des différences contrôlées entre les cartes et l'utilisation de noms de lieux imaginaires étiquetés limitaient les effets du genre, du vocabulaire et de la connaissance des lieux. La construction des cartes et l'affectation des cartes aux sujets font du corpus une expérience de devinement contrôlée. Chaque locuteur a participé à 12 dialogues au cours de l'étude. L'étude préliminaire de la longueur des dialogues ainsi que les mesures de performance sur la tâche font apparaître des effets clairs du traitement par la drogue, du manque de sommeil, et du nombre de partenaires dans la conversation. Le corpus est disponible pour les chercheurs intéressés par tous les niveaux d'analyse de la parole et du dialogue, dans les deux conditions, normale et sous stress.
Dans cette contribution, nous décrivons différentes techniques multi-capteurs de réduction de bruit à la prise de son pour la reconnaissance de mots indépendante du locuteur appliquée à un environnement de bureau. Nous examinons le taux de reconnaissance si la source perturbatrice n'est pas un bruit gaussien et stationnaire, mais un second locuteur présent dans le même local. Dans ce cas, les techniques de réduction de bruit classiques comme la soustraction spectrale sont inefficaces, alors que les méthodes multi-microphones peuvent améliorer le taux de reconnaissance en utilisant l'information spatiale. Nous comparons l'antenne retard-somme, l'antenne super-directive, et deux techniques de post-traitement. Un nouveau post-filtre adaptatif pour les antennes super-directives (APES) est proposé. Nos résultats montrent que les méthodes multi-capteurs peuvent améliorer significativement le taux de reconnaissance, parmi lesquelles la méthode APES se détache en performances.
L'article étudie la possibilité d'utiliser un module de reconnaissance automatique de la parole en tant que périphérique d'ordinateur en vue du traitement des caractères du chinois. Nous avons mené à bien une expérience de reconnaissance de la parole avec l'ensemble des syllabes du chinois standard à ton ascendant. Nous montrons que les distributions des distances intra- et intersyllabiques se chevauchent considérablement pour l'inventaire complet des 260 syllabes. Le taux de reconnaissance a èté évalué en fonction de la dimension du vocabulaire, il est de 47.3% pour l'inventaire syllabique complet.
Les fréquences caractéristiques des formants d'une voyelle pour différents locuteurs sont déterminées par plusieus facteurs dont, entre autres, les spécificités du tractus vocal du locuteur, son sexe, son accent régional et ses habitudes langagières. Dans les données, c'est la différence de sexe qui apparaît comme la source la plus importante de variation inter-locuteurs. Dans cet article, plusiers méthodes de compensation de ces différences ont étéétudiées. On a d'abord essayé la méthode des formants calculés avec l'échelle des Bark et la soustraction du ler formant de la fréquence fondamentale en Bark. Contrairement à ce qui est affirmé dans des articles récents, cette technique s'est révélée inadéquate. Les transformations se sont, par exemple, montrées incapables d'améliorer les groupements de voyelles cardinales. Cette technique a permis de rendre compte de la plus grande part de la variance due aux différences interlocuteurs, à partir d'une petite quantité de données d'entraînement. Cette technique a été appliquée à létude de voyelles américano-anglaises en contexte. Les fréquences des formants ont été étudiées pour 125 locuteurs de l'anglais américain générail. Les graphiques des formants pour les hommes et les femmes montrent des phénomènes intéressants. Premièrement, la limite fréquentielle inférieure du second formant ne diffère pas beaucoup en fonction du sexe tandis que celle du premier formant est plus basse pour les hommes. Deuxièmement, les maxima fréquentiels des premiers et seconds formants sont plus hauts pour les femmes. Grâce à la méthode modifiée de Gerstman, les cibles des formants pour une même voyelle dans un même contexte produite par différents locuteurs ont pu être superposées dans la même région de l'espace des deux premiers formants. Il restait néanmoins une variance résiduelle due à la différence de sexe. Ces tendances sont montrées dans une série de graphiques représentant les fréquences vocaliques cibles.
Le module de contrôle de gain d'un quantificateur “shape-gain” est rendu adaptatif, donnant lieu à un quantificateur vectoriel qui s'adapte à la variation temporelle de l'amplitude du signal de parole. La version adaptative n'exige qu'un faible accrossement de la charge de calcul. Nous présentons les méthodes de conception nécessaires pour optimiser le rapport signal sui bruit ou, alternativement, pour optimiser le rapport signal sur bruit arithmétique segmenté ; les deux produisent des résultats comparables. Le quantificateur fonctionne le mieux sur des segments de parole riches en fréquences basses à cause de la forme lisse du signal. Le fonctionnement global à débit unité est comparable au quantificateur adaptatif en amont de Chen et Gersho et il est légèrement inférieur à débit double.
De très petites irrégularités spectrales peuvent être détectées par le système auditif, ce qui laisse supposer l'existence d'un mécanisme de type dérivation. A l'opposé, le phénomène de “centre de gavité” suggère l'existence d'un mécanisme d'intégration. Notre objectif est d'analyser les résultats précédents à l'aide du test du seuil de pulsation, outil d'évaluation des représentation internes de spectres de signaux statiques. Il est généralement admis que cette méthode permet d'estimer le résultat de l'analyse spectrale du signal realisée par le système auditif périphérique, en tenant compte des effets de suppression latérale. La première partie de ce travail a consisté à déterminer les conditions expérimentales favorables pour effectuer nos mesures. Nous décrivons les résultats de cette étude préliminaire ainsi que les solutions adoptées. Nous montrons ensuite, sur un premier ensemble de données expérimentales, comment la représentation interne d'un signal à un formant est modifiée avec l'émergence d'un second formant ou la variation de la valeur numérique des pentes latérales du formant. La principale conclusion est que les mécanismes de lissage spectral liés à l'existence d'une sélectivité fréquentielle non infinie dominent les effets de suppression latérale dans ces deux cas expérimentaux.
La présélection lexicale est basée sur une segmentation et une classification du signal en six grandes classes phonétiques. Lors de la vérification, une représentation phonémique détaillée des mots candidats est utilisée pour sélectionner les plus probables. Chaque mot candidat est modélisé par un graphe de sous-mots représentés par des chaînes de Markov. Une arborescence d'un sous-ensemble de mots est construite afin de permettre une implantation efficace d'un algorithme de Viterbi “Beam Search” qui estime la vraisemblance de chaque candidat. Les résultats montrent qu'une réduction de 73% de la complexité peut être obtenue grâce à l'approche en deux temps si on la compare à l'approche directe, pour une précision de reconnaissance comparable.
COMPOST propose aux premiers un langage de programmation de systèmes de synthèse multilingues et multi-entrées et aux derniers une infrastructure logicielle basée sur la notion de serveur-client. Chaque système de synthèse pouvant être utilisé par le serveur est décrit par un scénario écrit dans un langage spécialisé. Les idées développées dans cet article sont assorties d'exemples concrets extraits d'un système de synthèse du français développé à l'aide de COMPOST.
Dans les études précédentes, on a constaté que dans une tâche de détection, les voyelles donnent lieu à des temps de réaction plus longs que les consonnes, ce qui suggère que les voyelles sont plus difficiles à percevoir. Une seconde explication met en cause les rôles différents des voyelles et des consonnes dans la structure syllabique des mots. Dans la présente expérience, on a examiné la seconde possibilité. On a utilisé comme cibles deux paires de phonèmes, chaque paire étant constituée d'une voyelle et d'une consonne qui se ressemblent en termes des caractéristiques phonétiques. Les sujets devaient appuyer sur un bouton aussitôt qu'ils avaient repéré dans une liste de mots anglais un phonème cible préspécifié. Cette fois, les phonèmes jouant le rôle de voyelle dans une structure syllabique ont donné des temps de réaction inférieurs à ceux des phonèmes jouant le rôle de consonne. Ceci élimine une explication de la différence des temps de réaction qui serait basée sur le rôle du phonème dans la structure syllabique. Nous proposons, en revanche, que cette différence provienne de la variation acoustique telle qu'elle se manifeste dans la réalisation des phonèmes cibles et dans leur représentation mentale chez les auditeurs.
On présente un quotient d'amplitude pour la paramétrisation du signal de source glottique obtenu par filtrage inverse. Le nouveau quotient, AQ (amplitude-domain quotient), est déterminé comme étant la proportion entre l'amplitude du flux AC de l'onde glottique et l'amplitude du minimum du flux dérivé. Ce quotient peut être employé même si le matériel d'enregistrement ne donne pas de valeurs absolues de flux. Le comportement d'AQ a été comparé aux quotients conventionnels, basés sur le temps, pour l'analyse de voix produites par différents types de phonation. Comme l'indiquent les résultats, les types de phonation peuvent être quantifiés de façon efficace lorsque la paramétrisation du flux glottique estimé par filtrage inverse se base sur le quotient AQ.
Cette étude porte sur la compréhension des phrases impératives dans des langues artificielles par deux dauphins (Tursiops truncatus). Le premier dauphin (Phoenix) a été instruit avec un langage acoustique dont les mots étaient générés par un computer à travers des hauts parleurs sous-marins. Avec l'autre dauphin (Akeakamai) on a utilisé un langage visuel dont les mots correspondent aux gestes de bras ou de mains d'un instructeur. Los mots correspondant à des agents, des objets, des modificateurs d'objets, des actions pouvalent se combiner selon une série de règles syntaxiques pour donner une centaine de phrases significatives de 2 à 5 mots. Ces phrases correspondaient à des ordres enjoignant aux dauphins d'effectuer des actions relatives aux objets dénommés ou aux modificateurs. La compréhension se mesurait par l'acuité de la réponse à l'ordre et était testée de façon à ce que soient éliminés les biais contextuels, les indices non linguistiques et les biais de l'observateur. Le traitement correct d'une grammaire de gauche à droite (Phoenix) ou d'une grammaire inverse (Akeakamai) montre que des règles syntaxiques entièrement arbitraires peuvent être comprises et que la compréhension des mots fonctionnels se présentant tôt dans la phrase est interpretée par les dauphins sur la base des mots suivants inclue, dans au moins un cas, des mots non-adjacents. Cette approche de la compréhension se distingue radicalement de l'emphase sur la production que l'on trouve dans les études des capacités linguistiques des primates. Les résultats obtenus offrent les premières preuves convaincantes de la capacité des animaux à traiter les traits syntaxiques et sémantiques des phrases. La capacité des dauphins à utiliser les modalités visuelles comme les modalités acoustiques dans ces tâches souligne la dépendance amodale de leur capacité de compréhension des phrases. On présente des comparaisons entre les performances des dauphins, celles des primates entrainés pour le langage et celles des jeunes enfants, sur des tâches reliées et pertinentes.
De nombreuses études sont en cours afin de développer des méthodes de traitement automatique des langues des signes. Plusieurs approches nécessitent de grandes quantités de données annotées pour l'apprentissage des systèmes de reconnaissance. Nos travaux concernent l'annotation semi-automatique de ces corpus de données vidéo. Nous proposons une méthode de suivi de composantes corporelles, de segmentation de la main pendant occultation et de segmentation des gestes à l'aide des caractéristiques de mouvement et de forme de la main. Afin de montrer les avantages et limitations de nos contributions, nous avons évalué chacune des méthodes proposées à l'aide de corpus internationaux. Le système de segmentation des signes montre des résultats prometteurs.
C'est pourquoi nous avons mis à l' épreuve l'hypothèse que l'entraı̂nement de modeles distincts pour des variantes accentuées et non-accentuées soit profitable pour la reconnaisance de la parole continue. Nous avons appliqué le modèlage de l'accent lexique aussi bien dans l'entraı̂nement que dans le test de reconnaissance. Des expériences de reconnaissance sur un ensemble de test indépendent a montré que les taux de reconnaissance n'ont pas été améliorés par l'emploi de l'accent lexique dans le modèlage. Cependant, apres avoir échangé les marques d'accent dans le lexique de reconnaissance, nous avons obtenu une réduction significative des taux de reconnaissance. Cela suggère que les modèles acoustiques pour les variantes accentuées et non-accentuées des voyelles onte été différentes. Un problème dans cette expérience était la confusion éventuelle des données sur l'accentuation lexique et le contexte phonématique. Dans une autre expérience nous avons exclu l'influence du contexte en employant des modèles de contexte généralisés. Les taux de reconnaissance ne se sont pas améliorés, bienque les modèles vocaliques étaient plus propres à représenter l'information liée à l'accent lexique. Notre conclusion est que la représentation de l'information sur l'accent lexique dans la surface acoustique n'est pas suffisamment directe pour aider la reconnaissance de la parole continue.
Dans cet article, nous présentons une nouvelle approche particulièrement performante de discrimination parole/musique dans le cadre d'applications réelles de transcription de nouvelles diffusées. Dans cette approche, un réseau de neurones artificiels (ANN) entraı̂né exclusivement sur de la parole claire (provenant d'un système standard de reconnaissance de la parole grand vocabulaire) est utilisé comme modèle de canal à la sortie duquel nous mesurons toutes les 10 ms l'entropie et le “dynamisme”. Ces caractéristiques sont alors intégrées dans le temps à l'aide d'un modèles de Markov caché (HMM) ergodique à deux états (parole et non-parole) incluant également des contraintes de durée minimum sur chaque état. Par exemple, dans le cas de l'entropie, il est effectivement clair (et observé en pratique) que l'entropie à la sortie du ANN sera en moyenne plus élevée pour des segments non-parole que des segments de parole présentés à son entrée. Dans notre cas, le modèle acoustique ANN est un perceptron multi-couche (MLP, comme souvent utilisé dans les systèmes hybrides HMM/ANN) générant à sa sortie des estimateurs de probabilités a posteriori de phonèmes étant donné les vecteurs acoustiques d'entrée. C'est à partir de ces sorties, et donc de “vraies” probabilités que l'entropie et le dynamisme sont estimés. Le modèle HMM parole/musique à deux états prends ensuite ces deux caractéristiques (entropie et dynamisme) dont les distributions sont modélisées par des densités multi-gaussiennes ou par un second MLP. Les paramètres de ce modèle HMM sont entraînés par un Viterbi supervisé. Bien que l'approche proposée ici puisse être facilement adaptée à d'autres applications de discrimination parole/non-parole, nous nous focalisons ici sur le problème de segmentation parole/musique. Différentes expériences, incluant différents styles de parole et musique, ainsi que différentes distributions temporelles des signaux de parole et musique (distributions réelles, surtout parole, ou surtout musique), illustrent la robustesse de l'approche qui résulte toujours en des performances de segmentation correcte supérieure à 90%. Finalement, nous montrons comment l'utilisation d'un niveau de confiance peut améliorer les résultats de segmentation, et comment ceci peut être utilisé pour traiter les cas de mélanges de parole et musique.
Dans cet article, nous proposons un algorithme parallèle pour la restauration d'images et la détection de contours. Son originalité réside dans l'emploi de techniques de relaxation stochastique combinées à des réseaux résistifs non-linéaires. Sa pertinence pour l'amélioration d'images et son adéquation à une architecture cellulaire mixte analogique numérique sont simultanément considérées. Les simulations présentées montrent l'efficacité de cet algorithme, y compris dans le contexte d'images particulièrement bruitées.
Une méthode d'extraction de la fondamentale du signal de parole basée sur la synthèse est proposée. Elle procède par la synthèse d'un certain nombre de spectres logarithmiques de puissance pour diffénentes valeurs de la fréquence fondamentale, et pour la comparaison de ces spectres avec le spectre logarithmique de puissance du segment de parole analysé. La différence d'amplitude moyenne (AM) entre les deux spectres est utilisée pour la comparaison. La valeur de la fréquence fondamentale qui fournit le minimum de différence AM entre le spectre synthétisé et le spectre du signal d'entrée est choisie comme estimation de la hauteur. La décision voisé/non-voisé est établie sur la valeur de la différence AM au minimum. Pour synthétiser le spectre de puissance, le signal de parole est supposé représenter la sortie d'un filtre tout pôle. La fonction de transfert du filtre tout pôle est estimée à partir du segment de parole par la méthode d'autocorrélation de la prédiction linéaire. Cette méthode basée sur la synthèse est testée sur des segments de parole naturelle et les résultats sont discutés.
En reconnaissance automatique de locuteurs, des situations peuvent se présenter, où ne peut pas être certain qu'une voix à reconnaître appartienne à un ensemble connu de classes de voix (ensemble fermé). Par conséquent, le problème se pose d'élaborer un algorithme de reconnaissance qui puisse opérer dans des ensembles ouverts de locuteurs, c.à.d. sans la prémisse qu'un échantillon de voix doive appartenir à l'un des locuteurs d'un ensemble donné. Deux mots clés, des ensembles différents de paramètres ainsi que de petites comme de grandes populations de locuteurs ont été examinés. Les prémisses méthodologiques et les résultats expérimentaux permettent de constater que notre méthode de reconnaissance de voix dans les ensembles ouverts est très souple et permet d'ajuster les caractéristiques globales, c.à.d. les erreus α et β, à la stratégie adoptée par le système de reconnaissance. Pour un ensemble donné d'échantillons de voix, il est toujours possible d'optimaliser la reconnaissance par une sélection correcte des approximations de la distribution de la classe de base, c.à.d. par une sélection appropriée de seuils de décision.
Nous sommes intéressés par la production de services automatisés par des systèmes de dialogue utilisant la parole naturelle. Nous entendons par naturel que la machine comprend et agit selon ce que les personnes effectivement disent, en opposition à ce que l'on aimerait qu'ils disent. Plusieurs problèmes apparaissent quand de tels systèmes sont visés pour une population large d'utilisateurs qui ne sont pas des experts. Dans ce papier, nous focalisons sur la tâche de routage automatique des appels téléphoniques se basant sur la réponse spontanée des utilisateurs à la question ouverte “How may I help you ?”. Nous décrivons d'abord la base de données générées par 1000 transactions orales entre des utilisateurs et des agents humains. Nous décrivons ensuite les méthodes pour l'acquisition automatique, à partir des données, des modèles de langage pour la reconnaissance et la compréhension. Les résultats expérimentaux pour l'évaluation de la classification des appels sont rapportés pour cette base de données. Ces méthodes ont été incorporées dans un système de dialogue oral avec des traitements subséquents pour le tri des informations et le remplissage des formes.
Face au passage à l'échelle des données, les méthodes de visualisation peinent à fournir de bons résultats. Dans cet article, nous présentons une approche de prétraitement de données (CTBFS) pour la fouille visuelle de données basée sur la théorie du consensus, le regroupement de données et une affectation visuelle de poids. Nous utilisons des ensembles de données de l'UCI et du Kent Ridge Bio Medical Dataset Repository pour évaluer les performances de notre nouvelle approche.
Durant ces dernières années, les évaluations Hub-4 des systèmes de reconnaissance de la parole continue sponsorisées par DARPA ont fait progresser les techniques de reconnaissance de la parole pour la transcription de nouvelles audio-diffusées (“broadcast news”). Dans cet article, nous présentons notre recherche et nos progrès dans ce domaine, en nous concentrant plus particulièrement sur une modélisation efficace utilisant sensiblement moins de paramètres, permettant ainsi d'améliorer la vitesse et les performances de la reconnaissance vocale. En termes de modélisation acoustique, les améliorations ont été obtenues en utilisant une nouvelle méthode pour l'ajustement des paramètres, l'agrégation des Gaussiennes, et le seuillage des poids des mélanges de Gaussiennes. L'efficacité de l'adaptation acoustique est grandement améliorée par l'agrégation non supervisée des données de test. En modélisation du langage, nous avons étudié le résultat de l'utilization de données d'entraı̂nement ne provenant pas de “broadcast news”, ainsi que de l'effet de l'adaptation au sujet et au style de parole. Nous avons développé une technique efficace d'élagage des paramètres pour des modèles de langage avec repli (“backoff”) ce qui nous a permis de supporter l'accroissement continuel de la quantité de données d'entraı̂nement et l'extension de la portée des N-grammes. Enfin, nous avons amélioré notre architecture de recherche progressive en utilisant des algorithmes plus efficaces pour la génération et la compaction de treillis, ainsi qu'en y incorporant des modèles de langage d'ordre supérieur.
Produites en grandes quantités, les connaissances issues d'un processus d'extraction de connaissances à partir de données (ECD) font l'objet d'une opération de filtrage automatique. Cette phase importante du processus, qui a pour objectif de réduire de manière drastique le nombre de règles que l'expert devra examiner "de près", est basée sur l'utilisation d'indices proposant des évaluations quantitatives de la qualité des connaissances. La recherche des meilleures connaissances parmi le vaste ensemble de connaissances produit, passe aussi par la recherche et l'utilisation des bons indices. Nous abordons dans cet article le problème du choix pertinent d'un indice par un utilisateur métier dont les critères d'appréciation rendent souvent difficile la sélection de l'indice le mieux adapté. Nous examinons dans cet article l'intérêt d'une approche de type "aide multicritère à la décision" (AMD) pour aborder ce problème de choix d'indices.
On étudie dans cette recherche les relations entre les niveaux de représentation de phrases et le vocabulaire. Dans une tâche de détection lexicale on a fait varier la classe du mot cible (ouverte ou fermée) ainsi que le rôle fonctionnel de différents éléments de la classe fermée (propositions lexicales, prépositions obligatoires et particules verbales). Différents contextes (phrases reliées sémantiquement ou non) ont été utilisées pour tester l'effet sémantique et/ou l'information syntaxique sur les différents types d'items. Les résultats combinés de sujets normaux et aggrammatiques prouvent que les différent types de vocabulaire sont traités de facon distincte et par conséquence attribués à différents niveaux de traitement. Ces résultats suggèrent également que l'information lexicale et l'information non-lexicale sont traitées à différents niveaux même si ces informations dependent du même item.
La notion de contraste dans les images numériques est proposée dans une approche multirésolution. L'amélioration du contraste en est une application principale par le biais d'un procédé itératif. De plus, ce procédé itératif permet l'obtention d'une forme simplifiée, i.e. binaire, de l'image de départ. De nombreux exemples sont présentés tout au long de cet article montrant les performances de notre algorithme tant sur des images synthétiques que sur des scènes réelles.
Les réseaux sémantiques que l'on construit à présent sont nommés ontologies. Au-delà de la logique, ce choix repose sur un lien réaffirmé avec la tradition métaphysique. Cependant, les lexiques des langues ne sont pas structurés comme des ontologies. Les relations sémantiques sont en effet plus complexes et variables que ce que prévoient les constructeurs d'ontologies. Pour construire une « dé-ontologie » , il faut restituer la diversité des discours et des genres, qui rendent illusoire une ontologie unique ; insister sur le problème de la diversité sémiotique des textes, les corrélations complexes entre contenu et expression, l'incidence constituante du contexte. C'est là une condition pour remplir des tâches de caractérisation, notamment en linguistique de corpus.
Les représentations d'images basées sur des régions offrent plusieurs avantages par rapport aux méthodes basées sur des blocs, tels que l'adaptation aux caractéristiques locales de l'image ou la compensation de mouvement d'objet par opposition à la compensation de mouvement par bloc. Pour la compression des données images, c'est-à-dire pour le codage d'images, de nouveaux algorithmes sont nécessaires qui peuvent travailler sur des régions de forme quelconque, appelées segments au lieu des blocs d'image rectangulaire. En utilisant une approche des moments généralisés, la fonction de luminance à l'intérieur du segment est approchée par une somme pondérée de fonctions de base, par exemple des polynômes. Un ensemble de fonctionsde base qui est orthogonal par rapport à la forme du segment à coder peut être obtenu en utilisant des méthodes d'orthogonalisation. Ceci conduit à l'établissement d'un codeur transformé adapté à la forme. Des structures appropriées de codeurs et de décodeurs qui ne nécessitent pas la transmission des fonctions de base pour chaque segment sont introduites. Finalement, une application de l'algorithme obtenu au codage de séquence d'images à faible débit est montrée, basée sur la segmentation de l'image d'erreur de prédiction de mouvement.
Cet article décrit la méthodologie de test utilisée pour évoluer los performances du Codeur CCITT LD-CELP à 16 Kbit/s (recommandation G.728), sur des signaux non-vocaux. Cette méthodologie est suffisamment genorale pour pouvoir être employee à l'évolution d'autres Codeurs de parole numériques à bas début de transmission. Les signaux non-vocaux envisagés dans cet article comprennent los données en bande téléphonique, la signalisation du réseau, los tonalités de signalisation et los signaux multifréquences (DTMF).
Dans cette étude, on présente une nouvelle méthode de mesure qui permet d'estimer la source vocale et ses valeurs d'amplitude par filtrage inverse de l'onde de pression acoustique, sans utiliser de masque de Rothenberg. Cette nouvelle technique est basée sur l'ajustement du gain DC du modèle du conduit vocal par filtrage inverse en unités. Les performances de cette nouvelle méthode sont testées par l'analyse de la corrélation entre l'amplitude de crête minimale du flux glottique différentiel fourni par la nouvelle méthode et le niveau de pression acoustique de la parole. Les résultats prouvent que la nouvelle méthode fournit des informations fiables sur les valeurs d'amplitude de la source glottique sans appliquer de masque de Rothenberg.
La diminution de l'efficacité des systèmes de reconnaissance vocale lors d'applications pratiques est due aux différentes exigences acoustiques pendant l'apprentissage et pendant la reconnaissance. Deux facteurs importants sont la présence de perturbations sonores en arrière plan et la transmission de fréquences entre le micro et l'entrée audio du reconnaisseur. L'étude présentée ici comporte deux modes de traitement de signaux pour estimer les perturbations sonores actuelles et la différence lors de la transmission de fréquences pendant l'apprentissage et pendant la reconnaissance. L'évaluation des perturbations sonores est utilisée pour une adaptation des paramètres cepstral des références du reconnaisseur, encore appelées HMM (Hidden Markov Models). Le mode d'aptation est basé sur la combinaison parallèle de modèles (PMC). Des améliorations importantes peuvent être apportées pour la reconnaissance d'un mot ou d'une chaı̂ne de mots malgré la présence d'un ou des deux types de perturbations sonores simultanément. Cette procédure d'adaptation a de plus été intégrée à un système de dialogue et de reconnaissance qui est disponible sur le réseau téléphonique public. L'application et le gain d'efficacité du reconnaisseur sont démontrés pour cette application dans un environnement de télécommunication existant et en temps réel.
Initialisé avec trois langues : le français, l'anglais et l'italien, le système mis au point dans le cadre du projet SPELL se veut un outil d'enseignement destiné à des utilisateurs de niveau moyen. Imbroquées dans un environnement intégré nommé DELTA, des informations de type graphique et sonore seront employées pour aider les étudiants à améliorer leur prononciation. L'analyse prosodique, de niveau macroscopique, prendra en compte les aspects intonation, durée, accent et rythme. L'approche phonologique utilisée lors du traitement de l'intonation fournit un système bien structuré d'unités contrastées faciles à corréler avec des fonctions linguistiques discrètes. Dans le système envisagé, l'accent et le rythme seront enseignés de manière moins approfondie en s'appuyant d'une part sur les traits acoustiques relativement simples liés à la qualité des voyelles et d'autre part sur la durée relative des segments. L'analyse des traits microprosodiques va être focalisée tout particulièrement sur les voyelles. Une approche à base de traits discriminants est utilisée pour caractériser la prononciation de voyelles par un locuteur ne parlant pas sa langue maternelle. Il est prévu de mettre en oeuvre des propriétés acoustiques si possible indépendantes du locuteur.
Cette étude propose une première exploration de l'importance des paramètres physiologiques dans les transformations de la voix. Une démarche générale est décrite pour transformer la qualité de la voix dans des phrases sans en modifier le contenu phonétique. Les transformations peuvent être reliées au sexe, à l'âge, à la qualité de la voix, à l'état émotionnel, à un état pathologique, à un dialecte ou à une imitation. Dans cet article, une seule qualité de voix, la voix nasillarde, est décrite en exemple. La question de base sous-jacente est la suivante : si on les compare à des méthodes fondées purement sur des techniques de traitement du signal, peut-on dire que les méthodes exploitant des principes de mise à l'échelle, dans les domaines biomécanique, acoustique et anatomique sont plus efficaces pour la transformation des voix ? Dans cet article, deux méthodes sont comparées, l'une fondée sur la Prédiction Linéaire, et l'autre sur des simulations biomécaniques.
La recherche de connaissances dans les données structurées a fait l'objet de nombreux travaux ces dernières années. La structure de ces objets est irrégulière et il est judicieux de penser qu 'une requête sur la structure des documents est aussi importante qu'une requête sur les données. De plus, les données manipulées ne sont pas statiques parce que de nouvelles mises à jour sont constamment réalisées. Le problème de maintenir de telles sous-structures devient aussi prioritaire que de les rechercher car, au fur et à mesure des mises à jour, les sous-structures trouvées peuvent devenir invalides. Dans cet article, nous proposons un système appelé AUSMS (Automatic Update Schema Mining System), permettant de collecter les données, de rechercher les sous-structures fréquentes et de maintenir les connaissances extraites suite aux évolutions des sources.
Cet article examine les correspondances existant entre les voyelles hautes du japonais ancien de l'Ouest et les voyelles moyennes du japonais ancien de l'Est, à la lumière des récentes hypothèses sur le vocalisme du proto-japonique. Des correspondances à la fois dans le lexique et dans la morphologie sont établies, puis des données comparatives de plusieurs dialectes japonais modernes et de langues ryukyu sont fournies pour confirmer qu'il s'agit de cas de rétention des voyelles *e et *o du proto-japonique
Cet article présente une méthode de régression pour les signaux non uniformément échantillonnés basée sur les ondelettes. Nous utilisons une formulation issue de l'apprentissage supervisé et des méthodes à noyaux qui combine une fonction coût L2 et une régularisation L1 multi-échelles. L'utilisation de l'algorithme Least Angle Régression pour la résolution du problème est à la fois efficace et intéressante, elle permet de calculer le chemin complet de régularisation et d'introduire de nouvelles solutions pour régler le compromis biais-variance.
Dans les bases hétérogènes, les images appartiennent souvent à différentes classes thématiques et nécessitent une large description permettant leur reconnaissance. Cependant, les caractéristiques utilisées ne sont pas toujours adaptées au contenu de la base d'images considérée. Nous proposons dans cet article une nouvelle approche se basant sur deux originalités, à savoir la sélection adaptative de caractéristiques et la classification multi- modèle intitulée MC-MM. La sélection adaptative permet de ne considérer que les caractéristiques les mieux adaptées au contenu de la base d'images utilisée. La méthode MC- MM assure la reconnaissance des images en se servant hiérarchiquement des caractéristiques sélectionnées. Les résultats expérimentaux obtenus confirment l'efficacité et la robustesse de notre approche.
Celles-ci peuvent être utilisées, après division par les probabilités a priori, comme probabilités d'émission dans des chaînes de Markov cachées. L'avantage d'un système hybride de ce type, incorporant un perceptron multicouche comme estimateur des probabilités d'émission d'un modèle de Markov, est son pouvoir discriminant et sa capacité d'intégration de multiples sources d'information (indices acoustiques, contexte temporel), sans devoir formuler d'hypothèses restrictives quant aux formes des distributions et à l'indépendance statistique. Bien que cette approche se soit révélée fructueuse en reconnaissance de la parole, il est cependant important de comprendre les problèmes sous-jacents et les limites, et de considérer leurs conséquences sur d'autres algorithmes. Par exemple, les systèmes de reconnaissance actuels les plus performants utilisent des triphones au lieu de phonèmes comme unité de base, tenant ainsi compte du contexte phonétique. En revanche, la plupart des systèmes basés sur l'estimation des probabilités d'émission à l'aide de perceptrons multicouches peuvent également être généralisé à des unités contextuelles. Nous discutons brièvement comment les résultats théoriques peuvent influencer le développement de nouveaux algorithmes, comme par exemple des Modéles Autorégressifs non linéaires, et de “Radial Basis Functions”.
Nous proposons une nouvelle manière de mettre en oeuvre un système de dialogue vocal. Avec cette méthode appelée Compréhension Simultanée, les opérations de reconnaissance de la parole, interprétation et réaction se déroulent pendant que le système reçoit l'énoncé. Le système de dialogue ainsi rendu plus “interactif” présente les avantages suivants : l'utilisateur n'a pas à attendre à moins qu'il ne souhaite confirmer le résultat de l'action et, au cas où il constate une erreur de saisie, il peut corriger avant l'accès à la base de données. Nous avons développé deux systèmes de réservation de billets par dialogue vocal en utilisant en procédé de reconnaissance de la parole existant ; le premier système est une application de notre méthode et accepte l'énoncé suivant pendant qu'il analyse le précédent, alors que le deuxième n'accepte l'énoncé suivant qu'après en avoir terminé avec l'analyse du précédent. Il s'est avéré qu'avec le système reposant sur notre méthode, la reconnaissance des expressions est améliorée de 5,4%, et le temps de réaction de 4,7%. Cette méthode semble donc prometteuse dans le domaine des systèmes de dialogue vocal interactifs.
Est-il possible de compenser le mauvais fonctionnement de la sélectivité fréquentielle qui accompagne la perte d'audition d'origine cochléaire en accroissant le contraste spectral du signal acoustique de la parole ? Deux groupes de sujets adultes ont été formés, le premier doté d'une audition normale, le second caractérisé par une perte auditive d'origine cochléaire. Pour chaque groupe, on constate que les taux de reconnaissance décroissent avec l'accroissement des largeurs de bande. Lorsque les largeurs de bandes formantiques sont fixées à la moitié de leurs valeurs normales nominales on observe une tendance vers une meilleure identification dans les deux groupes, mais uniquement pour les consonnes en position finale. Des mesures psychiacoustiques de sélectivité fréquentielle permettent d'appuyer les résultats des tests d'identification obtenus pour les consonnes en position finale. Ces résultats suggèrent qu'en plus des facteurs de résolution réduite en fréquence et de sensibilité globale réduite, il doit y avoir d'autres éléments qui contrôlent l'identification de la parole dans les cas de pertes d'audition d'origine cochléaire, en particulier pour les consonnes en début de syllable. On pourrait en trouver l'origine — non traitée ici — dans une résolution temporelle réduite et dans une susceptibilité croissante à l'effet de masque rétroactif. Les avantages très restreints de la réduction de largeur de bandes formantiques pour l'identification de la parole s'expliqueraient par le fait que cette modification ne peut pas compenser les déficiences du processus temporel auditif.
Cette recherche s'inscrit dans le courant actuel des études psychogénétiques genevoises qui, sans négliger le cadre structural des fonctions cognitives, s'orientent résolument vers l'analyse des processus. Au-delà de l'étude de la macro-genèse des étapes du développement, nous nous intéressons plus particulièrement à la micro-formation des processus de découverte au cours des séances expérimentales. Nous présentons ici un premier exemple de l'ensemble de travaux destinés à rendre compte de l'organisation des séquences d'action orientées vers un but. Notre analyse porte sur 67 enfants de 4;6 à 9;5 ans qui ont à résoudre un problème d'équilibre de plots sur un support étroit. Moins centrée que dans le passé sur l'explication de notions physiques particulières (en l'occurrence le principe de gravité) notre étude porte essentiellement sur l'aspect dynamique de l'interaction entre l'organisation des séquences d'action du sujet et ses théories implicites. Enfin, les résultats suggèrent des analogies de nature fonctionnelle plutôt que structurale entre la formation des connaissances physiques et celle du langage.
En compréhension automatique de la parole, la segmentation de parole continue en composants syntaxiques pose un grand problème. Ces composants sont souvent délimitées par des indices prosodiques. Cependant l'entraı̂nement de modèles d'étiquetage de frontières prosodiques statistiques nécessite de très grandes bases de données. Dans le cadre du projet allemand Verbmobil (traduction automatique de parole à parole), nous avons donc développé une méthode d'étiquetage prosodique–syntaxique de larges corpus de parole spontanée où deux principaux types de frontières (frontières syntaxiques majeures et frontières syntaxiques ambigües) et certaines autres frontières spéciales sont étiquetés. Cette méthode d'étiquetage est présentée et comparée à d'autres méthodes d'étiquetage de frontières basées sur des critères prosodiques perceptifs, syntaxiques, et de dynamique du dialogue. L'un des avantages principaux de la méthode d'étiquetage prosodique–syntaxique présentée dans cet article est la rapidité avec laquelle elle permet d'étiqueter de grandes bases de données. De plus, les classificateurs entraı̂nés avec les étiquettes de frontière produites se révèlent être très performants, les taux de reconnaissance atteignant 96%.
Des contrastes articulatoires simples pour une seule opposition phonologique génèrent une multiplicité d'indices acoustiques. La connaissance des covariations des traits de configurations acoustiques inter- et intra-locuteurs sont nécessaires pour la reconnaissance automatique de la parole. Un modèle des processus de production de la parole a été utilisé pour générer des stimuli suivant un continuum articulatoire : le degré d'abduction des cordes vocales pour les fricatives dans les mots anglais “hiss” et “his”. Les durées de transition imposent de fortes contraintes sur les schémas articulatoires servant d'entrées au modèle. Les durées des segments acoustiques produits par le modèle co-varient de manière semblable à celles produites par 5 locuteurs ; un bon accord quantitatif a été observé dans la plupart des cas. Les réponses des auditeurs indiquent que la dimension articulatoire synthétisée est appropriée à la parole naturelle. Finalement, sont discutées des approches futures pour la modélisation des dimensions articulatoires multiples et pour la mise en correspondance de configurations articulatoires spécifiques au locuteur et leurs perturbation avec la stabilité d'indices acoustiques particuliers.
Cet article décrit une méthode permettant un étiquettage automatique des événements prosodiques de la parole, à partir de l'information fournie par les durées segmentales. Il précise une façon de différencier, à partir des seuls indices de durée, les allongements dus à la prominence de ceux dus à la présence d'une frontière, et expose une anomalie trouvée dans le découpage syntagmatique effectué par 4 locuteurs lisant 200 phrases phonétiquement équilibrées. On décrit un algorithme qui utilise les différences de durée normalisée au niveau syllabique pour détecter les frontières prosodiques dans le signalle de parole. Des tests effectués sur des données de parole lue émanant de 4 locuteurs anglais-britanniques, montrent une forte concordance inter-locuteur en ce qui concerne le nombre de frontières détectées et la longueur des syntagmes délimités par chaque paire de frontière, mais la corrélation inter-locuteur sur la localisation effective des frontières est faible. On observe en particulier une différence nette, entre locuteurs, dans le cas de mots fonctionnels uniques liant deux groupes de mots lexicaux. Ce problème peut être résolu si l'on considère que la frontière est sur la position du mot fonctionnel lui-même plutôt que à gauche ou à droite du mot lexical. Ces résultats semblent montrer qu'il existe, dans ce cas, une certaine liberté dans la localisation des frontières prosodiques, qui peuvent êre déterminées soit par la frontière syntaxique, soit par des critères rythmiques.
Les locuteurs natifs du japonais sont incapables d'identifier correctement les phonèmes /l/ et /r/ de l'anglais. Pourtant, on peut montrer qu'ils sont capables de réagir comme s'ils étaient sensibles aux gestes articulatoires différents qui sont nécessaires pour produire /l/ et /r/. Dans une étude, des locuteurs natifs du japonais et des locuteurs natifs de l'anglais devaient classer des stimuli le long d'un continuum /da/-/ga/ lorsque le stimulus était précédé par des occurrences naturelles de /s/ ou /∫/, de /al/ ou /ar/. Chaque paire de “prédécesseurs” avait des effets différents sur l'emplacement de la frontière catégorielle entre /da/ et /ga/, et ni la direction ni l'étendue de l'effet ne dépendait de l'expérience linguistique. De manière intéressante, /al/ donnait naissance à plus de percepts de /ga/ que /ar/, à la fois pour les locuteurs japonais et anglais, indépendamment de leur aptitude à identifier /al/ et /ar/ en tant que tels. L'interprétation des résultats repose sur des observations plus anciennes selon lesquelles les effets perceptuellement contrastifs de /al/ vs. /ar/ et de /s/ vs. /∫/ ont un correspondant dans la structure acoustique des énoncés naturels de /al-da/, /ar-da/, etc. du fait de la co-articulation du geste qui produit la consonne qui précède et de celui qui produit le /ga/ ou /da/ suivant. Il semblerait que les locuteurs natifs du japonais soient sensibles aux conséquences acoustiques de la co-articulation de /l/ ou /r/ avec /d/ ou /g/, alors qu'ils sont incapables de catégoriser /l/ et /r/ en tant que phonèmes distincts. Il se pourrait donc qu'il existe, en deçà du niveau de perception propre au langage dans lequel les sons linguistiques sont représentés conformément aux contraintes d'un système phonologique, un niveau universellement partagé où la représentation des sons linguistiques correspond de plus près aux gestes articulatoires qui donnent naissance au signal linguistique.
Nous présentons une évaluation d'un modèle de contrôle de la production de la parole exploitant la notion de cible, fondé sur l'Hypothèse du Point d'Équilibre de Feldman. Elle consiste en des simulations, avec un modèle biomécanique bi-dimensionnel de la langue, de mouvements articulatoires lors de transitions vocaliques. Dans le modèle, les principaux muscles agissant sur la forme de la langue dans le plan sagittal sont représentés. La méthode des éléments finis modélise les propriétes élastiques de l'articulateur, et les principes de génération de force sont conformes aux Caractéristiques Invariantes Force-Longueur non linéaires de Feldman. Le mouvement est produit en déplaçant les variables de contrôle à vitesse constante pour chacune des transitions. Les contours externes de la langue sont ajustés pour correspondre aux données radiographiques acquises sur un locuteur français, et le modèle est placé à l'intérieur des contours fixes du conduit vocal de ce locuteur. Nous insistons sur le caractère réaliste des trajectoires formantiques synthétisées, et sur le rôle potentiel des propriétés biomécaniques de la langue sur les caractéristiques cinématiques mesurables.
Cet article présente un panorama rapide des travaux de recherche en technologie de la parole téléphonique menée chez les Opérateurs de Télécommunication européens.
Des études précedentes (Pind, 1986, 1995a) ont mis en évidence que le rapport de durée voyelle sur rime (voyelle + consonne) sert d'invariant d'ordre supérieur pour l'auditeur en lui permettant de distinguer les transformations de durée qui sont dues à des variations de débit de celles qui impliquent un changement de quantité phonémique. Pour que l'auditeur puisse calculer ce rapport, il faut que les deux segments soient présents dans le signal acoustique. Dans cet article, on décrit deux expériences perceptives où de la parole naturelle a été manipulée, de manière à ce qu'une fermeture à la suite de la voyelle soit audible ou non (dans le dernier cas la fermeture n'est pas relâchée). Les résultats soutienment l'hypothèse que le contexte a un effect plus grand sur la localisation de frontières entre phonémes pour la quantité vocalique dans les syllables non relâchées parce que dans ce cas l'auditeur ne peut pas calculer le rapport de voyelle sur rime.
Une expérience a été réalisée dans laquelle divers modèles à deux formants, proposés dans la littérature, sont évalués en fonction de leur capacité de prédire les fréquences formantiques obtenues lors d'une tâche d'identification de voyelles. Un modèle concurrent est proposé dans lequel le traitemenauditif des voyelles est supposé intervenir en deux étapes. A l'étape périphérique, le spectre de parole est transformé en son correspondant auditif et les fréquences formantiques sont extraites par une procédure de détection de pics. L'étape centrale effectuee une approximation à deux formants sur la sortie fournie par le traitement précédent ; l'identification de la voyelle s'appuie sur la paire de formants ainsi extraite. Les première et secondes fréquences formantiques de ce modèle sont obtenues en additionant un terme correctif aux fréquences des deux premiers formants extraits lors de la première phase. Ce terme correctif est inverément proportionnel à la distance séparant les formants principaux des formants voisins. Confronté aux modèles antérieurs, le nôtre se comporte avantage usement quant à la prédiction des fréquences formantiques obtenues dans une tâche d'identification de voyelles.
Cet article traite principalement du choix d'un critère pour évaluer l'efficacité d'un système de reconnaissance de mots enchaînes, lorsque l'on utilise la programmation dynamique pour quantifier les correspondances entre suites de mots. Certaines propriétés de l'évaluation par la méthode de programmation dynamique sont analysées. Des expériences menées avec des données du DARPA Research Management Task ont confirmé les prédictions faites à partir de simulations avec des nombres aléatoires : l'évaluation par programmation dynamique surestime le nombre d'erreurs de substitution et sous estime le nombre d'erreurs d'insertion et d'omission. Le biais du critère habituellement utilisé, le nombre total d'erreurs, est en conséquence particulièrement grand. Un autre critère, le pourcentage de mots reconnus, diminue ce biais mais ne tient pas compte des erreurs d'insertion. Un nouveau critère, le nombre total des erreurs pondérées, tient compte des trois types d'erreurs et minimise le biais. Enfin, certains critères d'évaluation plus sophistiqués sont abordés.
La résolution de processus décisionnels de Markov (PDMs) de grande dimension est habituellement basée sur le calcul hors-ligne d'une approximation de la fonction de valeur optimale et sur son exploitation en ligne pour définir une politique gloutonne. Dans cet article, nous proposons une méthode alternative reposant sur le développement en chaque état courant d'un arbre de recherche construit à partir de la simulation stochastique du PDM sur un certain horizon de raisonnement. Nous montrons expérimentalement son bon comportement anytime sur un problème de navigation modélisé comme un plus court chemin stochastique.
La méthode présentée dans cet article, constitue un nouvel outil d'extraction des contours d'une image en niveaux de gris, par coopération de techniques : décomposition en ondelettes et réseaux neuromimétiques. La première partie est consacrée aux rappels nécessaires quant au formalisme de la décomposition en ondelettes, ainsi que ses principales propriétés. La phase délicate de l'algorithme réside dans la recomposition optimale des différentes résolutions, afin d'obtenir des contours fins et sans bruit. Cette tâche est avantageusement confiée à un réseau de neurones, objet de la deuxième partie. L'attrait majeur de cette nouvelle technique, est sa capacité à traiter correctement des images aux caractéristiques très différentes, sans avoir à modifier de paramètres.
Cet article explique comment l'information visuelle sur le mouvement des lèvres et l'information acoustique du signal de parole peuvent être combinées pour segmenter le flux de parole. On rapelle les aspects psychologiques de la lecture labiale ainsi que l'état actuel des systèmes automatiques dans ce domaine. Cet article décrit un système de traitement d'image qui peut déduire la vitesse du mouvement des lèvres à partir de séquences d'images. La vélocité des lèvres est estimée par une combinaison de techniques d'analyse morphologique des images et de comparaison par blocs. Cette vélocité calculée est utilisée pour localiser la frontière des syllabes. Cette information est particulièrement utile quand le signal de parole est bruité. Cet article démontre également la corrélation qui existe entre le signal de parole et l'information fournie par les lèvres. Des techniques de fusion de données sont utilisées pour combiner les informations acoustiques et visuelles pour la segmentation de la parole. Les principaux résultats montrent que cette combinaision des informations visuelles et acoustiques peut réduire les erreurs de segmentation de 10.4% au moins quand le rapport signal sur bruit est inférieur à 15 dB.
Dans le cadre d'un décodeur acoustique-phonétique hybride (ANN/HMM), trois réseaux de neurones (ANNs) spécialisés ont été développés et évalués. Un de ces ANNs détecte le mode d'articulation. Les deux autres ANNs décrivent le signal en termes du lieu d'articulation. Le design de ces réseaux est inspiré par des connaissances acoustiques et phonétiques. Les entrées, la topologie et le codage des sorties ont été optimisés pour chacun des réseaux. Ceux-ci sont évalués sur la base de données TIMIT. Les erreurs de classification trame par trame sur un test de 77 locuteurs indépendants sont de 17.7% pour les 5 modes d'articulation, de 25.4% pour les consonnes nasales et plosives (10 phonèmes) et de 25.2% pour les consonnes fricatives (11 phonèmes). On évalue aussi la performance d'un système hybride ANN/HMM, pour lequel a été développé un algorithme d'optimisation globale de tous les paramètres. Le réseau dédié au mode d'articulation et un réseau dédié au lieu d'articulation ont été unis dans un seul ANN. Les sorties de ce nouveau réseau sont modélisées par un HMM. Ce système hybride atteint un taux d'erreur de 14% pour la reconnaissance en parole continue de 8 classes de phonèmes (7 plosives et une classe représentant tous les autres phonémes).
Dans cet article, nous présentons une nouvelle méthode pour sélectionner les variables les plus pertinentes à mettre en entrée d'un réseau de neurones de type Multi-Layer Perceptron (MLP) ou Radial Basis Function (RBF). Cette méthode repose sur l'analyse statistique des dérivées des sorties du réseau par rapport aux entrées. Lorsque toutes les dérivées des sorties par rapport à une entrée donnée peuvent statistiquement être considérées comme nulle, l'influence de l'entrée en question est négligeable et cette entrée pourra donc être éliminée. Les résultats seront présentés sur diverses séries temporelles simulées ou réelles.
Cette étude apporte une contribution à la classification de textures à l'appui de signatures déduites des corrélations et/ou spectres d'ordre élevé. La première partie montre que les textures ont pour la plupart une statistique non gaussienne, bien représentée à l'ordre trois. Les tests de normalité choisis, les tests d'asymétrie et du Kurtosis, ont été calibrés dans cette étude. Pour limiter la complexité calculatoire et obtenir de faibles variances d'estimation, nous nous sommes orientés vers des attributs fondés sur les corrélations d'ordre trois dans un cadre stationnaire : la bicorrélation, le bispectre et le bicorspectre. Nous avons opté pour une stratégie 2D séparable. Nous proposons dans une seconde partie une caractérisation fondée sur des représentations décrivant les corrélations spatiales d'ordre trois. La dernière partie est consacrée à la classification des textures s'appuyant sur les attributs précédents. Nous donnons des performances de discrimination sur neuf textures de Brodatz, en comparant avec les résultats des paramètres, extraits de matrices de cooccurrences, proposés par Haralick.
Jusqu'à ce jour la plupart des théories sur l'aptitude à la lecture n'ont proposé qu'un seul facteur en tant que source essentielle des différences individuelles. L'accord sur le facteur a été faible et parmi les principaux candidats proposés on trouve la discrimination visuelle, le recodage phonologique et sémantique, la mémoire à court terme et l'utilisation du contexte linguistique. Dans cet article on résume les théories à un seul facteur et on passe en revue la littérature pour montrer qu'aucune théorie à un seul facteur ne peut être adéquate. La réussite en lecture estcorrellée à de multiples savoir-faire. On conclut à la nécessité d'un modéle complexe multifactoriel et on présente certains essais récents pour rassembler les données contribuant à un tel modèls. Deux méthodes d'analyse des savoir-faire sont présentées et on recommande de les utiliser dans des opérations convergentes. Enfin on utilise les résultats de l'analyse des savoir-faire pour proposer un premier exemple d'une classe de modèles hiérarchiques de la capacité de lecture qui peut être étudié de façon developmentale.
Les travaux d'avant-garde de Chistovich et de ses collègues se sont servis de la tâche de répétition (shadowing) pour étudier le traitement immédiat de la parole. Ce faisant ils ont exploité le phénomène de répétition instantanée durant lequel le délai entre l'audition et la répétition du stimulus est réduit à 250 ms ou moins. La recherche ici décrite a débuté par étendre les découvertes de Chistovich à la répétition instantanée de la prose continue. 25% de nos sujets féminins furent capables de répéter avec précision de la prose continue avec des délais moyens de 250 à 300 ms. Les autres sujets féminins et tous les hommes testés manifestèrent des latences plus longues atteignant en moyenne plus de 500 ms. Ces sujets sont dénommés des répétiteurs distants. La seconde série d'expériences permit d'établir que les deux catégories de sujets procédaient à une analyse syntaxique et sémantique du matériau verbal pendant qu'ils le répétaient. Ceci est manifesté par les contraintes s'exerçant sur leurs erreurs spontanées et dans leur sensibilité aux ruptures de la structure syntaxique et sémantique du matériau verbal en cours de répétition. Une troisième série d'expériences a montré que la différence entre répétiteurs immédiats et distants résidait dans leur stratégie d'expression. Les premiers sont capables d'utiliser les résultats de leur analyse en temps réel pour diriger leur appareil articulatoire avant même d'être plenement conscients de ce que sont ces résultats. Ceci signifie que la répétition immédiate, non seulement reflète de manière continue le résultat du processus de compréhension du langage mais également y parvient en n'étant que relativement peu affecté par les processus post-perceptifs. En ce sens, donc, la répétition immédiate nous fournit un accès singulièrement privilégié aux propriétés du système.
Les nouveaux développements en matière d'intelligence artificielle ont modifié les suppositions de base sur lesquelles le progrès de la planification de l'usinage assistée par ordinateur (modelage et méthodologies) était fondé pendant les 30 dernières années. Les calculs numériques représentent donc dans certains cas des alternatives moins bonnes pour les modèles qualitatifs et/ou semi-quantitatifs ainsi que pour les procédés basés et utilisant des sources scientifiques à fondement plus large. Cet article montre comment le développement et la conception des processus ainsi que la planification, la commande, la surveillance, l'analyse et le contrôle des activités de processus peuvent profiter des schémas de représentation scientifique améliorés et des stratégies de contrôle modernes résonnables. Il est aussi argumenté que le défi central qui résulte des progrès accomplis dans le développement d'une intelligence artificielle est un “modelage des connaissances”, c'est-à-dire un modelage : (a) des phénomènes physiques et des systèmes dans lesquels ils se déroulent ; (b) des systimès de traitement et de transformation des informations ; et (c) des stratégies qui résolvent les problèmes lors de la planification, de l'exploitation et du contrôle. C'est pourquoi les diverses strategies d'argumentation exigent diverses forrnes de savoir explicatif et le succés ou l'échec de diverses planifications d'ébauches, de diagnostics et de systèmes de contrôle dépent de l'étendue du savoir réellement utile. Cet article represents également l'étendue théorique d'importants apports par l'intelligence artificielle ainsi que leurs répercussions sur la formulation et la solution apportées aux problèmes de la planification de la production dans le passé et à l'avenir.
Ce modèle s'appui sur la construction d'un arbre minimal, ses propriétés sont étudiées à travers le problème de la reconnaissance de symboles complexes. L'invariance de la reconnaissance - face aux translations et rotations de symboles dégradés - est vérifiée dans un contexte d'images binaires à faible résolution. Si les résultats sont concluant, le coût algorithmique peut être assez élevé. Une alternative consiste à exprimer l'objet cible dans l'espace Cosinus Discret (Transformation en Cosinus Discrète). La technique opère non plus dans l'espace image mais dans un espace compact où les données sont mieux décorrélées. Certains de nos choix font référence à des concepts de compression d'images. Ces résultats sont d'abord observés lors d'une expérience élémentaire puis confirmés par un test à moyenne échelle, mettant en jeu 500 symboles issus de la base de données Graphics Recognition - GREC2003.
Le livre soulève plusieurs interrogations sur la notion même de ponctuation qui y est développée. Ce compte-rendu critique attire l'attention sur quelques confusions relevées dans certaines contributions. Il propose en outre une contre-étude sur un problème paléographique concernant le point d'interrogation et enfin, parce que le terme « ponctuation » semble avoir été employé dans un sens trop large, souhaite apporter des nuances à ce qui apparaît comme une dérive terminologique.
Cet article décrit un algorithme de suivi automatique de formants intégrant des connaissances de parole. Il opère en deuxé tapes. La première détecte et interprète les lignes de pics du spectrogramme en termes de formants. La seconde utilise une méthode d'extraction des contours d'une image pour régulariser les lignes de pics détectés à la premiére étape. Des connaissances sur la parole servent de contraintes pour guider l'interprétation des lignes de pics. L'algorithme proposé a l'avantage de fournir des trajectoires formantiques, qui en plus d'être suffisamment proches des pics spectraux correspondant aux formants, sont suffisamment lisses pour permettre une évaluation précise des transitions formantiques. Les résultats obtenus montrent l'intérêt de l'approche proposée.
Il existe un point de vue selon lequel des processus fondamentaux différents sont impliqués dans la reconnaissance des mots pour la parole et l'écriture. Nous soutenons que ce point de vue est infondé, et que les modéles de l'accés lexical mis au point pour l'écriture sont aussi appropriés pour la parole, compte tenu des différences évidentes dues aux propiétés physiques des signaux de la parole. Un accent particulier est mis sur le rôle de la fréquence des mots dans le processus de reconnaissance, car cela limite les types de modéles à prendre en considération (par exemple, le modéle de la cohorte). Nous rejetons le point de vue selon lequel il n'existe pas d'effects de fréquence dans la reconnaissance des mots parlés, et nous rejetons aussi le point de vue selon lequel les effets de fréquence dans la reconnaissance des mots écrits ne sont que le reflet de décisions post-accès lexical.
Nous présentons un problème de caractérisation issu de la biologie végétale. Ce problème de caractérisation multiple consiste à traiter simultanément plusieurs groupes d'entités (représentées par des interprétations booléennes) et à trouver une caractérisation pour chacun d'eux sous forme de formules booléennes. Cette caractérisation doit être exacte et une des difficultés majeures est de trouver une caractérisation minimale. Une étude de complexité de ce problème est réalisée et nous arrivons à la conclusion que le problème est W[2]-Complet. Nous proposons une reformulation du problème en programmation linéaire ainsi que différentes approches de résolutions. Une étude expérimentale est réalisée sur des instances aléatoires ainsi que des instances réelles.
Nous décrivons une méthode permettant de déterminer la fréquence fondamentale de la parole voisée. Cette méthode exploite la structure harmonique du spectre à court terme afin de construire un 'histogramme harmonique'. La hauteur détectée est celle de la fréquence de la composante la plus importante. L'examen des histogrammes pondérés en échelles linéaire et logarithmique montre que ce sont ces derniers qui fournissent la meilleure indication de la hauteur. Les spectres sont dérivés à partir d'un banc de filtres digitaux comprenant 187 canaux se situant entre 50 Hz et 3200 Hz (échelle log). En tronquant les spectres à leur extrémité basse fréquence, il apparaît que l'on peut encore obtenir une indication claire de la hauteur dans la bande téléphonique de 200 Hz à 3200 Hz. L'influence du F1 de certaines voyelles sur les amplitudes des harmoniques perturbe l'indication correcte de la hauteur. Une méthode de 'renforcement harmonique' est proposée qui permet effectivement de surmonter cette difficulté. Des exemples de contours mélodiques obtenus par cette méthode montrent que la hauteur peut être déterminée avec succès pour des nasales, des voyelles et des fricatives voisées.
Nous présentons le premier formalisme de recherche heuristique permettant de résoudre les POMDPs décentralisés (DEC-POMDP). Nous présentons ici une nouvelle classe d'algorithmes qui fait le lien entre les méthodes de recherche heuristique classiques et la théorie du contrôle décentralisé. Nous prouvons l'optimalité de ce formalisme dans le cadre des politiques déterministes, et nous évaluons sa performance sur quelques exemples d'applications répandus dans le domaine du contrôle décentralisé.
Les réseaux de microphones (ou antennes acoustiques) peuvent être un moyen efficace pour combattre les dégradations dues au bruit et à la réverbération dans les terminaux de communication mains-libres. Dans cet article, nous discutons de la formation de voie classique retard-somme, ainsi que de la formation de voie filtrage-somme, plus générale. Cette dernière possède la capacité supplémentaire de contrôler le diagramme de directivité du réseau en fonction de la fréquence, et une nouvelle méthode de conception pour les réseaux à largeur de lobe constante est présentée. Les réseaux à formations de voie retard-somme et filtrage-somme doivent posséder des dimensions comparables aux longueurs d'onde. Cette caractéristique peut conduire à des dispositifs de grande taille. Pour les applications où on dispose de peu d'espace, nous présentons des réseaux de microphones différentiels. Finalement, deux types de systèmes adaptatifs de formation de voie sont présentés : un réseau en configuration “broadside” et un microphone différentiel à deux éléments.
Nous décrivons des expériences dans le domaine de la conversion de la voix qui utilisent des paramètres acoustiques provenant de la voix de deux individus (source et cible). Des transformations sont faites sur les paramètres de la source afin de les faire coïncider autant que possible avec ceux de la cible. Le signal de parole des deux individus et celui obtenu après transformation sont synthétisés et comparés au signal original. Le but de cette recherche est de développer un modèle pour (1) créer de nouvelles voix synthétiques, (2) étudier les facteurs responsables de la qualité des voix synthétiques, et (3) déterminer des méthodes pour la normalisation de la voix de différents individus.
A cause des énormes quantités de règles qui peuvent être produites par les algorithmes d'extraction, la validation des connaissances reste l'une des étapes les plus problématiques de la découverte de règles d'association. Il est nécessaire d'aider l'utilisateur à s'approprier ce volume de règles et de l'assister dans sa recherche de la connaissance pertinente en organisant une véritable fouille de règles. Pour cela, les techniques de réalité virtuelle, qui associent une interactivité forte et intuitive à des représentations 3D immersives capables d'intégrer une grande densité d'information tout en demeurant intelligibles, peuvent s'avérer très profitables. Nous proposons dans cet article une représentation graphique dynamique des règles d'association, fondée sur des métaphores en réalité virtuelle, qui supporte l'utilisateur dans sa tâche de fouille interactive de règles. Un premier prototype implémentant cette nouvelle représentation a été développé afin de valider notre approche.
Dans cet article, nous proposons une nouvelle méthode de détection de mots-clés basée sur des mesures de confiance et les machines à vecteur support (SVM). Les mesures de confiance sont calculées à l'aide des probabilités a posteriori des phonèmes fournies par un système de reconnaissance basé sur les modèles de Markov cachés. Nous présentons trois types de moyennes (arithmétique, géométrique et harmonique) pour calculer une mesure de confiance pour chaque mot. Nous proposons également l'utilisation des machines à vecteur support qui constituent une technique de classification développée à partir de la théorie de minimisation du risque structurel. La décision d'accepter/rejeter un mot est basée sur le vecteur de mesures de confiance qui est l'entrée du classifieur SVM. Les performances du classifieur SVM proposé sont comparées à celles obtenues par les différentes méthodes basées sur les mesures de confiance à base de moyenne.
Les polynômes qui n'ont que des racines à partie réelle négative et ceux qui n'ont que des racines à l'intérieur du cercle unité peuvent être caractérisés de différentes manières. Les critères fondés sur l'introduction d'une paire de polynômes dont les racines alternent sur l'axe des imaginaires ou sur le cercle unité sont étendus aux polynômes à coefficients complexes. Un algorithme de calcul pour tester les polynômes à coefficients réels ou complexes admettant toutes leurs racines dans un demi-plan donné, ou dans un secteur du plan délimité par deux demi-droites passant par l'origine, est établi. Une démonstration complète du critère de Routh pour tester la stabilité des filtres linéaires à temps continu et à coefficients réels ou complexes est proposée.
“Contour” et “trajectoire” sont devenus des termes familiers qui, pour toute voyelle, servent à décrire, sur l'axe des temps, l'évolution des fréquences propres à chacun des formants. Par contre, il y aurait lieu d'établir des vocables analogues permettant de préciser le profil de ces fréquences sur “l'axe des voyelles”. On introduit, donc, le concept de vowel-formant ensemble (et l'acronyme VFE qui en découle) afin de pouvoir regrouper, de voyelle à voyelle, les fréquences d'un formant (e.g., F2) qui sont obtenues, à un instant fixe de l'axe des temps, pour le même locuteur et dans le même contexte syllabique CVC. Notons que le concept de VFE contient à lui seul toute la démarche adoptée ici, à savoir que notre modélisation précédente des trajectoires des formants (Broad et Clermont, J. Acoust. Soc. Am. 81, 1987, 155–165) repose sur une fonction linéaire de la cible des voyelles et, de ce fait, suggère l'hypothèse que des relations linéaires devraient aussi servir à caractériser les VFEs propres à un locuteur et chacun des formants à la fois. On aborde cette question pour les fréquences des formants F1 et F2 de 7 voyelles de l'anglais australien qui ont été prononcées par un locuteur masculin, 5 fois de suite, dans 7 contextes syllabiques du type CVd. Nonobstant les variations aléatoires inhérentes aux 5 répétitions, l'application de notre hypothèse aux voyelles en question engendre un écart quadratique moyen qui ne dépasse pas la valeur, remarquablement faible, de 14 Hz pour F1 et F2. Les relations linéaires ainsi obtenues se prêtent à une normalisation par rapport au facteur contexte, que l'on démontre par une réduction de la dispersion intra-voyelle dans l'espace planaire F1F2. Les relations dérivées du concept de VFE constituent également un nouvel outil devant permettre la mise en évidence des effets de différents contextes au travers des noyaux vocaliques de syllabes.
Le signal de parole produit par deux locuteurs a été segmenté manuellement, donnant lieu à deux based de données comprenant 18,000 et 6,000 segments vocaliques.
Suite à l'abondance des textes spécialisés, une demande accrue de leur traitement automatique est souhaitée. L'extraction terminologique, c-à-d. l'extraction de groupes de mots significatifs pour le domaine, est une information communément recherchée dans tes domaines spécialisés. Dans cet article, nous proposons une méthode d'extraction automatique des termes spécifiques. Dans notre approche, nous avons en entrée un corpus spécialisé à partir duquel nous effectuons des traitements préliminaires : nettoyage et étiquetage. Lorsque ces prétraitements sont effectués, nous nous appuyons sur des mesures d'association classiques pour extraire la terminologie du domaine. Notre principale contribution est le fait d'ajouter différents paramètres afin d'améliorer la recherche des termes du domaine.
Nous explorons des méthodes d'amélioration de la parole altérée par un bruit additif indépendant avec une source unique. Nous présentons des systèmes d'amélioration adaptative basés sur une technique non-adaptative [Ephraim, Y., 19992a. IEEE Transactions on Signal Processing 40 (4), 725–735]. Cette approche permet de construire des modèles statistiques de la parole et du bruit en utilisant des modèles de Markov cachés auto-regressifs. Nous développons deux méthodes principales. La première méthode estime les modèles statistiques du bruit à partir des silences détectés. La deuxième crée des estimations du maximum de vraisemblance des paramètres du bruit inconnu en utilisant l'ensemble de la phrase. Les deux techniques opèrent sur un schéma auto-regressive hidden Markov models (AR-HMM). Nous avons montré précédemment que les possibilités des AR-HMMs pour modéliser la parole pouvaient être améliorées en incorporant une fréquence de perception utilisant une transformée bilinéaire. Nous introduisons cette correction dans nos systèmes d'amélioration de la parole. Nos approches sont évaluées sur les bases de données NOISEX-92 et Resource Management, en donnant des indications de la performance respectivement sur des taches simples et complexes. Les deux schémas permettent d'améliorer les résultats de base. La technique qui crée des estimations ML des paramètres du bruit apparaît être la plus efficace. Son efficacité est évaluée sur une large variété de bruits allant de −6 dB à 18 dB et sur divers types de bruit stationnaires réels.
Une nouvelle méthode d'analyse de la parole qui utilise plusieurs concepts psychoacoustiques bien établis, est appliquée à l'analyse des voyelles. Cette analyse par prédiction linéaire perceptivement fondée (PLP), modélise le spectre auditif par celui d'un modéle tout pôle d'ordre réduit. Le spectre auditif est dérivé de l'onde de parole par filtrage en bandes critiques, pré-accentuation par courbes d'égale sonie, et conversion d'intensité en sonie par extraction de racine (loi de puissance de Steven). Analysant la parole tant naturelle que synthétique, nous démontrons que les concepts psychoacoustiques d'intégration auditive du spectre s'appliquant aux voyelles, notamment le concept F1, F2′ de Carlson et Fant et le concept de Chistovich d'intégration auditive de 3.5 Barks sont bien modélisés par la méthode PLP. Un système complet d'analyse-synthèse, basé sur la méthode PLP, est également décrit dans cet article.
Ce papier présente les évaluations, sur des données d'exploitation (terrain), de deux serveurs d'information qui utilisent des technologies vocales et des interfaces homme–machine différentes. Le premier système, RAILTEL, utilise la reconnaissance de mots isolés et un dialogue contraint. Le second système, Dialogos, comprend la parole spontanée et implante une stratégie de dialogue avec initiative mixte. Les deux systèmes permettent l'accès à une base de données italienne d'horaires de trains à travers le réseau téléphonique publique. RAILTEL et Dialogos ont été testés par des utilisateurs non expérimentés dans de larges essais terrain. De plus, des essais comparatifs sur un nombre limité d'usagers ont été effectués afin d'évaluer l'impact des différentes technologies vocales sur le comportement des utilisateurs.
Nous avons proposé un ensemble de caractéristiques de ces règles et une classification : « directes » et de « modulation » . Pour pouvoir traiter de telles règles dans les systèmes hybrides, nous nous sommes inspirés des connexions présynaptiques étudiées en neurobiologie, qui permettent des traitements du type modulation. L'équivalent de ces connexions synaptiques dans les systèmes connexionnistes est constitué par les connexions Sigma-Pi. Nous avons proposé un nouveau type de connexion neuronale : les unités Sigma-Pi Asymétriques, lesquelles représentent le mieux les processus de modulation entre certaines entrées d'un réseau neuronal. Ces connexions ont été implémentées dans un SHNS pour l'apprentissage de bases d'exemples contenant des relations de modulation.
Cette étude concerne l'adaptation à de nouvelles langues, à partir de peu de données d'apprentissage, d'un système d'identification de langue déjà existant. La plate-forme utilisée dans cette étude est le système récemment développé pour exploiter les contraintes phonotactiques basées sur une reconnaissance de phones dépendante de la langue (Yan and Barnard 1995a, b). En utilisant la technique de ré-estimation du modèle de langage basée sur la descente de gradient probabiliste, deux nouvelles approches, ainsi que leur combinaison, sont proposées et testées. Toutes ces approches modifient les modèles de langage phonotactiques, et ne correspondent donc plus à l'estimation conventionnelle de maximum de probabilité. La spécificité de ces méthodes peut être vue comme une ré-estimation différente de l'information sur le même ensemble de données. Des expériences ont été menées en utilisant la base de données standard OGI_TS (Muthusamy et al., 1992). Le système de base (avec l'estimation conventionnelle des données) a également été soumis au même ensemble de tests, pour comparaison. Les systèmes, entraı̂nés avec diverses quantités de données d'apprentissage dans les nouvelles langues, ont été évalués. Les résultats montrent que les nouvelles méthodes améliorent l'adaptation à de nouvelles langues, par rapport à l'estimation des modèles conventionnelle. Le succès du modèle discriminant montre que l'estimation de modèle conventionnelle n'est pas optimale pour l'identification de langue, et donc que des améliorations peuvent être obtenues en modifiant les estimations de maximum de probabilité des modèles de langage.
Cet article fournit des données phonético-acoustiques sur trois styles langagiers : la parole conversationnelle informelle, la parole “claire” et le “baby-talk”. Ces ensembles d'observations illustrent le fait que la prononciation par un locuteur d'une forme linguistique donnée peut subir de fortes transformations physiques, particulièrement dans la grande variété de contextes qu'offre la parole produite spontanément. En dépit de leurs variations extensives, les mesures des formants vocaliques montrent un haut degré de prédictibilité. Les observations mettent au premier plan une question classique de la recherche en parole : la variabilité du signal et l'invariance phonétique. Bien que les résultats présents n'éliminent pas définitivement la possibilité que les échantillons de parole analysés soient organisés autour d'un noyau d'invariants du signal, l'ampleur aussi bien que la caractére systématique de la variabilité observée ouvrent une perspective différente. L'article propose que les patrons acoustiques dispersés de la parole soient considérés comme des produits de l'adaptation. Selon cette interprétation, les gestes phonétiques et les signaux sont modulés adaptivement en fonction des besoins de la communication en temps réel et de la situation socio-linguistique (par exemple, en contrôllant la “distance sociale” entre les locuteurs, en préservant l'intelligibilité, en utilisant les fonctions “phatique” et “émotive”, etc.). De plus, il est argué linguistique du signal phonétique n'est pas d'encoder des invariants mais de compléter l'information déjá disponible par le systéme de traitement de la parole du locuteur. Ainsi, les variations phonétiques intra-locuteurs ne doivent plus être considérées comme des invariants enchâssés dans une variabilité linguistiquement non pertinente. Elles représentent plutôt de réelles adaptations comportementales qui peuvent mettre en danger ou détruire l'invariance du signal mais qui transforment les patrons de parole selon des voies qui relèvent essentiellement de principes.
Les deux principaux instruments utilisés comme capteurs de perception en robotique sous-marine sont le sonar et la vidéo. Dans une première partie, nous présentons les principes utilisés en imagerie acoustique. Si certaines techniques sont classiques, d'autres, telles que l'antenne synthétique, l'interférométrie et l'antenne paramétrique sont encore du domaine de la recherche appliquée. Dans une seconde partie, les applications de l'imagerie acoustique sont évoquées. Elles sont essentiellement axées sur la caractérisation des fonds sous-marins et sur l'aide que l'image peut apporter à la navigation du robot. Enfin, la troisième partie évoque les technologies et les traitements vidéo. Ce capteur s'avère très complémentaire du sonar grâce à sa haute résolution et à la facilité d'interprétation des images.
Cet article traite le cas de l'inversion articulatoire acoustique en production de la parole. On propose un cadre d'analyse fondé sur une combinaison explicite des contraintes morphologiques et acoustiques du conduit vocal. La solution se base sur une analyse de Fourier du logarithme de la fonction d'aire du conduit vocal : le rapport entre les coefficients de Fourier en cosinus du logarithme de l'aire et les formants correspondants est utilisé pour formuler une contrainte acoustique. Le même jeu de coefficients est alors utilisé pour obtenir une contrainte morphologique. Cette représentation des contraintes acoustiques et morphologiques dans le même espace des paramètres permet une résolution efficace du problème inverse. Le principe de la formulation de la contrainte acoustique a été proposé pour la première fois par Mermelstein (1967). Cependant, la combinaison avec les contraintes morphologiques n'a pas été réalisée dans le cadre de ce travail. La méthode est testée pour quelques voyelles. Les résultats confirment la validité du modèle, mais montrent aussi la nécessité d'inclure des contraintes dynamiques.
On s'intéresse aux problèmes inverses sous déterminés, et plus particulièrement à la localisation de sources en magnéto et électro-encéphalographie (M/EEG). Bien que l'on ait à disposition un modèle physique de la diffusion (ou du « mélange » ) des sources, le caractère très sous-déterminé de ces problèmes rend l'inversion difficile. La nécessité de trouver des a priori forts et pertinents physiquement sur les sources est une des difficultés. Dans le cadre du problème inverse de la M/EEG, la parcimonie classique mesurée par une norme l\ n'est pas suffisante, et donne des résultats non réalistes. On propose ici de prendre en compte une parcimonie structurée grâce à l'utilisation de normes mixtes - notamment d'une norme mixte sur trois niveaux. La méthode est utilisée sur des signaux MEG issus d'expériences de stimulation somesthésique. Lorsqu'ils sont stimulés, les différents doigts de la main activent des régions distinctes du cortex sensoriel primaire. L'utilisation d'une norme mixte à trois niveaux permet d'injecter cet a priori dans le problème inverse et ainsi de retrouver la bonne organisation corticale des zones actives. Nous montrons également que la méthode la plus classiquement utilisée dans le domaine échoue dans cette tâche.
Le problème de séparation de sources, très classique en traitement du signal, correspond aussi à une réalité dans les systèmes biologiques. En effet, les capteurs biologiques sont sensibles à de multiples sources, le système nerveux central traite donc des signaux multi-capteurs dont chaque composante est un mélange inconnu de sources inconnues, supposées indépendantes. Par rapport aux règles utilisées en filtrage adaptatif, l'incrément d'adaptation fait intervenir nécessairement le produit de deux fonctions non linéaires. Plusieurs résultats expérimentaux dans le domaine du Traitement du Signal ou du Traitement d'images illustrent les performances de l'algorithme. La généralisation à des mélanges plus complexes, ou dégénérés est également discutée et illustrée. Cet algorithme révèle aussi un nouveau concept d'Analyse en Composantes Indépendantes, plus fort que celui d'Analyse en Composantes Principales, applicable dans le cadre général de l'analyse de données.
Dans cet article, nous proposons une méthode originale de détection et de correction des erreurs d'accord, que nous appliquons au cas de l'arabe. La détection se base sur une analyse syntaxique globale de la phrase. Il s'agit d'une « analyse syntagmatique étendue » qui permet, dans un premier temps, de localiser les frontières syntagmatiques et de regrouper, dans un deuxième temps, tous les éléments de la phrase qui ont un lien d'accord entre eux. La correction des erreurs détectées se base sur une méthode d'analyse multicritère permettant le classement des scénarios de correction en vue d'en faire émerger le meilleur. Cette méthode a l'avantage de réduire, d'emblée, les scénarios dominés, et de classer le reste selon différents critères d'évaluation.
Les trajectoires articulatoires de la fricative [s] produite par un locuteur féminin parlant l'anglais américain général ont été analysées dans la parole continue et dans des séquences logatomiques phonétiquement contrôlées et articulées à un débit plus lent. Les traces dérivées aérodynamiquement indiquant le paramètre acoustiquement pertinent de l'aire de section de la région de constriction du conduit vocal suggérent que, contrairement aux données rapportées pour les mouvements des structures solides, certaines portions des traces pour cet indicateur du conduit vocal ont la même forme de trajectoire à travers différents contextes vocaliques et à travers différents styles de parole. Dans la parole continue, la trajectoire entière de l'aire de section semble être invariante à travers différents contextes de voyelles accentuées. Les traits du patron acoustique associés aux portions invariantes de l'articulation du conduit vocal, en combinaision avec les articulations laryngées et respiratoires appropriées, sont discutées.
Dans un travail récent sur le syndrome aphasique de l'agrammatisme, Kean (1980a) soutient qu'on peut rendre compte des éléments dégradés vs. les éléments conservés en ne considérant que le niveau de représentation linguistique intermédiaire entre les structures syntaxiques et phonologiques.
Le burāq est la monture que le prophète Muḥammad aurait enfourchée lors de son voyage nocturne de la Mecque à Jerusalem (isrāʾ) et à l'occasion de son ascension céleste (miʿrāğ). Cet article examine la notion du burāq au sein des sources musulmanes comme occidentales non-musulmanes. Nous retraçons l'évolution de descriptions relativement sommaires du burāq telles qu'on les rencontre dans les premières sources musulmanes jusqu'aux comptes rendus tardifs enjolivés et pittoresques. Nous examinons également le rôle que le burāq joue dans des discussions musulmanes ayant trait à l'isrāʾ et au miʿrāğ. Pour ce qui ressortit aux approches occidentales non-musulmanes, l'article démontre comment le burāq fut tout d'abord utilisé dans la polémique contre l'islam, avant de devenir un objet de fascination et, plus tard, un sujet d'étude universitaire sur un mode plus impartial.
Les relations de compensation entre les indices de l'intensité de l'aspiration et ceux de l'intensité de la voyelle suivante pour la distinction entre /d/ et /t/ ont été étudiées aux niveaux auditif, phonétique, syllabique, du mot et de la phrase. Les résultats montrent qu'au fur et à mesure que s'élève le niveau du traitement, le moins catégoriel est l'identification et le plus efficace la compensation d'indices. Les relations de compensation plus fortes au niveau de la syllabe, du mot et de la phrase suggèrent que le mode “parole” de la perception est un mode distinct. Néanmoins, une tendance à la compensation entre indices persiste aux niveaux auditif et phonétique. Les résultats semblent aussi venir à l'appui du modèle interactif du traitement de la parole.
Généralement, la mesure de dissimilarité inter-mots fournie par les algorithmes de “distorsion temporelle dynamique” (DTW) ne peut sevir de métrique, car elle ne satisfait pas à toutes les propriétes requises (l'inégralité triangulaire en particulier). Dans cet article, cependant, l'évidence empirique selon laquelle la parole naturelle satisfait approximativement à ces propriétés, est mise en lumière ; ce fait autorise l'hypothèse d'une structure “d'espace métrique vague” dans l'ensemble des représentations paramétriques des mots dans un vocabulaire donné. Basé sur cette structure, un algorithme de recherche dans cet espace est introduit, algorithme qui en Reconnaissance de Mots Isolés, élimine la nécessité de calculer la distance-DTW entre le mot-test et un grand nombre de mots prototypes du dictionnaire. Des expériences menées sur des vocabulaires de caractéristiques différentes ont démontré que cet algorithme détermine le prototype le plus proche en effectuant les opérations de “distortion temporelle dynamique” (DTW) sur une moyenne de 30% seulement des mots du dictionnaire. Il a été observé que ce chiffre tend à décroître avec l'accroissement de la taille du dictionnaire, et aussi dans le cas où le mot est proche du prototype correspondant (mot “beien prononcé”).
Nous présentons dans cet article l'intégration d'un système de reconnaissance analytique de la parole dans une console sonar. Cette application correspond à un besoin des opérateurs qui ont continuellement les yeux occupés à scruter l'écran sonar. Le système DIAPASON présente deux particularités : le décodage acoustico-phonétique utilisé dans le système n'est pas fondé sur une reconnaissance phonétique classique ; son objectif est d'obtenir pour chaque segment de parole une description précise en termes de traits acoustico-phonétiques. Ce niveau de décodage est associé à une procédure spécifique d'accès lexical et de reconnaissance de phrases ; le système DIAPASON est de plus un véritable système de dialogue homme-machine et ne se limite pas à une simple reconnaissance de phrases comme c'est le plus souvent le cas. L'historique du dialogue est considéré comme une source de connaissances à part entière durant la phase de reconnaissance et cela permet d'augmenter de façon notable les performances globales du système. Cet article détaille l'architecture de DIAPASON et décrit ses diverses composantes. Il présente aussi les résultats expérimentaux obtenus en mode multilocuteurs et compare les systèmes de dialogue avec parole et sans parole pour une console sonar réelle.
Dans le cadre des télécommunications mains-libres, les deux problèmes que sont la réduction de bruit et l'annulation d'écho acoustique doivent être résolus pour améliorer la qualité de la communication. Notre objectif est de trouver une combinaison des systèmes résolvant chacun des problèmes pour obtenir un signal à transmettre faiblement distordu pour des niveaux d'écho et de bruit résiduels acceptables. Quatre structures (à 1 ou 2 microphones et 1 haut-parleur) sont étudiées dans lesquelles l'annulation d'écho précède la réduction de bruit. Des expérimentations sur signaux réels ont été conduites. Au vu des résultats obtenus, nous sommes conduits à proposer une structure contrôlée par un détecteur d'écho seul.
Nous décrivons dans cet article un réseau de microphones destiné à l'enregistrement de la parole dans une voiture (cette étude a été réalisée dans le cadre du projet ESPRIT ARS “adverse environment recognition of speech”). Le réseau est conçu pour un radio-téléphone mains-libres, et sert de point d'entrée pour un système de reconnaissance automatique de la parole. Nous commencerons par résumer les techniques de formation de voie adaptive que nous avons utilisées. Nous présenterons ensuite plusieurs aspects de l'implantation de ce réseau (configuration, conception de la formation de voie fixe, adaptation, réduction de la complexité). Dans la dernière section, nous évaluons les performances du réseau. Deux mesures sont utilisées, l'une est le rapport signal sur bruit, l'autre est le score obtenu par un système de reconnaissance de mots isolés.
En stéréovision binoculaire, la mise en correspondance est une étape cruciale pour réaliser la reconstruction 3D de la scène. De très nombreuses publications traitent ce problème. Ainsi, le premier objectif est de proposer un état de l'art des méthodes de mise en correspondance. Nous synthétisons cette étude en présentant un algorithme générique complet faisant intervenir des éléments constituants permettant de décrire les différentes étapes de la recherche de correspondances. Enfin, le dernier objectif est de présenter de nouvelles méthodes hybrides, dans le cadre des méthodes locales à base de corrélation. Nous nous appuyons sur l'utilisation de deux mesures de corrélation permettant de mieux prendre en compte le problème des occultations. Les résultats mettent en évidence la meilleure méthode qui consiste à fusionner deux cartes de disparités obtenues avec des mesures différentes.
Au cours de la dernière décennie, de multiples méthodes pour l'analyse et la classification de données fondées sur la théorie des espaces de Hilbert à noyau reproduisant ont été développées. Elles reposent sur le principe fondamental du kernel trick, initialement exploité par Vapnik et col. dans le cadre des Support Vector Machines. Celui-ci permet d'étendre au cas non-linéaire des traitements initialement linéaires en utilisant la notion de noyau. La méthode KFD, pour Kernel Fisher Discriminant, constitue ainsi une généralisation non-linéaire de l'analyse discriminante de Fisher. Cet article présente un algorithme séquentiel palliant cette difficulté puisqu'il ne nécessite, ni la manipulation, ni même le stockage de telles matrices. Un parallèle est également proposé entre KFD et KPCA, acronyme de Kernel Principal Component Analysis, cette dernière méthode constituant une extension au cas non-linéaire de l'analyse en composantes principales.
La synthèse de voyelles au moyen d'un modèle source-filtre s'effectue souvent avec un train d'impulsions delta comme signal d'entrée. Bien que des modèles sophistiqués de la source glottale puissent être employés, dans une certaine mesure, afin de simuler une voix soufflée, une simulation plus naturelle exige l'addition d'un bruit d'aspiration. Cependant, lorsqu'un bruit stationnaire est employé, il sera perçu en bonne partie comme provenant d'une source sonore séparée qui ne contribue pas au timbre soufflé de la voyelle. Ce problème peut être résolu en utilisant un bruit ayant une enveloppe temporelle de la même périodicité que le train d'impulsions. Dans un simple modèle source-filtre, des impulsions filtrées passe-bas combinées à un bruit pulsatif synchrone filtré passe-haut à énergie égalisée ont été employées comme signal de source. De cette façon, le bruit n'est plus perçu séparément, mais est intégré perceptuellement à la partie strictement périodique du signal. Il sera démontré que cette intégration consiste à la fois en une réduction de la force sonore du bruit et en une altération du timbre de la voyelle soufflée.
Dans cet article, nous présentons une nouvelle mesure de la vraisemblance qui étend à la fois le mécanisme d'adaptation a la réduction de la matrice de covariance et l'adaptation du biais du vecteur moyen. Un ensemble de fonctions d'adaptation est proposé afin d'obtenir les facteurs de compensation. Les expériences montrent que la mesure de vraisemblance proposée augmente de manière significative le taux de reconnaissance.
Cet article décrit un cas de dysgraphie pour lequel nous postulons une lesion selective de la mémoire-tampon graphémique. Les difficultés analogues que rencontre le patient pour l'orthographe orale et écrite et les difficultés d'orthographe comparables qu'il rencontre pour la denomination écrite, la copie avec temps de latence et l'écriture sous dictée interdisent de penser qu'il y a eu lésion selective des mécanismes d'input ou d'output. Plus important, la nature des erreurs du patient et le fait que la distribution de ces erreurs est virtuellement identique pour les mots familiers et les mots nouveaux, nous semble démontrer que les troubles de L.B. résultent d'une lésion sélective de la mémoire-tampon graphémique. Divers aspects de la performance du patient sont analysés par rapport à l'architecture fonctionnelle du processus d'orthographe et en termes de la structure de la mémoire-tampon graphémique.
Bien que moins appliquée, la conception de Henri Ey est en grande partie connue en Roumanie. Elle est présentée par l'œuvre du Pr Pamfil (de Timisoara), élève de Henri Ey pendant quelques années en France, et par les traductions en roumain de « La conscience » ainsi que des trois volumes des « Études psychiatriques » . En 2004, l'auteur vient de rééditer et compléter « Psihiatrie » , publié en 1997 à Bucarest et qui réserve, aux conceptions en psychiatrie en général et aux conceptions organodynamiques en particulier, le rôle de prémisses de sa propre conception sur la resocialisation des malades psychiques. La conception originale de Henri Ey est la domination du corps psychique par les structures de l'ego, du réfléchissement de la réalité et de la conscience-de-soi, et, enfin, de l'identité. Ainsi, Henri Ey a assimilé la psychanalyse, le psycho-organicisme comme la psychogenèse, dans une entité dominée par un ego rationnel. Henri Ey aura été un anthropologue et il a élevé la psychiatrie à une initiation théorique.
La perception auditive est modélisée à l'aide d'un automate à niveaux hiérarchiques multiples. Un certain nombre de niveaux hiérarchiques sont définis plus exactement, les aspects conceptueles sont décrits et le traitement du signal, qui a lieu dans le canal d'entrée/sortie, est exposé. Le système d'indices, qui tent compte de l'effect de masque, est décrit. La modélisation de l'effet de masque permet d'éliminer, sans perte d'information, les composantes spectrales qui sont masquées par des composantes voisines plus énergðiques. La validation dy système d'indices ainsi obtenu a été effectuée avec la participation de 5 locuteurs ; sur des lexiques comprenant jusqu'à 200 mots. Le taux de reconnaissance mono-locuteur est proche de 100% et le taux de reconnaissance multi-locuteurs varie entre 90 36 99%.
Notre but est d'obtenir des taux de succès de dialogue élevés avec une interaction très ouverte, offrant à l'utilisateur la possibilité de poser des questions ou de donner des informations à n'importe quel moment. Afin d'améliorer les performances avec une telle stratégie, nous avons utilisé la confirmation implicite en fonction des formulations des utilisateurs ainsi qu'un dialogue plus contraint lorsque l'interaction se passe mal.
Dans le codage de parole à bas débit binaire à base de source-filtres, une représentation efficace des impulsions d'excitation est nécessaire pour obtenir une bonne qualité de parole synthétisée. Dans cet article, nous traitons d'une représentation en forme d'onde des impulsions par des dictionnaires composés de formes d'impulsions. Les dictionnaires sont construits à partir de dérivées d'impulsions glottales obtenues par une technique de filtrage inverse à prédiction linéaire. Les impulsions sont extraites et normalisées en durée et amplitude pour former des d'impulsions typiques. Les méthodes de construction et l'évaluation des performances des dictionnaires sont traitées dans le cadre d'une quantification vectorielle (QV). Les gains de quantification obtenus en exploitant la corrélation entre impulsions sont étudiés de manière théorique, ce qui montre qu'on peut épargner 2 bits par vecteur (d'un budget de 7–10 bits) en exploitant la corrélation. La QV à mémoire est un schéma de quantification qui utilise les impulsions précédemment quantifiées. Nous étudions deux méthodes traditionnelles de QV à mémoire ainsi qu'une extension de QV à mémoire par une QV sans mémoire, appelée filet de sécurité. Les tests montrent que les performances s'améliorent quand on adjoint un filet de sécurité. Nous avons trouvé qu'aux débits binaires demandés, la QV à mémoire utilisant un filet de sécurité peut gagner jusqu'à 1.5–2 bits par rapport à la QV sans mémoire.
La recherche des images par le contenu dans des grandes bases généralistes d'images est une tâche fastidieuse vu le taux d'hétérogénéité assez élevé même au sein d'une seule classe de la base ainsi que la grande dimension de l'espace des descripteurs relatifs aux images. Pour cela, nous proposons de guider la recherche par des descripteurs de bas-niveau de taille réduite à base de sous-bandes d'ondelettes relatives aux régions les plus significatives dans chaque image après une phase de segmentation floue. De plus, nous proposons une technique de bouclage de pertinence négatif sur les poids relatifs aux régions. Les expérimentations et l'étude comparative avec des approches similaires prouvent la robustesse de l'approche proposée en termes d'apport sémantique offert par l'utilisation des sous-bandes d'ondelettes ainsi que par le bouclage de pertinence négatif.
Dans cet article nous proposons une méthode de segmentation d'images couleur selon une nouvelle approche que nous appelons bi-marginale. Afin de pallier les défauts des approches marginales classiques, nous considérons les composantes couleur deux à deux afin d'avoir une vue partielle de leur corrélation. Travaillant selon cette vision bi-composante, nous considérons les trois combinaisons possible comme trois sources d'informations indépendantes. Chaque information bi-composante est tout d'abord analysée selon un schéma de coalescence morphologique non supervisé qui recherche les couleurs dominantes d'un histogramme bidimensionnel. Cela permet de construire trois cartes de segmentation distinctes qui sont combinées par intersection après avoir été simplifiées. L'intersection produisant une sur-segmentation, une fusion des régions deux à deux est opérée selon un critère de similarité et selon la combinaison de Dempster-Shafer jusqu'à un critère de terminaison.
Le terme analogie couvre une confédération complexe de concepts liés entre eux et à d'autres concepts comme « métaphore » et « expression » . Dans cet article, nous proposons d'analyser d'une part, les différentes acceptions du terme analogie, et d'autre part, les relations entre l'analogie et l'expression. En ce qui concerne la relation avec l'expression métaphorique, les analogies régressives motivent la création de métaphores conventionnelles dont l'expression se réduit à un rôle instrumental, alors que les analogies projectives sont rendues possibles par l'expression et indissociables d'elle, et ne peuvent être conçues que comme le but d'interprétations créatrices de contenus complexes conflictuels.
La reconnaissance automatique de scénarios est cruciale pour l'aide à la supervision de systèmes dynamiques. La construction de tels scénarios représentatifs de situations de bon ou de mauvais fonctionnement n'est pas réalisable à partir de la connaissance experte. Notre objectif est donc d'extraire, à partir des données et des informations disponibles, des séquences d'événements pertinents et ensuite de construire des scénarios validés par les experts. Nous présentons notre méthodologie d'abstraction des données qui permettra au fur et à mesure de construire des séquences de granularité croissante, puis des scénarios.
Au fil des années, la controverse s'est étendue sur les mérites relatifs des liaisons en cascade ou en parallèle des générateurs de formants dans la réalisation d'un synthétiseur de parole. Ce rapport montre que la connexion en parallèle, théoriquement moins satisfaisante, permet de produire de meilleures approximations des propriétés du signal de parole que ce qui est générlement obtenu à partir d'un synthétiseur en cascade, et ce, à a fois pour les voyelles et pour les consonnes. Cependant, pour atteindre ce résultat, il est nécessaire de prendre garde aux caractéristiques de phase des générateurs de formants et de modeler de manère appropriée les pentes des courbes de réponses formantiques. Bien que dans le cas d'un synthétiseur en parallèle de l'information supplémentaire sur l'amplitude soit nécessaire, le mode de spécification acoustique est en conséquence plus directement relié aux proprétes de la parole humaine telles qu'elles peuvent être aisément measurées á partir d'une représentation spectrale.
Cette méthode est basée sur la normalité asymptotique d'une fonction non-linéaire des coefficients de détail et d'échelle de la transformée de Haar, appelée la transformée de Fisz. Nous exposons quelques résultats asymptotiques, tels que la normalité et la décorrélation des pixels de l'image transformée. Fort de ces résultats, l'image originale bruitée par un processus de Poisson, peut être considérée après transformation de Fisz comme étant contaminée par un bruit additif gaussien et blanc. Ainsi, les débruiteurs classiques s'appliquent directement. Elle dépasse clairement ces approches lorsque le taux de comptage est faible. Combiner la transformation de Fisz avec le débruiteur bayésien FKB offre les meilleurs résultats.
Cet article décrit une structure de codeur prédictif excité par codes pour des applications en transmission et clarifie les relations existant entre celle-ci et d'autres codeurs prédictifs ainsi que la quantification vectorielle. Pour un débit de 1 bit par échantillon on spécifie un dictionnaire constitué de 2 L formes d'onde de L échantillons à valeurs dans {t-1, +1}. Chaque forme d'onde est déduite de l'index binaire dans le dictionnaire par une correspondance bi-univoque entre chaque bit de l'index et chaque échantillon de la forme d'onde. Par construction un tel dictionnaire possède une robustesse intrinsèque vis à vis des erreurs de transmission et sa structure algébrique interne conduit à des algorithmes très rapides de sélection de la forme d'onde optimale. Les résultats objectifs et subjectifs confirment le haut niveau des performances obtenues par le codeur CELP à 16 kbit/s dans différentes conditions de transmission réalistes telles que la transmission en présence d'erreurs et de bruit ambiant.
Pouvoir synthétiser des voix pathologiques peut être un outil utile pour le développement de protocoles standards pour l'évaluation de la qualité vocale. On a appliqué une méthode d'analyse-synthèse, utilisant le synthétiseur de Klatt, à 24 énoncés de la voyelle /a/ prononcés par des locuteurs hommes et femmes ayant des troubles de la parole allant de modéré à sévère. Les indices tant spectraux que temporels des formes d'onde naturelles ont été analysés et les résultats utilisés pour guider la synthèse. Une évaluation perceptive montre qu'environ la moitié des voix synthétiques sont considérées comme identiques en qualité aux voix naturelles qu'elles sont sensées modéliser. Les stimuli considérés comme différents reflètent les échecs de la modélisation de voix très instables ou “gargarisées” ou d'imperfection dans la reproduction des spectres naturels. Diverses modifications apportées au synthétiseur de Klatt pourraient améliorer la synthèse des voix pathologiques. Ces modifications concernent l'introduction de paramètres de jitter et de shimmer ; la mise à jour des paramètres de synthèse en fonction de la période plutôt qu'en fonction d'une durée absolue ; la modélisation de la diplophonie par des paramètres indépendants pour les variations de fréquence fondamentale et d'amplitude ; la disponibilité d'un paramètre permettant d'augmenter l'énergie dans les basses fréquences ; et l'ajoût de plus de paires pôle-zéro.
Les systèmes d'inférence floue peuvent avoir une place importante dans un processus de modélisation, quand l'intégration de données et d'expertise est nécessaire. L'objectif de cet article est de donner des lignes directrices pour ce type de modélisation, basées sur notre expérience pratique dans les domaines de l'agronomie et de l'environnement. Nous discutons les points originaux de ces systèmes, leur capacité à intégrer expertise et données dans un cadre commun, ainsi que leur place par rapport à d'autres modèles. L'implémen- tation dans le logiciel open source FisPro est également présentée et deux cas d'étude illustrent l'approche.
Satisfaire la propriété de l'inégalité triangulaire (IT) par les mesures de dissimilarité de la méthode DTW (“dynamic time warping”) semble être une condition préalable importante à l'application des nouvelles méthodes de réduction du nombre de calculs pour la reconnaissance automatique de mots isolés. Le degré de satisfaction de cette propriété pour des échantillons de parole naturelle a été étudié empiriquement par plusieurs auteurs. Les résultats sont peu concluants quant aux différentes méthodes DTW employées et aux données expérimentales utilisées. Au cours des expériences intensives que nous avons menées, la propriété IT a toujours été satisfaite quelles que soient les nombreuses combinaisons de paramètres acoustiques, les méthodes DTW, métriques locales et les signaux de parole utilisés. Cette constatation a motivé une étude préliminaire des causes possibles de la violation de l'inégalité triangulaire constatée ailleurs. Les résultats suggèrent que l'usage de certaines méthodes de compression temporelles ainsi que de méthodes DTW sous-optimales sont à l'origine de la non-satisfaction de la propriété IT.
On désigne par microperturbations de la période fondamentale les légères fluctuations des durée des cycles glottiques. Afin d'analyser les microperturbations, il est nécessaire de mesurer la durée des cycles glottiques avec une très grande précision. En général, on y arrive en échantillonnant le signal de parole à une cadence moyenne et en interpolant le signal numérisé. Dans cet article nous décrivons un algorithme dédié à la mesure précise des microperturbations et qui propose une solution aux deux problèmes de traitement du signal suivants. Premièrement, les échantillons qui sont obtenus par interpolation ne sont que des estimations des échantillons d'origine qui sont inconnus. Le problème est d'évaluer la qualité de la reconstruction du signal. Deuxièmement, les petites variations dans les durées des cycles glottiques sont facilement biaisées par du bruit et des erreurs de mesure. Ici, le problème est d'estimer l'impact des erreurs de mesure sur le résultat final. Dans notre algorithme, la qualité de l'interpolation est évaluée à l'aide d'un test statistique qui tient compte de la distribution des corrections (dues à l'interpolation) des positions des événements qui marquent le début des périodes. Trois méthodes d'interpolation différentes ont été implantées. Les erreurs de mesure sont contrôlées en estimant indépendamment les durées des cycles glottiques à partir du signal de parole et à partir du laryngogramme. Si les deux séries coïncident, alors on peut conclure qu'elles reflètent l'activité des cordes vocales et qu'elles n'ont pas été biaisées exagérément par des erreurs de mesure ou du bruit. L'algorithme a été vérifié sur 77 signaux produits par des locuteurs sains et dysphoniques. Ses performances sont très satisfaisantes en général.
Le comportement de la source vocale dans la parole continue a été examiné. Des paramètres de la source vocale ont été obtenus à l'aide d'un filtrage inverse automatique, suivi par un appariement automatique d'un modèle d'onde de débit glottique aux observations. Des relations consistantes entre les paramètres de la source vocale et des traits prosodiques ont été observées.
Cet article a un double objet : examiner les méthodes de codage de la dernière décennie dans la gamme des 4.8–9.6 kbps et discuter les courants les plus récents de la recherche. L'essentiel de l'article est consacré au codage CELP, méthode obligée à la base de plusieurs standards en cours d'émergence. Suit une brève revue d'une méthode alternative de modélisation sinusoïdale. Une comparaison de ces techniques opposées permet d'identifier les futurs domaines de la recherche.
Dans cet article, nous décrivons une technique par laquelle une fonction, comportant des pôles et des zéros, peut être ajustée à la réponse en fréquence d'un système en résolvant un système d'équations simultanées. L'ordre de la fonction est défini par le double du nombre de maxima spectraux de la réponse en fréquence. La fonction est contrainte à ajuster les maxima et minima de la courbe de réponse. La procédure d'ajustement permet de faire varier la forme des vallées entre les maxima à l'aide d'un seul paramètre. Le problème que pose l'obtention d'une bonne approximation de la réponse en fréquence du conduit vocal à partir du spectre à court terme de la parole est résolu à l'aide d'une méthode de lissage spectral. La structure harmonique du spectre à court terme fourni par un banc de filtres digitaux est éliminée en tronquant le cepstre. A titre d'exemple, la procédure est appliquée à une voyelle synthétique. (Une indication quant au degré d'approximation propre à la procédure est ainsi obtenue).
Nous proposons, dans cet article, d'améliorer la classification d'images, en utilisant une approche de classification visuo-textuelle (à base de caractéristiques visuelles et textuelles), et en étendant automatiquement les annotations existantes aux images non annotées. L'approche proposée est dérivée de la théorie des modèles graphiques probabilistes et dédiée aux deux tâches de classification et d'annotation d'images partiellement annotées. Nous considérons une image comme partiellement annotée si elle ne possède pas le nombre maximal de mots-clés disponibles par image dans la vérité-terrain. Grâce à leur capacité à fonctionner en présence de données manquantes, un modèle graphique probabiliste a été proposé pour représenter les images partiellement annotées. Ce modèle est basé sur un mélange de lois multinomiales et de mélanges de Gaussiennes. La distribution des caractéristiques visuelles est estimée par des mélanges de Gaussiennes et celle des mots-clés par une loi multinomiale. Par conséquent, le modèle proposé ne requiert pas que toutes les images soient annotées : lorsqu'une image est partiellement annotées, les mots-clés manquants sont considérés comme des valeurs manquantes. De plus, notre modèle peut automatiquement étendre des annotations existantes à des images partiellement annotées, sans l'intervention de l'utilisateur. L'incertitude autour de l'association entre un ensemble de mots-clés et une image est capturée par une distribution de probabilité jointe (définie par un mélange de lois multinomiales et de mélanges de Gaussiennes) sur le dictionnaire de mots-clés et les caractéristiques visuelles extraites de notre collection d'images. De plus, de façon à résoudre le problème de dimensionnalité dû à la grande dimension des caractéristiques visuelles, nous avons adapté une méthode de sélection de variables. Les résultats de la classification visuo-textuelle, obtenus sur une base d'images collectées sur Internet, partiellement et manuellement annotée, montrent une amélioration de 32.3 % en terme de taux de reconnaissance, par rapport à la classification basée sur l'information visuelle uniquement. Par ailleurs, l'extension automatique d'annotations, avec notre modèle, sur des images avec mots-clés manquants, améliore encore la classification visuo-textuelle de 6.8 %. Enfin, la méthode proposée s'est montrée compétitive avec des classificateurs de l'état de l'art.
Dans cet article est proposée une nouvelle méthode de compression numérique d'image. Dans une première étape l'image est décomposée en sous-images au moyen d'une transformée en ondelettes. Les ondelettes choisies sont à la fois bien localisées dans l'espace et en fréquence, et privilégient les directions horizontale et verticale, ce qui permet de respecter les caractéristiques de la vision humaine. La décomposition est effectuée par un algorithme Tapide à structure pyramidale. Ensuite les coefficients d'ondelette sont codés par une méthode de quantification vectorielle. Un codebook est élaboré pour chaque résolution et direction privilégiée à partir d'une séquence d'apprentissage en utilisant un critère quadratique. Ainsi un vecteur à coder est classifié (direction, résolution) puis la seule sous-classe appropriée est scrutée.
Les réponses aux remarques formulées par L.J. Boë et P. Perrier sont organisées selon trois classes d'aspects : acoustiques, articulatoires et phonétiques. Au préalable, une présentation synthétique met en évidence les traits caract́eristiques du modèle en vue d'éviter des incompréhensions sur a nature.
Dans cet article, nous faisons le point sur les possibilités offertes par les modèles hybrides harmonique/stochastique (H/S) dans le cadre de la synthèse vocale à large bande par concaténation. Après un bref rappel des hypothèses sous-jacentes et d'un algorithme d'analyse bien connu, à savoir celui fourni dans le cadre de l'excitation multi-bandes (MBE), nous étudions comment les modèles H/S permettent de modifier la prosodie des segments et comment leur concaténation peut être organisée, dans le but de minimiser les incohérences au droit des frontières de segments. Nous proposons à cette occasion une méthode originale qui tire parti de certaines erreurs d'analyse. Nous examinons ensuite les algorithmes de synthèse, introduisons une méthode originale basée sur le calcul d'IFFTs judicieusement choisies, et détaillons la qualité segmentale du résultat. Nous insistons plus particulièrement sur les différences entre la qualité obtenue avec ce modèle dans le cadre du codage à bande étroite et dans le cadre de la synthèse à large bande par concaténation. Nous étudions trois explications possibles : le choix du critère d'analyse, l'inadéquation du modèle aux variations de pitch, et l'effet de la coarticulation sur les phases.
Les systèmes de recherche d'information renvoient généralement une liste ordonnée de documents, où seuls le titre et parfois un extrait comportant les mots de la requête permettent d'en évaluer la pertinence pour son besoin initial. Ces types de résultat conduisent toujours à devoir consulter de nombreux documents pour réellement trouver des réponses pertinentes. Afin d'éviter cet écueil nous nous sommes intéressés à la visualisation d'un texte : que doit-on montrer et comment ? Dans notre système, RÉGAL (RÉsumé Guidé par les Attentes du Lecteur), les informations nécessaires à la visualisation sont extraites automatiquement des textes par l'application d'une analyse thématique, sans présupposer l'existence d'une structure préalable ou d'un formatage du texte, et en combinant des approches fondées sur la cohésion lexicale et le repérage de marques clés.
Nous proposons une méthode permettant de générer automatiquement un dictionnaire de prononciations à l'aide d'un réseau de neurones qui prédit les prononciations les plus plausibles (variantes) à partir d'une prononciation standard. Le réseau de prononciation peut générer de multiples variantes de prononciation. Pour générer un dictionnaire de variantes de prononciation sophistiqué, deux techniques sont décrites : (1) variantes de prononciation avec valeur de vraisemblance, et (2) variantes de prononciation pour les phonèmes aux frontières des mots. Les résultats de nos expériences sur de la parole spontanée montrent que les dictionnaires de prononciation dérivés automatiquement permettent d'améliorer de façon significative le taux de reconnaissance, par rapport à un dictionnaire conventionnel.
Cet article concerne l'utilisation d'un système commercial de reconnaissance de parole à grande vocabulaire par une équipe d'utilisateurs au cours de leur travail quotidien. Il décrit en particulier son utilisation par des traducteurs utilisant quatre langues dans un milieu multilingue au sein de la Commission Européenne. L'article évoque tout d'abord quelques différences entre le point de vue d'un utilisateur courant typique et celui d'un chercheur en reconnaissance de la parole. Il montre que certaines barrières psychologiques doivent être surmontées pour que la reconnaissance de la parole soit largement acceptée et il conclut que cette acceptation dépendra au moins autant du partage d'expérience entre utilisateurs que des avancées techniques. Les résultats globaux des expériences menées au sein de la Commission Européenne ont été positifs et encourageants, mais plusieurs problèmes inattendus ont été rencontrés, pour la plupart liés au milieu multilingue. Cet article décrit comment la plupart de ces problèmes ont été traités.
Cet article décrit le projet de technologie vocale SPELL (Système interactif pour l'apprentissage des langues parlées européennes) ; son principal but est de définir un système automatique d'amélioration de la prononciation des langues étrangères pour les étudiants de l'anglais, du français et de l'italien. La phase d'étude de faisabilité a été conclue ; il en est issu un prototype comprenant des modules d'enseignement pour l'intonation, le rythme et la prononciation des voyelles. Cet article décrit les méthodes de traitement du signal employées, les mesures de ressemblance et les interfaces utilisateur qui ont été intégrées pour réaliser le système de démonstration de base. Une évaluation préliminaire, par un groupe de professionnels de l'enseignement des langues, montre que SPELL est un outil adapté pour explorer l'enseignement automatique de la prononciation.
La littérature en moyen français est dominée par l'imaginaire juridique. La présence de ce thème dans les Ballades de Charles d'Orléans reflète-t-elle seulement la mode contemporaine ? Les images de la loi donnent au recueil un cadre, de la Retenue à la Departie d'Amour. En transformant la traditionnelle loyauté courtoise en législation amoureuse, le poète met en valeur la communication particulière avec sa dame. L'amour à distance doit se dire à travers des écritures qui sont autant d'actes, engageant les deux amants à respecter le désir comme une loi. Les Ballades sont également un univers peuplé de juristes. Le sujet lyrique, comme les allégories avec lesquelles il dialogue, est juge, procureur, avocat. Mais si les lieux qui ouvrent le recueil sont des espaces de législation, ils deviennent, lorsque le poète s'égare, des tribunaux où les procédures judiciaires n'aboutissent jamais. La fiction juridique transforme enfin le dialogue avec d'autres poètes en un jeu dont le duc est à la fois juge et partie.
L'objet de cet article est une étude comparée des performances de ces méthodes pondérées en vue de leur application à court terme synchronisée à la fondamentale de brefs segments voisés non nasalisés (durée de l'intervalle d'analyse plus courte qu'une période). Les erreurs dans l'estimation du spectre de puissance, des fréquences formantiques et des largeurs de bande sont utilisées comme critère de performance. Nous montrons que la méthode de Burg pondérée proposée par Kaveh et Lippert est la plus performante. Les résultats d'une comparaison de ces méthodes avec les méthodes d'autocorrélation et de covariance sont également discutés.
Modeling user behavior on computer interface is a very complex task as data, usually manipulated by cognitive psychologist, are very abundant and few methods for visualizing them for seeking purpose exist.
Cet article présente une théorie et une implémentation informatique de la génération d'une intonation appropriée pour la parole de synthèse, dans un contexte de réponse à une interrogation de bases de données. Les distinctions spécifiques de contraste et d'emphase sont exprimées sous la forme de contours prosodiques qui sont synthétisés par règles sous le contrôle d'une grammaire, d'un modèle du discours et d'une base de connaissance. La théorie est basée sur la Grammaire Catégorielle Combinatoire, un formalisme qui permet d'intégrer aisément les notions de constituant syntaxique, de sémantique, de structure prosodique et de structure inormationnelle. Les résultats de l'implémentation actuelle montrent que le système est capable de générer diverses intonations pour une même phrase, suivant le contexte du discours.
De nombreux systèmes de traduction texte-parole sont actuellement en développment en Europe et dans le reste du monde. Nous discuterons en particulier du système en développement au Centre for Speech Technology Research (CSTR) de l'université d'Edinbourg. En général, ces systèmes génèrent les propriétés intonatives de phrases synthétiques sur base d'une représentation phonologique intermédiaire abstraite des traits prosodiques qui est indépendente de la réalisation acoustique. L'accent tonique et la conversion graphème-phonème est évaluée plus facilement à partir d'une représentation symbolique qu'à partir de la sortie acoustique. De même, la représentation abstraite est plus appropriée que la sortie acoustique du système pour l'évaluation de certains aspects de la prosodic synthétique (notamment le placement de l'accent et la division en domaines). Comme illustration, nous présentons les résultats d'un exercice d'évaluation effectué sur les règles de l'accent de phrase du système CSTR. Le choix d'une représentation abstraite a été utile pour l'amérioration de nos règles.
Dans cet article, nous proposons une méthodologie originale permettant la détection et la reconnaissance de caractères multi-orientés et multi-échelles. Les supports sur lesquels la méthode est appliquée sont des documents techniques représentant le réseau de l'opérateur de télécommunication français France Télécom. La technique adoptée, basée sur la transformation de Fourier-Mellin (TFM), est intégrée dans une stratégie globale permettant la résolution de situations ambiguës, par intégration d'informations contextuelles. La stratégie appliquée pour résoudre ce problème de reconnaissance de caractères et symboles multi-orientés et multi-échelles peut être divisée en deux étapes. La première réside dans l'extraction d'un ensemble de descripteurs invariants pour chacune des formes isolées de la couche « caractères » identifiée à partir d'un extracteur de composantes connexes. La seconde étape, basée sur un processus de filtrage, consiste à détecter et reconnaître les formes connectées au réseau ou à d'autres formes. Les résultats de l'application de cette technique sont très encourageants puisque le taux de classification atteint d'excellents niveaux en comparaison avec les techniques classiques de la littérature.
Dans cet article, nous présentons une méthode pour la résolution du problème d'estimation des angles d'arrivée de D cibles, par un réseau de L capteurs, où D < L, pour les systèmes actifs émettant des signaux codés en « Frequency Hopped » . Cette méthode est basée sur l'application de l'estimateur du maximum de vraisemblance à un nouveau modèle de données reçues sur différents canaux. Les résultats de simulation montrent que cette approche améliore la résolution des angles d'arrivée des cibles, comparativement à celle de la fréquence monotone. Cependant, quand le rapport signal sur bruit (Signal to Noise Ratio, SNR) est faible, la performance se dégrade et nécessite donc un nombre d'échantillons plus élevé.
Avant qu'existe une nouvelle génération de traitement du langage naturel qui puisse fonctionner der façon satisfaisante dans les conditions réelles actuelles, des techniques d'interfaçage seront nécessaires pour faire en sorte que le langage de l'utilissateur puisse coïncider avec les capacités des systémes actuels. Dans cet article, on examine comment la modalité d'entrée et la structure de la présentation influent sur la complexité linguistique des énoncés écrits et oraux à l'entrée d'un systéme interactif. En utilisant une technique de simulation semi-automatique, des énoncés ont été collectés lors d'échanges soit entiérement oraux, soit entiérement écrits, soit combinant écrit et voix et utilisant des formats de présentation ou bien structurés, ou bien non contraints. Les résultats indiquent que tant la modalité que le format de présentation ont une influence déterminante sur la complexité linguistique, bien que les natures de leur impact soient différentes. On présente une analyse approfondie de la façon dont ces deux facteurs jouent sur le nombre total de mots, les hésitations, la longuer des énoncés, la variabilité lexicale, la perplexité, l'ambiguïté syntaxique et l'intégration sémantique. Les préférences des utilisateurs en termes de formats et de modalité sont aussi analysées et l'on discute certaines implications pour le contrôle transparent du langage de l'utilisateur. Le but à long-terme de cette recherche est de développer des techniques d'interfaçage permettant de gérer les sources de grande variabilité dans le langage humain de façon à réaliser des technologies de traitement du langage natural qui soient robustes.
L'objectif de nos travaux est de comparer et fusionner les points de vue de paysans malgaches sur leur territoire. Notre démarche de modélisation utilise le modèle des graphes conceptuels afin de représenter les connaissances spatiales exprimées par les paysans, etl'ana- lyse formelle de concepts pour organiser la fusion de ces représentations. L'interprétation des résultats s'appuie sur une mesure d'intérêt évaluant les concepts formels obtenus après fusion et sur une expertise du terrain. Nous montrons la pertinence des concepts formels retenus pour analyser la façon dont les paysans organisent leur espace limité par la conservation de la forêt.
Dans le but d'améliorer les connaissances sur les relations articulatori-acoustiques, d'importantes quantités de données sont nécessaires. L'objectif de ce travail a donc été double : (1) obtenir pour un même sujet, un ensemble cohérent de fonctions sagittales, fonctions d'aire et formants sur un nombre réduit de voyelles et consonnes fricatives, et (2) déterminer un modèle de passage de la fonction sagittale à la fonction d'aire valable pour ce même sujet. Des vues radiographiques du conduit vocal et le son associé sont disponibles pour ce locuteur ainsi que des vues de face des lèvres et des moulages du palais dur. Le modèle utilisé est une extension du modèle de fonction d'aire A = αd β de Heinz et Stevens modifié pour que α dépende continûment de la position le long du conduit et de la distance sagittale. Les coefficients du modèle ont été déterminés par un algorithme d'optimisation fondé sur une technique de descente de gradient. Le gradient de l'erreur entre les formants désirés et les formants obtenus est déterminé à l'aide d'un réseau à rétro-propagation incluant le passage de la fonction sagittale à la fonction d'aire ainsi que la propagation des ondes acoustiques. Le fait que le modèle soit déterminé pour des configurations aussi différentes que des voyelles et des consonnes et qu'il soit cohérent aussi bien sur le plan sagittal qu'acoustique devrait assurer que les fonctions d'aire obtenues soient relativement proches de la réalité.
Dans cet article, on considère l'apprentissage des Modèles de Markov cachés (HMM) comme un problème général d'optimisation sous contraintes linéaires. On propose une méthode de projection de gradient, utilisée en programmation non linéaire sous contraintes linéaires, pour trouver les valeurs “optimales” des paramètres du modèle. En appliquant cette méthode classique à l'apprentissage des HMM (dont les densités sont soit des mélanges de densités gaussiennes, soit des densités discrètes), on peut dériver une formulation simple grâce à la structure particulière des contraintes sur les paramètres. On peut alors utiliser une méthode apparentée à l'optimisation classique par descente de gradient pour modéliser de manière plus souple le signal de parole, et fournir un apprentissage plus élaboré des paramètres des modèles de reconnaissance de la parole.
Dans cet article, nous nous intéressons au problème de la segmentation en locuteurs, étape préliminaire nécessaire à plusieurs tâches d'indexation. Le but de la segmentation en locuteurs est d'extraire des segments homogènes ne contenant les paroles que d'un seul locuteur et aussi longs que possible. Dans notre contexte, nous faisons l'hypothèse qu'aucune connaissance a priori des locuteurs ou des caractéristiques du signal n'est à notre disposition (pas de modèle de locuteur, pas de modèle de parole). Nous supposons néanmoins que les personnes ne parlent pas simultanément et que nous n'avons pas de contrainte de temps réel. Nous présentons les techniques de segmentation existantes et nous proposons une nouvelle méthode qui combine les avantages de deux techniques de segmentation. Cette nouvelle méthode de segmentation, appelée DISTBIC, s'opère en deux passes : les changements de locuteurs les plus probables sont tout d'abord détectés et ils sont ensuite validés ou annulés au cours de la deuxième passe. L'avantage de notre algorithme est son efficacité à détecter des changements de locuteurs proches les uns des autres (i.e. espacés de quelques secondes).
Dans les systèmes de reconnaissance de la parole fondés sur les segments, deux classes d'algorithmes de reconnaissance peuvent être distinguées. La première classe contient les systèmes s'appuyant sur le calcul de la densité de probabilité conditionnelle de la séquence de vecteurs acoustiques, étant données la séquence d'unités de parole et la segmentation. La seconde contient ceux qui s'appuient sur le calcul de la distribution a posteriori conjointe d'une séquence d'unités de parole et d'une segmentation possible, étant donnée la séquence de vecteurs acoustiques. Pour les systèmes de cette seconde classe, la distribution a posteriori conjointe peut être représentée sous forme du produit de la probabilité de segmentation et de la probabilité de séquence d'unités. Dans cet article, nous mettons en évidence le rôle joué par la probabilité de segmentation. Après avoir montré que la probabilité de segmentation n'est pas nécessaire dans les systèmes s'appuyant sur le calcul de la densité de probabilité conditionnelle, nous présentons les motivations de l'utilisation de la probabilité de segmentation dans les systèmes s'appuyant sur le calcul de la distribution a posteriori. Nous décrivons la modélisation et l'apprentissage de la probabilité de segmentation dans le cadre de ces systèmes. Nous présentons des expériences menées sur plusieurs tâches de reconnaissance et avec deux systèmes de reconnaissance différents et s'appuyant sur le calcul de la distribution a posteriori. Nous montrons finalement que l'importance de la segmentation est fortement liée aux valeurs des probabilités des unités sur les segments qui ne correspondent pas avec une unité.
Cet article traite de l'apprentissage par analogie dans l'univers des séquences, fondé sur la résolution d'équations analogiques. Il présente une définition de la relation d'analogie entre séquences à partir de la distance d'édition et étudie la résolution d'une équation analogique sur les séquences. Il donne un système de transducteurs à états finis pour calculer les solutions de cette équation, qui ramène également le problème à celui de l'analogie sur un alphabet fini. Il étudie aussi l'analogie sur les alphabets finis et examine deux structures algébriques compatibles avec le calcul des solutions sur les séquences. Pour finir, il présente un algorithme sous-optimal direct pour calculer une solution à une équation analogique sur les séquences.
Cet article présente un système complet de synthèse de la parole à partir du texte pour la langue Grecque, développé à WCL, qui est basé sur la synthèse de formants avec une excitation synchronisée sur le pitch (PSE). Le système utilise une base de données de 140 segments de parole du type Consonne (C), Voyelle (V), CV et CCV. On examine en détail la méthode de concaténation des segments, et la gestion de leur durée en fonction du contexte et des règles de co-articulation formulées pour le Grec. Le synthétiseur à formants est implementé sur une carte DSP32C.
L'objet de cet article est l'étude de la relation entre la notion de complémentation verbale et celle de valence verbale en français moderne. La construction trivalente, dans laquelle un verbe a un sujet et deux compléments d'objet (direct et/ou indirect), est au centre de la réflexion. Une étude des verbes trivalents dans un corpus extrait d'un exemplaire du journal Le Monde permet d'établir la distinction entre trivalence théorique d'un verbe et trivalence actualisée dans un contexte donné.
Dans cet article, nous étudions le problème de l'authentification de signatures à partir des paramètres temporels de l'écriture. Nous proposons ici une méthode qui, après normalisation des signaux, extrait des mesures de dissimilitude entre signatures. Ces mesures sont ensuite traitées par un réseau de neurones. Comme nous ne disposons pas toujours d'imitations de signatures, le problème se présente comme un problème à une classe statistique et l'utilisation d'algorithmes neuronaux classiques nous est donc interdite. Pour pallier ce type d'inconvénient, nous présentons également un nouvel algorithme d'apprentissage de réseau de neurones.
Un analyseur grammatical pour la parole continue traite des treillis lexicaux où les mots hypothèses des phrases correctes ne sont généralement pas alignés de façon parfaite, et où les mots fonctionnels courts peuvent manquer. Afin de résoudre ces problèmes, nous avons mis au point une intéraction bidirectionnelle entre le module de reconnaissance et l'analyseur grammatical. La solution possédant le meilleur score est choisie par l'analyseur grammatical. Nous présentons des résultats obtenus pour des essais de reconnaissance de parole continue indépendant du locuteur à travers le téléphone.
Les changements environnementaux brutaux et massifs, qui affectent généralement de grandes surfaces, doivent être localisés le plus rapidement possible pour gérer l'impact immédiat de ce type d'événements sur les écosystèmes et prévenir les risques associes. Il est donc nécessaire de développer des méthodes permettant d'établir efficacement une carte des changements. Dans cette optique, une approche region quasi non supervisee de detection de changements sur des images satellite a haute résolution spatiale est proposée. Un procédé innovant de selection automatique d'attributs, inspire des procédures de calibrage, optimise la segmentation et la classification. Un nouveau descripteur spatio-temporel, base sur le taux de fragmentation des régions détectées, permet alors de réaliser une classification binaire des changements en zones intactes et altérées. Cette méthode paisse par des étapes de segmentation et de classification mean shift. L'approche a été évaluée en milieu forestier sur un couple d'images satellite multispectrales Formosat-2 acquises avant et après une tempête majeure pour reconnaêtre et cartographier les dégats.
Cet article étudie le problème de la traduction de ('information visuelle en de l'information utilisable par la faculté de langage, c'est-à-dire la question de savoir comment il est possible de parler de ce que l'on voit. Notre hypothèse est qu'il existe une traduction entre le modèle 3D de la théorie de la vision de Marr's (1982) et la structure sémantique/conceptuelle de la théorie sémantique de Jackendoff's (1983). Nous montrons qu'il existe de nombreuses correspondences par lesquelles le codage des objets physiques et de leur emplacement et déplacement peut être coordonné entre ces deux niveaux de représentation, et que ces deux niveaux jouent un rl̂e fondamental dans la compréhension aussi bien visuelle que linguistique.
Une étude sur la perception des consonnes, par lecture labiale seule, ainsi que par lecture labiale et par dispositif vibro-tactile, a mis en évidence une amélioration de la perception du voisement et du lieu d'articulation sous la deuxiéme condition. Les résultats varient d'un patient à l'autreslors de tests portant sur des mots et des phrases. Un patient, sourd de naissance, n'ayant jamais utilisé un appareil auditif, n'a pas amélioré ses performance, tandis qu'un autre ayant toujours fait bon usage d'un appareil auditif a réalisé de meilleures performances pour les deux sortes de matériaux. Au niveau du discours continu, deux sujets ont démontré des améliorations par opposition à un troisième qui n'avait eu qu'une expérience limitée avec un appareil auditif. L'interpretetation des résultats, ainsi que les recherches futures sont discutées.
Le traitement de formes non grammaticales dans lesquelles les contraintes sur les règles de mouvement n'ont pas été respectées a été étudié avec un tâche d'appariement. Curieusement, il n'y a effet des ces formes ni dans le cas de non-respect de la Contrainte du Sujet Spécifié ni dans celui de non respect de la Contrainte de Sous-Jacence. Ces phrases “sur-engendrées” peuvent être traitées aussi facilement que des phrases grammaticales contrôles alors que d'autres types de non-grammaticalité induisent des temps d'appariement plus grands. Il est possible que la tâche d'appariement fasse appel à un niveau de représentation mentale où les phrases surengendrées ne sont pas distinguées des phrases grammaticales. Ceci implique une correspondence étroite entre les mécanismes de dérivation formelle et des aspects de l'opération du processeur du langage.
Les modèles d'apparence permettent d'encoder les variabilités de forme, de pose, et d'illumination dans une seule représentation compacte. Le modèle d'apparence probabiliste de Moghaddam et al. (Moghaddam and Pentland, 1997 ; Tipping and Bishop, 1997b), reposant sur une interprétation statistique de l'Analyse en Composantes Principales (ACP) s'est récemment illustré par ses excellentes performances en détection et en reconnaissance des formes, surpassant de nombreuses autres méthodes linéaires et non linéaires. Ce modèle, performant, se heurte toutefois à une complexité calculatoire importante. Nous proposons, dans cet article, une approximation de ce modèle qui se prête à une mise en œuvre rapide, dans le cadre de schémas d'estimation statistique. Des gains en complexité et en temps de calcul supérieurs à 10, sont obtenus, sans aucune perte de qualité dans les résultats des traitements.
Comme mentionné dans l'article récent de Bourlard et al. (1996) publié dans ce journal, la solution, à ce jour la meilleure et la plus simple, pour introduire des connaissances sur la durée dans les systèmes de reconnaissance de parole standard serait d'imposer une durée minimale (apprise) par segment, simplement en duplicant ou en ajoutant des états qui ne peuvent pas être omis. Dans notre article, nous défendons le point de vue que les performances de reconnaissance peuvent être encore améliorées en incorporant des connaissances “spécifiques” (comme la durée et le pitch) au sein des systèmes. Ceci peut être obtenu en optimisant les modèles acoustiques et de langage, et probablement aussi par un post-traitement entièrement basé sur cette connaissance spécifique. Nous avons utilisé la base de données TIMIT, largement répandue et segmentée manuellement, pour extraire les régularités de durée qui persistent, malgré la grande variabilité inter- et intra-locuteur. Deux approches ont été principalement mises en oeuvre. Dans la première approche, on considère les distributions de durée pour les phones individuels, ainsi que pour des classes plus larges, comme celles spécifiées par les voyelles longues ou courtes, l'accent lexical, la position de la syllable au sein du mot et du syntagme, les consonnes post-vocaliques et la vitesse d'articulation. L'autre approche utilise une analyse hiérarchique de la variance pour étudier la contribution numérique de 11 facteurs différents aux variations de durée. Quant à savoir si l'exploitation de cette connaissance sur la durée dans un étage de post-traitement va réellement améliorer les performances de reconnaissance, ceci reste à montrer. Cependant, conformément à l'esprit du message prophétique de l'article de Bourlard et al, nous considérons ici l'amélioration des performances comme un enjeu d'importance pour l'instant secondaire.
Cet article présente des statistiques en relation avec différents algorithmes de devinement de phonèmes. Les statistiques de ont été obtenues à partir de l'analyse exhaustive d'un lexique de 96,998 mots phonétiques. Les résultats montrent qu'il est possible de formuler un algorithme prenant en compte une connaissance phonotactique détaillée à une large connaissance phonétique, dont le taux de devinement correct de phonèmes atteint 67% en moyenne. Ceci implique, au moins d'un point de vue informatique, que l'anglais parlé présente, au minimum, 67% de redondance. Les résultats montrent aussi que la performance de devinement correct dépend de la longueur et de la position du mot ; le type de phonème et le nombre de phonèmes inconnus dans le mot ont orès peu d'effet sur les résultats finaux.
La décomposition temporelle d'un message vocal fournit une description des paramètres vocaux sous la forme de fonctions-cibles se recouvrant et des vecteurs-cibles correspondants. Les premières peuvent correspondre à des gestes articulatoires et les seconds à des positions articulatoires idéales. Bien que développée pour un codage économique de la parole, cette méthode constitue également un outil intéressant pour extraire des informations phonétiques du signal vocal acoustique. Les paramètres vocaux utilisés par Ataal lorsqu'il a proposé cette méthode (1983) sont les paramètres “log-area”. Notre méthode de décomposition temporelle modifée (1987) utilise ces paramètres comme information d'entrée. Toutefois, la méthode ne se limite pas aux paramètres “log-area” : en principe, on peut également choisir les groupes de paramètres plus couramment utilisés. Dans ce présent article, nous comparons les résultats obtenus avec neuf groupes différents de paramètres vocaux, notamment les paramètres “log-area”, les formants, les coefficients de réflexion et les paramètres de filtre de bande. Le principal critère de qualité du résultat sera la correspondence entre les fonctions-cibles et les phonèmes ou sous-phonèmes. On considérera aussi l'importance phonétique des vecteurs-cibles, quoique de manière moins détaillée. La resynthèse du signal vocal fournira un autre critère ; tant les erreurs de perception que les erreurs physiques fournissent des informations sur l'efficcié du groupe de parametrés pour la décomposition temporelle. On peut conclure de ces expériences que les parametrés “log-area” constituent le groupe de paramétres le plus approprié pour la décomposition temporelle. Les paramétres de filtre de bande donnent de meilleurs résultats à certains égards, mais compte tenu des propriétés relatives à la resynthèse, ce groupe n'est pas considéré comme étant le meilleur.
La structure prosodique de la parole est le résultat d'interactions complexes entre différents niveaux d'organisation et à l'intérieur de ces niveaux. La hiérarchie intonative, manifestée essentiellement par la nature des marqueurs prosodiques est le produit d'interactions et de contraintes entre ces niveaux d'organisation. Je présente ici un modèle de prédiction et d'interprétation de l'organisation des énoncés en parole spontanée. Ce modèle est un système hiérarchique composé de six modules : (1) sémantique-pragmatique, (2) syntaxique, (3) phonotactique, (4) accentuel, (5) d'ajustement sémantique, (6) rythmique. Pour un énoncé donné, le système détermine (i) les niveaux de frontières et les marqueurs prosodiques sur la base de l'information sématique, et de la structure syntaxique définie sur la base de la nouvelle syntaxe X barre(s) ; (ii) les structures accentuelles et rythmiques conditionnées par les contraintes phonotactiques. L'étape phonétique qui devrait transformer les étiquettes abstraites en valeurs acoustiques n'est pas présentée ice. Ce modèle peut et doit être développé ultérieurement. Les améliorations à apporter concernent (a) la nature des règles, (b) les différents aspects de la conversation, (c) certains problèmes théoriques. En ce qui concerne ce dernier point, les développements récents et en cours de la théorie X barre(s) sont susceptibles d'apporter des modifications positives dans l'interprétation des règles qui permettront de rendre compte de certains faits encore inexpliqués. Toutefois, dans son état actuel, le modèle fournit des résultats très convaincants, puisqu'il prédit l'organisation intonative et accentuelle avec un haut degré de fiabilité.
Les différentes régles trouvées ont donné lieu à un logiciel baptisé PHONEMIA, premier module d'un ensemble plus vaste qui a pour but la synthése à partir d'un texte éerit. Ce programme a également été utilisé pour définir les diphones du gree moderne.
Ce papier discute la nature des données qui forment l'entrée des descriptions linguistiques, et particulièrement en ce qui concerne la plus ou moins grande artificialité de ces données. L'article préconise d'accorder beaucoup plus d'importance dans les travaux de linguistique aux données de parole naturelle en incluant même de la parole spontanée. Une partie majeure de l'article est consacrée à la discussion générale de quelques préliminaires à l'étude de la variation linguistique en parole naturelle.
Nous présentons une approche inspirée par la biologie du système auditif humain, qui prédit l'intelligibilité d'enregistrements directes de paroles ou après transmissions sous différentes conditions de bruit propre, réverbérations, et autres déformations. La méthode est basée sur un modèle auditif qui analyse les effets du bruit sur les modulations conjointes de temps et fréquences, présentes dans la parole. Par ailleurs, cette méthode analyse la capacité d'un canal à transmettre fidèlement ces modulations. Les effets sur les modulations sont convertis en un indice des modulations spectro-temporelles, appelé STMI. La validité de cet indice est établie en comparant ses prédictions à celles du STI classique ; ainsi qu'aux résultats expérimentaux des taux d'erreurs de sujets humains qui écoutent de la parole contaminée par des combinaisons de bruit propre et de réverbération. Nous démontrons également que le STMI est capable de manipuler des conditions encore plus sévères, comme les déformations non-linéaires, tels les décalages et autres instabilités des phases ; conditions auxquelles le STI classique s'avère être insensible.
Il s'agit de la structure de treillis utilisée dans la méthode Navigala, méthode de reconnaissance de symboles basée sur un parcours (de type arbre de décision) dans le treillis. De ce lien de fusion nous déduisons un algorithme d'extraction d'un arbre de décision à partir d'un treillis dichotomique. Nous finissons par des expérimentations visant à comparer, pour de la reconnaissance de symboles, les performances des arbres de classification et des treillis construits avec la méthode Navigala.
L'efficacité des algorithmes de reconnaissance des formes est fortement conditionnée par la définition adéquate des formes censées structurer les données. Le modèle multigramme fournit un outil statistique permettant de retrouver des régularités séquentielles de longueur variable dans des flux de données. Dans cet article, nous présentons une formulation générale de ce modèle, applicable à des flux, uniques ou multiples, de données, ayant des valeurs discrètes ou continues. La première évaluation du modèle concerne l'extraction, à partir de données textuelles, d'un répertoire de séquences de lettres de longueur variable, dans lesquelles tous les espaces entre mots ont été supprimés. Il apparaı̂t que les séquences de lettres inférées lors de cette procédure totalement non supervisée sont clairement liées à la structure morphologique du texte. Le modèle est ensuite utilisé pour inférer, directement à partir des données de parole, un ensemble d'unités acoustiques de longueur variable. Des fichiers audio contenant des exemples d'unités acoustiques sont fournis avec cet article afin de montrer leur consistance d'un point de vue auditif. Cet article rend également compte des résultats d'expériences utilisant ces unités, définies acoustiquement, pour la reconnaissance de parole continue.
Les réseaux bayésiens sont d'excellents outils de modélisation de l'incertain grâce à leur représentation graphique claire et aux lois de probabilités conditionnelles définies sur ce graphe. La structure et les probabilités sont généralement données par un expert. Dans ce papier nous nous sommes intéressés à l'apprentissage direct de la structure de tels réseaux à partir de bases de données. Nous avons adopté une approche bayésienne qui permet de retrouver une adéquation entre la structure et les données. Notre point de départ a été deux algorithmes : K2 de Cooper et Herskovits et B de Buntine. Nous avons alors développé un nouvel algorithme K2B qui profite des avantages de ces deux algorithmes tout en essayant d'atténuer leurs inconvénients. L'implémentation de K2B a donné naissance à Alexso, qui arrive à trouver un compromis entre représentativité et simplicité de la structure.
Le but de cet article est de présenter le schéma d'une théorie sémantique fondée sur l'analogie entre le langage naturel et le langage programmation de l'ordinateur. On décrit un modéle unique de compréhension et de perception de phrases pour illustrer la métaphore centrale “compiler et executer” qui sous-tend les sémantiques des méthodes. On réanalyse á la lumiére de la théorie des méthodes (procedural theory) le rôle de la connaissance générale interne au lexique et du mécanisme arbitrant les restrictions sélectives.
Trois projets concernant la reconnaissance auditive des mots et la structure de lexique sont décrits. Le premier a été conçu pour tester expérimentalement certaines prédictions spécifiques dérivées de MACS, un modèle de simulation de la théorie de la cohorte. A l'aide d'un paradigme d'amorçage, des indications en faveur d'une activation acousticophonétique dans la reconnaissance de mots ont été obtenues dans trois expériences. Le second projet décrit les résultats d'analyses de la structure et de la distribution de mots dans le lexique en utilisant une large base de données lexicales. Des statistiques sur des espaces de similitudes pour des mots de haute et basse fréquence ont été appliquées à des données antérieures sur l'intelligibilité de mots présentés dans le bruit. Il apparaît que les différences d'identification sont liées à des facteurs structuraux à propos des mots spécifiques et à la distribution des mots similaires dans leurs voisinage. Le troisième projet développe une nouvelle théorie de la reconnaissance de mots connue sous le nom de Théorie d'Affinement Phonétique. Cette théorie basée sur des données propres à l'auditeur humain, a été conçue pour incorporer certaines des connaissances acoustico-phonétiques et phonotactiques dont disposent les auditeurs humains sur la structure interne des mots et leur organisation dans le lexique, ainsi que sur la manière dont ils utilisent cette connaissance pour reconnaître les mots. La théorie s'appuie sur plusieurs techniques nouvelles formalisant des stratégies de recherche de réduction spatiale à partir de grands vocabulaires dans des situations où seules des informations partielles sur le contenu phonétique d'un mot sont disponibles. Dans l'ensemble, nos résultats aboutissent à des découvertes nombreuses, nouvelles et importantes sur la relation entre la perception de la parole et la reconnaissance auditive des mots, deux domaines de recherche qui ont traditionellement été dans le passé sous des perspectives très différentes des nôtres.
L'étude de la mémoire est un grand défi, peut-être le plus grand dans les sciences biologiques. La mémoire implique des changements dans une infime fraction d'un ensemble extrêmement vaste d'éléments, une conclusion qui rend formidable la tâche de trouver ces changements en utilisant les technologies courantes. Que peut-on faire pour contourner cet obstacle dans les recherches neurologiques de l'apprentissage ? Une voie de réponse devenue particuliérement productive au cours des années récentes est d'étudier les phénoménes d'apprentisage dans des systémes “modéles” relativement simples. L'idée est d'extraire des principes de base de ces modéles dans lesquels les détails moléculaires et anatomiques peuvent être étudiés, puis de les utiliser en analysant l'apprentissage dans les régions supérieures du cerveau. Nous présentons dans cet article les progrés en cours et les nouveaux concepts dérivés de cette approche sur des modéles animaux simples.
Nous décrivons un analyseur stochastique pour la compréhension de la parole spontanée dans une application de demande d'informations pour les transports ferroviaires en langue française. Un autre facteur important concerne la création, par une méthode d'étiquetage itérative, d'un corpus de représentations sémantiques sur la base desquelles le modèle stochastique peut être établi. L'analyseur a été testé sur les transcriptions corrigées des requêtes formulées par des utilisateurs et sur les transcriptions exactes du module de reconnaissance.
Un sonar latéral de cartographie enregistre les signaux qui ont été rétrodiffusés par le fond marin sur une large fauchée. L'analyse des statistiques de ces signaux rétrodiffusés montre une dépendance à ces angles de rasance, ce qui pénalise fortement la segmentation des images en régions homogènes. Pour améliorer cette segmentation, l'approche classique consiste à corriger les artefacts dus à la formation de l'image sonar (géométrie d'acquisition, gains variables, etc.) en considérant un fond marin plat et en estimant des lois physiques (Lambert, Jackson, etc.) ou des modèles empiriques. L'approche choisie dans ce travail propose de diviser l'image sonar en bandes dans le sens de la portée ; la largeur de ces bandes étant suffisamment faible afin que l'analyse statistique de la rétrodiffusion puisse être considérée indépendante de l'angle de rasance. Deux types d'analyse de texture sont utilisés sur chaque bande de l'image. La première technique est basée sur l'estimation d'une matrice des cooccurrences et de différents attributs d'Haralick. Le deuxième type d'analyse est l'estimation d'attributs spectraux. La bande centrale localisée à la moitié de la portée du sonar est segmentée en premier par un réseau de neurones compétitifs basé sur l'algorithme SOFM (Self-Organizing Feature Maps) de Kohonen. Cette nouvelle méthode de segmentation est évaluée sur des données réelles acquises par le sonar latéral Klein 5000. Les performances de segmentation de l'algorithme proposé sont comparées avec celles obtenues par des techniques classiques comme l'algorithme K-moyennes (K-means).
L'un des principaux défis posés à l'industrie du jeu vidéo est de mettre en scène des personnages non joueurs (PNJ) dont les comportements sont crédibles. Or, les recherches montrent que les émotions jouent un rôle déterminant dans le comportement des individus. Pour augmenter la crédibilité des comportements des PNJ, nous proposons dans cet article un modèle de la dynamique des émotions prenant en compte la personnalité et les relations sociales du personnage. Nous présentons tout d'abord les travaux de la littérature sur les émotions, la personnalité et les relations sociales en informatique et en sciences humaines et sociales. Nous soulignons l'influence de la personnalité sur le déclenchement des émotions et des émotions sur la dynamique des relations sociales. En nous appuyant sur ces travaux, nous proposons un modèle dynamique de l'état socio-émotionnel et son implémentation sous la forme d'un outil simple qui permet de simuler la dynamique de l'évolution des émotions et des relations sociales des PNJ suivant leur personnalité et leur rôle.
Cet article expose de récentes recherches sur les techniques de contrôle de la qualité ainsi que de conversion de la voix. Après un bref rappel de quelques résultats scientifiques de base sur les corrélations acoustiques dans le caractère individuel de la voix, nous décrivons les dernières techniques de traitement de la parole en matière de contrôle de la voix et de reproduction des caractéristiques du locuteur. Nous nous concentrons plus particulièrement sur une description des méthodes non paramètriques d'identification spectrale segmentée des caractéristiques des diffèrents locuteurs et nous introduisons á ce sujet plusieurs types d'identifications spectrales, qui ont évolué de pair avec les techniques d'adaptation au locuteur développées en reconnaissance de la parole.
Cet article est consacré à l'utilisation des statistiques d'ordre quatre en Traitement d'Antenne. Après avoir rappelé brièvement les propriétés des moments et cumulants, on propose un formalisme algébrique pour exprimer commodément les statistiques d'ordre deux et quatre de variables aléatoires vectorielles. Nous définissons ainsi la « quadricovariance » qui est une représentation exhaustive des cumulants du quatrième ordre, et ses « matrices propres » qui en fournissent une décomposition orthogonale. Dans notre écriture, il y a une forte analogie entre la covariance et la quadricovariance, ce qui suggère une extension au quatrième ordre des méthodes développées pour exploiter le second ordre. On obtient aussi avec « 4-MUSIC » une capacité théorique de détection supérieure au nombre de capteurs. Elle passe de N − 1 pour 2-MUSIC à 2(N − 1) pour 4-MUSIC sur une antenne linéaire de N capteurs équidistants. Cette capacité peut être portée jusqu'à N(N − 1) sources en choisissant une antenne non uniforme. La notion de matrice propre permet aussi d'obtenir une solution directe au problème de « séparation de sources » où il s'agit de séparer un mélange vectoriel de composantes statistiquement indépendantes.
Pour évaluer la composante d'émission d'une voix synthétique intégrée dans un système complexe, on a besoin de méthodes et de méthodologies qui ne sont pas fournies par les tests d'évaluation standards et indépendants d'une application. Ces derniers analysent la parole synthétique surtout dans sa forme (structure de surface) et seulement en second lieu dans la signification qui lui est attribuée (structure profonde). Pour obtenir un cadre d'évaluation fiable pour un système d'application, les aspects fonctionnels de la parole doivent être pris en compte. Dans cet article, on présente deux études d'acceptabilité des dimensions qualifiantes de la voix synthétique utilisée dans différents scénarios d'application. Pour des raisons de dépenses (temps et coûts), on s'est limité à une évaluation en laboratoire. La première étude évalue la voix synthétisée d'un système de navigation et d'information de trafic, intégré dans une voiture. La deuxième étude est relative à la voix synthétisée d'un système de dialogue naturel. Les résultats montrent que les différentes dimensions contribuent à des degrés variables à l'acceptabilité globale, en fonction du scénario d'application. Il est donc nécessaire d'utiliser des méthodes d'évaluation orientées vers les applications pour identifier les dimensions qui lui sont spécifiques. Les caractéristiques de l'application qui demandent une modélisation dans les tests d'évaluation sont discutées, et des exemples sont fournis pour les deux domaines considérés.
Le problème type du classement par masses de véhicules à partir de mesures d'accélérations et de vitesses est traité. Une méthode de discrimination optimale pour ce problème est construite en considérant 4 niveaux : choix de l'espace de recherche (sélection de variables par algorithmes évolutionnaires ou par heuristiques, analyse discriminante), choix du critère de discrimination (critère Bayésien ou de marge large), choix de la complexité et choix des paramètres des algorithmes.
Dans la production de consonnes occlusives par les mal-entendants, les erreurs de voisement sont beaucoup plus fréquentes que celles de lieu d'articulation. Le problème vient de la complexité phonétique de certains types d'occlusives homorganiques. Les sourds angophones éprouvent des difficultés particulières à prononcer les /ptk/ aspirés qui requièrent un décalage temporel entre l'occlusion orale et l'ouverture du laryyx. Les données présentées dans cet article monrrent que les sourds francophones éprouvent des difficultés similaires pour produire les /bdg/ prévoisés qui demandent un d'elai temporel précis entre le début des vibrations laryngées et la détente de l'occlusion orale. La succession rapide de ces deux gestes articulatoires permet de soutenir la voix jusqu'à la fin de l'occlusion, ce qui a une importance décisive pour la perception du voisement. Nos données montrent par ailleurs que les locuteurs qui parviennent à produire correctement le prévoisement sont généralement ceux qui parviennen à percevoir correctement le trait de voisement. Bienque le lieu d'articulation des occlusives ne soit pas mieux perçu que leur catégorie de voisement, la plupart des sujets modérément sourds de cette expérience peuvent parfaitement produire les distinctions de lieu. Le rôle des rétroactions perceptives dans la maîtrise des gestes articulatoires est abordé dans la discussion.
Plus spécifiquement on avance que la construction des propositions relatives rend conflictuels les principes d'origine structurelle et ceux d'origine perceptuelle dans les langues de type SOV. La manière dont une proposition relative est structurée dans un langage SOV est un obstacleàson calcul perceptuel. Ce conflit serait un des facteurs majeursàl'origine du changement diachronique d'un langage d'une typologie OVàun langage d'une typologie VO.
Ce système est totalement interactif et ouvert en ce sens qu'il permet l'intégration facile de nouveaux paramètres.
Une présentation unifiée des méthodes de séparation de sources fondées sur les moments d'ordre supérieur est proposée. L'approche considérée part du recensement systématique des paramètres caractéristiques de toutes les méthodes, comme : les familles d'hypothèses statistiques concernant les données ; les catégories de modèles conjecturés (standards ou doublement orthogonaux) ; les critères de séparation (d'indépendance), qui conduisent à la restitution des sources, énoncés à partir de moments ou de cumulants ; les principes effectifs des méthodes de séparation (démarches directes utilisant une matrice de restitution des sources, démarches indirectes ou globales identifiant au préalable ou simultanément d'autres entités propres aux sources, amplitudes etc…). De manière générale, il est établi que l'ensemble de ces méthodes conduisent à restituer, non pas un jeu de sources uniques, mais plutôt les éléments appartenant à l'intersection de deux classes d'équivalence. La première appelée classe du second ordre est associée à tous les vecteurs aléatoires de même matrice de covariance. La seconde qualifiée de classe d'indépendance, doit son existence à l'invariance de l'indépendance mutuelle de variables aléatoires dans toute opération de permutation- homothétie.
La problématique abordée dans cet article est celle de la conception automatique d'agents autonomes devant résoudre des tâches complexes mettant en œuvre plusieurs objectifs potentiellement concurrents. Nous proposons alors une approche modulaire s'appuyant sur les principes de la sélection d'action où les actions recommandées par plusieurs comportements de base sont combinées en une décision globale. Dans ce cadre, notre principale contribution est une méthode pour qu'un agent puisse définir et construire automatiquement les comportements de base dont il a besoin via des méthodes d'apprentissage par renforcement incrémentales. Nous obtenons ainsi une architecture très autonome ne nécessitant que peu de réglages. Cette approche est testée et discutée sur un problème représentatif issu du "monde des tuiles"
De grandes bases de données sont nécessaires pour tester des modèles de production et de perception à différents niveaux linguistiques. La gestion de telles bases de données pose d'importants problèmes à la fois pour étiqueter le signal de parole et pour accéder au matériel stocké. De manière à simplifier certains de ces problèmes, nous avons créé un système d'analyse de la parole. Les signaux de parole sont archivés dans des fichiers de la taille d'une phrase. Ces fichiers sont segmentés et transcrits de manière semi-automatique à partir d'une transcription phonétique de la phrase. La transcription est générée par les règles lettres-sons de notre système de conversion texte-parole. La base de données est plutôt orientée vers la recherche de type acoustico-phonétique que, par exemple, vers l'évaluation de systèmes de reconnaissance. L'accent a donc été mis sur la souplesse et la spécification linguistique des requêtes de recherche dans la base de données. Dans notre solution — inhabituelle — à ce problème, nous utilisons pour l'accès aux données la structure de nos règles de synthèse qui est similaire aux notations de la phonologie générative. Grâce à une formulation sous forme de règles, on peut identifier facilement les segments de parole satisfaisant certaines conditions relatives au contexte. On peut recueillir directement des informations sur la durée durant la recherche dans la base de données. Des programmes d'analyse spectrale utilisant une variété de représentations spectrales sont également disponibles.
Le taux de reconnaissance de la parole contnue réalisé par des algorithmes de focalisation dépend de facteurs tels que la perplexité, la structure de recombinaison du modéle linguistique, la difficulté du vocabulaire, la qualité du décodeur acoustico-phonétique et la stratégie d'élagage choisie. Un modèle statistique qui prend l'ensemble de ces facteurs en considération est dèveloppé ici. Un algorithme itératif est présenté qui calcule la distribution des différents chemins parcourus ainsi que le taux d'erreurs par phrase qui en résulte.
Il n'est donc guère étonnant qu'on puisse finalement se demander à quel genre de problème répond la présence centrale du concept de représentation dans la linguistique de Gustave Guillaume. Si « promouvoir le langage à l'existence, c'est le promouvoir à la représentation − ce sans quoi rien n'existe pour l'esprit » , ce n'est pas en raison de la nature du langage que le linguiste recourt au concept de représentation mais parce qu'il existe une certaine façon d'être un linguiste qui consiste à poser le langage comme un objet pour l'esprit, attitude qui se distingue, parmi bien d'autres solutions, de celle consistant par exemple à le voir comme un objet ou un « paramètre » de la vie sociale.
L'article décrit le développement et l'évaluation du module de conversion graphème-phonème d'un système complet de synthèse en temps réel développé à l'Université de Macquarie. L'évaluation du système a été grandement facilitée par l'usage de statistiques pondérées qui reflètent la fréquence d'occurrence de chaque mot contenu dans les corpus LOB et Brown de l'anglais. Ces statistiques sont déduites d'une base de données de mots test qui inclut pour chaque mot toutes les prononciations acceptables de l'australien (selon le dictionnaire de Macqaurie) ainsi que leur fréquences d'après LOB et Brown. Ces scores facilitent les décisions quant aux modifications des règles et du lexique afin d'obtenir une amélioration maximale des performances globales sur un texte ordinaire.
Le centre d'intérêt dans la recherche de la reconnaissance automatique de la parole (ASR), parti des mots isolés, s'est engagé vers le discours conversationnel. Par conséquence, la quantité de variation de prononciation présente dans le discours dont nous rapportons les résultats a graduellement augmenté. La variation de prononciation détériorera la performance d'un système ASR si l'on n'en rend pas compte. C'est probablement la raison principale pourquoi la recherche dans le domaine de la modélisation de la variation de prononciation pour ASR a augmenté récemment. Dans cette contribution on fournit une vue d'ensemble des publications sur ce sujet, et en particulier on référe aux articles de cette edition spéciale et aux contributions présentées dans les sessions qui ont eu lieu a 'Rolduc'. Puis les questions d'évaluation et de comparaison sont adressées. Une attention particulière est prêtée à certains des facteurs les plus importants qui rendent difficile de comparer les différentes méthodes d'une maniere objective. Enfin quelques conclusions sont tirées quant à l'importance de l'évaluation objective et de la façon dans laquelle elle pourrait être effectuée.
Cet article stipule que la spécification des traits d'un ça déficient dans une variété de français suisse permet de rendre compte de sa distribution syntaxique. Contrairement aux clitiques accusatifs ordinaires le/la/les, cette forme pronominale ne présente pas de trait de genre, de nombre et de Cas, mais possède un trait aspectuo-temporel locatif. Les arguments qui appuient l'hypothèse de l'absence de Cas pour le ça déficient sont les suivants : 1. (i) l'impossibilité de le redoubler, 2. (ii) l'impossibilité pour ça d'être un enclitique et 3. (iii) son interaction avec la topicalisation et la dislocation à droite qui diffère de ce qui est observé avec les clitiques ordinaires dans ce contexte. Une autre distinction entre les traits de ça et ceux des pronoms ordinaires réside dans le statut catégoriel double de ça en tant que D et DP. On observe que la composition en traits de ça exige une quantification générique événementielle. Cette interprétation est toujours disponible avec les verbes transitifs événementiels mais avec les inaccusatifs et les statifs transitifs, cette lecture est bloquée au temps présent. Nous montrons que c'est la non-ambiguïté aspectuelle de ça, i.e. le fait qu'il n'apparaisse que dans des contextes de quantification générique événementielle, qui est responsable de séquences agrammaticales telles que ∗Je ça aime dans cette grammaire.
Le but de cet article est d'étudier différentes techniques de lissage de modèles de langage et différents algorithmes de construction de modèles de langage à base d'arbres de décision. Pour cela, nous construisons des modèles de langage pour des caractères écrits (lettres) à partir du Brown corpus. Nous considérons deux classes de modèles pour le processus de génération du texte : le modèle de langage n-gram, et différents modèles de langage à base d'arbres de décision. Dans la première partie de l'article, nous comparons les algorithmes de lissage les plus couramment appliqués au modèle de langage n-gram. L'algorithme “bottom-up deleted interpolation” donne les meilleurs résultats pour le lissage du modèle de langage n-gram, dépassant de façon significative la technique de lissage “back-off” pour de grandes valeurs de n. Dans la seconde partie de l'article, nous considérons différents algorithmes de développement d'arbres de décision. Parmi eux, un algorithme de type classification K-means aboutit aux meilleurs résultats pour la construction des arbres de décision. Cependant, le modèle de langage n-gram fournit de meilleurs résultats que les modèles de langage à arbres de décision pour la modélisation du langage écrit. Nous croyons que cela est dû à la nature prédictive des chaı̂nes de caractères, qui semble être naturellement modélisée par les n-grams.
Par `annotation linguistique' nous désignons toute notation descriptive ou analytique appliquée à des données langagières brutes. Ces données brutes peuvent être des signaux temporels – enregistrements audio, vidéo et/ou physiologiques – ou du texte. Les notations ajoutées peuvent être des transcriptions de toute nature (des traits phonétiques aux structures du discours), des catégories grammaticales ou sémantiques, une analyse syntaxique, l'identification d' `entités nommées', l'annotation de coréférences, etc. Malgré les efforts entrepris pour créer des formats et des outils adaptés à de telles annotations et pour diffuser des bases de données linguistiques annotées, le manque de standards largement acceptés devient un problème critique. Les standards proposés, lorsqu'ils existent, se concentrent sur les formats de fichiers. Cet article se concentre au contraire sur la structure logique des annotations linguistiques. Nous passons en revue une grande variété de formats d'annotations existants et en dégageons une structure conceptuelle commune, le graphe d'annotation. Ceci fournit un cadre formel pour construire des annotations linguistiques, les tenir à jour et y effectuer des requètes, tout en restant cohérent avec de nombreux autres structures de données et formats de fichiers.
Dans les représentations visuelles du signal acoustique de la parole telles que l'oscillogramme ou le spectrogramme, la parole apparaît comme des séries concaténées de phénomènes acoustiques qui varient dans leur spectre, en amplitude et en durée. Les résultats d'une grande variété d'expériences psychiacoustiques, de la fusion auditive au masquage temporal en passant par les études sur la fluence (streaming) peuvent être interprétées comme pertinentes pour la découverte des capacités auditives utilisées dans l'écoute de ces séquences de parole. Un échantillonnage de ces résultats expérimentaux servira à illustrer les relations entre la psychoacoustique des phénomènes non verbaux et ceux de la parole de manière à suggérer des lignes de conduite pour le travail futur sur les configurations temporelles non verbales afin d'aboutir à une psychophysique plus complète des sons complexes.
Dans le cadre du déploiement des réseaux cellulaires de radiocommunication, il est nécessaire de prédire la zone de couverture des émetteurs. Pour un site d'émission, la technique classique consiste à appliquer un modèle de propagation des ondes électromagnétiques en différentes positions définies selon un pas spatial constant. Toutefois, cette méthode conduit à un temps de calcul très important voire prohibitif dans des environnements géographiques complexes. Des approches existent pour réduire le temps de calcul ; elles consistent à simplifier la complexité du modèle de propagation utilisé. La démarche proposée dans cet article est complémentaire. En effet, elle est indépendante du modèle et porte sur la réduction du nombre de points d'application de ce modèle. La méthode présentée s'appuie sur une hypothèse dont la vérification nécessite la segmentation de signaux mesurés par un récepteur mobile et un logiciel d'analyse électromagnétique de l'environnement de mesures. Ainsi, l'objectif est de segmenter le signal reçu en intervalles correspondant à des combinaisons particulières de phénomènes physiques. Pour cela, une représentation proposée par Mallat et Zhong appelée « représentation en maxima d'ondelettes » est étudiée. Cette décomposition permet l'étude des dérivées d'une fonction à différentes échelles. Nous proposons une méthode de segmentation de signaux basée sur le chaînage des maxima à travers les échelles. Ce chaînage permet de sélectionner les discontinuités les plus importantes du signal et ainsi de le segmenter.
Nous présentons une méthode originale de classification de trajectoires dans des séquences vidéos pour la reconnaissance d'événements dynamiques. Les Modèles de Markov Cachés (MMC) sont utilisés afin de représenter chaque trajectoire et d'évaluer leurs similarités. Nous avons pu valider notre méthode en la comparant à plusieurs autres méthodes telles que la comparaison d'histogrammes, une méthode utilisant les Séparateurs à Vaste Marge (SVM) ainsi qu'une méthode de MMC utilisant des modélisations par mélanges de gaussiennes. Des descripteurs appropriés, invariants à la translation, à la rotation ainsi qu'au facteur d'échelle sont calculés sur les trajectoires, puis exploités dans une représentation par MMC. Une méthode statistique est également proposée pour le choix du nombre d'états pour la modélisation par MMC choisie.
Cet article décrit comment les performances d'un reconnaisseur de parole continue (CSR) pour le néerlandais ont été améliorées en modelant la variation de prononciation. Nous proposons une procédure générale pour modeler cette variation. En bref, elle consiste à ajouter des variantes de prononciation au lexique et dans le ré-apprentissage des modèles de phones en utilisant des modèles de langage auxquels les variantes de prononciation ont été ajoutées. D'abord, des variantes de prononciation à l'intérieur de mot ont été produites en appliquant un ensemble de cinq règles phonologiques optionnelles aux mots dans le lexique de base. Ensuite, un nombre limité de processus entre-mots ont été modelés, en utilisant deux méthodes différentes. Dans la première approche, des processus entre-mots ont été modelés en ajoutant directement les variantes “entre-mots” au lexique, et dans la deuxième approche ceci a été fait en utilisant des “mots-multiples”. En conclusion, la combinaison de la méthode qui se limite aux processus à l'intérieur de mot avec les deux méthodes “entre-mots” a été testée. La performance de base était un taux d'erreur de 12.75% mots (WER) ; comparée à cette performance de base, une amélioration petite mais significative de 0.68% dans WER a été obtenue avec la méthode 'à l'intérieur de mot', tandis que les deux méthodes d'entre-mots en isolation ont mené à des petites améliorations non significatives. La combinaison de la méthode “à l'intérieur de mot” avec la méthode 2 “entre-mots” a mené au meilleur résultat : une amélioration absolue de 1.12% dans le WER a été trouvée comparée à la ligne de base, qui est une amélioration relative de 8.8% dans le WER.
Il a été montré que des techniques d'analyse typologique hiérarchique constituent des outils puissants pour construire des références indépendantes du locuteur dans les systémes de reconnaissance de la parole basés sur des méthodes de distorsion dynamique de l'échelle temporelle (DTW). Dans cet article, nous proposons un algorithme d'analyse typologique qui génère, en considérant simultanément le spectre et la durée, des patrons de références pour des systémes basés sur des modéles markoviens (HMM) à densité continue. De meilleures performances de reconnaissance sont ainsi démontrées dans le cadre d'une tâche de reconnaissance de chiffres utilisant la base de données TI/NBS de chiffres connectés.
Cet article présente, d'une manière informelle, l'historie de la recherche sur la synthèse de la parole depuis la machine à parler de Von Kempelen jusqu'à la prédiction linéaire.
Dans cet article, nous proposons un cadre d'étude pour rendre compte de certaines variations mélodiques dans la parole. Ce cadre consiste à définir des points cibles de F 0 et les régles gouvernant leurs réalisations. Les cibles sont définies comme les plus petites unités opératives associées à des unités fonctionnelles d'un point de vue linguistique ; elles sont comparables à des phonèmes segmentaux. Les règles d'implémentation sont fondées sur des contraintes articulatoires influant la production des contours mélodiques. En raison de ces contraintes, la réalisation d'une même cible peut résulter en diverses formes de F 0 qui ne reflètent que partiellement les cibles sous-jacentes. Nous discuterons également de l'intérêt de ce cadre d'étude pour la compréhension de certains contours de F 0, incluant les variations liées au recouvrement et à l'anticipation, la descente graduelle, la déclinaison, et l'alignement des pics de F 0. Enfin, nous considèrerons les interactions possibles entre les cibles locales et non-locales.
Après avoir rappelé le principe de rehaussement par filtrage polynomial de l'image du relief Braille numérisée, il est décrit la méthode de reconnaissance choisie pour ce type particulier de forme d'objets. Cette méthode est basée sur la projection de chaque graphème sur deux axes orthogonaux. Il est décrit les cinq érapes de reconnaissance de chaque rangée de relief Braille qui tiennent compte de ses irrégularités de forme, et qui exploitent une méthode de maximum de vraisemblance. Le relevé de la dispersion des positions des axes des graphèmes permet de donner une estimation théorique du taux de réussite de reconnaissance pour des reliefs fabriqués manuellement. Le taux vérifié dans la pratique est voisin de 99 %.
La description des langues en danger est cruciale pour la typologie linguistique, comme source possible d'information sur des types de structures non attestés dans les langues préalablement décrites. Inversement, une bonne information sur l'état des connaissances en typologie est particulièrement utile aux linguistes qui décrivent des langues jusque là peu décrites, ce qui est le cas de la plupart des langues en danger. Toutefois, les typologues ne doivent pas perdre de vue qu'il y a un problème à mettre sur le même plan, dans la recherche de généralisations typologiques, des langues toujours bien vivantes et largement décrites, et d'autres dont l'unique description est impossible à vérifier ou à compléter. En outre, on ne peut pas travailler sur des langues moribondes comme sur des langues qui sont encore le moyen de communication usuel d'une communauté, et on peut avoir des doutes sur la représentativité des données recueillies dans ces conditions, surtout dans des domaines comme la syntaxe.
Dans cet article, nous introduisons un nouveau concept : les transversaux cubiques sur te treillis cube d'une relation d'attributs catégories. La découverte des transversaux cubiques est un sous-problême de la recherche des transversaux d'un hypergraphe car il existe un plongement d'ordre du treillis cube vers le treillis des parties des attributs binaires (valeurs). En se basant sur ce fait, nous proposons un algorithme par niveau pour l'extraction des minimaux transversaux cubiques. Nous appliquons ce concept à la recherche d'une représentation condensée de l'espace de version émergent, une nouvelle fonctionnalité OLAP. L'espace de version émergent représente la différence de deux cubes de données uni-compatibles ou l'ensemble des tuples les plus fréquents dans cette différence. Finalement, nous proposons un algorithme par niveau avec partition et fusion pour le calcul des bordures de l'espace de version émergent sans calculer les deux datacubes associés.
Des variations fines de la qualité de la voix (phonatoire) peuvent révéler des aspects de l'humeur et de l'attitude du locuteur, et forment donc un aspect important du style langagier. Cet article illustre une recherche en cours sur les corrélats dans la source vocale de certaines de ces différences de qualité. Les qualités de voix incluaient les voix modale, soufflée, chuchotée, tendue, lâche et grinçante décrites par Laver (1980). Les analyses présentées mettent l'accent sur un mot extrait d'un passage de prose lu avec ces qualités. La méthode principale utilisée pour analyser la source de voix impliquait un filtrage inverse de l'onde de parole. Pour quantifier les paramètres de la source, un modèle de la source de voix à quatre paramètres (le modèle LF) était mis en correspondance avec l'onde obtenue par filtrage inverse. Des analyses fréquentielles de l'onde de parole, basées sur des sections spectrales à bande étroite et sur un moyennage spectral ont également été effectuées. Des comparisons détaillées des données mesurées directement à partir de l'onde glottique et de celles mesurées sur la parole à la sortie ont permis d'entrevoir des phénomènes qui n'auraient pas été inférés à partir d'une seule de ces deux analyses. Les résultats mettent à jour aussi bien des differences importantes entre les qualités qu'une variation considérable au sein d'une seule qualité. Les données pourraient également se révéler utiles pour la resynthése, qui constitue un outil important pour tester les aspects perceptifs de la qualité vocale ; entre autres la “coloration” d'attitude et d'émotion qui peut être associée à des qualités vocales particulières.
Cet article expose une méthode simple pour accélérer les calculs des k plus proches voisins. Malgré l'augmentation sensible du taux d'erreur, cette méthode devrait trouver sa place dans des applications qui souhaitent intégrer un algorithme de classification et où la contrainte de vitesse d'exécution est forte.
Cet article présente un nouvel outil théorique fondé sur la Théorie de l'Information afin de réaliser une évaluation d'un outil de classement plus fine que les mesures classiques. Nous travaillons dans le cadre de la Reconnaissance d'objets naturels complexes et compliqués. Nous montrons que les réseaux connexionnistes permettent l'apprentissage d'une fonction de fusion optimisée selon la nature du problème et la structure du Système de Reconnaissance. Nous montrons aussi que la répartition de l'information sur chaque outil de classement contribue à une meilleure reconnaissance. Une approche de type génétique est alors conçue pour adapter la partition de l'espace des paramètres relativement à l'ensemble des outils disponibles.
Nous présentons “Transcriber”, un outil d'aide à la création de corpus de parole, et nous décrivons des éléments de son développement et de son utilisation. Transcriber a été conçu pour permettre la segmentation manuelle et la transcription d'enregistrements de nouvelles radio-diffusées de longue durée, ainsi que l'annotation des tours de parole, des thèmes et des conditions acoustiques. Cet outil très portable, reposant sur le langage de script Tcl/Tk et des extensions telles que Snack pour les fonctionnalités audio et tcLex pour l'analyse lexicale, a été testé sur différents systèmes Unix et sous Windows. Le format de données respecte le standard XML avec un support d'Unicode pour les transcriptions multilingues. Distribué sous license libre pour encourager la production de corpus, faciliter leur échange, augmenter le retour d'expérience des utilisateurs et motiver les contributions logicielles extérieures, Transcriber est utilisé depuis plus d'un an dans plusieurs pays. Suite à cette utilisation, de nouveaux besoins sont apparus comme le support de formats de données supplémentaires, de la vidéo, et un meilleur traitement de la parole conversationnelle. En utilisant le modèle des graphes d'annotation formalisé récemment, l'adaptation de l'outil vers de nouvelles tâches et le support de différents formats de données sera facilité.
Cet article explore plus avant la question de savoir à partir de quel moment les musulmans commencèrent d'ajouter des imprécations divines à la mention des Francs, sujet que nous avions déjà abordé dans cette revue. Cette pratique mit un certain temps à s'imposer dans les usages après l'arrivée des Francs dans le Levant et nous avions fait valoir que les premières invocations n'avaient pas collé aux préoccupations des contemporains, à la différence de celles employées par la suite, plus en phase avec les besoins de l'époque. Depuis la publication de cet article, nous avons eu l'opportunité de travailler sur le manuscrit original de notre source la plus ancienne, lequel a révélé que son auteur avait bel et bien recouru à une forme d'imprécation qui allait devenir populaire ultérieurement, mais que la manière dont il avait procédé demeurait suffisamment ambiguë pour en empêcher l'adoption par d'autres auteurs.
Si les mouvements articulatoires peuvent être calculés, les paramètres articulatoires qui représentent le mouvement des organes articulatoires pourraient être des traits utiles pour la reconnaissance de la parole. Une méthode efficace pour l'estimation de ces mouvements est décrite ainsi que son application à la reconnaissance de la parole. Nous décrivons d'abord une méthode dite de modèle apparié et nous évaluons diverses mesures de distance spectrale. Les résultats indiquent qu'en moyenne la meilleure mesure est celle de la distance cepstrale d'ordre élevé. Ensuite, les parametres articulatoires sont utilisés pour la reconnaissance des voyelles. Il est montré que l'adaptation du modèle en fonction de la longueur estimée du conduit vocal normalise efficacement les différences inter-locuteurs. Enfin, les commandes motrices des mouvements articulatoires sont estimées en tenant compte de la dynamique articulatoire, ce qui permet de reconnaître les voyelles émises de manière continue grâce à ces commandes. Une part considérable des effets de coarticulation peut aussi être compensée à l'aide de ces commandes estimées, ce qui rend la méthode utile pour la reconnaissance de la parole continue.
Conformément aux principes du modèle de la séquence des tons le contour F0 est analysé comme une suite de valeurs de temps et fréquence discrètes qui sont liées par des fonctions de transition. Leur position est représentée par rapport à la syllabe et l'étendue de la fréquence fondamentale. Toutes les étiquettes tonales sont examinées sur la base de ces paramètres. Les résultats sont transformés en une série de règles qui rend possible la génération d'un contour F0. Tones and Break Indices (ToBI), un système servant à la transcription des structures tonales de l'anglais américain, fournit un inventaire d'étiquettes tonales et une collection d'énoncés d'exemples pour l'analyse. Des énoncés de ToBI et de la Boston Radio News Corpus ont été utilisés pour l'évaluation des règles de génération : on a déterminé l'erreur quadratique moyenne et la corrélation entre les contours générés et les contours originaux et, dans une expérience de perception des locuteurs natifs ont estimé que la qualité des contours resynthétisés s'avérait naturel dans l'ensemble. De même ils n'ont constaté que de petites différences par rapport aux originaux correspondants.
Une approche variationnelle et robuste est proposée pour le recalage de signaux 1D et appliquée au calcul des géodésiques de formes pour la classification. L'approche est ensuite étendue au recalage d'images de séquences de formes. Cette approche de recalage basé-géométrie est plus adaptée aux images peu contrastées pour lesquelles le recalage basé-intensité trouve toutes ses limites. Une étude de validation est menée sur des signaux et des images issus d'archives biologiques marines, qui présentent une grande variabilité interindividuelle, où les approches de recalage sont d'un intérêt tout particulier.
Le but de cette étude a été d'examiner les capacités de compréhension de parole de quatre patients sourds après implantation de la prothèse cochléaire Nucleus 22-canaux (N-22). Les expériences ont été menées dans deux conditions. D'abord, des tests d'intelligibilité (voyelles isolées, mots bisyllabiques et parole continue, en listes fermées et ouvertes) ont été menés avec les frontières de fréquence par défaut (DFBs) du processeur de parole de la prothèse. Ces DFBs de chaque électrode, spécifiées par le logiciel du système, sont censées avoir été optimisées pour l'Anglais. Les patients ont été alors de nouveau testés avec ces valeurs de fréquence s modifiées (MFBs) sur le même matériau de parole. Pour chaque classe de sons de parole, les résultats obtenus dans les deux cas ont été comparés. Les meilleures performances observées, au moins sur certaines classes de sons, avec les fréquences modifiées (MFBs) suggèrent que l'ajustement, en fonction de la langue, de la carte des associations fréquence-électrode de la prothèse N-22 peut améliorer, au moins en partie, la compréhension de parole.
Les tests d'articulation standards ne sont pas toujours suffisamment sensibles pour être à même de discriminer entre échantillons de parole hautement intelligibles. On peut augmenter la sensibilité de ces tests en brouillant ces échantillons avec du bruit. De cette manière, de petites différences d'intelligibilité sont amplifiées dans les tests d'articulation. Nous avons utilisé deux tests pour évaluer l'intelligibilité de neuf techniques différentes de codage de la parole : un test d'articulation conventionnel et un test d'interférence monosyllabique adaptatif. Ces deux tests ont abouti à différentes types de réponses. Ces divergences peuvent être expliquées par le fait que des méthodes de codages différentes encodent des propriétes acoustiques et phonétiques différentes. Certaines de ces p ropriétés sont plus facilement masquées par du bruit que d'autres. Nos résultats montrent que dans le cas de la parole synthéique des différences d'intelligibilité ne sont pas toujours amplifiées par l'addition de bruit : elles peuvent même disparaître.
Etudiée dès l'Antiquité, la rhétorique, ou art de l'argumentation, a été tour à tour thème central d'enseignement, puis objet de nombreuses critiques. Elle a été finalement réhabilitée en tant que support fondamental au développement des sciences et techniques de la communication. En effet, ces dernières décennies, l'apparition des systèmes de dialogues, de génération du langage naturel et les systèmes multi-agents autour d'un noyau central d'argumentation ainsi que des développements de modélisations basées sur des approches formelles et informelles de la représentation de l'argumentation ont étayé cette réhabilitation. Cet article propose une synthèse de ces travaux. Il s'attache à mesurer l'adéquation de différentes approches à la modélisation de l'argumentation naturelle et souligne les difficultés qui restent à surmonter. Le système de planification de l'argumentation APLA basé sur le modèle MARINE, développé par les auteurs dans le but d'atténuer ces difficultés est également présenté dans cet article.
L'analyse de parole montre que les transitions du second formant dans des séquences voyelle–voyelle n'ont pas toujours la même durée que celle des transitions du premier formant et qu'elles ne sont pas toujours synchronisées. De plus, les transitions des formants ont souvent des directions différentes de leurs cibles finales. Pour étudier si ces déviations de linéarité et de synchronisation sont perceptivement significatives, des tests de perception on été conduits avec la paire de voyelle /a/–/i/. On a montré que des retards entre les transitions du premier et du second formant inférieur à 30 ms ne sont pas perçus, ainsi que des différences en durée inférieur à 40 ms si les premier et second formants débutant ou bien se terminent en même temps. Si la transition du second formant est symétrique dans le temps par rapport au premier formant, des différences inférieur à 50 ms sont tolérées. Des excursions dans la forme de la transition du second formant inférieures à 500 Hz ne sont pas perçues. Ces résultats suggèrent que la plupart des déviations de linéarité et de synchronisation trouvées des séquences naturelles de voyelle–voyelle ne sont pas perceptivement significatives.
Grâce aux méthodes transformationnelles, l'acceptabilité est devenue la mesure et le système de classification par excellence de la linguistique. De tous les paramètres possibles qui peuvent influencer les résultats de ce test, le problème soumis au lecteur dans cet article est celui de l'interprétation sémantique. L'auteur essaie de démontrer la nécessité de dissocier tout facteur extra-linguistique (y compris l'univers du discours de celui qui parle, la culture à laquelle il appartient, l'importance de certains facteurs de connaissance ou ignorance du monde) d'une interprétation hypothétique linguistiquement pertinente étroitement liée à la syntaxe et à la morphologie. Les concepts sémantiques extra-linguistiques sont 'naturels', peuvent être facilement évoqués et filtrent la recherche des concepts sémantico-linguistiques beaucoup plus abstraits, moins connus et probablement inconscients. Ceci représente la limite qu'il faut établir dans la sémantique entre ce qui appartient au domaine de la linguistique et ce qui n'y appartient pas, c'est-à-dire entre ce qui doit, et ce qui ne doit pas être considéré comme appartenant à la grammaire générative. Il faut, d'ailleurs, insister à ce sujet sur le besoin qui existe dans la linguistique de contrôler et donc de varier les univers du discours qui peuvent modifier l'acceptabilité d'une phrase donnée. Dans cet article, la discussion est centrée sur les divers usages du verbe 'planter'.
Dans le domaine de l'analyse de scène en vision par ordinateur, un compromis doit être trouvé entre la qualité des résultats attendus et les ressources allouées pour effectuer les traitements. Une solution flexible consiste à utiliser un système de vision adaptatif capable de moduler sa stratégie d'analyse en fonction de l'information disponible et du contexte. Dans cet article, nous décrivons comment concevoir et évaluer un système d'attention visuelle conçu pour interagir avec un système de vision de façon à ce que ce dernier adapte ses traitements en fonction de l'intérêt (de la saillance) de chaque élément de la scène. Nous proposons également un nouvel ensemble de contraintes nommé PAIRED, permettant d'évaluer l'adéquation du modèle à différentes applications. Nous justifions le choix des systèmes dynamiques par leurs propriétés intéressantes pour simuler la compétition entre différentes sources d'informations. Nous présentons enfin une validation à travers différentes métriques montrant que nos résultats sont rapides, hautement configurables et pertinents.
L'hypothése de la classe fermée affirme que les mots fonctionnels jouent un roˆle privilégiédans les processus syntaxiques. On fait, en production de langage, la conjecture suivante : les mot fonctionnels sont intrinséques et non superposés au squelette de la phrase ; autrement dit, ils peuventeˆtre identifiésáce squelette. Deux expériences ont testécette hypothéseál'aide de la procédure de facilitation syntaxique. Dans chacune de ces expériences, les sujets avaient tendanceáproduire des phrases de structure syntaxique semblableácelle des phrases qui leurétaient présentées aupravant ; les structures des phrases générées par les sujets variaent en fonction des différences dans les structures des phrases qui leurétaient présentées. Les changements intervenant parmi leséléments de la classe fermée de ces phrases n'avaient aucun effet sur cette tendance au deláde l'impact des changements de structures. Ces résultats suggérent que les morphémes libres de la classe fermée ne sont pas des composants inhérents au squelette structural de la phrase.
Dans les situations de communication quotidiennes, toutes les parties du message parlé ne sont pas prononcées de manière également claire. En particulier, les mots portant une lourde charge d'information sémantique sont mis en évidence par le locuteur. L'objet de cette étude est de savoir comment cela est réalisé dans la parole spontanée et dans la parole lue et si la connaissance ainsi acquise pourra être appliquée à la synthèse pour en améliorer le naturel et l'acceptabilité. En introduisant un modèle “crêtes et paliers”, nous examinons des aspects spectraux et temporels de mots mis en évidence et de mots non mis en évidence extraits de matériaux identiques, spontanés et lus après transcription orthographique. On a enregistré un locuteur masculin professionnel dont la voix avait également servi pour la composante à diphones du programme national hollandais de synthèse de parole. Pour un certain nombre de paramètres acoustiques, on peut conclure qu'il y a une différence nette, à la fois en “valeurs de crêtes” et en “valeurs de paliers”, entre les deux styles de parole naturelle, bien que des contrastes comparables apparaissent dans les deux styles. Let résultats de nos mesures en parole naturelle ont été comparés aux données fournies par les mêmes textes synthétisés à l'aide du système à diphones hollandais de conversion texte-parole. Au cours d'une expérience pilote dans laquelle les aspects temporels de la parole synthétique ont été modulés, il a été demandé aux sujets de juger du naturel et de l'intelligibilité afin de pouvoir déterminer le point de départ d'une future évaluation de la synthèse texte-parole incluant des contrastes “crêtes et paliers”.
L'article décrit un détecteur de formants simple destiné à être utilisé avec implant cochléare multicanaux. Treize patients implantés se sont entraînés avec un processeur qui traitait la fréquence du deuxième formant, la fréquence fondamentale et l'enveloppe du signal de parole (F 0 F 2). Neuf patients ont été entrînés avec un processeur qui présentait la fréquence du premier et deuxième formant, la fréquence fondamentale et l'amplitude du premier et deuxième formant (F 0 F 1 F 2). Le groupe F 0 F 1 F 2 a obtenu de meilleures performances en discrimination et en reconnaissance de mots et de phrases à l'audition seule. Au cors d'une tâche de détection de parole, le même groupe a également démontré une amélioration significativement plus forte lorsque l'audition et la lecture labiale étaient associées qu'en lecture labiale seule. Un étude de reconnaissance de spondée en présence de bruit à l'aide de la seule audition a aussi indiqué que l'information fournie par F 1 produisait une amélioration équivalente à une augmentation de 5 dB du rapport signal sur bruit.
Nous étudions dans cet article le problème de la combinaison de classifieurs binaires. Cette approche consiste à résoudre un problème de discrimination multi-classes, en combinant les solutions de sous-problèmes binaires ; nous nous intéressons aux stratégies opposant chaque classe à chaque autre, et chaque classe à toutes les autres. La combinaison est considérée ici du point de vue de la théorie de Dempster-Shafer : les sorties des classifieurs sont ainsi interprétées comme des fonctions de croyance, conditionnelles ou exprimées dans un cadre plus grossier que le cadre initial. Elles sont combinées en calculant une fonction de croyance consistante avec les informations disponibles. Les performances des deux approches sont comparées à celles d'autres méthodes et illustrées sur divers jeux de données.
La complexité des relations entre l'information acoustique du signal de la parole et les catégories phonétiques des locuteurs adultes est bien connue. On recherche si les mêmes relations complexes existent entre les signaux de la parole et les catégories perceptives prelinguistiques chez les nourrissons. Pour deux classes de relations la manière dont se font la catégorisation de l'information pour la parole est virtuellement identique pour les adultes et les nourrissons. Ces résultats indiquent que les bébés possèdent des capacités perceptives linguistiquement pertinentes finement ajustées qui facilitent et orientent leur acquisition du langage.
Nous avons adapté un algorithme de reconnaissance de mots pour une application en téléphonie mobile. Pour ce faire, nous avons évalué plusieurs manières de générer des vecteurs de traits en utilisant deux bases de données collectées dans une petite voiture roulant à 120 km/h. Les bases de données contiennent des chiffres et des séquences de chiffres pour 10 locuteurs utilisant un combiné téléphonique ou agissant en mode “main libre”. Dans un premier temps, nous avons utilisé comme vecteur de traits les coefficients d'un banc de filtres redimensionné linéairement. Avec un apprentissage sur des mots isolés et en utilisant le combiné, cette approche donne un taux d'erreurs de 6% sur une séquence de 7 chiffres. La deuxième approache remplace les coefficients du banc de filtres par des coefficients d'énergie, l'énergie étant redimensionnée logarithmiquement. Ces résultats obtenus dans un environnement simulé ont été vérifiés dans une automobile avec notre appareillage.
Nous proposons dans cet article une nouvelle méthode d'extraction de caractéristiques appliquée à la reconnaissance de phonèmes. Le modèle proposé : le codage neuronal prédictif (NPC pour Neural Predictive Coding) et ses deux déclinaisons NPC-2 et DFE-NPC (Discriminant Feature Extraction - NPC), est un modèle connexionniste de type perceptron multicouches (PMC) basé sur la prédiction non linéaire du signal de parole. Nous montrons qu'il est possible d'améliorer les capacités discriminantes d'un tel codeur en exploitant des informations de classe d'appartenance phonétique des signaux dès l'étape d'analyse. À ce titre, il entre dans la catégorie des extracteurs DFE déjà proposés dans la littérature. Dans cette étude, nous présentons une validation théorique du modèle dans l'hypothèse de signaux respectivement non bruités et bruités (bruit additif gaussien). Les performances de l'extracteur NPC pour la classification de phonèmes sont comparées avec celles obtenues par les méthodes traditionnellement utilisées en extraction de caractéristiques sur des signaux des bases Darpa Timit et Ntimit. Les simulations présentées montrent que les taux de reconnaissance sont nettement améliorés, en particulier dans le cas de phonèmes de la langue anglaise fréquents mais réputés délicats à catégoriser. Enfin, une application en reconnaissance de mots isolés et petit vocabulaire est présentée dans le but de montrer comment l'on peut insérer les paramètres NPC dans une application de reconnaissance à l'aide d'un système mixte ANN-HMM (Artificial Neural Networks - Hidden Markov Models).
Comme reporté à IVTTA-94, le service de numérotation vocale (`VoiceDialingSM') de NYNEX a été d'abord déployé dans la région de NYNEX à la mi 1993. Depuis il a été déployé dans les régions de plusiers opérateurs Bell et de nouveaux développements importants ont été effectués. Un de ces développements a été la transition, commencée en 1995, d'une implantation hardware d'un algorithme de reconnaissance à base de DTW vers une implantation sur un DSP à usage général d'un algorithme de reconnaissance à base de HMM ayant des densités continues multigaussiennes. Ceci a permis une extension du service d'une simple reconnaissance de noms en mode dépendant du locuteur en ajoutant la reconnaissance en mode indépendant du locuteur des chiffres en continu et des mots de commande. Ce papier décrit les principaux travaux conduits lors de cette transition et fournit une description plus détaillée des composantes du système de reconnaissance de la parole.
Pour résoudre ce problème, nous proposons un nouveau modèle de langue, les “n-grammes multi-classes composites”. Dans les classes de mots, les commutations possibles en chaque position sont retenues comme attribut des n-grammes, et une classe différente est créée pour chaque position. Les n-grammes multi-classes sont étendus en n-grammes multi-classes composites en considérant les n-grammes de longueurs supérieures les plus fréquents qui représentent les suites de mots les plus fréquentes. Lors des expériences réalisées, nous avons constaté d'une part une diminution de la perplexité de 9,5% et d'autre part une diminution de 16% du taux d'erreurs en nombre de mots non reconnus en reconnaissance de la parole, ce avec une réduction de 40% de la taille des paramètres par rapport aux trigrammes conventionnels.
Le locus de la consonne et le nucleus sont significativement plus proches dans les mots de la parole spontanée que dans les mêmes mots lus, dans les syllabes non proéminentes que dans les syllabes proéminentes, dans les mots apparaissant pour la seconde fois que dans les mots nouveaux. Ces resultats peuvent refléter des différences de coarticulation, qui peuvent être dues à un effet d'anticipation plus grand de la voyelle sur la consonne précédente et/ou un degré plus élevé d' “undershoot” du F 2 dans la parole spontanée. La distance du locus au nucleus semble dépendre en partie de la durée de l voyelle ce qui confirme le modèle de Lindblom (1963), mais elle paraît aussi être influencée par d'autres facteurs tels que la situation de communication.
Le bruit perçu dans les segments du signal vocal est du aux irregularites des oscillations de la glotte et au bruit additif en présence d'un fuseau glottique. On peut déterminer la contribution du bruit à l'aide du SNR (signal-to-noise ratio). Dans la première partie de cette étude, nous discutons les avantages et les inconvénients des méthodes de mesure du SNR pratiquées couramment. Dans la deuxième partie, nous présentons une nouvelle méthode pour mesurer le SNR qui reconstruit les oscillations harmoniques par un algorithme utilisant le principe de la synthèse par analyse. Enfin, nous étudions les voyelles synthétiques et le signal vocal émis par des locuteurs normaux et dysphoniques. La mesure du SNR ne permet qu'une différenciation globale des pathologies. Les problèmes de la reconnaissance des effets de bruit sont également discutés.
Nous décrivons une méthode de lecture automatique des chaînes de caractères sur cartes scannées. Cette méthode prend en compte les chaînes orientées qui sont fréquentes sur les cartes. L'application se décompose en trois modules principaux : analyse des particules connexes, chaînage des hypothèses, recherche des caractères connectés. Les résultats obtenus semblent suffisants pour passer au stade opérationnel à condition d'utiliser quelques règles syntaxiques de haut niveau pour améliorer la détection des cas douteux.
Cet article décrit notre système de reconnaissance de mots isolés à grand vocabulaire Dspell. Le système utilise un modèle à base de diphones et un algorithme de décodage des mots très efficace. Le système est implanté sur le multiprocesseur emma-2∗ d'ELSAG.dspell permet un apprentissage rapide et exhibe un taux de reconnaissance élevé avec un temps de réponse très court sur des vocabulaires allant jusqu'à 10,000 mots.
Cet article traite du problème du débruitage de la parole pour les radiocommunications mobiles. Nous proposons ici de nouvelles méthodes de réduction de bruit qui se sont avérées satisfaisantes à la suite de tests informels d'écoute : en approche monovoie, une technique de “soustraction spectrale modifiée” incluant la surestimation du bruit dépendant de la fréquence et la segmentation du signal est proposée. Dans le cas bivoies où les bruits sont décorrélés ou faiblement corrélés, l'approche développée fait apparaître l'intérêt de la fonction de cohérence entre signaux en tant que critère de discrimination entre une source localisée et une source diffuse ; une nouvelle technique basée sur la mesure de la cohérence entre observations est utilisée pour filtrer les observations ; utilisée comme outil de détection d'apparition du signal dans le cas de bruits décorrélés, cette fonction présente également un grand intérêt pour toute méthode de débruitage nécessitant un système de détection. Ces méthodes sont finalement comparées en fonction de leur complexité de mise en œuvre et de leurs performances. Il apparaît que la soustraction spectrale modifiée est prometteuse dans le cas de bruits stationnaires et que dans le cas de bruits non stationnaires et décorrélés, la méthode basée sur la cohérence est plus attractive.
Un test d'intelligibilité a permis d'évaluer différents synthétiseurs à partir du texte à l'aide de vingt phrases sémantiquement imprédictibles générées dans chacune des cinq structures syntaxiques retenues. Ces structures de base ont été définies dans le cadre d'une méthodologie translinguistique visant à la génération de corpus dans un contexte européen. Les réponses des vingt auditeurs ont été également analysées. Leurs distributions montrent une forte relation entre la proportion des phrases (p s) et celle des mots (p w) correctement retranscrits. Le rapport de leurs logarithmes r = Log(p s)/Log(p w) apparaît comme un indice robuste de la complexité d'un message oral. Des données extraites de la littérature confirment l'hypothèse selon laquelle plus une phrase contient d'informations contextuelles (sémantiques, syntaxiques, etc.), plus faible est cet indice r. Dans cette optique, l'index r pourrait être relié au nombre d'unités de décision qu'un auditeur doit traiter en écoutant une phrase. Les synthétiseurs de parole distordent ici la compréhension des phrases. Or, les omissions et les erreurs n'obéisser pas à la loi binomiale qui régitrait leur distribution si l'on considérait un modèle simplifié dans lequel les unités auraient la même probabilité indépendente d'être correctement identifiées. L'analyse des divergences entre l'observation et la théorie issue de ce modèle simpliste explique clairement le fait que les relations linguistiques entre unités corrigent des mots “théoriquement incompris” et entachent d'erreur des mots “théoriquement compris”. Ce phénomène de correction/distorsion dépend essentiellement du contenu linguistique des phrases, lequel peut être quantifié au moyen de l'indice r suggéré. Cet indice présente également des variations du second ordre dues à d'autres facteurs tels que la compétence des sujets, leur entraînement, ou le niveau de dégradation acoustique du message.
Dans la plupart des systèmes d'identification de locuteurs on suppose que tous les locuteurs donnent lieu à la même matrice de covariance. Cette hypothèse conduisant à un classificateur linéaire simplifie l'algorithme de classification. Cependant, les sujets ne diffèrent pas seulement par leurs vecteurs caractéristiques moyens mais aussi par leurs matrices de covariance. L'utilisation d'une matrice de covariance individuelle, propre à chaque sujet, conduit à un classificateur quadratique. Si on fait l'hypothèse que la matrice de covariance est commune à tous les locuteurs, un espace d'indices optimal unique peut être déterminé. Avec une matrice de covariance individuelle, chaque personne est reconnue dans un espace d'indices propres. La procédure de reconnaissance exige par conséquent la comparison d'un locuteur inconnu avec des référence définies dans des espaces différents. L'utilisation du classificateur quadratique avec des espaces d'indices individuels augmente considérablement la précision du processus de reconnaissance alors que l'exigence en mémoire supplémentaire est négligeable. Le classificateur quadratique proposé basé sur des vecteurs caractéristiques optimisés individuellement a été testé à l'aide d'un système d'identification utilisant six locuteurs masculins. Pour une mesure de séparation donnée, ce classificateur améliore la performance de deux fois par rapport à l'approche conventionnelle.
Les comparaisons interlangues peuvent éclaircir les niveaux de traîtement impliqués dans l'exécution des tâches psycholinguistiques. Par exemple, si l'on observe le même type de réponses, que les sujets comprennent le matériel expérimental ou non, on peut en conclure que ces résultats ne reflètent point des processus linguistiques de haut-niveau. Dans cette expérience des auditeurs français et anglais ont accompli deux tâches - localisation de clics et détection de clics accélérée - en phrases françaises, et en phrases anglaises. Ces phrases étaient bien appareillées au niveau de leur structure syntaxique et phonologique. Les clics étaient localisés avec plus de précision dans les mots à contenu que dans les mots fonction en anglais, mais non en français. Les deux groupes d'auditeurs ont manifesté ces mêmes résultats ; ce qui semble indiquer que les processus linguistiques de haut-niveau ne jouaient aucun rôle dans la performance des auditeurs. En conclusion on peut dire que la détection de clics est une tâche qui est sensible principalement aux effets de bas-niveau, par exemple des effets acoustiques, et donc ne se prête guère à l'étude des processus linguistiques.
Cet article présente une étude des coordinations temporelles entre les différents articulateurs du Langage Parlé Complété. Le Langage Parlé Complété (LPC) est un augment manuel de la lecture labiale. Il est composé de clés digitales réalisées à l'aide de la main placée à différentes positions particulières sur le côté du visage afin de désambiguïser des syllabes de type CV. Le mouvement de la main, le geste des lèvres ainsi que le signal acoustique ont été analysés à partir de l'enregistrement d'une codeuse diplômée en LPC prononçant et codant un corpus constitué d'un ensemble de syllabes. L'expérience I analyse la position de la main en relation avec le mouvement des lèvres et le son correspondant. Les résultats montrent que le mouvement de la main peut débuter jusqu'à 239ms avant le début de la réalisation acoustique de la consonne de la syllabe CV. La main atteint sa cible durant la consonne et bien avant la cible vocalique aux lèvres. Les résultats montrent que la clé digitale se met en forme durant le déplacement de la main d'une position à l'autre. Les deux expériences montrent ainsi une anticipation du geste de la main sur celui des lèvres. Le contrôle de l'information sur la consonne et sur la voyelle transmise par la main est discuté dans le cadre de la coarticulation en parole. Enfin la coordination temporelle observée entre les articulateurs du LPC et le son correspondant a permis de définir des règles pour le contrôle d'un système audiovisuel délivrant des syllabes CV en Français.
La biométrie, qui consiste à identifier un individu à partir de ses caractéristiques physiques ou comportementales, connaît depuis quelques années un renouveau spectaculaire dans la communauté du traitement du signal. Elle a aussi reçu une attention accrue de la part des médias depuis les tragiques événements du 11 septembre 2001. Dans cet article nous introduisons tout d'abord la notion de biométrie. Nous décrivons l'architecture d'un système biométrique ainsi que les métriques utilisées pour évaluer leur performance. Nous donnons un bref aperçu des technologies biométriques les plus courantes et des moyens de les fusionner pour obtenir des systèmes multimo-daux. Nous présentons enfin les applications possibles de la biométrie.
Cet article etude comment les participants a une conversation coordonnent leur utilisation et lent interprétation du langage dans un contexte restreint. Cette etude repose sur l'analyse de descriptions spatiales qui sont apparues au cours de 56 dialogues obtenus en laboratoire en utilisant un jeu de labyrinthe sur ordinateur specialement conçu a cette fin. Nous avons effectué deux types d'analyses. D'abord, une analyse sémantique des differents types de description qui indique comment des couples de locuteurs développent differents schémas linguistiques associés a differents modèles mentaux de la configuration du labyrinthe. Ensuite, une analyse de la manière dont les communicants coordonnent la mise sur pied de leurs descriptions. Les résultats de cette etude nous paraissent suggérer que le traitement du langage au cents d'un dialogue est pent-titre régi par des principes locaux d'interaction qui ont reçu pen d'attention de la part des psychologues et des linguistes jusqu'à aujourd'hui.
Une nouvelle combinaison de méthodes de codage pour les systèmes de transmission à 64 kbit/s pour des situations typiques de vidéotéléphone est étudiée. La structure du codeur est basée sur un codeur standard hybride DCT avec prédiction temporelle. L'image est divisée bloc par bloc en zones changées et inchangées. Un vecteur de mouvement de précision supérieure à la taille d'un point image est calculé et transmis pour chaque bloc de la zone changée. Pour l'analyse progressive, l'erreur de prédiction par bloc est calculée dans l'image entière. Seuls les blocs avec les plus grandes erreurs de prédiction sont mis à jour par une transformée discrète en cosinus (DCT) et une quantification adaptive perceptuelle. Le nombre de blocs mis à jour par DCT dépend des bits restant après la transmission de l'information de gestion. Le codeur est régulé par l'analyse progressive de l'erreur de prédiction et non par rétroréglage á l'aide de mémoires-rampons. La résolution spatiale du signal de source est réduite en deux étapes pour empêcher la saturation du codeur par une trop grande activité entre deux trames.
On propose que l'idée tous les F sont G est souvent interprétée comme “neutre au point de vue structure” c'est-à-dire comme tous, F, G sans distinction sujet-prédicat. Dans une premiére expérience, on demandeàdes enfants agés de 7–8 ans et de 11–12 ans ainsi qu'àdes adultes d'agir selon des instructions du type “Faîtes un baˆtiment oùtous les blocs jaunes sont carrés”. Dans une seconde expérience faite avec des meˆmes groupes d'aˆge, on présente comme prémise majeur de syllogismes, des propositions de la forme tous les sont G qui varient selon les relations d'inclusion des faits exprimés. Les résultats montrent qu'il y a, sous certaines conditions, présence d'interprétations “neutres au point de vue structure” chez les adultes aussi bien que chez les enfants. Les résultats indiquent aussi l'existence chez tous les sujets d'un mode de “traitement pragmatique” qui devient moins nécessaire avec l'aˆge. Dans les interprétations pragmatiques, le sens est déterminéplus par les relations factuelles connues entre les choses représentées par les mots que par les relations grammaticales entre les mots.
Dans cette contribution, nous proposons d'évaluer la qualité de différents algorithmes de réduction de la palette couleur d'une image. Deux techniques originales sont particulièrement détaillées (avec deux variantes pour chacune d'elles) : l'une basée sur la transformation du boulanger et l'autre employant la matrice des palettes locales. Dans la campagne d'évaluation, les résultats de ces deux techniques sont comparés à ceux d'algorithmes standards tels que « median cut » , « octree » et « split & merge » . L'évaluation se veut à la fois objective (utilisation d'une métrique et de descripteurs locaux de qualité) et subjective (utilisation d'expériences psycho-visuelles). En effet, l'usage seul d'une métrique n'intègre pas la notion de HVS (Human Visual System). La couleur étant davantage considérée comme propriété perceptuelle que comme donnée quantitative, une mesure classique ne peut décrire correctement l'altération que subit une image lors d'une réduction des couleurs. Les résultats de la campagne d'évaluation psycho-visuelle montrent une fois de plus que les métriques classiques sont souvent en contradiction avec la perception humaine de la couleur.
Cet article présente une étude portant sur la capacité de la prosodie à les frontières du discours subséquentes. Plus spécifiquement, on a étudié si la fin proche d'une description d'itinéraire peut être signalée en avance par des caractéristiques mélodiques et temporelles. L'experience 1 fait apparaître que les auditeurs sont capables d'estimer, sur la base de ces propriétés prosodiques, à quelle distance de la fin d'une description se trouve un énoncé donné. Toutefois, la porteé de cette prédiction prosodique est relativement limitée : les auditeurs ne peuvent estimer la position absole dans le discours que pour les deux dernières phrased du monologue analyse. L'experiénce 2 a été menée pour explorer systématiquement, par un test en parole de synthèse, dans quelle mesure les propriétés mélodiques et de durée suffisent pour influencer les jugements de finalité.
Au cours de ces dernières années, les systèmes de reconnaissance automatique de la parole ainsi que les systèmes de synthèse de la parole à partir du texte ont atteint une qualité leur permettant d'être intégrés à des applications quotidiennes. Un problème demeure cependant quant à ces applications, à savoir, l'expansion fréquente des inventaires de phones d'une langue spécifique à des phones issus d'autres langues, problème d'autant plus important dans un monde où les services automatisés de la parole multilingues sont un souhait. Cet article examine la nature de l'expansion des phones en suédois. Nous discuterons du statut de ces phones, et, puisque ces phones supplémentaires n'ont pas une fonction phonémique (ou allophonique), nous proposons le terme de `xénophones'. Les résultats montrent que peu d'informants ont recours à une rephonématisation complète, l'expansion xénophonique étant la règle, bien que la distribution soit inégale selon les phonèmes, allant de ceux produits par la plupart des informants à ceux produits par très peu d'informants. Parmi les facteurs explicatifs potentiels analysés, tels les origines régionales, le sexe, l'âge et le niveau d'étude, ce dernier s'avère de loin être le plus important.
Dans tout dialogue, il existe au moins deux sortes de frontiéres entre unités de discours. Un premier type de frontière signale la fin d'une unité de thème du discours ; l'autre tupe de frontiére indique la fin d'un tour de parole. Ces deux types de frontiéres ne coïncident pas nécessairement, car le locuteur peut souhaiter passer à autre sujet sans vouloir être interrompu par son interlocuteur. Pour tester si des indices prosodiques peuvent permettre de distinguer, de fçon non ambigue, les frontières de théme des frontières de tour de parole, une série d'expériences de production de parole a été menée. Les paramètres finalité-thème et finalité-tour de parole étaient manipulés de façon indépendante. Les indices visuels ainsi que les indice verbaux non-prosodiques ne pouvaient pas être utilisés. Dans la condition la plus complexe, le locuteur devait donner des indices clairs de finalité-thème sans perdre la parole prématurément. Dans cette condition, les locuteurs évitent d'utiliser une intonation basse pour les frontières de thèmes intra-tour de parole, et les réservent pour les frontières de thème qui sont aussi des fins de tour de parole. Les auditeurs confrontés à des extraits hors contexte ont pu distinguer de façon fiable les unités de thème finales de tour de parole des unités non finales. Il est intéressant de remarquer que, même quand les parties finales des unités de thème supprimées, les auditeurs continuaient à faire la distinction entre les expressions de fin de tour de parole et de non-fin de tour de parole. Apparemment, ils se basaient sur d'autres indices prosodiques, plus globaux. Ceci a été observé également pour des unités minimalement et maximalement incomplètes.
Dans le passé, les enseignants dependaient de l'observation des sujets en classe pour decider de l'importance de diverses questions d'ordre pedagogique. L'apprentissage des langues automatisé (ALA) nous permet de poser ces questions de manière bien plus rigoureuse. Nous pouvons utiliser un système ALA comme base, traçant toutes les reponses de l'utilisateur et controlant strictement les informations fournies. Nous avons utilisé le système Fluency [Proceedings of Speech Technology in Language and Learning, 1998, p. 77] de cette manière pour examiner la question du choix de la voix que l'utilisateur doit imiter lors de l'apprentissage de la prononciation. Dans cet article nous allons nous demander s'il doit y avoir un choix de locuteur à copier et si oui, quelles caracteristiques de sa voix sont importantes dans ce choix.
Dans cet article, nous nous sommes intéressés aux problèmes de reconnaissance non- coopérative de cibles (NCTR) en tant que problème de classification supervisée. Dans un second temps, cet algorithme a été parallélisé sur un processeur many-cœurs (GPU : Graphics Processing Unit). Les opérations arithmétiques et le modèle d'accès mémoire ont été étudiés pour obtenir la meilleure parallélisation des calculs. Enfin, nous terminons par une discussion autour des perspectives envisageables pour la méthode proposée, notamment en s'intéressant à d'autres espaces de représentation ou à d'autres méthodes de classification.
Les approches de modélisation d'entreprises actuelles décrivent des conceptions de tâches génériques qui ne capturent pas les pratiques du terrain. Cependant, il existe plusieurs voies d'amélioration dans les organisations qui sont reliées aux manières particulières dont les tâches sont implantées. Le but de cette recherche est d'enrichir la modélisation d'entreprises par une approche méthodologique pour capturer et modéliser les pratiques de travail, basée sur un modèle d'agents organisationnels et de leurs contextes. L'approche permet l'acquisition et l'analyse de cadres de travail personnels et interpersonnels. Ces cadres de travail sont acquis à partir d'entrepôts d'actions. L'approche est illustrée avec une étude de cas. Nous présentons des résultats concernant la découverte automatique de contextes personnels.
Cet article traite du problème de l'apprentissage des réseaux de neurones à fonctions radiales de base pour l'approximation de fonctions non linéaires L 2 de R d vers R. Pour ce type de problème, les algorithmes hybrides sont les plus utilisés. Ils font appel à des techniques d'apprentissage non supervisées pour l'estimation des centres et des paramètres d'échelle des fonctions radiales, et à des techniques d'apprentissage supervisées pour l'estimation des paramètres linéaires. Les méthodes d'apprentissage supervisées reposent généralement sur l'estimateur (ou le critère) des moindres carrées (MC). Cet estimateur est optimal dans le cas où le jeu de données d'apprentissage (z i,y i)i=i,2,..,q est constitué de sorties y i, i = l,..,q bruitées et d'entrées z i, i = l,..,q exactes. Cependant lors de la collecte des données expérimentales il est rarement possible de mesurer l'entrée z i sans bruit. L'utilisation de l'estimateur des MC produit une estimation biaisée des paramètres linéaires dans le cas où le jeux de données d'apprentissage est à entrées et sorties bruitées, ce qui engendre une estimation erronée de la sortie. Cet article propose l'utilisation d'une procédure d'estimation fondée sur le modèle avec variables entachées d'erreurs pour l'estimation des paramètres linéaires (pour l'apprentissage supervisé) dans le cas où le jeux de données d'apprentissage est à entrées et sorties bruitées. L'interprétation géométrique du critère d'estimation proposé est établie afin de mettre en évidence son avantage relativement au critère des moindres carrés. L'amélioration des performances en terme d'approximation de fonctions non linéaires est illustrée sur un exemple.
La reconnaissance automatique de séquences de chiffres connectés (séquences composées des chiffres zéro à neuf, et oh forme un domaine important de la reconnaissance de la parole. Les applications de cette technologie comprennent les autorisations de cartes de crédit, la commande sur catalogue, la composition de numéros de téléphone et la saisie de données. Depuis deux ans, AT&T a expérimenté un système de reconnaissance automatique de codes marchands d'identification de 10 chiffres et de numéros de cartes de crédit de clients de 15 chiffres, dans le but de permettre des achats par carte de crédit. Notre évaluation a utilisé des données récoltées chez 1000 clients qui ont produit 2000 séquences de chiffres connectés au travers du système téléphonique basé sur la composition de chiffre 800. Notre système a correctement reconnu 97% des séquences de chiffres sans rejet en utilisant des contraintes sur la validité du code marchand d'identification et du numéro de carte de crédit. Plusieurs schémas d'application de ces contraintes dans une implémentation pratique sont discutés dans l'article. De même, la reconnaissance du montant en dollars de la transaction est présentée, avec quelques résultats préliminaires.
Avec une cochlée artificielle, des personnes mal entendantes sont capables de comprendre la parole lorsque les conditions d'écoute sont bonnes. Toutefois, en présence de bruit ou de réverbération la compréhension pose des problèmes. Des tests ont été menés pour améliorer l'intelligibilité de la parole bruitée en utilisant deux techniques différentes de suppression de bruit à un seul canal. Ceci fut réalisé par prétraitement, c'est a dire en réinjectant a la cochlée artificielle le signal de parole résynthétisé. Des tests d'intelligibilité ont été menés en collaboration avec un service médical.
Des instabilités de la source vocale apparaissent, en parole normale, sous certaines conditions (cris de nourrisson, voix “cassée”, etc.) et sont aussi symptomatiques des voix pathologiques. Ces instabilités sont intimement liées aux bifurcations dans le système dynamique non-linéaire sous-jacent. Dans cet article, nous analysons les bifurcations dans un modèle à 2 masses des cordes vocales et étudions, en particulier, comment l'incorporation du conduit vocal modifie les diagrammes de bifurcation. Une comparaison d'un modèle simplifié (Steinecke et Herzel, 1995) et d'une version étendue incluant les résonances du conduit vocal révèle que les caractéristiques essentielles des diagrammes de bifurcation (c'est à dire, le verrouillage en fréquence à la fois des oscillations des cordes et des oscillations torroïdales) sont observées dans les deux types de modèles. Toutefois, les instabilités vocales apparaissent, dans le modèle étendu, pour des pressions sous-glottiques plus basses et même pour des assymétries faibles.
L'analyse et la reconnaissance des documents écrits consistent à traduire leurs images numérisées sous une forme électronique réutilisable. L'analyse permet d'extraire à partir de l'image d'un document une structure dite physique, tandis que la reconnaissance associe aux composants de la structure physique leurs fonctions logiques dans le document. Le travail présenté dans cet article porte sur la phase de reconnaissance de documents dont la structuration logique est caractérisée par des marquages typographiques tels que les sommaires ou les tables des matières. Nous proposons une approche perceptuelle qui se base sur l'extraction de ces marquages typographiques directement à partir des images des documents. Ces documents présentent cependant une structuration variable et complexe. Notre objectif est d'aborder ce problème de reconnaissance en présence de ces difficultés. Nous avons développé un système de reconnaissance automatique basé sur un modèle hybride combinant un classifieur bayésien et un automate probabiliste. Le rôle du classifieur est la correspondance entre les blocs de texte extraits dans les images des documents et les entités logiques à un niveau de structuration de base, alors que l'automate permet de regrouper ces entités logiques sur plusieurs niveaux hiérarchiques reconstruisant ainsi toute la structure logique. Ce modèle hybride est construit par apprentissage semi-supervisé, en s'appuyant d'une part sur la connaissance fournie de manière interactive par l'utilisateur, et d'autre part sur les propriétés typographiques des documents considérés. Nous avons expérimenté le système proposé pour l'indexation de sommaires de revues. La complexité et la variabilité de la structuration de ces documents nous ont permis de montrer l'efficacité de l'approche développée.
Diverses applications du traitement de la parole utilisent la préaccentuation du signal aux fréquences élevées. Dans cet article, nous étudions l'effet de la préaccentuation sur la performance de reconnaissance de voyelles. La préaccentuation est réalisée par différentiation du premier ordre. Les coefficients cepstraux, obtenus à partir d'une analyse par prédiction linéaire, sont utilisés comme paramètres de reconnaissance. Il est fait usage d'un classificateur par minimum de distance,et la performance de reconnaissance est étudiée pour quatre mesures de distance différentes : la distance euclidienne, la distance par corrélation, la distance de Mahalanobis et la distance d'Itakura. Nous montrons que la préaccentuation conduit à une détérioration du taux de reconnaissance des voyelles. Des implications de ce résultat pour la reconnaissance de mots isolés sont également discutées.
Dans ce papier, nous traitons des structures syllabiques et de leur variation dans un corpus de parole en français issu d'entrevues radio-diffusées. Un des buts est de montrer comment des systèmes de reconnaissance automatique de la parole (RAP) peuvent servir d'outils linguistiques pour explorer de façon cohérente des corpus virtuellement illimités. Des sous-ensembles automatiquement sélectionnés peuvent être vérifiés manuellement pour accroître notre connaissance des variantes de prononciation. Pour se focaliser sur elles, une méthodologie a été mise au point, utilisant des descriptions aux niveaux phonématique, syllabique et lexical. Cette étude repose sur un corpus de parole de radio constitué de trente émissions d'une heure. Des phénomènes, moins bien décrits ont également été observés : d'autres voyelles telles que /u/, /ε/, /i/ et /a/ peuvent tomber en position inaccentuée (non finale). Les syllabes CV non accentuées, précédées d'une syllabe ouverte, sont enclines à la restructuration : effacement de la voyelle et transfert attaque-coda. Les syllabes complexes tendent à être simplifiées : les consonnes liquides tombent souvent, plus en position de coda qu'en position d'attaque. Le /v/ est la consonne la plus facilement élidée indépendamment de sa position dans la syllabe. Enfin un pourcentage substantiel de syllabes faibles de fin de mot, ayant un schwa comme noyau, peuvent disparaître, ainsi que les mots outils monosyllabiques indépendamment de l'identité de leur noyau vocalique.
Le problème abordé dans ce travail est celui de la reconnaissance des états affectifs d'un utilisateur à partir de mesures physiques (accéléromètres) et physiologiques (ECG, EMG...) issues de capteurs portés. Etant donné la nature complexe de la relation entre les signaux dont nous disposons et les états affectifs à reconnaître, nous proposons d'utiliser une méthode d'apprentissage statistique. Nous commençons par discuter des états de l'art dans les domaines de l'apprentissage statistique et de la reconnaissance d'émotions. Nous présentons ensuite un cadre permettant de comparer les différents algorithmes d'apprentissages et leurs conditions d'utilisation. A l'issue de cette préétude, nous proposons une architecture globale d'un système embarqué de reconnaissance en temps réel. Au lieu de chercher à directement reconnaître les états affectifs, nous proposons de commencer par une phase de détection de changement dans les signaux et par la suite nous étiquetterons les segments identifiés entre deux ruptures. Nous démontrons enfin l'intérêt de notre approche sur deux exemples réels.
Cet article évalue deux hypothéses qui jouent un rôle central dans des modèles récents de l'acquisition du langage : (1) la connaissance de la structure linguistique est “projetée” sur des formes préalables de connaissance non linguistique, et (2) l'acquisition d'une langue est un apprentissage continu dans lequel l'enfant passe d'une communication gestuelle précoce a la maitrise de l'expression linguistique. Nous avons étudié l'acquisition des pronoms de premiere et deuxième personne MOI et TOI chez deux enfants sourds, nés de parents sourds, qui apprenaient l'American Sign Language (ASL) en tant que langue maternelle. En ASL, les pronoms personnels sont formes en montrant directement du doigt l'interlocuteur (YOU) oun soi-meme (ME), et ne sont done pas des symboles arbitraires. De ce fait, les pronoms personnels en ASL ressemblent à des gestes para-linguistiques qui accompagnent souvent la parole et sont utilisés pré-linguistiquement par les enfants sourds et entendants a partir d'environ 9 mois. Cela permet d'étudier le passage du geste pré-linguistique à l'expression linguistique dans un cas où geste et langage appartiennent à la même modalité. Les résultats indiquent qu'il faut un certain temps aux enfants sourds pour acquérir les pronoms, et qu'ils commettent des erreurs du type de celles que commettent les enfants entendants, en dépit de la transparence des gestes. Au départ (les enfants dtaient respectivement âgés de 10 et 12 mois), ils montraient du doigt des personnes, des objets et des endroits. Les deux enfants ont ensuite connu une longue pdriode d'évitement, pendant laquelle Tune des fonctions du geste (montrer les autres et soi-meme du doigt) disparut complétement. Pendant cette pdriode, leur langage et leur développement cognitif étaient par ailleurs entièrement normaux, et ils continuérent a montrer du doigt des objets, par exemple. Lorsqu'ils recommencèrent a montrer du doigt les autres et eux-mêmes, ils commettaient des erreurs courantes chez des enfants entendants ; un des enfants commettait des erreurs systdmatiques d'inversion, pensant que le signe TOI l désignait lui-même, alors que l'autre commettait des erreurs d'inversion non systdmatiques. Les résultats des tâches expérimentales pour le premier enfant montrent qu'il produisait également ces erreurs en compréhension. L'usage des pronoms MOI et TOI ne fut completement maitrisd que vets Page de 25–27 mois, ce qui correspond a Page vets lequel les enfants entenclants maitrisent ces formes. Notre étude étaye done l'iddée qu'il existe une discontinuité chez l'enfant clans le passage de la communication prd-linguistique à la communication linguistique. Nous essayons de montrer que l'acquisition de la structure linguistique repose vraisemblablement sur des connaissances bien dĺimitées, propres au langage.
Pour permettre à l'utilisateur d'interrompre les réponses du système, TOSBURG II utilise une technique adaptive spécifique. Le développement d'un système de dialogue qui soit fiable en situation réelle requiert de pouvoir le perfectionner en en testant des versions prototype successives dans des contextes de dialogues réels. Pour accroitre les performances de TOSBURG II, nous avons donc mis l'accent sur l'élaboration d'un environnement performant d'évaluation. Contrairement à la méthode prédominante, de type Wizard of Oz, pour la collecte de données de dialogue, TOSBURG II transmet, en temps réels, les données du dialogue. Ces données comportent non seulement les résultats de la compréhension des énoncés mais aussi les résultats des traitements intermédiaires, ce qui permet d'analyser précisement les comportements globaux du système.
La reconnaissance de parole a été utilisée pour automatiser le service des renseignements annuaire lors d'une expérimentation de six mois avec les usagers résidentiels de Bell Canada. Ce service bilingue donnait à l'usager le choix de s'exprimer en anglais ou en français. Plus de 89% des appels ont été partiellement ou complètement automatisés. Les réactions des utilisateurs et des téléphonistes vis à vis du service ont été positives. Le système de reconnaissance à vocabulaire flexible de Bell Northern Research a fourni de bonnes performances avec un vocabulaire de 1700 noms de ville et synonymes. On a pu mettre en évidence une réduction significative, du point de vue économique, du temps de travail des opératrices.
Cet article décrit une interface pour accès vocal à un grand nombre d'applications de divertissement, navigation et de communication dans l'environnement de l'automobile par un dialogue oral homme-machine. Le système a été développé dans le cadre du projet européen SENECA. Il fait appel à des techniques de réduction du bruit, à la reconnaissance de la parole ainsi qu'à la gestion des dialogues. Un aspect intéressant du système réside dans le fait que les résultats à faible confidence du module de reconnaissance ainsi que les ambiguı̈tés au niveau du mot sont compensés par un dialogue de clarification flexible que le système mène avec l'utilisateur. Un prototype de SENECA à été testé par des utilisateurs réels. La sécurité routière peut être améliorée de manière significative en utilisant la parole, notamment pour manipuler des tâches complexes. L'impression d'être distrait de la conduite est également moins prononcée en utilisant la parole par rapport à l'interaction manuelle.
Cet article présente les résultats d'un système de reconnaissance de mots isolés, indépendant du locuteur développé pour permettre l'accès à une base de données vocale australienne, à travers le réseau téléphonique commuté (RTC). Le Système de reconnaissance est basé sur une modélisation markovienne (HMM) utilisant des densités continues. La base de parole d'apprentissage a été enregistrée à travers le RTC par une large variété de locuteurs de régions différentes. Cette base comporte 55 mots : 41 noms de pays et leurs variantes de prononciation, plus quelques mots de commande. Les performances de reconnaissance, testées sur 100 locuteurs diférents (50 hommes et 50 femmes), sans grammaire, atteignent 97.3%. Cet article décrit la méthodologie d'apprentissage des HMMs qui comporte trois étapes : apprentissage des modèles à partir d'une segmentation manuelle, segmentation automatique des mots et ré-estimation. Pour faciliter l'implantation ultérieure du système de reconnaissance sur DS3, un algorithme de Viterbi rapide et trame-synchrome a été implémenté sans dégradation des performances. La détection bruit-parole est effectuée en associant un modèle silence/bruit aux modèles de mots. Pour les paires de mots pouvant être confondus, des modèles sub-lexicaux sont utilisés qui améliorent le taux de reconnaissance. Une approache par post-traitement est aussi utilisèe pour améliorer les performances : tous les candidats classés par le décodage de Viterbi sont soumis à des tests de durée minimale des mots et de différence statistique entre le premier et le deuxième candidat.
Dans les applications pratiques, les systèmes de reconnaissance de la parole ont besoin d'être insensibles aux différences entre les conditions acoustiques des ensembles d'entraı̂nement et de test. Les différences d'environment acoustique peuvent résulter de différentes sources telles que bruit de fond ambiant, variations des caractéristiques du canal de transmission, et le stress du locuteur. Ces perturbations peuvent détériorer fortement les performances d'un système de reconnaissance. Plusieurs techniques ont été proposées pour améliorer la robustesse à ces facteurs de bruit. Cet article considère une approche particulière de technique de compensation basée sur des modèles de bruit, appelée compensation prédictive, qui s'est montrée particulièrement robuste au bruit dans le cas de nombreux environnements acoustiques. La caractéristique de ces approaches est de combiner un modèle de parole avec un modèle de bruit additif, un modèle du canal de transmission et, dans le cas général, un modèle de stress du locuteur, afin de créer un modèle de parole déteriorée. La théorie générale de ces techniques prédictives est discutée ici. Différentes approximations permettant d'effectuer rapidement la combinaison des modèles ont été proposées et sont décrites ici. Les avantages et les limitations de ces méthodes prédictives pour la robustesse au bruit sont également discutés. De plus, des méthodes permettant de combiner des approches prédictives avec des méthodes utilisant les données de parole dans le nouvel environnement, à savoir les méthodes adaptatives, sont discutées en détail. Cette approche combinée a alors l'avantage d'effacer certaines des limitations des approches prédictives.
La taille croissante du web et l'hétérogénéité de l'information accessible rendent l'extraction d'informations (EI) de pages web de plus en plus complexe. Dans le contexte de la collecte d'information sur des domaines restreints du web, cette recherche concerne le développement de systèmes d'EI de pages web, dits adaptatifs dans la mesure où ils peuvent être adaptés à de nouveaux domaines par apprentissage sur un corpus de pages web annotées de ces domaines. Les performances de WEPAIES sont évaluées sur trois corpora standard plus ou moins structurés, et comparées à celles d'autres systèmes d'extraction d'information adaptatifs.
A l'aide d'un vocabulaire de 12 mots artificiels, les auteurs ont développé une méthode pour évaluer les performances auditives de patients équipés avec un implant cochléaire. La répétition aléatoire de ces 12 mots a conduit à une liste de 129 éléments qui a été lue aux patients et qui teste simultanément plusieurs caractérs du langage. L'exploitation statistique des résultats a concerné la reconnaissance des mots, des consonnes, des éléments de base du vocabulaire. L'association de ces pourcentages est aussi étudiée. Les résultats sont présentés pour deux patients porteurs d'une prothèse Chorimac. Ils montrent que : (1) les différents tests ne sont pas équivalents (même les associations de pourcentages), (2) quelques propriétés principales de la prothèse Chrorimac sont retrouvées, telles que la bonne discrimination de l'opposition plosive-fricative et la mauvaise distinction du voisement, et (3) l'aide à la lecture labiale n'est pas mise en évidence ; ceci incite à discuter la sensibilité de la méthode proposée.
Cet article est dédié au problème de l'approximation de la fonction de valeur dans le cadre des algorithmes d'apprentissage par renforcement. Nous présentons une méthode de modélisation de la fonction de valeur qui alloue de nouvelles ressources au fur et à mesure que l'agent explore son environnement. La fonction de valeur est représentée par un réseau de fonctions de base radiale gaussiennes. Le modèle est construit incrémentalement en ajoutant de nouvelles unités à chaque fois que le système entre dans une région inconnue de l'espace des états. Les paramètres du modèle sont adaptés en utilisant la descente du gradient et l'algorithme Sarsa(X). Cette méthode ne requiert ni un modèle de l'environnement ni une approximation de ce modèle. La performance de la méthode est évaluée sur deux problèmes type : l'Acrobot et le Bioréacteur. Dans les deux cas, les systèmes sont simulés dans un espace d'états continu et un pas de temps discret.
Les étudiants anglais de Londres, du niveau licence, font une erreur systématique en épellant Gandhi sous la forme Ghandi, et cela malgré le fait qu'ils aient souvent vu ce nom correctement écrit. C'est une faute d'orthographe modéle que nous étudions dans cet article. On en conclut que même avec une connaissance négligeable des mots et noms 'hindous', les lecteurs anglais utilisent des 'règles' pour de telles tâches. Cela laisse espérer que, une fois acquise la façon correcte d'épeller, celle-ci se maintiendra car de nouvelles règles remplaçeront sans doute les anciennes.
Dans cet article nous proposons une approche de communication entre agents logiciels basée sur les engagements sociaux et les arguments. Dans cette approche, les agents doivent utiliser leurs capacités de raisonnement pour raisonner au sujet de leurs états mentaux avant d'agir sur les engagements ou les contenus des engagements sociaux d'une façon pertinente. Afin de choisir les arguments les plus pertinents à chaque étape de l'interaction dialogique, les agents utilisent deux types de raisonnements : stratégique et tactique. Le raisonnement stratégique permet d'une part, de choisir le plan global de la communication en termes de sous-buts à accomplir afin de réaliser le but conversationnel. Ainsi, le raisonnement tactique permet aux agents de choisir localement, à chaque tour de l'interaction dialogique, l'argument le plus pertinent selon la stratégie adoptée.
La performance des algorithmes de renforcement du langage baisse rapidement avec le rapport signal sur bruit (SNR). A faible SNR, la probabilité de renforcement des phonèmes à haute intensité, tels que certaines voyelles, est plus grande que celle de la plupart des consonnes. Même si le renforcement sélectif des consonnes améliore la reconnaissance des voyelles, il diminue, d'autre part, les amplitudes relatives. Nous avons mené des expériences sur des sujets bien-entendants afin de déterminer l'effet global que peut avoir le renforcement sélectif des voyelles sur la compréhension des consonnes dans des phonèmes consonne–voyelle–consonne. En l'absence de bruit, si l'on compare avec les conditions de contrôle de non-renforcement à 65 dB (A), le renforcement des voyelles par 12 dB n'affecte guère la compréhension des consonnes. En présence d'un bruit de fond correspondant à un SNR de −6 dB, une fraction de 50,1% des phonèmes non-renforcés ont été reconnus, alors que ce taux augmentait à 69,8% avec le même SNR mais un renforcement sélectif des voyelles de 12 dB. Or, un renforcement simultané des voyelles et des consonnes de 12 dB, donnait un taux de reconnaissance des consonnes de 91,5%. En conclusion, les algorithmes de renforcement du langage devraient agir le plus fortement possible sur l'ensemble des éléments du langage, même si cela résulte en un renforcement sélectif de certaines catégories de phonèmes, au détriment d'autres.
Afin d'évaluer cette fi- délité, nous proposons un moyen de visualiser toute mesure associée aux données en coloriant les cellules de Voronoï de l'image de ces données dans l'espace de projection, et nous étudions des mesures spécifiques. Nous présentons des cas d'analyse de données réelles et artificielles à partir des projections obtenues par l'Analyse en Composantes Principales et l'Analyse en Composantes Curvilignes.
Cet article de synthèse s'adresse à un large public provenant de différentes disciplines mais également aux spécialistes de l'intonation. Il comprend cinq parties. Dans la première partie, ou Introduction, sont brièvement rappelés les concepts de base de l'intonation et de la prosodie et mises en lumière les périodes charnières de la recherche intonative. Dans la deuxième partie, Fonctions et formes de l'intonation, un large éventail des fonctions des niveaux morpholexical, phrastique, discursif ou dialogal est examiné ; des formes intonatives provenant de langues différentes sont présentées et comparées. Dans la troisième partie, Mod lisation et transcription de l'intonation, on fait référence aux modèles courants de l'intonation et aux systèmes d'étiquetage opérationnels. Dans la quatrième partie, Les applications de l'intonation, sont présentées les applications les plus courantes de l'intonation, plus particulièrement les applications technologiques ; une discussion est engagée sur les problèmes méthodologiques. Dans la cinquième partie, Perspectives de recherche, des directions de recherche sont tracées ; on précise les buts à atteindre et on souligne le sens et l'intérêt de la recherche intonative pour les années à venir.
L'analyse specrale des signaux non stationnaires nécessite de mettre en œuvre des outils spécifiques permettant de décrire une évolution temporelle de caractéristiques fréquentielles. De tels outils, appelés représentations temps-fréquence, peuvent être définis de manière objective en partant de contraintes imposées a priori. Si Ton se place dans un cadre aléatoire et non paramétrique, deux grandes classes d'approches sont offertes, suivant que Ton privilégie l'existence d'une décomposition doublement orthogonale, ou que Ton cherche à préserver le concept usuel de fréquence. Après avoir établi les définitions correspondantes et souligné l'importance de la transformation de Wigner-Ville, on s'intéresse à leurs possibilités d'estimation et on discute comment une représentation temps-fréquence peut être utilisée pour des opérations de traitement dépassant la seule description.
Plusieurs traductions du Speculum humanae salvationis ont été composées et copiées dans les Pays-Bas bourguignons durant la seconde moitié du XVe siècle. Dans ce contexte, la traduction de Miélot, commandée par le duc Philippe le Bon, et ses deux manuscrits, dont une minute, a souvent été considérée comme un échec. La comparaison des caractéristiques textuelles et matérielles de la traduction de Miélot avec celles des trois autres traductions contemporaines, en prose, permet de mettre en évidence la spécificité du travail de traduction et de mise en livre de Miélot.
Cet article illustre les avantages apportés par l'utilisation de la Transformation Cosinus Discrète (DCT) par rapport à celle de la Transformée de Fourier Discrète (DFT) standard, pour le débruitage de la parole bruitée. On montre comment dériver un filtre MMSE à partir de la modélisation statistique des coefficients DCT. On montre également comment dériver un facteur de sur-atténuation basé sur le fait que, dans les signaux bruités, l'énergie de la parole n'est pas toujours présente à chaque instant ni dans chaque coefficient. Ce facteur de sur-atténuation est utile pour supprimer tout bruit résiduel musical. Les méthods proposées ont été évaluées favorablement par rapport du filtre de réduction de bruit proposé par Ephraim et Malah (1994), en utilisant tant du bruit blanc guassien que du bruit de ventilateur enregistré
La coopération entre agents, quelle que soit leur nature, ne peut s'établir que si ceux-ci disposent d'un ensemble de représentations. En fonction de ses capacités de perception et de raisonnement, chacun d'eux construit une représentation plus ou moins riche de la situation dans laquelle il coopère. Les décisions qu 'il prend dépendent en grande partie de ces représentations. On montre comment la perception, le raisonnement et l'action sont liés dans le cadre général de l'activité coopérative. Pour cela, on observe la relation entre l'activité coopérative et l'activité individuelle. Ensuite, on examine le cas particulier de la coopération homme/machine comme cas particulier de la coopération entre agents, pour lequel la machine doit être dotée de représentations adaptées et doit permettre à l'utilisateur de construire des représentations performantes. La modélisation pour la conception des systèmes à base de connaissances apporte une base de représentation essentiellement conceptuelle. Deux points de vue doivent en effet cohabiter dans les systèmes coopératifs ; celui de l'organisation dans laquelle intervient la coopération et celui de l'utilisateur qui coopère avec le système pour réaliser une tâche. Outre le modèle conceptuel de l'application, on trouvera donc dans les systèmes coopératifs un modèle de coopération (point de vue de l'organisation) et un modèle d'utilisateur.
Plusieurs auteurs soutiennent que le dialogue doit être considéré comme une activité conjointe (voir par example (Clark et Wilkes-Gibbs, 1986 ; Grosz et Sidner, 1990 ; Schegloff, 1981 ; Suchman, 1987)) - quelque chose que les agents font ensemble - plutôt que simplement comme le produit de générateurs et reconnaisseurs de plans fonctionnant en synchronie et harmonie, comme le proposent les théories fondées sur la notion de plans. Les approches à base de plans n'expliquent pas pourquoi les destinataires posent des questions de clarification, pourquoi ils confirment, ou même pourquoi ils ne s'en vont pas. En revanche, le modèle d'action conjointe suggère que les deux parties participant à un dialoque sont conjointement responsables de son maintien. Participer à un dialogue requiert des conversants d'avoir au moins un engagement conjoint, pour pouvoir se compredre. Parmi les questions clés auxquelles il faut répondre, il y a la formalisation précise de ces engagements généraux et la manière dont ils prédisent cette fine synchronie si frappante dans une conversation ordinaire. Afin de commencer à répondre à ces questions, nous esquissons ici la façon dont une théorie formelle de l'action conjointe explique les confirmations que l'on trouve dans les dialogues téléphoniques orientés-tâche. Un développement plus formel est donné dans (Cohen et Levesque, 1991a). Nous montrons ensuite que des extensions de cette analyse à un cadre général de dialogue sera difficile. En particulier, ceci nous forcera à abadonner nos analyses simplistes de contenu propositionnel et de sens littéral.
Le système tient dans un ordinateur personnel - type 386 et fonctionne sous MS-DOS. Parmi ses caractéristiques les plus intéressantes, nous pouvons citer la capacité d'adapter rapidement le système au locuteur et ce, de manière indépendante de l'application, ainsi que la facilité de créer des dictionnaires spécifiques aux applications. L'adaptation est rapide parce que le système extrait les distributions spectrales-cibles des phonèmes à partir des mots d'entraînement et combine cette information avec des données indépendantes du locuteur concernant d'autres aspects du signal, comme le profil énergétique, la durée des phonèmes et leur similarité. Le système accepte le langage naturel sans aucune restriction et peut être utilisé pour dicter des documents de n'importe quelle nature, pour autant que le dictionnaire du domaine d'application soit spécifié. La dictée n'est toutefois pas la seule application envisagée. Dans cet article, nous décrivons notre approche de la reconnaissance de la parole et fournissons quelques informations sur l'implémentation et les performances actuelles de notre système.
Nous décrivons un nouveau modèle stochastique en vue de générer des signaux de parole appropriés au codage à bas débit. Dans ce modèle, l'onde de parole est représentée sous la forme d'un processus gaussian à moyenne nulle possédant un spectre de puissance à variation lente. La séquence “innovée” optimale est obtenue en minimisant un critère d'erreur fondé sur les propriétés du système auditif humain. Chaque bloc de 40 échantillons (représentant 5 ms du signal de parole échantillonné à 8 kHz) du signal nouveau est codé dans l'une des 1.024 séquences gaussiennes de longueur 40 générées de manière aléatoire. La séquence choisie minimalise un critère d'erreur pondéré spectralement. Le nouveau signal est dès lors encodé à 2 kbits/s. Un filtre linéaire variant temporellement et dont les paramètres sont déterminés directement à partir du signal de parole est utilisé pour produire le spectre de puissance voulu. Même à ce très faible débit, la parole resynthétisée peut à peine être distinguée de l'original.
Nous présentons une nouvelle théorie de la production de la parole. Le formalisme est basé sur la théorie de la perturbation et s'appuie sur des simulations sur ordinateur. Des fonctions de sensibilité qui relient les variations des fréquences formantiques à de petites perturbations des fonctions d'aires sont reformulées de manière à étre applicables à des variations importantes. Des phénomènes phonétiques, articulatoires et acoustiques bien connus devienneny explicables au sein d'une théorie globale et formalle confirmée par des données expérimentales. Notre système formel éclaire sous un jour nouveau quelques principes propres aux relations acoustico-articulatoires et leur application à la théorie phonétique. Nous montrons dans cet article que de notre formalisme découlent une simplification des relations acoustico-articulatoires, une confirmation de la nature quantale de la parole, une reconsidération des universaux et systèmes phonétiques, une explication et normalisation des transitions formantiques et un modèle à 9 paramètres facilement contrôlables. D'autres phénomènes tels que les effets de compensation et de symétroe sont également interprétés. Le modèle peut également servir à la formulation et au calcul de structures dynamiques de base. Plusieurs applications et de nouvelles perspectives de recherche sont également proposées.
Un aspect bien connu de la prononciation anglaise est l'existence de consonnes syllabiques. On considère en général la syllabicité consonantique comme une conséquence de l'élision vocalique, en suggérant que par exemple la prononciation du mot “button” comme /bλtm/ est la réalisation d'une forme sous-jacente /bλtən/ ou même /bλt⊃n/. Puisque l'élision est un phénomène soumis ă l'influence du style parlé, il semblerait donc que dans le parler rapide ou familier on devrait s'attendre à trouver davantage de cas de consonnes syllabiques, et moins de cas de voyelles non-accentuées suivies de consonnes continues. Cette communication se propose de montrer que le phénomène n'est pas si simple : nous examinons les problèmes qui font obstacle à nos tentatives de reconnaissance automatique des syllabes et autres unités inférieures au mot et considérons les facteurs phonotactiques et phonétiques qui peuvent permettre de les résoudre.
Cet article présente une édition critique accompagnée d'une étude d'un recueil de poésie des XVIIe et XVIIIe siècles que l'on avait jusque-là pris pour le Kitāb al-Ġilmān, œuvre d'al-Ṯaʿālibī disparue. Nous l'accompagnons d'une analyse codicologique du manuscrit Berlin MS Wetzstein II 1786 – qui contient ledit recueil – et nous expliquons et corrigeons l'attribution erronée de longue date à al-Ṯaʿālibī.
Cet article décrit le langage SSML (Speech Synthesis Markup Language) qui a été défini pour servir de standard d'interface, indépendant de la plate-forme, pour des systèmes de synthèse de la parole. Cet article traite de la nécessité de normalisation au sein des systèmes de synthèse et explique en quoi cela peut aider les constructeurs de systèmes à faire un meilleur usage de la synthèse. Les caractéristiques principales de SSML (qui est basé sur SGML) sont ensuite présentées.
Les performances d'un système de reconnaissance sont souvent dégradées par la présence de bruit. Cette dégradation est en partie due au fait qu'il y a souvent une grande différence entre les conditions d'appentissage et de test, c'est-à-dire que les valeurs des paramètres mesurés lors de l'apprentissage sont très différences des valeurs mesurées en condition de test sous l'effet du bruit. Une solution pour contourner ce problème est d'utiliser des paramètres qui sont moins sensibles aux conditions de bruit. Dans cet article, nous proposons l'utilisation d'une famille de limiteurs de signal pour la reconnaissance de parole bruitée. Le limiteur de signal correctement ajusté équivaut à appliquer une transformation arcsin sur les fonctions d'autocorrelation du signal d'origine. L'effet de l'utilisation du limiteur de signal comme préprocesseur est de réduire la variabilité du vecteur de paramètres de sorte que la différence entre les conditions d'apprentissage et de test se trouve réduite. L'évaluation sur le vocabulaire des chiffres etdes lettres en anglais, en mode monolocuteur, montre que les performances d'un système de reconnaissance par alignement temporel dynamique (DTW) peuvent etre augmentées lorsque le limiteur de signal est utilisé comme préprocesseur pour réduire la variabilité due à des conditions très différentes.
Des technologies récentes telles que les microarrays permettent de mesurer le niveau d'expression de milliers de gènes au cours du temps. Cependant, le nombre de points réduit de ces séries temporelles rend difficile la prise en compte des dépendances entre les temps par les algorithmes de classification. De plus, certaines des classes les plus intéressantes pour le biologiste peuvent être totalement omises par les algorithmes classiques du fait du faible nombre de gènes qui les composent. Nous proposons une approche bayésienne de ce problème. Un modèle de mélange est utilisé pour décrire et classer les données. Les paramètres de ce modèle sont contraints par une distribution a priori définie grâce à un nouveau type de modèles qui exprime les connaissances a priori dont on dispose. Ces connaissances permettent de traiter les dépendances temporelles d'une manière très naturelle, et de prendre en compte des connaissances approximatives concernant les profils temporels les plus intéressants.
Nous examinons des facteurs qui ont affecté la synthèse de parole de haute qualité par l'analyse-synthése. L'influence d'un sous-groupe de ces facteurs sur la qualité de voix synthétique a été évaluée par un test d'écoute comparant la parole naturelle à la parole synthétique de deux synthétiseurs : le synthétiseur à prédiction linéaire (LPC) et le synthétiseur à formants. Plusieurs sources d'excitation pour la synthèse ont été considérées, incluant des paramètres importants qui reproduisent certains faits ayant lieu au niveau de la glotte, tels que les instants d'ouverture et de fermeture de la glotte. De plus, le fait d'identifier les parties voisées, non voisées, et silencieusses du signal de la parole, et de mesurer la fréquence fondamentale des parties voisées, a contribué à la synthèse de parole de haute qualité. Une approache à deux niveaux concernant l'analyse de la parole est recommandée afin d'améliorer le traitement automatique de la parole ; le premier niveau est constitué par le traditionnel signal de la parole, alors que le deuxiéme niveau est constitué par l'éléctroglottogramme (EEG).
Pour identifier avec précision la suite des phones correspondant à un signal de parole continu, nous proposons une nouvelle approche caractérisée par des traitements de bas en haut (ascendant) et de haut en bas (descendant) fortement couplés. La segmentation, la reconnaissance et l'étiquetage caractérisent le chemin ascendant. L'étiquetage, la génération de la parole et la segmentation sont les constituants du traitement descendant. Ainsi ces quatre processus forment une boucle de “feed-back” qui permet une interprétation optimale du signal de parole, pour une observation bruitée et une connaissance a priori. Le but essentiel de cette étude est d'identifier un système modèle en employant la théorie de l'estimation statistique et celle du champ moyen. Les résultats expérimentaux sont obtenus sur la base des données TIMIT. Par conséquent l'ensemble du système est capable de transformer le signal d'entrée continu en un des 61 sons de base, avec un taux de reconnaissance de 73,7%.
Dans ce papier, nous avons cherché à évaluer l'intérêt de la création de classes de signatures manuscrites pour un système d'authentification en ligne. Dans notre étude, la création des classes s'effectue grâce à deux algorithmes de clustering et en se basant sur différents sous-espaces de description des signatures. La spécialisation du système consiste à déterminer non plus un seuil de décision (acceptation ou rejet) global au système (i.e. le même pour toutes les personnes qui s'enrôleront) mais un seuil adapté à chacune des classes. Cependant la sensibilité de la classification est très grande et la notion de classe unique pour un signataire semble trop restrictive.
On décrit un algorithme qui fournit une courbe de référence de la mélodie d'un signal de parole en vue d'études comparatives de détecteurs du fondamental. On discute d'abord le problème d'analyse des erreurs et particulièrement la question de l'exactitude de la mesure. On montre que l'exactitude de l'algorithme doit étre supérieure à 0.5% afin de rendre inaudibles les petites inexactitudes de mesure. L'algorithme développé dans notre laboratoire traite le signal de sortie d'un laryngographe qui mesure les vibrations laryngiennes par la conductance électrique du larynx. Le point d'inflexion du laryngogramme est interprété comme l'instant de clóture de la glotte, e'est-a-dirc le début d'une période fondamentale. En utilisant un filtre interpolateur local on maintient l'erreur de quantification de la mesure au-dessous de 0.5%.
Dans cet article, nous suggérons que la cognition humaine utilise deux modes d'apprentissage, le mode s et le mode u. Le mode s fait appel à une mémoire de travail abstraite ; l'apprentissage est sélectif et peut être verbalement décrit. Le mode u ne fait pas intervenir de mémoire de travail abstraite ; l'apprentissage est non sélectif et ne peut pas être verbalement décrit. Dans trois expériences, nous avons utilisé deux tâches dont il a été démontré qu'elles donnent lieu à deux types d'apprentissage compatibles avec la distinction entre deux modes que nous postulons. Au cours de ces expériences, nous avons étudié l'effet que produit l'introduction d'une tâche verbale secondaire sur l'apprentissage, la performance et le ré-apprentissage pour la première tâche. On pouvait s'attendre à ce que la tâche secondaire interfère avec le mode s d'apprentissage. Nos résultats montrent que l'introduction de la tâche secondaire interfère avec la performance et le ré-apprentissage pour l'une de ces tâches, celle pour laquelle les sujets pouvaient décrire verbalement ce qu'ils avaient appris. Par contre, pour la tâche où les sujets ne pouvaient pas décrire verbalement leur apprentissage, la performance et le ré-apprentissage étaient facilités par l'introduction de la tâche supplémentaire. Ces résultats militent pour une distinction entre deux modes d'apprentissage, dont l'un seulement repose sur le langage.
On émet l'hypothèse que les cris des bébés sourds sont différents de ceux des bébés otologiquement sains à cause de l'absence de contrôle auditif. Les résultats montrent que les experts sont capables d'une discrimination auditive des cris des deux groupes de bébés (sourds et entendants), sur la base de propriétés vocales et mélodiques des cris. Les cris des bébés sourds diffèrent par le timbre, le rythme et la mélodie. Les propriétés sonores sont corrélées aux caractéristiques spectrales, et l'on peut extraire des paramètres mélodiques et rythmiques qui diffèrent de manière significative entre les deux groupes des bébés. Les résultats sont discutés sur la base d'un modèle de production des cris. Les paramètres des signaux ainsi déterminés permettent une classification automatique à partir des cartes neuronaux topologiques et pourraient être utilisés ultérieurement pour l'établissement d'un diagnostic précoce.
Nous nous plaçons dans le cadre de la segmentation bayésienne. Parmi les trois étapes (modélisation, estimation, optimisation), nous considérons la modélisation et l'optimisation. La modélisation est appréhendée sous l'angle des champs de Markov. Nous montrons les limites du modèle de Potts couramment employé et proposons un nouveau modèle (le chien-modèle) permettant de contrôler la longueur des contours et des lignes dans l'image segmentée. Nous préservons ainsi les structures fines présentes dans les données. Nous comparons ensuite les critères MPM et MAP conjointement aux algorithmes qui permettent de les optimiser. Les différents résultats sont obtenus sur des images synthétiques et des images SPOT. Le problème de la classification fait l'objet d'une seconde partie.
De plus en plus, les produits hypermédias (CD-Rom ou sites web) constituent des ressources riches en informations mais faiblement structurées. Pour pouvoir exploiter la richesse de tels hypermédias, il est nécessaire de proposer une aide efficace à l'utilisateur, qui lui soit adaptée. Pour cela on cherche à modéliser le comportement de navigation de l'utilisateur, qui traduit son but. Cet article traite de l'apprentissage et de la reconnaissance de comportements d'utilisateurs de produits hypermédias à l'aide de modèles markoviens.
Une étape cruciale dans le traitement de la parole pour l'extraction d'information, la détection du sujet de conversation et la navigation est la segmentation du discours. Celle-ci est difficile car les indices aidant à segmenter un texte (en-têtes, paragraphes, ponctuation) n'apparaissent pas dans le language parlé. Nous étudions l'usage de la prosodie (l'information extraite du rythme et de la mélodie de la parole) à cet effet. Nos résultats indiquent que le modèle prosodique est équivalent ou supérieur au modèle du langage, et qu'il requiert moins de données d'entraı̂nement. De plus, nous obtenons un gain significatif en combinant de manière probabiliste l'information prosodique et lexicale, et ce pour différents corpora et applications. Une inspection plus détaillée des résultats révèle que les modèles prosodiques identifient les indicateurs de début et de fin de segments, tel que décrit dans la littérature. Par exemple, le ton s'avère extrèmement utile pour la segmentation des bulletins télévisés, alors que les caracteristiques de durée et celles extraites du modèle du langage servent davantage pour la segmentation de conversations naturelles.
La transcription automatique d'émissions parlées d'informations radio-télévisées (tâche désignée par “Hub-4”) a été l'objet d'intenses travaux de recherche ces dernières années. Ce papier présente les lignes principales de nos efforts d'élaboration d'un système de reconnaissance de parole continue qui soit à même de traiter le signal hétérogène provenant d'émissions d'information sans entraı̂ner une trop grande complexité ou le recours à des ressources de calculs excessives. L'essentiel de nos efforts a porté sur les points suivants : • La segmentation automatique du signal audio en une suite de passages parlés ; • Le décodage rapide en une passe intégrant un modèle de trigrammes avec une technique d'anticipation ; • L'interpolation log-linéaire optimale d'une variété de modèles acoustiques et grammaticaux au moyen d'une technique de combinaison discriminative de modèles (DMC) ; • La prise en compte de corrélations linguistiques à court terme et, plus faiblement, à long terme au moyen de groupements de mots (phrases) et de modèles de languages dits “à distance” ; • L'amélioration de la modélisation acoustique à l'aide d'une extraction robuste du contenu du signal combinée à la normalisation des canaux, l'adaptation des modèles phonétiques ainsi que la sélection et la vérification des scripts du corpus d'entraînement. Notre point de départ fut le système Philips “NAB-64k” fondé sur l'emploi de triphones intra-mots et de modèles de trigrammes. Pour la tâche “NAB” impliquant la transcription d'articles lus à l'aide d'un microphone connu, ce système indépendant du locuteur atteint un taux d'erreur moyen de 10% au niveau du mot. Au terme de ce travail, nous avons développé un système qui combine par DMC des modèles phonétique intra-mots et inter-mots, des pentaphones, des groupements de mots ainsi que des modèles de langage jusqu'à l'ordre 4. Ce système produit une transcription d'émissions parlées d'information avec un taux d'erreur global d'environ 17%.
Cet article montre comment un modèle articulatoire, doté de la capacité de produire des sons à partir des déplacements de ses articulateurs, peut apprendre à parler, c'est-à-dire à coordonner ses mouvements de telle manière qu'ils produisent des séquences de sons appartenant à un langage donné. Cet apprentissage complexe est accompli en quatre phases : (a) une phase de babillage, où le modèle construit une copie interne des tranformations directes, c'est-à-dire la transformation articulo-audio-visuelle ; (b) une phase d'imitation, où il cherche à reproduire un jeu limité de séquences sonores par inversion ; (c) une phase de construction de représentation, où il se dote de prototypes sensori-moteurs des cibles caractéristiques des sons du langage ; et (d) une phase “rythmique”, où il apprend les coordinations nécessaires entre les activations de ces représentations.
Cet article présente un outil pour l'étude de l'usage de sites internet qui repose sur une analyse automatique de l'activité des internautes et sur un mécanisme interactif de visualisation des navigations. La phase d'analyse résume l'information avant la phase de visualisation ; elle catégorise les traces d'activité des internautes à l'aide d'un algorithme de clustering relationnel biomimétique, et fournit un ensemble de profils représentatifs pour chacun des clusters, définis à partir de degrés de typicalité. L'outil proposé a été appliqué et évalué sur des fichiers log issus du muséum de Bourges et a montré sa capacité à produire des visualisations pertinentes et interprétables des navigations des internautes.
ASTEC est un projet de recherche dont l'objectif est d'augmenter le taux d'inclusion des patients dans les essais cliniques de cancérologie grâce à l'exploitation automatique des données contenues dans le dossier médical informatisé. Le projet ASTEC explore deux enjeux scientifiques majeurs dans le champ de l'informatique médicale : 1) l'interopérabilité syntactique et sémantique entre systèmes d'information. Il s'agit ici de faire interopérer un dossier structuré informatisé avec un outil d'aide à la décision. Le projet ASTEC propose un cadre syntaxico-sémantique d'interopérabilité, basé sur des standards internationaux. Sont développées des méthodes génériques de médiation sémantique basées sur les ontologies pour adapter l'information issue des dossiers aux critères d'inclusion/exclusion des études cliniques ; 2) l'aide à décision : développer des méthodes d'inférence sur les dossiers patients en utilisant un formalisme de représentation adapté aussi bien à la structuration des données cliniques qu'à celle des critères d'inclusion et d'exclusion des essais cliniques. Nous exposons ici les choix procéduraux et technologiques retenus dans le cadre de ce projet.
Cet article présente une vue générale du système de reconnaissance de parole continue pour de grands vocabulaires développé par les chercheurs de Philips. Utilisant des modèles de phonèmes, ce système a été appliqué avec succès à diverses tâches couvrant l'éventail des petits jusqu'aux très grands vocabulaires, dans les langues allemande et anglo-américaine. Ce texte est consacré aux applications de la reconnaissance de la parole à des tâches de dictée réelle, en particulier celles concernant des rapports juridiques et radiologiques dans la langue Allemande. Ces tâches sont décrites de même que les résultats obtenus expérimentalement. Nous décrivons également une version commerciale d'un système de dictée issue de notre prototype et qui a été implémentée sur PC. Afin de rendre possible une comparaison des performances avec d'autres systèmes, une section est consacrée à l'expérimentation sur des données provenant du quotidien Américain “Wall Street Journal”, incluant les tests réalisés lors de la procédure d'évaluation de novembre 1993. L'architecture générale est fondée sur une approche statistique intégrée. Par rapport à d'autres systèmes, les caractéristiques majeures qui se dégagent de notre système sont : 1. l'application constante du critère de Viterbi aussi bien pour l'apprentissage que pour la reconnaissance ; 2. l'usage de mixtures de densités de probabilité continues sans recourir à aucune forme de partage ou de lissage ; 3. un décodage synchrone avec une technique d'élagage en faisceau utilisée conjointement avec une organisation en arbre du lexique et une méthode d'anticipation rapide du phonème suivant.
Des voyelles produits dans un même contexte par des adultes, hommes et femmes, ont été analysées et transformées pour obtenir des représentations spectrales mesurables. L'information phonématue contenue dans le spectre, ainsi que celle concernant le sexe du locuteur, a été examinée par classification automatiques sous des conditions variées, en utilisant la moyenne spectrale appropriée pour opérer une taxinomie des catégories. Les pourcentages de classification obtenus selon cette méthode sont éleveés et ils montrent que, en ce qui concerne l'identité phonémique, un seul exemplaire de voyelle n'est pas aussi ambigu que peuvent le suggérer les mesures de formats. Les resultats s'accordent avec ceux des expériences sur l'identification de voyelles pronocées par des locuteurs inconnus et qui montrent que la connaissance antérieure de la voix d'un locuteur n'est pas cruciale pour corriger l'identification. Il peut être utile d'opérer un calibrage, particulièrement en fonction du sexe du locuteur, mais il est montré que la plus grande par de l'information néceessaire à cette normalisation est présente dans le spectre de l'exemplaire témoin. Une procédure préliminaire de normalisation algorithmique basée sur l'information spectrale contenue dans le témoin est présentée.
Cet article de tonalité théorique vise à dresser un état des lieux des dernières avancées en ingénierie des connaissances médicales dans le domaine spécifique de la conception d'ontologies et systèmes à base de connaissances. Reprenant des débats ayant animé le paysage de l'intelligence artificielle (IA) à partir des années 1960, sous l'impulsion des travaux de H. L. Dreyfus, il vise notamment à montrer que la plupart des difficultés aujourd 'hui rencontrées par l'ingénierie des connaissances dans le domaine de la santé sont inhérentes à la nature même de l'IA, en tant que projet de mécanisation de l'activité cognitive. Et il promeut à ce titre l'idée que seule une juste compréhension de ce que les machines ne peuvent faire, étant donné leur caractère machinique même, et qui reste, malgré sa finitude cognitive, une propriété exclusive de l'humain, pourra offrir d'équilibrer la balance entre les tâches allouables aux machines et celles laissées à la charge de ce dernier.
Les systèmes actuellement les plus performants en reconnaissance de la parole continue, indépendants du locuteur, atteignent un taux de reconnaissance de mots qui dépasse 94% en utilisant un lexique de 1000 mots maximum et une grammaire ou un modèle de langage d'une perplexité d'au maximum 60. Ces performances décroissent rapidement lorsque la perplexité de la grammaire augmente. Si l'on permet à l'usager de parler naturellement et d'utiliser des constructions de son choix, les perplexités augmentent de plus d'un ordre de grandeur. Heureusement, grâce à la technologie actuelle, la connaissance d'un domaine et celle des comportements de communication et de résolution de problème peuvent être utilisées pour faire décroître dynamiquement la perplexité et obtenir une interaction plus naturelle. La réduction de la perplexité à partir de ces connaissances aboutit à des performances égales à celles de systèmes usant d'un modèle de langage de basse perplexité dans le même ou dans des domaines différents. Dans cet article, nous abordons les problèmes liés à l'utilisation de connaissances sur la sémantique du domaine, sur le dialogue, les conventions de communication et le comportement de résolution de problème pour améliorer la reconnaissance et la compréhension automatique de la parole. Nous expliquons également les principles de base du système minds et en décrivons les sources de connaissance importantes et les heuristiques. Suit une brève analyse de certaines heuristiques qui ne doivent pas être réimplantées pour différents domaines. Nous abordons plus spécifiquement le fait de savoir pourquoi les heuristiques sont efficaces et de combien chacune d'elles pourra diminuer l'entropie et le facteur de branchement moyen pour tout domaine d'application possible.
Dans les applications, les erreurs d'un système de reconnaissance automatique de parole sont principalement dues à un manque d'efficacité de la détection des segments de parole dans le signal, à un manque de fiabilité du rejet des mots hors vocabulaire ou des bruits, et à une considération insuffisante des effets du bruit et des canaux de transmission. Dans ce papier, nous passons en revue un ensemble de techniques développées au CNET pour augmenter la robustesse aux variations des conditions d'utilisation et d'apprentissage d'un système de reconnaissance. Ces techniques se divisent en deux classes : prétraitement et adaptation des paramètres des modèles de Markov cachés (HMM). Les résultats de plusieurs expériences menées sur des bases de données d'exploitation, ainsi que sur des bases de données collectées à travers les réseaux RTC et GSM, sont présentées. Les sources principales d'erreurs sont analysées. On montre que l'égalisation aveugle des effets des lignes améliore significativement les performances de reconnaissance sur les données d'exploitation et les données GSM. Le module de détection de la parole dans le signal permet au système de déterminer les frontières des mots à reconnaı̂tre. Des techniques de prétraitement ont été utilisées pour améliorer la robustesse de la détection dans l'environnement GSM bruyant. On montre que la soustraction spectrale améliore la détection dans l'environnement GSM bruyant. Nos expériences montrent qu'un niveau de performance équivalent peut être obtenu par les adaptations Bayésienne et par régression des paramètres des HMMs. Les résultats obtenus prouvent que l'adaptation et les techniques de prétraitement peuvent être avantageusement combinées pour améliorer la robustesse de la reconnaissance automatique de la parole.
Cet article décrit les travaux menés au CNET ces dernières années, dans le domaine de la reconnaissance de la parole. Après avoir rappelé le contexte de cette recherche, on décrit le logiciel PHIL86 destiné à reconnaître des vocabulaires de petite taille, indépendamment du locuteur, et les développements matériels qui lui ont été associés. Deux expérimentations de la reconnaissance dans le domaine des Télécommunications sont ensuite présentées, en insistant principalement sur les enseignements qui en ont été tirés et les résultats des évaluations menées sur le terrain.
Dans cet article, nous décrivons notre avancée durant ces quatre dernières années (1995–1999) en transcription automatique d'émissions d'information provenant de la radio et de la télévision en utilisant le système de reconnaissance de la parole Byblos de BBN. De façon générale, nous avons réalisé des progrès constants comme le reflètent les résultats des quatre dernières évaluations Hub-4 de DARPA, avec des taux d'erreurs de 42.7%, 31.8%, 20.4% et 14.7% pour 1995, 1996, 1997 et 1998, respectivement. Ce progrès peut être attribué à des améliorations dans la modélisation acoustique, dans l'adaptation du locuteur et du canal de transmission, dans les algorithmes de recherche ainsi que dans la prise en compte de caractéristiques précises de la parole spontanée et de sa nature variable que l'on trouve dans ces émissions d'information radio et télédiffusées. En plus d'améliorer la précision de la reconnaissance, nous avons aussi réussi à développer plusieurs algorithmes afin d'atteindre une vitesse de reconnaissance proche du temps-réel sans sacrifier pour cela de façon significative la précision de la reconnaissance.
Dans cet article, nous nous intéressons à l'extraction automatique des contours des traits permanents du visage à savoir : les yeux, les sourcils et les lèvres. Pour chacun des traits considérés, un modèle paramétrique spécifique capable de rendre compte de toutes les déformations possibles est défini. Dans la phase d'évolution, chaque modèle est déformé afin de coïncider au mieux avec les contours des traits présents sur le visage analysé. Cette déformation se fait par maximisation d'un flux de gradient (de luminance et/ou de chrominance) le long des contours définis par chaque courbe du modèle. La définition de modèles permet d'introduire naturellement une contrainte de régularisation sur les contours recherchés. Néanmoins, les modèles choisis restent suffisamment flexibles pour permettre une extraction réaliste des contours des yeux, des sourcils et de la bouche. L'extraction précise des contours des principaux traits du visage constitue la première étape d'un ensemble d'applications multimédia.
Dans cette communication nous abordons des aspects multilingues de la reconnaissance automatique de la parole et nous essayons de les lier au concept d'interoperabilité. Après une définition possible de l'interopérabilité multilingue, les composantes d'un système de reconnaissance sont discutées en vue de séparer des éléments spécifiques à une langue des parties plus génériques. Nous donnons un aperçu de quelques projets de recherche en matière de reconnaissance multilingue en les séparant suivant différents styles de parole (lu, préparé, spontané). Le problème de l'adaptation à d'autres langues est ensuite abordé. Concernant la modélisation acoustique il existe actuellement des approches de modélisation (indépendante de la langue, inter-lingue,…) permettant le passage à une nouvelle langue sans corpus acoustique spécifique. Cependant l'ajout de telles données constitue toujours un avantage indéniable. Les dictionnaires de prononciation et les corpus textuels apparaissent aujourd'hui comme les ressources vraiment indispensables pour un portage rapide à une nouvelle langue. Or le portage rapide constitue une ètape importante vers l'interopérabilité multilingue. Les efforts en cours visant à produire des dictionnaires de prononciation et des corpus des texte, y compris des transcriptions de parole, devraient être étendus au plus grand nombre de langues possible. Ces efforts pourraient être combinés avec des initiatives ayant comme but la sauvegarde des langues minoritaires.
Les logiciels de CAO ont pour perspective de devenir de véritables outils d'aide à la conception d'objets physiques. Mais la conception préliminaire reste un domaine de recherche largement ouvert. Cet article de synthèse s'efforce de montrer qu'une approche par contraintes du processus de conception est incontournable pour atteindre ce but. La conception est vue ici comme un processus cyclique d'élaboration et de satisfaction de contraintes. Le modèle conceptuel associé est un modèle d'objets géométriques sous contraintes. Il est à plusieurs niveaux et intègre des connaissances géométriques et non géométriques. L'article se poursuit par l'exposé des différentes approches de la modélisation géométrique : paramétrique, variationnelle, par caractéristiques (features en anglais) et déclarative. Il se termine par une présentation rapide des méthodes de résolution et de décomposition des systèmes de contraintes utilisées en CAO.
De ce fait, l'introduction d'un détecteur d'activité vocale s'avère indispensable pour distinguer les séquences de bruit de celles du signal. Ce papier présente un algorithme de classification parole/bruit basé sur la fonction de cohérence estimée entre deux observations reçues et évalue son influence sur la méthode de réduction de bruit proposée par Ephraïm et Malah. Il apparaît que la détection ainsi réalisée conduit à des performances comparables à celles obtenues avec un détecteur manuel.
Le propos de cet article est de présenter une bibliographie récente sur l'utilisation des méthodes de représentation temps-fréquence en analyse et en traitement automatique de la parole. Les méthodes sont classées en trois grandes familles : méthodes dérivées de la production, méthodes d'analyse du signal, méthodes modélisant la perception. Après ce panorama, quelques rapides conclusions sur l'état actuel de l'utilisation de ces méthodes, et quelques perspectives sont tentées.
Ce papier présente un système de décision multi-classifieurs dont la conception est pilotée par la topologie des données d'apprentissage. Celle-ci est extraite grâce à l'introduction d'un nouvel algorithme d'apprentissage de carte neuronale auto-organisée qui a la propriété d'être incrémentale en données. Cette carte est utilisée en apprentissage pour distribuer la tâche de classification sur un ensemble de classifieurs. Elle permet ensuite d'activer en phase de décision le ou les classifieurs utiles pour une nouvelle donnée. Des résultats comparatifs sont donnés sur des exemples synthétiques, sur la base de segmentation d'images de l'UCI et sur le problème de reconnaissance de chiffres manuscrits sur des données de la base NIST.
Cet algorithme a été testé sur 3 bases de données (parole téléphonique bruitée artificiellement à 0 dB, enregistrement dans une automobile et parole “propre”) regroupant cinquante-huit locuteurs. Le système a été comparé, à AMPEX (modèle auditif) et à des contours de fréquence glottale obtenus de façon manuelle ou par laryngogrammes. Notre algorithme inclut un module de sélection automatique des canaux significatifs ainsi qu'un module d'extraction de fréquence glottale basé sur un pseudo-histogramme périodique (obtenu par combinaison de produits scalaires normalisés des signaux provenant des canaux sélectionnés). Sur les enregistrements bruités (voiture et parole téléphonique à 0 dB), le système proposé dépasse AMPEX. Il a été observé que la sélection automatique des canaux améliore les performances sur la parole à 0 dB mais pas sur les enregistrements en véhicule automobile. L'article décrit le système proposé ainsi que les performances en termes de décisions voisé/non voisé, d'erreur fine et grossière.
Cet article décrit un cadre théorique pour l'optimisation de la structure et des paramètres d'un système de reconnaissance de grands vocabulaires basé sur des HMMs avec des densités d'émission continues, utilisant le critère d'estimation de l'information mutuelle maximale (MMIE). Pour réduire la complexité calculatoire de l'algorithme d'apprentissage MMIE, les segments de parole pouvant être confondus sont identifiés et stockés sous forme de treillis de mots des diverses hypothèses de séquences. Une procédure itérative de division des gaussiennes est également employée pour ajuster, à chaque état, le nombre de composantes des mélanges pendant l'apprentissage afin d'obtenir le meilleur compromis entre le nombre de paramètres et le volume de données d'apprentissage disponible. On présente des résultats expérimentaux sur divers ensembles de test de la base de données “Wall Street Journal” qui utilisent jusqu'à 66 heures de données de parole pour l'apprentissage. Ces résultats démontrent que l'utilisation de treillis rend l'apprentissage MMIE utilisable pour des systèmes de reconnaissance très complexes et des ensembles d'apprentissage très grands. De plus, ils montrent que l'optimisation MMIE de la structure des systèmes et des paramètres peut aboutir à des améliorations utiles des performances de reconnaissance.
Nous nous intéressons au problème d'appartement de primitives entre deux images. Nous proposons dans ce papier une approche utilisant un modèle de réseau de neurones pour résoudre le problème. Nous avons choisi le modèle de Hopfield d'une part parce qu'il est souple et ouvert, d'autre part parce qu'il peut s'implanter aisément sur des calculateurs massivement parallèles.
Le maintien à domicile des personnes âgées est devenu un enjeu important de santé publique. Nos travaux sont destinés à traiter à grande échelle l'information recueillie au domicile des personnes pour en faire une information consolidée décrivant des comportements globaux. Nous proposons pour ce faire des algorithmes de classification pour identifier des profils collectifs et y rattacher les personnes suivies. Ces algorithmes tirent profit des technologies multi-agents afin de gérer l'hétérogénéité des équipements et des services produisant l'information ainsi que leur totale distribution. Les profils obtenus sont utilisés pour estimer l'état des personnes âgées et les efforts à déployer pour qu'elles puissent continuer à vivre à leur domicile, et à un niveau plus global pour évaluer des tendances sanitaires générales (épidémie, fortes chaleurs, etc.).
Puisque l'optimisation simultanéee du codage de source et de la voie de transmission est souvent impossible en ce qui concerne le codage de la parole, il est utile de développer des codages optimaux correspondant à l'agorithme spécifique de codage de la parole qui fonctionne sous des conditions spécifiées d'erreur de transmission. De tels codes d'erreur de transmission qui dépendent de la source peuvent être obtenus en minimisant un critère approprié de distorsion de la parole. Nous utilisons une procédure de “recuit simulé” afin d'accomplir cette minimisation. Les codes qui en résultent fonctionnent bien puisqu'ils fournissent une correction d'erreur non uniforme (les niveaux de quantification à grande probabilité sont corrigés de manière plus précise) et/ou une détection d'erreur non uniforme (les erreurs qui ont un impact important sur la qualité de la parole ont plus de chances d'être détectées). On peut obtenir un compromis optimal entre les corrections et détections d'erreurs. Les codes de voie de transmission dépendants de la source et développés pour réagir conre les faibles taux d'erreurs aléatoires (pas plus de 2%) sont appliqués à algorithme de CELP et les performances qui en résultent sont décrites. Il a été constaté qu'une petite allocation de mots de code pour la protection d'un paramètre particulier (qui équivaut à moins d'un bit) aboutit souvent à une grande amélioration des performances.
Cet article présente un panorama des travaux de recherche réalisés à l'occasion du projet européen CAVE, consacré à la vérification du locuteur en mode dépendant du texte sur le réseau téléphonique, et basé sur la modélisation de mots par modèles de Markov cachés. Ce texte détaille les différents aspects technologiques et méthodologiques sur lesquels ces recherches se sont appuyées. Il traite plus particulièrement du problème de l'estimation de modèles du locuteur dans le contexte de données d'apprentissage limitées et du réglage a priori du seuil de décision. Les expériences sont effectuées sur une base de données de parole téléphonique réaliste : la base de données SESP. Les performances obtenues sont au niveau de l'état de l'art, ce qui valide les choix techniques développés et évalués lors du projet, ainsi que l'infrastructure de travail qui a favorisé la coopération entre les partenaires.
Notre étude traite de l'estimation des paramètres dans les chaînes de Markov cachées et de la segmentation statistique non supervisée d'images. Nous proposons deux algorithmes originaux d'estimation obtenus à partir des méthodes Iterative Conditional Estimation (ICE) et Stochastic Expectation Maximisation (SEM), notés MICE et MSEM respectivement, et montrons leur compétitivité vis-à-vis de l'algorithme Expectation Maximisation (EM) dans différents cas d'homogénéité et de bruitage des chaînes. L'étude du comportement des trois algorithmes de restauration non supervisée des chaînes obtenus par l'adjonction à la méthode Mode de la Marginale a Posteriori (MPM) des algorithmes EM, MICE, MSEM respectivement est ensuite proposée. La transformation des processus bi- dimentionnels en processus mono-dimentionnels par le parcours de Peano rend possible l'application de ces algorithmes au problème de la segmentation statistique non supervisée d'images. On obtient ainsi des méthodes plus rapides que celles utilisant des modélisations par champs de Markov cachés et nous montrons que la perte de l'efficacité est, en général, acceptable. La souplesse de notre modélisation permet par ailleurs la conception de nombreux algorithmes de segmentation statistique non supervisée spatio-temporelle d'images. Nous en proposons trois et présentons les résultats de leur application à la segmentation d'une séquence d'images réelles.
Cet article présente un réseau RFR récurrent (Réseaux Récurrent à Fonction de base Radiales) appliqué à un problème de pronostic d'un système non linéaire. Le processus d'apprentissage du réseau RRFR se décompose en deux étapes. Dans une seconde étape, les poids des connexions de sortie sont déterminés par une technique supervisée de régression linéaire. La technique FuzzyMinMax rend la convergence de l'algorithme des K-moyensplus stable.
Les techniques de modifications de l'échelle temporelle et, à un degré moindre, de la fréquence fondamentale présentent un intérêt théorique et pratique certain. Les applications sont nombreuses, et incluent, pour n'en citer que quelques-unes, la synthèse de parole à partir du texte (par concaténation d'unités acoustiques), les transformations du timbre de la voix, l'apprentissage des langues étrangères, mais aussi le contrôle audio ou la post-synchronisation. Pour satisfaire ces besoins, un grand nombre d'algorithmes ont été proposés ces dernières années, apparemment différents mais en fait très proches sur le plan des mécanismes de base. Cet article présente les méthodes frequentielles (vocodeur de phase) et temporelles (Time-Domain Pitch-Synchronous Overlap/Add) dans un même formalisme. Plusieurs méthodes plus récentes, dérivées de ces techniques fondamentales sont également décrites.
La reconnaissance automatique de la parole par des ordinateurs peut fournir le moyen de communication homme — machine le plus naturel et le plus efficace. Bien que ces dernières années des systèmes de reconnaissance très performants aient déjà émergé des centres de recherche, les scientifiques s'accordent unanimement à dire que le déploiement de systèmes de reconnaissance de la parole dans un environnement de travail réel va nécessiter de nombreuses heures de données de parole pour pouvoir modéliser la variabilité inhérente au signal de parole. Cette dernière base de données est particulièrement utile comme source de phrases spontanées induites dans un environnement réaliste et ciblé.
Il faut résoudre límportant problème de la relation entre le traitement de la parole et le traitement linguistique pour pouvoir utiliser la reconnaissance de la parole continue avec de grands vocabulaires dans des systèmes de traduction de la parole ou comme interface de système homme-machine. Dans une première phase, notre système reconnaît les phonèmes à l'aide de chaînes de Markov cachées (HMM). Ensuite, un analyseur grammatical LR généralisé est utilisé pour prédire les mots et phonèmes suivants. La combinaison des deux méthodes (HMM-LR) permet de reconnaître une phrase japonaise. L'utilisation d'informations linguistiques permet d'éliminer un grand nombre de phrases candidates. Un système expérimental de traduction japonais-anglais a été implémenté. La traduction se déroule en trois phases : analyse, transfert, génération. Une nouvelle méthode incorporée dans le système analyse l'expression des intentions contenues dans les énoncés.
Cet article présente un résumé des usages actuels, en 1994–1995, en France, des systèmes de Reconnaissance et de Synthèse de la parole du CNET dans des Services Vocaux Interactifs. On y analyse également les résultats d'évaluation de certains de ces services, en condition d'exploitation. Enfin, cet article décrit brièvement les principaux développements récents des technologies de reconnaissance et de synthèse de la parole du CNET.
Mais en l'absence d'information sur le signal d'excitation, l'application de ces méthodes ne peut être directe. Après avoir mis en évidence le mécanisme qui limite la précision de l'estimation dans ce cas, nous présenterons une solution fondée sur la détection et la suppression d'impulsions dans le résidu. Cette approche permet d'améliorer l'estimation des paramètres dans le cas où le résidu est proche d'un train d'impulsions. Nous examinerons enfin l'utilité de cette méthode pour l'analyse spectrale du signal de parole.
Dans cet article, nous proposons une nouvelle méthode d'apprentissage des unités de synthèse pour une synthèse de la parole multi-langues et nous en décrivons une application à la synthèse de la parole en anglais. Cette méthode appelée Agglomération Orientée vers un Contexte Multi-Couches (ML-COC en anglais) repose sur la généralisation de la méthode COC qui a été appliquée à la synthèse de la parole pour le japonais. La méthode COC classique produit un ensemble d'unités dépendantes du contexte phonétique par un processus de clivage d'un agglomérat. Avec la ML-COC, la notion de contexte est généralisée et des facteurs autres que le contexte phonétique, comme l'accentuation et les frontières syntaxiques, sont pris en compte pour appréhender la plus grande diversité des phonèmes de la langue anglaise. Une expérience de génération d'unités de synthèse a montré que la ML-COC produit environ trois fois plus d'unités de synthèse que la classique SL-COC, c'est-à-dire COC à simple couche, et qu'il y a environ 20% de variance en moins sur les unités de synthèse ML-COC. Ces résultats suggèrent que les unités de synthèse produites par la ML-COC reflètent plus fidèlement la structure phonologique de l'anglais que celles obtenues par la SL-COC. Pour valider l'efficacité de la méthode ML-COC, nous avons effectué une expérience où les sujets devaient choisir la parole synthétique qu'ils préféraient. L'essai portait sur 52 phrases et a été répété avec 10 sujets. La méthode ML-COC l'emporte sur la méthode classique SL-COC avec un score de 70% à 30%.
Ce travail concerne les techniques de reconstruction d'images tridimensionnelles pour la détection de petits foyers tumoraux et de métastases, à partir de données acquises en Tomographie d'Emission de Positons (TEP). En TEP, la présence d'un foyer tumoral se traduit par une hyperfixation du traceur injecté, localisée au niveau de la tumeur. Ceci nous conduit à modéliser la distribution volumique du radiotraceur à l'aide d'un mélange de lois, qui traduit le fait que chaque point de l'objet a une activité soit normale, soit surélevée. Nous proposons de résoudre ce problème par une méthode de Maximum d'Entropie sur la Moyenne. Les résultats obtenus avec l'approche proposée sont comparés à ceux fournis par deux méthodes de référence en milieu hospitalier. Sur données simulées, les résultats obtenus avec MEM sont significativement meilleurs que ceux obtenus par les autres méthodes, au sens d'un critère d'évaluation développé afin de quantifier la qualité des images en terme de détectabilité d'hyperfixations. La faisabilité clinique de la méthode est également illustrée.
En radiothérapie conformationnelle, le calcul des doses et des balistiques des faisceaux à appliquer pour irradier la tumeur se fait en se basant sur des images tomographiques (IRM ou scanner (TDM)) réalisées avant le traitement. Celui-ci dure plusieurs séances réparties sur plusieurs semaines. Au début de chaque séance le patient doit être installé sur la table de traitement dans les conditions initiales de planification. Actuellement, les méthodes les plus utilisées pour ce repositionnement se basent sur l'anatomie externe du patient et supposent une immobilité des organes internes. Ce travail présente une nouvelle approche, adaptée aux conditions cliniques, pour le repositionnement automatique du patient en radiothérapie de la prostate. Elle est basée sur un repérage temps réel par échographie et une mise en correspondance rapide et précise avec des images générées dans le volume de planification. La méthode exploite une modélisation statistique de la prostate pour extraire automatiquement ses contours. Les premiers tests de la méthode dans les conditions réelles d'une séance de radiothérapie montrent que le repositionnement peut être obtenu avec une précision de l'ordre de 1.4 mm.
Les consonnes occlusives sont produites en réalisant une occlusion du conduit vocal, en créant une pression de la bouche derrière cette occlusion puis en relâchant cette occlusion. Au moment de la détente, ces composantes comportent une transitoire initiale, une bouffée de bruit fricatif, et un intervalle où l'on observe une source sonore au niveau de la glotte et des transitions de formants. Les modèles prédisent les niveaux absolus des ces différentes composantes pour divers lieux d'articulation des consonnes.
Ce papier présente une nouvelle approche pour l'égalisation des effets des lignes téléphoniques sur le signal observé à l'entrée d'un système de reconnaissance automatique de la parole afin d'augmenter la robustesse de ce système. Des mesures effectuées sur des données téléphoniques réelles confirment que les lignes téléphoniques introduisent des composantes convolutives dans le signal observé. Les effets de ligne sont presque constants pour un appel donné mais varient d'un appel à un autre. Le filtrage adaptif proposé est comparé à deux techniques classiques, la soustraction du cepstre à long terme et le filtrage passe-haut des trajectoires cepstrales. Des expériences de reconnaissance en mode indépendant du locuteur sont effectuées sur des bases de données téléphoniques. Les résultats montrent que la réduction des effets des lignes téléphoniques améliore les performances d'une manière significative. Ces résultats montrent aussi que la méthode proposée donne des meilleures performances que le filtrage passe-haut des trajectoires cepstrales. Néanmoins, la soustraction du cepstre à long terme, qui n'est pas une approche en ligne, reste légèrement plus performante que l'approche proposée. Quelques expériences ont été effectuées pour mesurer la quantité du signal nécessaire pour une bonne estimation des effets du canal. Il semble que moyenner les cepstres des trames sur quelques secondes de parole permette d'obtenir une estimation fiable du cepstre du canal.
Dans le cadre d'une discussion sur le phénomène du Pétrarquisme, en tant que procédé d'imitatio à l'intérieur des différents genres littéraires, on étudie les modalités de transmission des schémas et des images pétrarquistes, en comparant les sonnets préliminaires (I et II) des Erreurs amoureuses de Pontus de Tyard (1549), analysés en parallèle avec Voi ch'ascoltate in rime sparse il suono et avec le premier sonnet des Amours de Ronsard. Les deux premiers sonnets des Erreurs amoureuses représentent un dédoublement de l'apostrophe préliminaire traditionnelle, adressée à un public qui est spectateur des souffrances d'amour et prend part lui-même à ces souffrances. Ces sonnets dérivent de Pétrarque le thème du giovenile errore, tout en interprétant erreur selon les deux acceptions principales, dans la polysémie du terme : erreur en tant que voyage (errance), et erreur en tant que faute. Pour ce qui concerne Pontus de Tyard, de toute évidence Pétrarque est le modèle fondamental, aussi bien au niveau de la structure qu' au niveau du lexique. En effet, c'est le niveau lexical qui nous fournit des renseignements dans ce domaine : l'emploi même des lexèmes errore/erreur nous démontre dans quelle mesure la tendance à la variatio sur l'archétype pétrarchiste devient un fait en premier lieu rhétorique.
Les termes de 'racine', 'affixe', puis 'suffixe' et 'préfixe' n'appartiennent pas au matériel lexical créé pendant l'Antiquité, mais comme celui de 'scheva' ou 'shewa', résultent de la découverte de la grammaire hébraïque par les grammairiens de langue latine, à la Renaissance. Ces mots nouveaux, dont on examine ici la naissance et le développement, nous semblent caractéristiques d'un nouveau type d'approche des langues. Pour la première fois, les grammairiens de langue latine sont confrontés à une tradition étrangère, vivante et prestigieuse. La tradition grammaticale hébraïque, qu'ils découvrent, leur fournit aussi un champ de réflexion et des outils d'analyse. De cette rencontre avec une langue et avec sa tradition critique, qui offre vaste matière à comparaisons, vont sortir des termes nouveaux et une perspective renouvelée sur l'analyse morphologique des langues.
L'article présente une méthode d'inversion acoustico-géométrique basée sur le calcul direct des dérivées par rapport au temps des sections et longueurs d'un modèle du conduit vocal. Ce modèle du conduit est une concaténation de tubes uniformes dont la taille varie avec le temps. Ces dérivées sont obtenues en résolvant un système algébrique linéaire d'équations. Elles sont intégrées numériquement pour aboutir aux mouvements des sections et longueurs. Des contraintes sur les pseudo-énergies potentielles et cinétiques sont imposées afin d'arriver à une solution unique.
Nous nous intéressons aux méthodes heuristiques pour résoudre un problème de classification de bouchons naturels en liège. Plus précisément, nous cherchons à optimiser les valeurs de paramètres d'une règle de tri utilisée quotidiennement pour classer les bouchons. Nous expérimentons plusieurs métaheuristiques et nous les comparons à l'aide d'un jeu de données réelles issues de l'industrie. Les résultats que nous obtenons permettent d'améliorer le taux de classement actuel. Nous proposons aussi, à partir de nos observations, de nouvelles pistes de recherche qui pourront permettre d'améliorer encore plus la qualité de la classification des bouchons en liège.
Nous présentons un système de lecture automatique des montants numériques des chèques dont le principe repose sur une technique de segmentation des caractères validée par la reconnaissance. Ce système est décrit depuis la phase de localisation du champ montant sur le document numérisé, jusqu'à la génération de la liste des hypothèses de montant. La segmentation, de type explicite, permet de déterminer des zones de coupure potentielles entre caractères et fournit une représentation spatiale des composantes segmentées. Le meilleur chemin de segmentation du montant est déterminé par la combinaison des scores de reconnaissance des caractères, de la vraisemblance de la segmentation et de la probabilité d'apparition de ce montant. Afin de pouvoir quantifier la robustesse de ce système, nous avons mesuré ses performances à partir d'une base de 10 000 images de montants de chèques réels.
Cet article décrit le système RailTel développé au LIMSI, destiné à l'accès vocal en Français aux horaires des trains de la SNCF et permettant d'évaluer l'adéquation des techniques vocales pour les services interactifs. Le système utilisé pour le recueil de corpus des tests a été développé à partir du système Mask du LIMSI. Il fonctionne sur une station Unix avec une interface téléphonique de haute qualité. Le système offre un dialogue à initiative partagée où l'utilisateur peut fournir les informations à tout instant. Les utilisateurs expérimentés peuvent fournir toutes les informations en une seule phrase, tandis que les utilisateurs moins expérimentés ont tendance à donner de courtes réponses laissant le système les guider. Les tests de RailTel ont été effectués selon une méthodologie commune définie par le consortium. 100 sujets naı̈fs ont participé aux tests, chacun a appelé le système une seule fois et rempli un questionnaire. 72% des sujets ont achevé leurs scénarios avec succès. L'évaluation subjective du prototype était en majorité favourable, avec un intérêt d'utiliser un tel service.
Nous étudions le comportement des prédicteurs ARMA adaptatifs du point de vue de leur stabilité, en utilisant, pour l'adaptation, l'algorithme LMS récursif et un algorithme avec erreur a posteriori. L'entrée du prédicteur est un signal stationnaire à bandes étroites, ou un signal non stationnaire de parole. D'une part, nous montrons que l'utilisation de l'erreur a posteriori dans l'algorithme d'adaptation amortit les oscillations dues au phénomène d'autostabilisation, par rapport au cas de l'algorithme LMS. D'autre part, nous faisons le lien entre l'instabilité de l'algorithme LMS et la non-stationnarité due à des sauts de puissance dans les signaux de parole. Finalement l'utilisation d'un algorithme avec erreur a posteriori assure la stabilité au sens entrée bornée/sortie bornée, même pour -un signal non stationnaire.
Cet article étudie les performances d'un système d'identification du locuteur en mode dépendent du texte pour un petit ensemble de locuteurs. Une phrase commune àtous les locuteurs est utilisée comme mot de passe, chaque locuteur disposant de son modèle acoustique de phrase représentépar un modèle de Markov caché(HMM). Différentes méthodes d'estimation de modèles sont étudiées : l'une fondée sur un critère du maximum de vraisemblance (MLE), l'autre sur un critère du minimum d'erreurs de classification (MCE). Le modèle MLE de chaque locuteur est estimé à partir des données d'apprentissage associées, alors que le modèle MCE est construit à partir de toutes les phrases d'apprentissage du groupe de locuteurs. Dans une autre série d'expèriences, des phrases d'apprentissage supplémentaires, provenant soit des locuteurs du groupe, soit de locuteurs externes au groupe, sont utilisées pour estimer les modèles. Les résultats expérimentaux montrent que les taux d'erreurs d'identification sont multipliés par 2 lorsque l'on passe d'un ensemble de 5 locuteurs àun ensemble de 10 locuteurs. Les taux d'erreurs d'identification en ensemble ouvert et fermésont réduits de 25% lorsque MCE est utiliséàla place de MLE, alors que les taux de fausse acceptation d'imposteurs diminuent d'environ 10%. L'amélioration la plus importante est obtenue lorsque des phrases additionnelles sont utilisées pour l'apprentissage, à la fois pour les modèles MLE et MCE. Sous cette configuration, avec les modèles MCE, les taux d'erreurs d'identification sont approximativement 0.4% et 0.6% pour les ensembles de 5 et 10 locuteurs, alors que les taux d'acceptation des imposteurs sont respectivement de 4% et 10%, pour un taux de faux rejet de 5%.
Nous présentons un formateur de faisceau à double fonction applicable dans le cas d'un système de reconnaissance La sortie à niveau de bruit diminué convient aussi bien pour la transmission que pour l'entrée d'un système de reconnaissance de la parole. Les conditions ambiantes visées sont la voiture, l'atelier ou un bureau bruyant. La structure sous-jacente est constituée par un formateur de faisceau Griffiths-Jim dirigé, avec interrupteur supplémentaire de détection de la parole à utiliser pour l'adaptation sélective des deux fonctions. Ce formateur de faisceau est efficace pour la suppression des interférences stationnaires et des interférences non-stationnaires et constitue de la sorte une unité de pré-traitement destinée à une gamme d'applications de reconnaissance de la parole plus large que celles pourrait traiter un système de suppression de bruit de fond à canal unique. Des expériences ont été réalisées dans une chambre à écho équipée d'un réseau à 4 microphones. Les améliorations typiques en matière de rapports signal/bruit à des fins de communication se situent entre 4 et 12 dB. L'amélioration effective du rapport signal/bruit à des fins de reconnaissance de la parole se situe entre 4 et 8 dB.
A nos jours, la synthèse de la parole automatise avantageusement les services en donnant oralement l'information contenue dans des bases de données d'ordinateur. Quelques uns de ces services offrent des informations routières, des informations sur le trafic et sur les horaires, des quota de stock et des informations financières correspondantes, et des commandes sur catalogue. Un service de télécommunications, qui connaı̂t un succès tout particulier, est l'automatisation des noms et adresses des abonnés (`Automated Customer Name and Adress' ACNA), connu parfois sous le nom d'annuaire inverse (`Reverse Directory Assistance' RDA). Ce service demande une synthèse de parole avec une grande intelligibilité et une bonne prononciation des noms, ce qui peut être atteint par l'état de l'art de la technologie de synthèse. Néanmoins, même la meilleure des technologies actuelles n'est pas suffisamment performante pour s'appliquer directement dans des services complexes. Un prétraitement d'un répertoire personnalisé est nécessaire pour transformer une liste de données, qui généralement contient des abréviations non conventionnelles, des acronymes non connus par le synthétiseur, et un ordre de mots chiffré, en une phrase appropriée pour la synthèse. Nous décrivons nos programmes de prétraitement des répertoires qui sont utilisés avec succès dans des implantations de la synthèse chez deux opérateurs téléphoniques majeurs aux états unis. Il est aussi nécessaire que les noms des localités, qui ont une variabilité géographique considérable, soient prononcés en accord avec les accents locaux ; sinon, le service sera perçu comme étranger par les usagers. Nous décrivons aussi des expériences visant à déterminer si le naturel de la parole enregistrée pour des prompts et des messages fixes compensent l'effet non désiré de la discontinuité entre les mots synthétisés et naturels.
Dans cet article nous proposons une approche de reconnaissance de l'écriture manuscrite. L'objectif étant de proposer un système indépendant de la nature du script, nous procédons alors sans segmentation. Pour valider l'approche proposée nous avons effectué des expérimentations sur deux bases de données de référence, la base de mots arabes IFN/ENIT et la base IRONOFF de mots latins. Les résultats montrent que le système proposé donne de bons résultats comparables aux meilleurs approches rapportées dans la litérature, aussi bien sur le Latin que sur l'Arabe.
Dans cet article, des développements récent concernant l'extraction, à partir de l'onde de parole, des indices dépendants du locuteur, l'identification et la vérification automatiques du locuteur, l'adaptation au locuteur en reconnaissance automatique de la parole et les techniques de conversion de voix sont discutés. L'information concernant le locuteur se trouve à la fois dans l'enveloppe spectrale et dans les traits prosodiques de la parole. Cette information peut de plus être classée en traits temporels et traits dynamiques. Les méthodes de vérification/identification du locuteur peuvent être divisées en méthodes dépendantes du texte et méthodes indépendantes du texte. Bien que les techniques de vérification du locuteur dépendantes du texte aient presque atteint le niveau de développement approprié pour l'implémentation pratique, les techniques indépendantes du texte en sont toujours au stade de la recherche fondamentale. En reconnaissance de parole, des algorithmes d'adaptation au locuteur supervisés et non supervisés ont récemment été proposés, et des progrès remarquables on été réalisés dans ce domaine. L'amélioration de la qualité de la parole synthétique par l'ajout de caractéristiques vocales individuelles et la conversion de l'individualité vocale synthétique d'un locuteur à l'autre sont des sujets de recherche peu exploités actuellement qui devraient être étudiés dans un proche avenir. La recherche sur l'information dépendante du locuteur constitue l'une des plus importantes directions à suivre pour réaliser des systèmes avancés de traitement de l'information dans le domaine de la parole.
La communication interethnique au Cameroun se caractérise souvent par un discours dévalorisant l'identité ethnique de l'autre. Lequel discours apparaît généralement sous forme d'insultes, de vannes, railleries ou blagues, racontées, chantées, romancées, radiodiffusées et télévisées parfois, et colportées de génération en génération. Cet article rend compte de quelques stratégies employées pour dénigrer l'altérité ethnique au Cameroun. Les analyses menées à partir de données (questionnaires, observations participantes, interviews), collectées à Yaoundé et dans d'autres régions du pays, montrent comment les Camerounais utilisent les emprunts, compositions nominales, métaphores, glissements sémantiques, métonymies, entre autres, pour déprécier, déshumaniser, diaboliser les membres de certains groupes ethniques et/ou pour gommer, phagocyter ou contester l'identité ethnique d'autres groupes.
La reconnaissance des syllabes est un problème-clé pour les systèmes de reconnaissance de larges vocabulaires en Madarin. Traditionnellement, le ton et la syllabe de base correspondant à une syllabe donnée sont reconnus séparément. Dans cet article, on propose une approche de la reconnaissance des syllabes en Madarin basée sur la classification d'unités sub-syllabiques : parties initiales, finales et transitions. Les unités finales sont classées en fonction des variations des tons pour optimiser les possibilités de discrimination tonale. Nous avons développé un système de reconnaissance des syllabes en Mandarin qui utilise des modèles de Markov cachés (HMM) à partir de paramètres cepstraux et dans lequel les syllabes de base et leurs tons associés sont reconnus conjointement. Les résultats expérimentaux montrent que ce système fournit une taux de reconnaissance plus élevé que les systèmes de reconnaissance de syllabes tranditionnels quand on utilise une quantité suffisante de données d'apprentissage. On montre également que les performances de ce système peuvent être améliorées en y incorporant un système de reconnaissance de tons.
Cet article se propose de dresser une synthèse et une classification des diverses applications du dialogue oral homme-machine. Il présente, dans une première partie, les avantages et les limites de la parole comme moyen de communication entre un utilisateur et un système automatisé. Le problème essentiel pour le développement d'interfaces utilisateur à composante orale, à côté du choix d'applications appropriées, est la reconnaissance de la parole, spécialement de la parole continue. Comme les approches diffèrent suivant le type d'applications, nous présentons tout d'abord les problèmes et les techniques spécifiques à l'entrée orale de données et, à titre d'exemple, nous décrivons rapidement l'approche que nous avons adoptée pour la machine à dicter que nous développons dans notre laboratoire. Ensuite nous abordons la compréhension et la gestion de dialogues oraux. Pour illustrer cette présentation, nous présentons l'architecture et les fonctionnalités de divers prototypes que nous avons mis en œuvre : système de messagerie électronique, dialogue pour la commande d'une console sonar et dialogue entre un chirurgien et un système d'aide au diagnostic. Enfin, nous détaillons le gestionnaire de dialogues DIAL, en cours de développement, dont l'objectif est d'aider et de guider un utilisateur dans des activités cognitives complexes telle la recherche de renseignements administratifs.
Nous présentons et discutons le modèle SAPHO (segmentation par les connaissances acoustico-phonétiques) mis en œuvre en langage AWK sous UNIX, sur une station de travail Masscomp. Ce système est conçu comme une procédure de segmentation indépendante du locuteur fondée sur une reconnaissance préalable du mode d'articulation phonétique. Dans la plupart des modèles RAP, les connaissances phonétiques sont toujours utilisées, au moins de façon implicite. Elles doivent l'être de façon explicite. Les unités phonémiques ne peuvent pas être directement construites à partir du signal acoustique ; elles ne sont pas encore disponibles à la sortie de SAPHO. Suivant le modèle de Construction de Niveaux (Level Building), SAPHO fournit un ensemble hiérarchisé de propriétés et de segments acoustiques, de propriétés et de segments phonétiques congruents avec les unités phonétiques et leur structure interne. La souplesse de ce système est assurée par sa modularité. La fiabilité de SAPHO est corroborée par l'exactitude des résultats.
Des spectres moyens à long terme (LTS) définis sur 400 canaux de largeur de bande constante (12.5 Hz) ont été tirés de productions françaises au moyen d'un analyseur BK 2033. Le coefficient de correlation a été utilise pour étudier la variabilité résiduelle intralocuteur du LTS en conditions tant inter-qu'intratexte. D'importantes différences provenant des sujets ont été relevées dans les deux types de conditions. Elles indiquent l'existence de variations de la coherence vocale parmi les locuteurs. L'abaissement des corrélations en conditions intertexte révéle, en outre, la dépendance du LTS vis-à-vis du contenu. La nécessite d'entreprendre des recherches fondamentales sur le LTS avant de passer aux applications est dés lors soulignée.
L'utilisation massive des catégories cliniques de l'aphasie dans les recherches en neurolinguistique et en neuropsychologie cognitive laisse présumer que les classements des patients reflètent les atteintes du système de traitement du language selon des cadres théoriquement pertinents. On examine ce présupposé en se rapportant plus particulièrement à l'aggramatisme. De nombreuses raisons amènent à s' interroger sur la cohérence de l'aggramatisme comme entité psychologique. Pour répondre aux objections, il est nécessaire de remplacer les intuitions cliniques qui fondent cette catégorie d'aphasie par des critères objectifs permettant un groupement theoriquement pertinent des patients. Pour cela on doit établir une distinction theoritiquement motivée entre la variation inter et intra catégorie. Dans le cas de l'agrammatisme il semble des obstacles méthodologiques sérieux rendent ce propos impossible. Les théories ne doivent donc pas prendre les catégories telles que l'agrammatisme comme des données psychologiques, particulièrement lorsque le but de la recherche est de comprendre les mécanismes de traitement du langage ou les déficits aphasiques eux-mêmes dans l'étude de l'aphasie.
Notre conception de ce que le mécanisme de production de parole essayd'implémenter lors de l'acte de parole vient de la linguistique. Mais la linguistique a d'abord développé ses méthodes pour d'autres buts. Au début du 19èmes siècle, elle a mis au point une méthode pour retracer les relations de parenté entre des mots de même origine et les sons qui les constituent. Cette méthode, la méthode comparative, impliquait d'établir une filiation optimale entre ces formes via une forme-parent reconstruite. La linguistique structuraliste du 20ème siècle (y compris la phonologie générative) a appliqué essentiellement la même méthode pour tâcher de découvrir les constituants phonémiques sous-jacents des mots. Bien que la structure sous-jacente découverte de cette manière puisse constituer une bonne hypothèse de ce que sont les èlèments mentaux qui déterminent les phrases effectivement produites, il y a des raisons de suspecter que cela est trop simple. Trop d'importance est attachée à la simplicité du système et à la fonction purement lexicale (en opposition avec les fonctions démarcative et stylistiqué) des éléments dans la parole. Cet article présente quelques essais préliminaires pour différencier les variantes phonétiques de la parole qui prennent leur origine dans une seule forme sous-jacente de celles qui proviennent de formes sous-jacentes séparées (bien qu'elles puissent avoir eu historiquement une source commune).
L 'information n 'est utile que si elle répond à un besoin et lorsqu 'elle est communiquée de manière à en faciliter la compréhension et l'utilisation. Nous avons tous fait l'expérience de la recherche d'information sur le web, multipliant les requêtes à l'aide d'un moteur de recherche dans l'espoir d'obtenir un lien intéressant, et finalement, essayant d'organiser ensemble les différents résultats obtenus. Dans cet article, nous présentons le Virtual Document Planner, une plateforme conçue pour aider à la génération de documents personnalisés. Le VDP sélectionne et organise de l'information pouvant provenir de sources variées et nécessitant d'être présentée de manière à en faciliter la compréhension et l'utilisation. Pour illustrer cette approche, nous présentons une application dans laquelle le VDP génère des brochures présentant les recherches menées à CSIRO dans un domaine donné. Enfin, nous présentons les résultats préliminaires d'une expérience que nous avons menée pour évaluer l'impact d'une telle approche sur l'utilisateur.
Cet article propose une comparaison des processus de sélection séquentielle dans la recherche d'indices pertinents permettant la prédiction anticipée de la syncope lors d'un test diagnostique. Afin d'exploiter au mieux les qualités des différentes approches de sélection de variables, une approche hybride a été proposée combinant un processus séquentiel et un algorithme génétique. Les résultats obtenus permettent de prédire l'apparition de la syncope avec une sensibilité de 100 % et une spécificité de 94 %.
Le rôle de l'Analyse des Scènes Auditives dans la perception de la parole est encore mal défini, notamment en ce qui concerne l'établissement d'un groupement perceptif des formants par les auditeurs. Les expériences présentées ici ont pour objet d'étudier le rôle des formants vocaliques dans la perception de syllabes synthétiques voyelle-nasale et l'importance de la continuité entre voyelle et nasale. Lorsque la transition de la voyelle vers la nasale est abrupte, l'accroissement de la fréquence de F2 favorise la perception d'un /n/. L'introduction d'une transition formantique continue supprime cet effet, permettant aux auditeurs de percevoir le phonème approprié pour chacune des nasales. Cependant, lorsque transition formantique et prototype nasal sont discordants, le percept est déterminé uniquement par la pente de la transition. Dans chacune des expériences présentées, le percept est donc déterminé par la cible de la transition du F2 vers la nasale, cet indice dominant la structure formantique de la consonne nasale. Les résultats ne favorisent pas un modèle de poursuite des formants et conduisent plutôt à envisager des processus d'appariement de formes.
Cet article présente une méthode d'adaptation des modèles de Markov cachés (HMMs) pour la reconnaissance de parole téléphonique. Notre but est d'adapter automatiquement les paramètres HMM à l'environnement téléphonique. Dans cet article, on étudie deux types de d'adaptation basées sur des transformations. L'une est la transformation par biais et l'autre la transformation affine. Pour estimer les paramètres de la transformation, on applique une technique d'estimation Bayésienne qui incorpore la connaissance a priori dans la transformation. Les expériences montrent que l'approche proposée peut être appliquée avec succès tant pour l'auto-adaptation que pour l'adaptation supervisée. De plus, on montre que les performances de la reconnaissance de parole téléphonique utilisant l'adaptation Bayésienne sont supérieures à celles utilisant l'adaptation par maximum de vraisemblance. On montre enfin que la transformation affine est également nettement plus efficace que la transformation par biais.
Nous expliquons le bégaiement par un déficit au niveau de la quantité de neurones pouvant véhiculer l'information sensorimotrice. Nous pensons que le bègue manque des ressources de traitement nécessaires au maintien et à l'adaptation des modèles internes qui sous-tendent la production de la parole. Nous précisons les mécanismes computationnels sous la forme d'un circuit d'un contrôleur adaptatif autorégulé pour le contrôle d'un système à sorties et à entrées dynamiques multiples, non-linéaires et variables.
Le système auditif dispose souvent d'une quantité suffisante d'indices qui lui permettent de déterminer si les composantes du son se prolongent pendant ces obstructions. Cet article recense les situations au cours desquelles des assomptions de continuité sont garanties et démontre comment les principes sous-tendant ce qu'on appelle “l'illusion de continuité” peuvent être utilisés au sein d'un modèle informatique de séparation des sources acoustiques.
Pour traiter de grands lexiques (plus de 2000 mots), les systèmes de reconnaissance automatique de la parole (RAP) utilisent une représentation phonétique interne du signal de parole et des modèles phonémiques de prononciation du lexique pour rechercher la séquence de mots émis ou la phrase. Il est donc possible de modéliser différentes prononciations d'un mot dans le lexique. En allemand, on observe que les locuteurs individuels prononcent les mots d'une manière typique qui dépend de divers facteurs comme le sexe, l'âge, le lieu d'habitation, le lieu de naissance, etc. Notre but est d'améliorer la reconnaissance de parole en adaptant automatiquement les modéles de prononciation du lexique aux nouveaux locuteurs. Une autre méthode présentée dans cet article concerne l'adaptation au locuteur par ré-estimation des probabilités a posteriori des unités phonétiques utilisées dans un système de RAP “bas-haut”. Une hypothèse de mots est basée sur le produit des probabilités a posteriori des unités phonétiques produites par la classification. Normalement, ces probabilités sont estimées pendant la phase d'apprentissage et restent fixes pendant la reconnaissance. Nous proposons un algorithme qui prend en compte les observations des confusions typiques entre unités phonétiques pour le locuteur et adapte les probabilités a posteriori de façon continue.
Les sources de bruit magnétique sont nombreuses et viennent perturber les signaux magnétiques sous-marins. Afin de détecter toute distorsion du champ magnétique terrestre, engendrée par le déplacement d'une masse ferromagnétique, nous utilisons quatre magnétomètres pour lesquels nous savons que le signal utile (s'il existe) ne peut être vu que par l'un d'entre eux.
Nous proposons un outil graphique interactif, CA Viz, qui permet de visualiser et d'extraire des connaissances à partir des résultats de l'AFC sur les images. En analyse de données textuelles, le tableau de contingence croise mots et documents. Pour l'adaptation de l'AFC aux images, la première étape consiste donc à définir des « mots visuels » dans les images (analogue des mots dans les textes). Ces mots sont construits à partir de descripteurs locaux (SIFT, Scale Invariant Feature Transform) des points d'intérêt des images. CAViz projette le nuage de points dans des plans factoriels et permet d'extraire visuellement des informations intéressantes comme des mots caractérisants, des facteurs importants en utilisant des indicateurs pertinents de l'AFC (qualité de représentation et contribution à l'inertie). Une application à la base Caltech4 démontre l'intérêt de CAViz pour l'analyse des résultats de l'AFC.
Mrayati et al. utilisent les fonctions de sensibilité d'un tuyua uniforme pour proposer un découpage en huit régions associées aux combinaisons possibles des variations des trois premières résonances ; ils mettent ainsi en évidence des propriétés géométrico-acoustiques de symétrie et de compensation. Les auteurs considèrent que la production des voyelles et des consonnes repose sur ces propriétés : le conduit vocal peut être découpé en ces huit zones auxquelles ils associent des caractéristiques morphologiques et articulatoires. Ils proposent une nouvelle théorie de la production des voyelles et un nouveau système phonologique universel des consonnes. Mais plusieurs critiques peuvent être faites aux auteurs : • - les limitations des fonctions de sensibilité sont sous-estimées ; • - l'anthropomorphisme du découpage est pauvre ; • - leurs prédictions ne permettent pas de retrouver des données acoustiques bien connues ; • - la classification universelle est en contradiction avec des connaissances phonétiques de base. D'une manière générale ce type d'approche semble intrinsèquement très limité : le conduit vocal peut difficilement être réduit à une série de tuyaux manipulés indépendamment les uns des autres, sans aucune référence à un modèle articulatoire sous-jacent. La Nouvelle Théorie ne pourra être véritablement appréciée qu'une fois replacée dans son véritable champ de validité : la description des propriétés acoustiques du conduit vocal autour de sa position neutre, et un outil pour la synthèse de la parole.
Dans le cadre d'un système de reconnaissance automatique de mots isolés par approche analytique pour un vocabulaire de grande taille, nous avons envisagé une adaptation automatique du système au locuteur. L'adaptation se fait par l'apprentissage automatique des formes de référence du locuteur, ainsi que par l'adjustement automatique des paramètres du système. Un algorithme de cadrage de segments phonétiques décodés à l'aide de traits acoustico-phonétique peu dépendants du locuteur est à la base de cet apprentissage. La session d'apprentissage a été testée avec succès sur 18 locuteurs parmi un échantillon de 20 personnes (10 femmes et 10 hommes) et les formes de références ainsi obtenues ont fourni de bons résultats pendant la phase de reconnaissance. Une analyse des voyelles de 15 locuteurs fondée sur la statistique descriptive et l'interprétation statistique a été entreprise en vue délaborer des procédures de normalisation et de génération automatique des formes de référence des voyelles d'un locuteur.
Dans le cadre du traitement STAP, une modélisation autorégressive (AR) des interférences utilisée avec un détecteur appelé Parametric Adaptive Matched Filter (PAMF) donne lieu à un filtre de réjection du fouillis pour lequel le domaine d'entraînement est réduit. La principale difficulté de cette approche réside alors dans l'estimation des matrices AR à l'aide des données d'entraînement. Dans cette publication, les auteurs proposent une estimation récursive fondée sur un filtrage de Kalman et ses variantes. Une étude comparative des différentes méthodes est menée sur les données fournies par la DGA - Maîtrise de l'Information.
Cet article présente une architecture logicielle basée sur les services web et permettant la création et l'évaluation d'applications visuelles interactives. Les services web sont une standardisation d'échange de données dans un système distribué, tel que le web. Ils servent principalement à la publication de données (au moyen d'API) stockées dans des bases de données, mais peuvent également servir au traitement de celles-ci. Nous montrons que leur composition permet la création de représentations visuelles de données, en reconstituant le modèle de référencede celles-ci. Les visualisations ainsi générées peuvent être rendues interactives une fois couplées avec un programme interactif (tel qu'un navigateur web), afin de permettre à l'utilisateur de réaliser des tâches d'exploration et d'analyse visuelle de données. Nous présentons une interface de composition de services et l'application à la visualisation de graphes et de nuages de mots. Enfin nous montrons comment l'usage des logs générés côté serveur permet la représentation et l'évaluation de l'activité de l'utilisateur.
La réalisation d'une Machine à Ecrire à Entrée Vocale en Françcaise nécessite à la fois l'étude de comment faire la reconnaissance acoustique, et de comment obtenir un modèle de la langue Française. Un tel projet a été lancé au LIMSI il y a 15 ans. Cet article présente les différentes étapes qui ont été franchies depuis le début du projet. Tout d'abord, les résultats d'une étude de la transformation phonè—graphème pour des suites de phonémes exactes, avec un grand vocabulaire et une syntaxe du langage naturel, ont été présentés en 1979. Ces résultats ont été alors élargis, avec quelques essais pour traiter des suites de phonèmes entachées d'erreurs simulées, tout en appliquant la même approche au cas de la conversion sténotypes-graphèmes. Dans le projet ESPRIT 860 “Analyse Linguistique des Langues Européennes”, notre approche de la modélisation du langage a été comparée à d'autres approaches pour le traitement de 7 langues européennes. La liaison entre la reconnaissance acoustique et le modéle de langage a conduit à un système de reconnaissance complet (“Hamlet”), pour un vocabulaire limité (2000 mots), prononcés de façon isolée, qui a ensuite été étendu à un vocabulaire de 5000 mots, grâbe à un circuit intégré de Programmation Dynamique (MUpCD) également réalisé au LIMSI. Cette étude a conduit à la conclusion que la dictée de texte par mots isolés n'était pas acceptable. Nous développons à présent un système de reconnaissance de parole continue multilocuteur pour des vocabulaires de 5000 à 20000 mots.
Le principe de la stéganalyse est de classer un document incriminé comme original ou comme stéganographié. Il est montré que l'écart type des résultats obtenus habituellement en classification peut être très important (jusqu'à 5 %) lorsque des ensembles d'entrainements comportant trop peu d'échantillons sont utilisés. Ces tests sont menés sur six algorithmes de stéganographie, utilisés avec quatre taux d'insertions différents : 5,10,15 et 20 %. D'autre part, les caractéristiques sélectionnées (généralement 10 à 13 fois moins nombreuses que dans l'ensemble complet) permettent effectivement de faire ressortir les faiblesses ainsi que les avantages des algorithmes utilisés.
Nous présentons dans cet article une nouvelle technique de transformation de timbre de la voix. Cette technique s'articule autour d'un synthétiseur dérive de l'approche PSOLA (Pitch-Synchronous Overlap and Add) et d'un module de transformation des paramètres spectraux. Le synthétiseur allie décomposition source-filtre et modification prosodique du signal d'excitation par application de TD-PSOLA (Time Domain PSOLA). Deux approches de transformation spectrale, dérivées de techniques d'adaptation en reconnaissance de parole, sont comparées : la Régression Linéaire Multiple (LMR) et l'Alignement Dynamique en Fréquence (DFW). Une étape préliminaire de quantification vectorielle permet de rendre ces transformations dépendantes des réalisations acoustiques des sons. Un test d'écoute formel démontre que le synthétiseur permet d'obtenir une voix “transformée” d'un naturel satisfaisant.
L'interaction main-libre est très importante pour augmenter la flexibilité des applications actuelles de reconnaissance de la parole et pour développer de nouvelles applications pour lesquelles l'utilisateur ne peut pas être gêné par un microphone tenu dans la main ou posé sur la tête. Lorsque le microphone est loin du locuteur, le signal reçu est perturbé par des dégradations de différente nature souvent imprévisibles. L'utilisation de microphones spéciaux ou de systèmes multi-microphones représente une façon de réduire les effets des bruits environnementaux. Des techniques de traitement robuste et d'adaptation peuvent également être utilisées pour compenser les différentes sources de variabilité qui peuvent agir à l'entrée d'un système de reconnaissance. Le but de cet article est de revoir certaines des hypothèses relatives aux différentes sources de variabilité et de discuter à la fois des systèmes de “transducers” spéciaux et de techniques de compensation/adaptation qui peuvent être adoptées. Plus spécifiquement, cet article considérera l'utilisation de réseaux de microphones pour traiter certains des effets non désirés résultant de l'acoustique ambiante (par exemple, réverbération) ainsi que du bruit cohérent/incohérent (par exemple, locuteurs simultanés, ventilateur d'ordinateur). Pour finir, nous présentons des expériences qui ont été réalisées sur des signaux réels et simulés.
Cet article examine les caractéristiques de l'intonation de plusieurs types de “non-mots” comme les chiffres, dates, heures et abréviations, que l'on trouve dans des textes et qui sont aisément identifiables. Cet article présente des illustrations de ce phénomène et propose des heuristiques pour sa prise en compte dans un système automatique. Une évaluation formelle donne un taux de succés de plus de 94% pour ces heuristiques. Les avantages et inconvénients de ce traitement sont discutés et des suggestions sont faites pour de futures recherches dans ce domaine.
Cet article propose l'édition originale d'une maqāma jusqu'alors inconnue et attribuée à Badīʿ al-Zamān al-Hamad̠ānī (m. 398/1008). Il établit dans un premier temps un état de la recherche sur les manuscrits des Maqāmāt d'al-Hamad̠ānī puis examine les raisons pour lesquelles le texte de cette maqāma ne se trouva préservé que dans un seul manuscrit [Yale University, Beinecke Library, Salisbury collection no. 63]. Celui-ci, copié en 603/1206, était au demeurant bien connu des chercheurs européens, pour s'être trouvé entre les mains d'Everard Scheidius (1742-1794), Silvestre de Sacy (1775-1838) et Edward Eldridge Salisbury (1814-1901). La maqāma qui y est insérée narre la vente malhonnête par un médecin d'ingrédients médicinaux censés avoir été élaborés à partir de substances pharmacologiques rares. Nous faisons figurer en facsimilé le texte de cette maqāma que les auteurs de la présente contribution ont intitulée al-Maqāma l-Ṭibbiyya, ainsi qu'une édition critique et une traduction annotée en langue anglaise. Suit une analyse détaillée de ladite maqāma, qui en examine la forme, le sujet, la langue et le style, en relation avec le corpus des autres maqāmāt d'al-Hamad̠ānī. En conclusion, nous avançons un certain nombre d'hypothèses sur la possible authenticité de cette œuvre perdue.
La théorie formelle de l'apprentissage doit se concevoir comme un moyen de relier les théories de grammaire comparative aux études sur le développement linguistique. Aprés avoir brièvement passé en revue les concepts pertinents, on examine dans cet article certains effets formels dans la théorie de l'apprentissage qui suggèrent des contraintes correspondantes sur la théorie linguistique. On porte une attention particulière à la question : combien y-a-t-il de langues naturelles possibles ?
Le radar à visée latérale et à ouverture synthétique est un système d'imagerie micro-onde capable de produire des images de très haute résolution des terrains, et ceci à partir d'un traitement approprié des signaux reçus par une antenne de faible dimension. Dans cet article, nous présentons la formulation exacte du signal reçu, ainsi que les traitements associés afin de former l'image. La qualité de l'image ainsi formée est déterminée par celle de la fonction d'ambiguïté. Cette dernière est analysée et optimisée pour deux critères de performance. Pour un récepteur filtre adapté (récepteur optimal au sens meilleur rapport signal sur bruit), la forme d'onde optimale est une onde FM non linéaire dont la fonction d'ambiguïté est de type Taylor. La fonction de pondération optimale en azimut est liée à celle de Taylor par une transformée de Fourier. Pour un récepteur filtre de Wiener (récepteur optimal au sens des moindres carrés) la forme d'onde optimale est la première fonction sphéroïdale. Afin de mesurer simultanément les quatre termes de la matrice de rétrodiffusion d'une cible, l'émission de deux ondes optimales orthogonales est discutée.
Les systèmes d'extraction d'objets sont mis à mal par la diversité de ces derniers. Leur adaptation est donc nécessaire pour maintenir des performances équivalentes quelle que soit la nature des objets sur lesquels ceux-ci sont appliqués. S'attachant plus particulièrement, dans l'optique de cette adaptation, à la tâche d'optimisation du paramétrage de ces systèmes, nous proposons dans cet article une méthode originale de ciblage de l'optimisation aux seuls paramètres des opérateurs du système estimés responsables des différentes catégories d'erreurs produites par le système. Cette méthode s'appuie alors sur deux analyses distinctes. La première porte sur les performances du système considéré et permet d'extraire les différentes catégories d'erreur déjà mentionnées. La seconde concerne le fonctionnement des différents opérateurs composant le système et donne lieu à la détermination d'un opérateur responsable pour chaque catégorie d'erreur. Une application de cette méthodologie à un système de détection de texte est par ailleurs détaillée.
Nous verrons que le résultat de ces recherches est loin d'être réductible au seul travail philologique : plutôt une des retombées critiques et épistémologiques qui permette d'aller plus loin.
Il existe un fort consensus pour dire que les sons et les patrons sonores observés dans le babillage et dans les premiers mots sont fondamentalement les mêmes. Cet état commun relève de la notion de “Frame Dominance” — un schéma syllabique produit par une oscillation ouverture/fermeture de la mandibule qui prédomine dans ces deux étapes du développement, la capacité des autres articulateurs, et en particulier celle de la langue, à produire des changements intra- et inter-syllabiques étant limitée. La question de savoir si les premiers mots sont similaires à tous égards au babillage, a étéévaluée chez 4 sujets, par le biais d'un ensemble de données correspondant à 152 heures d'enregistrements audio. Les progrès observés dans les mots prennent la forme d'une augmentation du panachage des énonciations, principalement dû à un panachage des voyelles, dont l'essentiel provient d'un accroissement de l'usage des voyelles hautes et moyennes arrières, en particulier en position finale dans le mot. La présence de régression et la nature limitée des progrès observés nous semblent être une indication de la force du patron de “Frame Dominance”, et de la difficulté qui en découle, de s'en échapper.
Cet article présente une série d'études phonétiques qui sont fondées sur une analyse du corpus TIMIT de l'anglais américain parlé, et qui sont susceptibles d'intéresser les spécialistes de linguistique et de reconnaissance de la parole. D'abord, nous discutons les avantages et les défauts de TIMIT pour la recherche linguistique, et nous indiquons l'esquisse d'une méthodologie utilisant la base de données. Ensuite, plusieurs petites enquêtes révèlent de nouveaux résultats sur les effets du sexe et du dialecte des locuteurs sur la prononciation. Cet article essaie d'utiliser la base de données pour examiner la variation attribuée aux différences de sexe et de dialectes afin d'établir les différences qui pourraient mériter une étude experimentale plus approfondie. Ce rapport porte sur la variation entre locuteurs qui se manifeste dans certaines caractéristiques phonétiques qui sont souvent associées à la réduction, telles que le débit de la parole, les relâches d'occlusives, les sons battus, les voyelles centrales, les laryngales, les consonnes syllabiques, et le processus de palatalisation. Plus précisément, nous suggérons que les traits phonétiques qui sont le plus fréquent chez les locuteurs mâles sont ceux qui caractérisent la réduction dans le langage parlé.
La disponibilité croissante de grandes collections de documents faiblement structurées a fait émerger en recherche d'information le besoin d'une structuration globale de ces collections et de l'établissement de liens sémantiques entre documents. En Recherche d'information, les principaux éléments de structuration globale de corpus utilisés sont l'hyperlien entre documents et la structuration des documents en hiérarchies de concepts. Nous proposons ici un algorithme pour construire et maintenir des hiérarchies de concepts et de documents de manière automatique. Nous présentons également des mesures de qualité pour l'évaluation des hiérarchies générées et des tests effectués sur des données issues du site Looksmart qui montrent la pertinence des méthodes proposées.
Ce travail concerne la prosodie du suédois dans le cadre de la synthèse de la parole. On examine deux problèmes principaux : la prominence et la formation des groupes prosodiques. Dans ce modèle de la prosodie du suédois, les niveaux de prominence (accent tonique, accent mélodique, focus) sont représentés hiérarchiquement et de façon multidimensionelle pour différents domaines (syllabe, pied, mot). La formation des groupes prosodiques implique à la fois une cohérence dans la forme des combinaisons spécifiques des gestes accentuels existants et un marquage des gestes de frontières. On décrit les principales caractéristiques de ce modèle d'intonation. Les éxperiences sur la prominence incluent la modélisation des durées dans le cadre d'une base de données de parole et d'un système de synthèse par règles ou l'alternance accentué-non accentué apparait être le facteur le plus important pour la durée. Une autre expérience concerne l'étude des principales différences dans les caractéristiques temporelles des gestes intonatifs pour l'accent focal entre les mots composés et les mots simples à accent II. Les expériences sur la formation des constituants portent sur des données de production extraites de divers corpus de parole ainsi que sur leur synthèse et leur perception. Nos expériences montrent que les indices de cohérence et les indices de frontière contribuent ensemble à la mise en évidence de constituants qui sont typiquement signalés par une combinaison d'indices de F 0 et de durée. Nour prévoyons de poursuivre ce travail en modélisant la prosodie du suédois dans un contexte de dialogue et pour la synthèse à partir de concepts.
Nous comparons dans ce papier deux méthodes pouvant être utilisées pour annoter phonétiquement et de manière automatique un corpus de parole continue, comme c'est généralement nécessaire pour la mise au point de systèmes de reconnaissance ou de synthèse de la parole. Les deux systèmes ont été évalués sur des phrases lues n'ayant pas servi à l'entraı̂nement des systèmes (HMM ou hybride) et manuellement segmentées. Cette étude met en évidence les avantages et inconvénients de chacune des méthodes. Le système basé sur le synthétiseur a le grand avantage qu'aucune phase d'entraı̂nement (et donc aucun grand corpus segmenté) n'est nécessaire, alors que les systèmes classiques basés sur les HMMs peuvent facilement prendre en compte des transcriptions phonétiques multiples. Ces méthodes de segmentation automatique sont d'une grande importance pour le dévelopement de systèmes de synthèse et de reconnaissance de la parole multilingues.
Vérard fit paraître son editio princeps du Merlin en 1498, dans une belle édition en trois tomes in-folio ; le troisième tome contient les Prophéties. Ce texte difficile – « détestable logorrhée » selon Langlois – est doté par le grand éditeur d'un jeu de rubriques d'une remarquable densité : comme aucun des manuscrits existants ne bénéficie de rubriques, c'est vraisemblablement l'atelier de Vérard qui en fut responsable. Alors que les rubriques introduisant les chapitres « narratifs » du texte – les malheurs de Merlin – se contentent très souvent de composer un titre à partir de quelques mots saisis dans la/les première(s) phrase(s) du chapitre, pour les prophéties proprement dites le rubricateur semble avoir voulu saisir, plus ou moins bien, la totalité du chapitre. Avec la table en début de volume, Vérard et son atelier semblent avoir en vue – toutes proportions gardées – de fournir un instrument de travail.
Nous présentons différents algorithmes de génération du signal qui améliorent de façon significative la qualité sonore de systèmes de synthèse de parole à partir du texte par concaténation d'unités acoustiques (Moulines et Charpentier, 1988 ; Hamon et al., 1989). Ces algorithmes qui permettent de modifier les paramètres prosodiques et de concaténer les unités acoustiques sont fondés sur le principe de l'addition-recouvrement synchrone de la fréquence fondamentale de formes d'onde élémentaires (PSOLA). Les modifications du signal de parole sont réalisées soit dans le domaine fréquentiel (FD-PSOLA), soit directement dans le domaine temporel (TD-PSOLA), suivant la résolution spectrale et temporelle de la fenêtre utilisée lors du processus de synthèse. Nous discutons les différentes catégories de distorsions entraînées par ces algorithmes.
Les recherches entreprises jusqu'à maintenant sur le nom propre en français nous permettent de mettre à profit les résultats auxquels ont abouti les rhétoriciens, les grammairiens et les linguistes pour un traitement lexicographique bilingue des unités lexicales et phraséologiques contenant des noms propres employés figurativement en français et macédonien. Dans cet article, nous essayons de distinguer l'ensemble des critères pertinents permettant au lexicographe de sélectionner et recenser ces unités, de proposer des solutions sur leur traitement et d'identifier les problèmes et les spécificités du nom propre.
Nous présentons un algorithme d'intelligence en essaim pour résoudre le problème du fourragement dans le cas discret. Nous illustrons l'algorithme proposé à l'aide de simulations et nous faisons une analyse complète de convergence : nous démontrons que la population d'agents simples qui compose l'essaim calcule la solution d'un problème de contrôle optimal et que sa dynamique converge. Nous étudions le taux de convergence de l'algorithme en fonction de la taille de la population et donnons des arguments expérimentaux et théoriques qui suggèrent que ce taux de convergence est superlinéaire en fonction du nombre d'agents. En outre, nous expliquons comment ce modèle peut être étendu au cas où l'espace est continu et pour résoudre des problèmes de contrôle optimal en général. Nous argumentons qu 'une telle approche peut être appliquée à tout problème qui implique le calcul du point fixe d'une contraction. Ceci permet de concevoir une grande classe d'algorithmes d'intelligence en essaim bien compris formellement.
L'algorithme de transformation d'échelle de fréquence dans le domaine temporel (TDHS) fournit une méthode numériquement efficace (appropriée à une implantation en temps réel) pour la compression et l'expansion de la largeur de la bande fréuentielle de la parole. Dans cet article, nous étudions un système de codage. TDHS/bandes-partielles de la parole opérant à 16 k bits/s, et nous investigons l'efficacité relative de cinq méthodes différentes d'estimation du pitch (la méthode d'autocorrélation, la méthode du cepstre, la technique du filtrage inverse simplifié, la méthode AMDF et la méthode du maximum de vraisemblance. Un test d'audition formel avec 17 auditeurs a été entrepis pour évaluer les performances comparatives des cinq méthodes considérées. La méthode AMDF se dégage comme étant la meilleure procédure d'estimation du pitch pour le codage par TDHS/bandes-partielles.
Une tâche de répétition de mots (“shadowing”) a été utilisée pour étudier la contribution de la position du point d'unicité (PU, c'est-á-dire le moment auquel l'information acoustique déjà présentée n'est plus compatible qu'avec une seule représentation lexicale) au point de reconnaissance des mots parlés. La comparaison destemps de réponse à des mots à PU précoce et tardif a mis en évidence un effet significantif mais relativement faible du PU. Cependant, l'examen des résultats de chacune des deux séries de mots a fait appraître des différences importantes entre elles. Une analyse de régression multiple prenant en considération la position du PU, ainsi que la durée et la fréquence des mots, a montré que la position du PU était le meilleur prédicteur du temps de réponse pour les mots de la série précoce mais qu'elle ne contribuait pas du tout au temps mis pourrépéter ceux de la série tardive. Il semble donc que, pour une gamme relativement précoce de positions dans les mots, le PU soit un déterminant important du point de rreconnaissance. Pour les mots de la série tardive, le meilleur prédicteur du temps de réponse était la durée des mots chez les sujets lents et leur fréquence chez les plus rapides, ce qui suggère l'intervention de mécanismes différents.
L'adaptation dans les jeux qu 'ils soient ludiques ou sérieux est une fonctionnalité importante qui permet d'individualiser et de contextualiser l'expérience de jeu. Elle permet également de gérer la frustration des joueurs-apprenants tout en augmentant leurs motivations. Cet article présente l'état de l'art des travaux traitant de l'adaptation dans les jeux ludiques et sérieux. Ces travaux sont ensuite analysés suivant un cadre d'évaluation qui détermine le périmètre, les paramètres, le modèle de l'adaptation ainsi que le type de jeu : mono ou multijoueur. L'analyse de l'état de l'art montre que la réalisation de jeux sérieux multijoueurs adaptables soulève des problèmes importants à tous les niveaux allant de la conception jusqu 'à la gestion des vues et interactions avec les joueurs-apprenants. Ceci nous conduit à identifier le développement de jeux sérieux multijoueurs adaptables comme un défi majeur à aborder par la communauté à moyen terme.
Cet article s'interroge sur les bases phonétiques des théories traitant de la structure interne des segments. Il porte un regard sur la naissance et le développement de l'idée que le phonème n'est pas le constituant ultime de la chaîne phonique indissociable en unités plus petites, mais le produit de l'association d'une liste finie de paramètres universels appelés différemment par les divers modèles : traits, éléments, gestes. La rupture avec la conception « atomique » du phonème et l'élaboration des théories des primitives phonologiques vont cependant de pair avec une complication du formalisme et une hermétisation de la phonologie par son isolement de la phonétique.
Normalement, le lexique d'un système de reconnaisance de la parole contient des modèles de pronunciation qui décrivent comment les differents mots peuvent être réalisés en fonction des unités phonétiques (p.e. phonèmes). Dans cette contribution on présente une méthode pour améliorer ces modèles simples et peu réalistes grâce à l'addition de plusieurs variantes de pronunciation pour chaque mot. Puisque la stratégie présentée peut produire des variantes de prononciation et dériver des dependances à travers des mots, elle est également une alternative attirante pour l'encodage manuel de plusieurs pronunciations dans le lexique. En apprenant des règles plutôt que des variantes, on peut créer des variantes de mots pas observés dans le corpus, tandis que l'on garde tout de même les avantages d'une procedure dirigée par les données. Les caractéristiques importantes de la méthode sont qu'elle tient compte des dépendances entre les règles dès le début, qu'elle supporte des règles d'exception affectant la production de variantes par d'autres règles, et finalement qu'elle sait estimer d'une façon bien fondée les probabilités des variantes de pronunciation. Les résultats expérimentaux indiquent que l'intégration des variantes obtenues dans les modéles de pronunciation diminue le taux d'erreurs de manière significative : les erreurs résultant d'une reconnaissance de timit au niveau des mots sont reduites relativement avec 17%.
Cet article présente les résultats d'une analyse statistique et déterministe de deux lexiques phonémiques qui tient compte du stockage et de la génération de règles orthographiques utilisant des graphèmes. Le but de l'article est de montrer la faisabilité de la génération de mots anglais orthographiés correctement sur base de règles phonèmes/graphèmes. Un algorithme pour générer les règles est présenté. Un ensemble de règles orthographiques a été identifié en analysant deux lexiques de 93.939 et 11.638 mots, le dernier étant un sous-ensemble du premier. Ces règles ont été ensuite testées quant à leur utilité en général. 62.3% des 96.939 mots ont été orthographiés correctement avec la seule aide des règles. Un petit lexique contenant des mots communs et une sélection de mots moins fréquents a montré que 84.5 de ce lexique pouvait être orthographié correctement en utilisant des règles générées par l'analyse du même lexique. Par contre, seulement 62.3% de ce lexique ont pu être orthographiés correctement sur base des règles découlant du lexique de 96.939 mots. On a aussi montré que la correspondance entre phonèmes et graphèmes était alphabétique de 63% à 69% en fonction de la taille du lexique. 59 règles par défaut ont été identifiées ; mais seulement 22.6% du petit dictionnaire ont été orthographiés correctement à l'aide de ces règles.
L'introduction de connaissances dans les systèmes de reconnaissance de parole (ASR) est un bon moyen d'améliorer leurs performances. Dans cet article, nous proposons le système orion dans le cadre d'une application de reconnaissance multicuteur de mots isolés. orion est un système hybride à deux phases intégrant plusiers sources de connaissances : psychoacoustiques, physiologiques et phonétiques. Pendant la première phase un modèle d'analyse acoustique perceptivement fondé (PLP), combinant des caractéristiques spectrales statiques et dynamiques, est utilisé pour fournir des vecteurs de paramètres à un algorithme de programmation dynamique. A l'issue de cette première phase, plus de 98% de mots ont été correctement reconnus pour un vocabulaire de chiffres avec 12 références par mot. Pour un vocabulaire de mots acoustiquement similaires (E-SET), l'introduction de connaissances phonétiques durant la deuxième phase diminue l'erreur de reconnaissance de plus de 60% (par rapport aux résultats obtenus lors de la première phase).
Cet article présente les travaux effectués au LIMSI pour le développement d'un système de traitement automatique d'informations radio et télédiffusées. Partant d'un système de transcription de textes lus, nous décrivons les adaptations qui ont été nécessaires pour le traitement d'un flux audio continu et de données dites “trouvées”. Ces développements ont été validés dans le cadre des évaluations ARPA BN (Nov96, Nov97, Nov98 et Dec99). Les principales difficultés posées par ce type de données sont liées à leur nature hétérogène, qu'il s'agisse de changements de nature acoustique (environnement, communication, musique) ou de nature linguistique (styles d'élocution, diversités des sujets et des locuteurs). La partition du flux continu est effectuée de manière itérative, par un algorithme de segmentation–agglomération reposant sur des mélanges de Gaussiennes. Le système de reconnaissance utilise des modèles de Markov cachés à densités continues pour la modélisation acoustique, et des statistiques 4-grammes de mots estimées sur un grand corpus de textes et de parole transcrite pour modèle de langage. La transcription en mots est obtenue en plusieurs passes de décodage, où les hypothèses intermédiaires sont utilisées pour adapter les modèles acoustiques. Les taux d'erreur obtenues avec différentes versions de ce système lors des évaluations ARPA sont 27,1% (Nov96 avec partition manuelle), 18,3% (Nov97), 13,6% (Nov98) et 17,1% (Dec99, moins de 10 fois le temps réel).
La mise au point de mécanismes de coordination spatiale pour des agents évoluant dans des univers continus et dynamiques est un problème difficile. Alors que la démarche descendante ne parvient pas à appliquer sa méthode de décomposition de façon satisfaisante sur cette classe de problèmes, l'approche ascendante obtient des résultats plus convaincants, mais elle implique souvent de fastidieux réglages manuels qui posent des problèmes de passage à l'échelle. Notre démarche pour traiter cette difficulté consiste à adjoindre à un formalisme de coordination spatiale ascendante un algorithme évolutionniste multicritère dédié à ce type de problèmes. Nous montrons sur un problème de coordination spatiale traité précédemment par Balch et Hybinette que les solutions obtenues avec notre plate-forme, GACS, sont comparables à celles obtenues par ces auteurs, malgré un investissement moindre de la part du concepteur.
On décrit ici une procédure permettant d'acquérir automatiquement les règles intonatives à appliquer aux syntagmes, à partir d'un texte annoté, pour la synthèse à partir du texte. Les règles générées par cette méthode ont été implémentées dans la version Anglaise du système de synthèse à partir du texte des laboratoires Bell et ont été développées pour la version de ce système en Espagnol Mexicain. Ces règles fournissent, à ce jour, des prédictions adéquates dans plus de 95% des cas pour l'Anglais et dans plus de 94% pour l'Espagnol.
Cet article décrit les prinicipes de réalisation d'une système de dictée vocale à large vocabulaire, employant une technologie avancéee de reconnaissance de parole. Il peut être utilisé pour une grande variété de tâches, et est rapidement adaptable à de nouveaux domaines. On décrit ici une étude de cas d'une application de cette technologie dans le contexte de la création de rapports médicaux. Les objectifs de l'utilisation d'une technologie de reconnaissance de grands vocabulaires pour réaliser un système de dictée de texte libre sont décrits. On discute également du processus de création des textes, de la première à la dernière version, en termes de prérequis tant vis à vis de la technologie que de son implémentation. On évoque également les contraintes sur les performances et l'acceptabilité du système. On décrit également l'implémentation d'une composante d'un système flexible permettant l'adaptation à l'utilisateur. On évoque également l'utilité, pour une grand nombre d'applications potentielles, d'une système de dictée autonome, non-spécialisé. On décrit également les possibilités d'adaptation du système à une nouvelle tâche par reconstruction rapide de ses tables de paramêtres. L'étude de cas concernant la station de travail pour rapports médicaux sert d'exemple pour montrer comment une version adaptée du système peut être exploitée dans l'environnement réel d'un utilisateur.
Dans cet article, nous décrivons sphinx, le premier systéme de reconnaissance automatique de la parole continue, indépendant du locuteur et à grand vocabulaire. Nous présentons ses premiers résultats, comparons ses performances à celles d'autres systèmes semblables et expliquons sa grande précision.
On a construit un système de microprocesseur qui convertit en temps réel n'importe quel texte français en parole. Le système, dont le logiciel est écrit en langage Pascal modulé, traduit le texte en une série de phonèmes, et désigne une durée et une hauteur pour chaque phonème en utilisant une analyse syntaxique simple. Un circuit intégré spécialisé pour programmer des traitements de signaux numériques génère dix mille échantillons de la parole par seconde. Le système consiste en deux cartes de circuits imprimés : l'une avec un microprocesseur Intel 8086 et la mémoire associée, et l'autre avec la puce spéciale avec un interface, un convertisseur numérique-analogique et un amplificateur. Une version antérieure du système, qui fonctionnait sur un ordinateur VAX-11/780, exigeait huit secondes de calcul pour chaque seconde de parole. Le système actuel qui fonctionne en temps reel démontre la faisabilité d'une synthèse du français de haute qualité.
La variabilité interlocuteur est une source majeure d'erreurs en reconnaissance automatique de la parole (RAP). Cet article décrit une série d'expériences, menées par l'Équipe « Reconnaissance des Formes et Traitement de la Parole » de TÉLÉCOM Paris, dans le but de contrôler certains aspects de cette variabilité, et permettre ainsi une adaptation au locuteur des systèmes actuels de reconnaissance de parole. Les premières expériences utilisent une technique linéaire empruntée à l'analyse des données, la régression linéaire multiple. L'amélioration des taux de reconnaissance obtenue est, en moyenne, de 16% pour les secondes, contre 15 % pour les premières. Ces techniques peuvent également être utilisées pour l'adaptation des reconnaisseurs à de nouveaux environnements acoustiques ou conditions de prise de son.
Dans cet article nous présentons les résultats de tests auprès d'utilisateurs du kiosque Mask (Multimodal Multimedia Service Kiosk). Le but du projet Esprit Mask était de développer un kiosque d'information et de distribution avec une interface innovante et conviviale combinant les modalités tactiles et vocales. Le prototype a été développé après une analyse des besoins dans le cadre du transport ferroviaire en collaboration avec la SNCF et le groupe d'ergonomie de l'université College of London (UCL). Tous les objectifs fixés par la SNCF au début du projet ont été atteints par le prototype, qu'ils concernent le taux de succès, le temps de transaction, ou la satisfaction des utilisateurs.
Nous présentons dans cet article deux nouvelles méthodes de détection de l'instant de fermeture de glotte à partir de la forme d'onde acoustique. Ces deux méthodes détectent les discontinuités dans les caractéristiques spectrales à courtterme du signal de parole apparaissant à l'intérieur de chaque cycle d'excitation glottique. Ces deux méthodes exploitent la même approche de détection séquentielle d'événements à l'aide de tests statistiques d'hypothèses. La première méthode est fondée sur la maximisation séquentielle d'un rapport de vraisemblance. Un certain nombre de résultats expérimentaux sur des données de parole démontrent la robustesse des méthodes proposées.
Dans cet article, nous comparons deux approches différentes de vérification du locuteur basées sur la technologie des modèles de Markov cachés (HMM) : HMMs à gaussiennes simples et différents types de HMMs multi-gaussiennes liées. Pour évaluer la performance en situation réelle, nous avons testé chaque système avec une base de données de chiffres connectés, enregistrés via lignes téléphoniques locales et longue-distance. Selon nos expériences, les modèles multi-gaussiennes liées sont plus performants à condition d'utiliser suffisamment de données d'entraînement. Cependant, nos expériences indiquent que les HMMs à gaussiennes simples doivent être préférés pour la vérification du locuteur en situation réelle, lorsque on dispose seulement de quantitées limitées de données d'entraînement. Les résultats sont discutés pour la vérification dépendante et indépendante du texte.
A la recherche d'une meilleure performance, les systèmes de reconnaisance de la parole actuelles inclinent à des modèles acoustiques et des modèles de langage de plus en plus compliqués. Des modèles de phones en contexte intramot et des modèles de langage de longue envergure sont maintenant largement répandus. Dans cet article, nous présentons une topologie de recherche qui permet l'utilisation de tels modèles détaillés, dans un système de reconnaisance temps-synchrone à une passe. Caractéristique à notre approche est (1) le découplage des deux sources de connaissance de base, à savoir l'information de prononciation et l'information de modèle de langage, et (2) la représentation compacte d'information de prononciation – le lexique en termes de phones en contexte – au moyen d'un réseau statique. L'information de modèle de langage est incorporée à la recherche au délai d'exécution au moyen d'un algorithme de passage de jeton (token passing) légèrement modifié. Le découplage du modèle de langage et du lexique permet une grande flexibilité dans le choix des modèles de langage, alors que la représentation statique du lexique évite le coût d'expansion dynamique du réseau et facilite l'intégration d'information de prononciation supplémentaire telle que des règles d'assimilation. En plus, la représentation par un réseau est très efficace quand les mots ont des prononciations multiples, et à cause de sa construction, la structure proposée offre l'anticipation partielle de modèle de langage sans coûts supplémentaires.
La source de voix est un facteur important dans la production de différentes qualités de voix. Celles-ci sont utilisées dans la parole pour tarnsmettre, entre autres choses, différents aspects suprasegmentaux, par exemple l'emphase, les frontières de phrase ainsi que différents styles de parole comme le style autoritaire ou soumis. Les variations de la source vocale sont également un moyen important de transmettre des informations extralinguistiques de différentes sortes dans la parole ordinaire. Dans la présente étude, les variations de la source dans la parole normale de locuteurs féminins sont investiguées en utilisant un filtrage inverse. Les résultats du filtrage inverse sont donnés en paramètres de source de voix appropriés pour contrôler la synthèse de parole. De cette manière, les descriptions résultantes ont été utilisées pour produire des variations de la voix dans notre nouveau système de synthèse.
Ce papier présente quatre nouvelles méthodes de vérification du locuteur. La première, un modèle hybride de Perceptron multicouche (MLP) et de Fonctions Radiales de Base (RBF), est un prédicteur MLP dont les poids sont ensuite utilisés comme entrées pour un classificateur RBF - lequel effectue la vérification du locuteur. La seconde utilise un tableau de prédicteurs linéaires pour modéliser le locuteur de référence ; chaque élément est associé avec une sous-unité particulière de la phrase de test. La troisième, un Modèle Prédictif Neuronique, est composé d'un tableau de prédicteurs MLP ; la quatrième, un Réseau Neuronique à contrôle caché, est un prédicteur MLP unique auquel sont ajoutées des entrées de commande ; celles-ci modulent la fonction réalisée par le MLP et permet à ce seul MLP de modéliser une phrase complète. Chaque méthode a été apprise et testée sur une petite base de données. Les performances sont 100% de taux de vérification poor les 3 premiers modèles, 90% pour le Réseau Neuronique à contrôle caché.
Lors d'une étude trans-culturelle sur des enfants japonais et américains nous avons examiné le développement de la conscience des syllabes et des phonèmes. Les expériences I et III, qui utilisent des tests de comptage et d'effacement, montrent que, à la différence des élèves américains de première année d'école primaire, qui ont en général conscience à la fois des phonèmes et des syllabes, presque tous les élèves en première année d'école primaire au Japon ont conscience d'unités phonologiques de l'ordre de la syllabe alors qu'assez peu ont conscience des phonèmes. Cette différence est attribuable au fait que les élèves japonais apprennent à lire un syllabaire alors que les élèves américains apprennent à lire un alphabet. Pour la plupart des enfants de cet âge, la conscience des phonèmes nécessite l'expérience d'une transcription alphabétique, alors que la conscience des syllabes peut être facilitée par l'expérience d'un syllabaire, sans en dépendre aussi fortement. Pour éclaircir davantage le rôle de la connaissance d'un alphabet sur la conscience des phonèmes chez les enfants, nous avons fait effectuer des tâches de comptage et d'effacement (expériences II et IV) à des enfants japonais en fin d'école primaire. Les résultats montrent que beaucoup d'enfants japonais prennent conscience des phonèmes vers dix ans d'âge, qu'ils aient ou non appris une transcription alphabétique. La discussion de ces résultats porte sur certains autres facteurs qui peuvent produire la conscience phonologique.
Cet article présente une étude systématique d'un modèle de reconnaissance des voyelles, indépendant du locuteur. La technique de transformation de Karhunen-Loève (KLT), ou analyse en composantes principales, a été appliquee apres une analyse spectrale du signal parlé à l'aide de 18 filtres dont les bandes critiques ne se recouvrent pas. 4 expériences ont été conduites avec segments de 8 voyelles isolées de Putonghua (Mandarin), prononcées 2 fois, avec 5 tons différents par 38 femmes et 13 hommes. La première expérience utilise le même énoncé pour l'entraînement et le contrôle pour évaluer les effets du KLT, la normalisation du locuteur, la distance métrique et le nombre de classes vocaliques. Une distance de Mahalanobis modifiée couplée à une condition de 7 classes a donné les meilleures performances. Dans l'expérience suivante, les deux échantillons du même énoncé sont produits par un groupe de locuteurs. Le premier échantillon est utilisé pour l'apprentissage et le deuxième pour le test. On a trouvé, qu'en général, on peut renoncer à une normalisation spécifique au sexe et au ton sans affectation notable de la performance. La troisième expérience entraîne, de façon répétée, le modèle avec 50 sujets et le teste avec un sujet, ceci pour les 51 locuteurs. Dans ces conditions sévères, on atteint un taux de reconnaissance moyen de 88,2% en utilisant seulement une classification en 4 dimensions. Dans la dernière expérience, tous les segments d'une voyelle sont étiquetés sous les conditions les plus strictes. Il est confirmé que le modèle fonctionne bien pour un homme et une femme, sélectionnnés au hasard. La voyelle qui a causé le plus de confusions est bien reconnue quand elle est traitée comme un allophone d'une autre voyelle. Enfin, quelques résultats préliminaires discutent la possibilité d'étendre cette technique à la reconnaissance des diphtongues.
L'anglais et l'italien présentent des contrastes intéressants et pertinents pour un problème crucial en psycholinguistique, celui de la frontière entre connaissance grammaticale et extragrammaticale dans le traitement des phrases. Bien que tous deux soient des langues avec un ordre SVO sans inflections de cas pour indiquer les relations grammaticales de base, l'italien autorise beaucoup plus de variations dans l'ordre des mots pour des buts pragmatiques. Les italiens doivent, donc, s'appuyer plus que les anglais sur des facteurs autres que l'ordre des mots. Dans l'expérience présentée, on a demandè à des adultes anglais et italiens d'interpréter 81 phrases simples où variaient l'ordre des mots, les contrastes animés/non animés entre deux noms, le stress contrastif et la topicalisation. Les italiens s'appuient principalement sur des stratégies sémantiques alors que les auditeurs anglais s'appuient sur l'ordre des mots et cela inclue une tendance à interpréter le second nom comme sujet dans les ordres de mots non-canoniques (correspondant aux variations d'ordre de la production de l'anglais informei). Les italiens font un plus grand usage du thème et de l'information donnée par l'accent. Enfin, les italiens sont beaucoup plus lents et moins consistants dans l'application de stratégies d'ordre de mot même pour des phrases reversibles NVN où il n'existe pas de conflit entre l'ordre et la sémantique. Cela suggère que l'italien est 'moins' une langue SVO que l'anglais. Les stratégies sémantiques tiennent apparemment au 'coeur' de l'italien les mêmes rôles que les stratégies d'ordre des mots au 'coeur' de l'anglais. Ces résultats font problème pour parler d'une séparation 'universelle' entre sémantique et syntaxe et pour les théories qui postulent une priorité 'universelle' d'un type d'information sur l'autre. Les résultats sont examinés dans le cadre d'un modèle de compétition, approche fonctionnaliste de la grammaire qui rend compte de façon rigoureuse des données probabilistiques et des poids différentiels des différentes sources (converges et rivales) d'information dans le traitement des phrases.
On décrit un système de synthèse de la parole en temps réel. Ce système s'applique sans restriction à tout texte en langue allemande et se base sur l'enchaînement d'éléments préenregistrés : les sons simples et les transitions diphoniques. L'entrée se présente (pour l'instant) sous forme d'un texte phonétique accompagné de l'indication de la fréquence fondamentale. Le signal de sortie est généré par un vocodeur à 'log-area-ratio' (LAR), contrôlé par un ordinateur. Les sons stationnaires sont codés par des cadres simples de paramètres du vocodeur et les transitions par des paires de cadres, extraites, moyennant quelques légères modifications, de paroles réelles. Les cadres intermédiaires sont interpolés en cours de synthèse. On décrit les expériences préliminaires sur l'interpolation et le choix des cadres à préenregistrer ainsi que le procédé de synthèse (2 variantes) qui comprend la structure des tables, le traitement de la fréquence fondamentale et de la durée des sons. Des mesures d'intelligibilité et des comparisons sur la qualité des deux variantes ont étè effectuées.
Des recherches ont été menées pour déterminer si les caractéristiques acoustiques de la voix étaient altérées pendant les périodes de travail soutenu. Douze hommes de l'équipage d'un bombardier B-1B de la force aérienne des Etats-Unis ont participé à cette étude. Les participants ont servi dans des équipes de 4 personnes et ont effectué trois périodes (missions) expérimentales de 36 heures chacune dans un simulateur de haute fidélité. Les missions étaient séparées de 36 heures de repos. Les données de deux membres de la troisième équipe ont été perdues à cause d'un défaut de communication. Des données de parole, des données cognitives et les impressions subjectives de fatigue ont été collectées toutes les trois heures environ et pour onze essais par mission. On a trouvé que la fréquence fondamentale et la durée des mots variaient signifïcativement d'un essai à l'autre (fréquence fondamentale F(10,90) = 2.63, p = 0.0076, durée des mots F(10,90) = 2.5, p = 0.0106). Les résultats sur la durée ont aussi montré, et d'une manière significative, un effet important de la mission (F(2,18) = 6.91, p = 0.0082). Les données de parole suivent les mêmes tendances que les tests cognitifs et les mesures subjectives de la fatigue. Un fort effet diurne apparait dans presque toutes les mesures de dépendance. Globalement, les résultats montrent que la parole peut être un indicateur valide de l'état de fatigue du locuteur.
Les structures syntaxique et phonotactique des phrases sont variées systématiquement pour comprendre comment deux fonctions peuvent être véhiculées en paralléle dans le continuum prosodique : (1) énonciative : démarcation des constituants ; (2) illocutoire : attitude du locuteur. L'analyse statistique du corpus démontre que des contours prosodiques globaux caractérisent chaque attitude. Cet encodage global s'accorde avec des expériences de dévoilement progressif montrant que les attitudes peuvent être identifiées très tôt dans l'énoncé. Ces résultats sont commentés dans la perspective d'un modèle morphologique et superpositional de l'intonation. Ce modèle, propose que l'information spécifique à chaque niveau linguistique (structure, hiérarchie des constituants, attributs sémantiques et pragmatiques) est encodée sous forme de contours multiparamétriques. Nous décrivons une implémentation de ce modèle qui capture puis génère automatiquement ces contours prosodiques prototypiques. Il s'agit d'un ensemble de réseaux de neurones récurrents, chacun d'eux encodant un niveau linguistique particulier. Les scores d'identification des attitudes pour des phrases synthétiques d'apprentissage ou de test sont similaires aux scores obtenus pour des stimuli naturels. Nous concluons que l'étude d'attributs linguistiques au niveau discursif, comme ici les attitudes prosodiques, est un paradigme intéressant pour comparer les modèles de l'intonation.
Nous avons utilisé un réseau de neurones récurrent pour reconnaître des successions de noms de letters b, d, e et v de l'anglais américain prononcées par plusieurs locuteurs. L'appretissage est basé sur une propagation du potentiel des unités au lieu de la rétropropagation de l'erreur des unités dans le temps. La fonction cible se base sur un paramètre caractérisant le signal de parole qui est activé puis désactivé au début de la prononciation de chaque lettre. Le réseau apprend à reproduire ce même paramètre à l'unité de sortie correspondent au nom de lettre correcte. Les résultats sur les phrases de test atteignent un taux de discrimination de 85%.
Cet article porte sur les analyses définitionnelles de la structure du langage. Plusieurs classes d'arguments ayant trait aux définitions sont passées en revue, entre autres, celles liées aux théories classiques de la référence, aux théories de lalidation informelles, aux théories de la compréhension de phrases et aux théories de l'apprentissage de concept. On suggére que, dans chacun de ces domaines, les travaux qui s'appuient sur une définition ne sont pas plus justifiés par les preuves qu'une alternative plausible non-définitionnele. On présente, en outre, une série d'observations expérimentales portant sur un de ces domaines : celui de la compréhension de phrase. De façon indépendante, on montre que les jugements du sujet sont sensibles aux relations structurales de type comparable dans des formes linguistiques.
La présence d'une distance de visibilité réduite sur un réseau routier (épais brouillard, pluie forte, etc.) affecte la sécurité de celui-ci. Nous avons conçu un système de bord de voies qui vise à détecter des situations critiques telles que le brouillard dense ou les fortes chutes de pluie à l'aide d'une caméra vidéo. Les différents traitements d'image sont présentés, en particulier l'estimation de la distance de visibilité, la détection de brouillard, ainsi que la détection de pluie. En se fondant sur les principes sous-jacents de ces algorithmes, une caméra est ensuite spécifiée pour répondre aux besoins exprimés par la norme NF P 99-320 sur la météorologie routière. Des résultats expérimentaux sont présentés ainsi que des perspectives de validation à plus grande échelle.
On présente une nouvelle méthode d'analyse du flux glottique : le PSIAIF (Pitch Synchronous Iterative Adaptive Inverse Filtering). Cet algorithme se base sur une méthode (IAIF) développée précédemment. La contribution glottique totale au spectre de la parole y était tout d'abord évaluée itérativement. Dans la nouvelle méthode, l'onde glottique est calculée en appliquant deux fois l'algorithme IAIF au même signal. La première analyse donne une estimation de l'excitation glottique qui s'étend sur plusieurs périodes. L'onde ainsi obtenue est utilisée ensuite pour déterminer les positions et les longueurs des fenêtres d'analyse synchronisées. Pour obtenir le résultat final, il ne rest plus qu'à analyser le signal original de la parole, période fondamentale par période fondamentale, avec l'algorithme IAIF. L'algorithme PSIAIF a été appliqué à l'analyse du signal glottique, dans le cas de voyelles naturelles et synthétiques. Les résultats montrent que la méthode est capable de fournir une estimation relativement précise de flux glottique, si l'on exclut l'analyse des voyelles à premier formant bas produites par un type de phonation pressée.
Cet article présente une analyse d'un corpus de grammaires écrites pour l'apprentissage du français en Angleterre de 1660 à 1820, une période parfois qualifiée par euphémisme de « long siècle » où l'enseignement des langues évolua en fonction de mutations plus larges, y compris la codification de la grammaire vernaculaire contre un fond de rationalisme scientifique et l'instauration des pédagogies scolaires. Mon analyse comporte deux axes complémentaires : il s'agit, premièrement, d'identifier quelques changements-clés dans la formulation du contenu, en particulier des changements dans la structure générale et la répartition des sections, y compris des différences dans la nomenclature grammaticale, et deuxièmement, de contextualiser ces évolutions en considérant la mutation du rôle des enseignants grammairiens et la manière dont ils se positionnent en tant qu'auteurs auprès de publics différents.
Cet article présente une application de l'algorithme de programmation dynamique utilisé dans l'étape de décodage acoustico-phonétique d'un systéme de reconnaissance de parole. Deux méthodes sont comparées utilisant comme unités de reconnaissance : (1) les demysllabes, et (2) les groupes consonantiques et les voyelles (ou les diphtongues). L'utilisation des demisyllables ainsi que das groupes consonantiques et les voyelles a permis d'obtenir de bons résultats en ce qui concerne la reconnaissance de la parole continue. De plus, la programmation dynamique est une méthode qui est largement utilisée en reconnaisance de mots connectés. Dans cet article, nous présentons un processus de décodage acoustico-phonétique utilisant le principe de programmation dynamique appliqué précisement à ces unités de reconnaissance. Dans son principe, l'algorithme est le même que celui que l'on utilise pour reconnaissance de mots connectés ; quelques modifications ont été introduites du fail de la nature des unités, en particulier par l'apport d'une syntaxe interne. L'algorithme ainsi modifié a été testé sur un corpus de phrases à partir d'un lexique de 75 mots contenant les groupes consonantiques et les voyelles les plus fréquents de la langue allemande. Différents tests ont été effectués pour mettre en évidence l'influence des contextes dans la reconnaissance d'une unité, d'abord à partir des phrases du corpus d'apprentissage, ensuite sur de nouvelles phrases. Enfin une comparaison avec une méthode similaire utilisant une segmentation “explicite” est présentée.
Dans une conversation, les participants ont parfois des difficultés à se comprendre, mais, quand ils sont conscients du problème, ils collaborent ou négocient afin de déterminer le sens de l'énoncé qui pose le problème. Pour traiter l'incompréhension, nous avons développé des modèles de collaboration à deux plans en identifiant le référent correct d'une description : l'un des plans couvre les situations où les deux interlocuteurs connaissent le référent, l'autre plan couvre les situations, comme celle d'indication de direction, dans lesquelles le récipiendaire ne le connait pas. Dans les modèles, les interlocuteurs utilisent les mécanismes de reformulation, de suggestion et d'élaboration pour raffiner ensemble une expression du référent jusqu'à ce qu'elle soit satisfaisante. Pour traiter la mècompréhension, nous avons développé un modèle qui combine les aspects intentionnels et sociaux du discours pour aider à la négociation de la signification. L'approche étend les aspects intentionnels en utilisant des prédictions dérivées des conventions sociales pour guider l'interprétation. Reflétant la symétrie inhérente à la négociation du sens, tous nos modèles peuvent être utilisés comme locuteur ou comme auditeur.
L'introduction de connaissances dans les systèmes de reconnaissance de parole (RAP) est un bon moyen d'améliorer les performances des systèmes actuels. Dans cet article nous proposons le système ORION dans le cadre d'une application de reconnaissance multilocuteur de mots isolés. Pendant la première passe un modèle d'analyse acoustique perceptivement fondé (PLP), combinant des caractéristiques instantanées et des caractéristiques spectrales dynamiques, est utilisé pour fournir des vecteurs de paramètres à un algorithme de programmation dynamique. A l'issue de cette première passe plus de 98 % de mots ont été correctement reconnus pour un vocabulaire de chiffres et 12 références par mot. L'introduction de connaissances phonétiques durant la deuxième passe diminue l'erreur de reconnaissance de plus de 60 % (par rapport aux résultats obtenus lors de la première passe) pour un vocabulaire de mots acoustiquement similaires (E-SET).
L'expérience gagnée avec le système à micro-faisceau a confirmé que l'on peut considérablement le dosage des Rx. Les mouvements de 6 pastilles sur la langue et les dents sont suivis à plus de 100 images par seconde, avec une surface effective d'exposition d'environ 1 cm2 par image et un taux d'exposition de 120 mR par minute sur cette surface. L'approximation des mouvements de ces pastilles sur la langue, la mâchoire et le voile au moyen d'une réponse en échelon d'un système linéaire du second ordre a révélé qu'il y avait de grandes différences dans les valeurs des constantes de temps entre ces différents organes. La durée de la commande-échelon varie également selon le type de la voyelle. Ces différences sont réfléchies par l'allure du sous-dépassement et par le schème coarticulatoire entre consonne et voyelle. L'investigation des mouvements du voile a montré qu'une observation simultanée par EMG est importante pour interpréter la forme du contrôle moteur sous-jacent.
Le présent article traite du choix d'intonations appropriées pour les systèmes intelligents de dialogue homme-machine dans le contexte, par exemple, des bases de données. On propose une approche qui réunit dans le cadre du dialogue homme-machine deux paradigmes jusqu'ici divergents, celui de la génération automatique de textes et celui de la synthèse de la parole. Une telle approche permettrait de combler les lacunes bien connues des systèmes de génération de parole à partir de textes écrits ou de concepts.
À l'heure d'une internationalisation accrue des échanges scientifiques, la question de la langue des publications scientifiques – réglée en sciences de la nature depuis les années 1980 – est devenue un enjeu pour les sciences sociales. Cet article propose une analyse détaillée des stratégies linguistiques adoptées par deux revues françaises majeures de sciences sociales, Population et Revue française de sociologie (RFS), qui ont choisi de traduire en anglais une sélection (RFS) ou la totalité (Population) d'articles. Au vu des résultats en termes de visibilité dans le champ scientifique international – accroissement de la visibilité de la revue Population au détriment de la version française et effets marginaux pour la RFS –, on s'interroge sur le rôle joué par les revues nationales de sciences sociales.
Dans cet article, nous proposons une synthèse des stratégies mises en œuvre pour la conception de discriminateurs avec options de rejet opérant en deux étapes séquentielles. Outre l'approche classique dite « accepte d'abord » , nous avons récemment défini des classes générales qui suivent deux approches différentes dites « rejette d'abord » [Fré98a, MF01b] et « mélange d'abord » [SFM02]. Ces trois approches diffèrent par la nature, et l'ordre, des tests effectués pour produire la sortie du discriminateur. La première consiste à tester en premier lieu le rejet de distance, puis seulement si nécessaire à tester l'affectation exclusive contre le rejet d'ambiguïté, la deuxième et la troisième, quant à elles, débutent, respectivement, par un test pour le classement exclusif et un test pour le rejet d'ambiguïté à opposer aux alternatives correspondantes. Nous unifions ici ces trois familles de discriminateurs par l'utilisation d'opérateurs flous fondés sur des opérateurs de De Morgan (t-norme, t-conorme, complément). Les comportements des différentes approches sont illustrées sur des exemples synthétiques.
Quand les locuteurs de référence sont représentés par un modèle de mélange de gaussiennes, l'approche conventionnelle est d'accumuler les probabilités de trame sur l'énoncé de test entier et de comparer les résultats pour l'identification du locuteur ou d'appliquer un seuil pour la vérification du locuteur. Dans cet article, nous décrivons une méthode dans laquelle les probabilités de trame sont transformées, avant d'être sommées, en de nouveaux scores, suivant une certaine fonction non-linéaire. Nous avons étudié deux familles de fonctions. La première effectue de fait une normalisation des probabilités – une technique largement utilisée en vérification du locuteur –, mais qui est appliquée ici au niveau des états. Le deuxième type de fonctions transforme les probabilités en poids, suivant un certain critère. Nous appelons cette transformation “Weighting Models Rank” (WMR). Les deux types de transformations requièrent de pouvoir disposer de tous (ou d'un sous-ensemble de tous) les modèles de référence. Pour obtenir ceci, chaque trame de l'énoncé d'entrée est incorporée en parallèle dans les modèles de référence requis, puis la transformation des probabilités est appliquée. Les nouveaux scores sont ensuite accumulés sur l'ensemble de l'énoncé pour obtenir un score de l'énoncé pour un modèle de locuteur donné. Nous avons trouvé que la normalisation de ces scores d'énoncés est également efficace pour la vérification du locuteur.
L'amélioration de la qualité du son synthétique est le problème le plus urgent auquel l'étude de la synthèse du Chinois est confrontée. Cet article présente la structure et les traits de notre système de synthèse pour le Chinois standard. Le système a été construit sur base d'une analyse acoustico-phonétique des syllabes du Chinois. Le système incorpore plusieurs règles et modèles originaux. Toutes les 1268 syllabes du Chinois standard ont été synthétisées avec une qualité proche de l'original en ce qui concerne l'intelligibilite et le naturel.
Cet article décrit les résultats d'un projet lancé par deux laboratoires de recherche français (LIMSI-CNRS et INSERM-CREARE) et une organisation d'utilisateurs, l'Institut National des Jeunes Aveugles (INJA). Ce projet vise à exploiter des interfaces multi-modales (incluant de la reconnaissance et de la synthèse de parole) pour faciliter l'accès des aveugles aux ordinateurs. Un éditeur de texte multi-modal a été développé pour fournir des textes enrichis, une manipulation directe et un retour immédiat. Toutefois, la combinaison de la parole avec d'autres modalités au sein d'une même interface fait également apparaı̂tre des problèmes techniques nouveaux qui ne sont pas visibles quand la parole est utilisée seule. Ces problèmes sont discutés dans cet article qui présente également les besoins et attentes des utilisateurs.
Il présente l'implémentation de ce modèle, sa spécialisation pour certains systèmes de classeurs et son utilisation pour des applications diverses.
Nous exposons une méthode novatrice concernant le codage des paramètres “Line Spectrum Pair (LSP)”, ceci pour une transmission par canal bruité. Typiquement, les codeurs de parole à faible vitesse de transmission utilisent ces paramètres pour transmettre des données spectrales perceptivement importantes. Aussi, il est nécessaire que ces paramètres ne soient pas seulement quantifiés d'une manière efficace, mais également protégés tout au long de la transmission. Cette méthode utilise une technique combinant le codage de la source et celui du canal, appliquée à une structure de treillis joints entre-eux. Opérant en tant que codeur de source, le système encode avec une distorsion spectrale inférieure à 1 dB. Il est démontré que modifier la fonction-coût de l'encodeur, afin d'inclure la distorsion de canal déterminé à l'avance, améliore la robustesse du codage aux erreurs de canal. Ceci est réalisé avec un accroissement minimal de la complexité du système et sans augmenter la vitesse de transmission. De plus, elle est favorablement comparable au standard du quantificateur scalaire LSP couplé à un codeur de canal, du point de vue de la vitesse de transmission ainsi que du point de vue de l'immunité au bruit de canal.
Dans les explications traditionnelles de la prosodie de la parole, la fréquence fondamantale, la durée et l'intensité ont été décrites comme les attributs les plus importants. Parmi ceux-ci, l'intensité a le moins attiré l'attention. Dans les études perceptives, à la fois la fréquence fondamentale et la durée ont eu un rôle indiscutable dans le signalement des catégories prosodiques mais le rôle de l'intensité a été moins clair. Il en a résulté une accentuation de ces premiers attributs dans les schèmes actuels de synthèse de la parole. Dans cette étude, nous explorons l'emploi de l'intensité ainsi que d'autres corrélats segmentaux de la prosodie. L'intensité a un aspect dynamique, discriminant les portions de parole emphatiques et réduites. Un aspect plus global de l'intensité doit être contrôlé lorsqu'on essaye de modéliser les styles langagiers. Spécifiquement, nous avons essayé de modéliser le continuum de la parole faible à la parole forte.
Plusieurs groupes ont étudié la relation entre le taux d'erreur au niveau du mot et la perplexité du modèle de langage. Cette question est d'un intérêt central dans la mesure où la perplexité peut être optimisée indépendamment du système de reconnaissance et que, dans la plupart des cas, il est possible d'aboutir à des procédures simples d'optimisation. De plus, de nombreuses tâches intervenant lors de l'entraı̂nement d'un modèle de langage, par exemple, l'optimisation des classes de mots, sont suceptibles d'utiliser la mesure de perplexité comme objectif ce qui conduit à des formules explicites d'optimisation qui ne seraient pas accessibles si le taux d'erreur avait été choisi comme objectif. Cet article présente d'abord des arguments théoriques en faveur d'une relation étroite entre perplexité et taux d'erreur. Ensuite, la notion d'incertitude d'une mesure est introduite et appliquée aux fins de tester l'hypothèse que la corrélation entre perplexité et taux d'erreur est régie par une loi de puissance. Il n'y a pas d'évidence pour rejeter une telle hypothèse.
Les dérivés en -(cu)-lus, -(cu)-la, -(cu)-lum posent des problèmes de traduction dans les textes techniques latins. Dans certains cas le suffixe joue un rôle de diminutif qui lui est bien connu : l'objet désigné par le dérivé est plus petit que l'objet désigné par le simple. Dans d'autres cas nous avons affaire à des « emplois décalés » dans le temps ou dans l'environnement thématique : le simple et le dérivé sont utilisés pour désigner le même objet, dans le même contexte, mais à deux époques différentes, ou bien ils désignent deux objets différents (ou similaires) dans des contextes différents, sans distinction de taille. Il reste enfin de curieux cas de synonymie parfaite que nous examinons ici : comment et pourquoi, dans un même chapitre, un même paragraphe, voire une même phrase, un auteur technique désigne-t-il un même objet alternativement par son nom simple et par son nom dérivé ?
Ce système procure toute l'information utile aux connections entre 1200 villes allemandes. L'utilisateur peut s'exprimer librement, de manière naturelle et continue, ainsi qu'il le ferait normalement vis à vis d'un opérateur humain et il ne reçoit aucune instruction au préalable. Le système est constitué de quatre composantes majeures, à savoir la reconnaissance de la parole, la compréhension du message, la gestion du dialogue et la synthèse vocale, qui sont organisées en modules indépendants et exécutées séquentiellement. Dans le cadre d'une procédure d'évaluation toujours en cours, le système a été mis à la disposition du public, d'une part pour collecter des données et d'autre part afin de mesurer ses performances. Ces tests de validation ont été organisés par étapes successives : le système a d'abord été entrainé à l'aide des seules voix de ses concepteurs, pour être ensuite testé dans l'équipe. Après quoi, le numéro de téléphone du système a été communiqué à l'ensemble de l'entreprise, et enfin au monde extérieur.
Dans le cadre de la reconnaissance et de l'anticipation de situations dynamiques, différentes méthodes calculatoires basées sur des outils mathématiques existent déjà, cependant, leur implémentation est souvent complexe et débouche sur des programmes dont les temps de calcul sont longs. Nous proposons, dans cet article, une autre méthode d'apprentissage et d'anticipation, prévue pour assister un utilisateur dans le cadre de situations dynamiques. Ses connaissances sont donc structurées de manière à limiter la complexité de la solution et à faciliter l'apprentissage et l'anticipation.
Un grand ensemble de facteurs ont été avancés comme pouvant expliquer des différences dans le traitement des phrases relatives. Parmi ces facteurs, on trouve : le rôle grammatical de la téte de la phrase relative, l'ordre de surface des constituants, l'existence d'interruptions de la phrase principale, et l'existence ou non d'indications morphologiques. Comme l'anglais posséde un ordre strictement SVO, les relatives qui modifient le sujet de la principale interrompent nécessairement celle-ci, et par conséquent il est impossible de séparer les effets dûs au rôle grammatical et aux interruptions. Le hongrois, dont l'ordre des mots est variable, permet de mieux distinguer l'effet du rôle grammatical, des configurations, des interruptions et des indications morphologiques. Une étude basée sur 144 types de relatives en hongrois suggére que trois facteurs jouent un rôle important dans le traitement des relatives. Premiérement, l'importance de la conservation de la perspective est démontrée par le fait que les phrases SS sont les plus faciles á traiter, et les phrases SO les plus difficiles. Deuxiémement, la grande difficulté de traitement des phrases NNV, où la relative modifie le second substantif, démontre les limitations importantes du processus de construction de fragments par une analyse syntaxique “bottom-up”. L'existence d'un marquage de l'antécédent pour les relatives extraposées dans le cas de langues SOV avec ordre des mots variable comme le hongrois et le géorgien, est une autre indication des limitations importantes que conanait la construction de fragments. Troisiémement, le conflit qui apparait entre une phrase relative focalisée et une phrase principale focalisée montre que la conservation du focus joue un rôle important. Un ensemble d'autres facteurs auxquels on attribute souvent un rôle dans le traitement des relatives ne semblent pas avoir d'influence sur le traitement des relatives en hongrois.
Un codage de parole haute qualité à faible retard de 8 à 16 kbit/s peat être obtenu grâce aux algorithmesd'analyse par synthèse aver adaptation arrière : par exemple le CELP à faible retard (LD-CELP, le nouveau standard CCITT à 16 Kbit/s), le codage faible retard à excitation vectorielle (LD-VXC) et les codecs en arbre ou en trellis à adaption arrière. Cet article examine et passe en revue certaines des techniques de base saus-jacentes aux algorithmes de codage “faible retard” et présente des compromis performance/conception pour les codecs faible-retard à analyse par synthèse aux débits de 8 à 16 kbit/s. Plusieurs approches pour améliorer la qualité de la parole à 8 kbit/s sont examinées. Une prédiction arriére du fondamental est comparée à one configuration avant en boucle fermée (semblable à celle du dictionnaire adaptatif des codeurs CELP classiques). Pour conclure, on analyse la robustnese aux errears de transmission et on propose un certain nombre de compromis permettant de réduire la sensibilité aux erreurs de transmission.
Une théorie motrice de la perception proposée initialement pour rendre compte des résultats des premières expériences avec de la parole synthétique a été largement révisée afin d'interpréter les données récentes et de relier les propositions de cette théorie à celles que l'on peut faire pour d'autres modalités de perception. La révision de cette théorie stipule que l'information phonétique est fournie par un système biologique distinct, un 'module' spécialisé pour détecter les gestes que le locuteur a eu l'intention de faire : ces gestes fondent les catégories phonétiques. En conséquence le module provoque la perception de la structure phonétique sans traduction à partir d'impressions auditives préliminaires. Ce module est ainsi comparable à d'autres modules tels que celui qui permet à l'animal de localiser les sons. La particularité de ce module tient à la relation entre perception et production qu'il incorpore et an fait qu'il doit rivaliser avec d'autres modules pour de mêmes variations de stimulus.
Le propos de cet article est de faire un bilan des recherches récentes sur la première révolution urbaine, en s'appuyant sur deux sites emblématiques : Uruk puis Mari. La démarche ne se limite pas à l'analyse du bâti mais est élargie à celle des rapports entre ces villes et leur arrière pays, en combinant résultats des fouilles anciennes et résultats des recherches les plus récentes.
Le stress provoqué par divers types de situations conduit à des modifications du signal vocal. Des études précédentes ont indiqué que la parole stressée est caractérisée par une fréquence fondamentale plus élevée et des altérations du spectre des voyelles. Cet article présente les analyses conjointes de ces deux paramètres à partir de corpus de parole stressée obtenus à la fois dans une situation réelle et dans une situation artificielle. Le corpus de laboratoire est celui du test de Stroop et le corpus de la situation réelle est extráit d'un enregistreur des conversations d'un avion accidenté. La fréquence fondamentale est étudiée macroscopiquement et un index μ de la variation microprosodique est introduit. Les indicateurs spectraux du stress résultent d'un histogramme cumulé du niveau sonore et d'analyses statistiques des fréquences des formants. Les distances par rapport au centre F1-F2-F3 sont aussi étudiées. Toutes ces variations, à travers les deux situations, montrent un lien direct entre certains nouveaux paramètres du signal vocal et les apparitions du stress. Les résultats confirment la validité des expérimentations de laboratoire, mais mettent également en évidence des différences quantitatives aussi bien que qualitatives entre les situations et les locuteurs concernés.
Des expériences sont présentées aussi bien sur des phonèmes isolés que sur de la parole continue.
Le CITH de Rennes a une double vocation d'innovation et d'évaluation des technologies pour la santé. Il s'inscrit, plus spécifiquement, dans le cadre des systèmes de surveillance multivariés de diagnostic et des prothèses actives implantables permettant d'explorer, d'évaluer et de traiter les fonctions cardiovasculaire, nerveuse et respiratoire. Cet article décrit brièvement sa genèse, ses partenaires et quelques-unes des activités conduites depuis 2001.
Dans cet article, nous déterminons la densité spectrale de signaux ayant périodiquement des données manquantes, et nous établissons leur modèle lorsqu'ils sont issus d'un processus ARMA.
Les performances de la reconnaissance sont fortement dégradées lorsque les systèmes de reconnaissance sont employés sur des réseaux téléphoniques particulièrement difficiles et dans des environnements bruités. Il apparaît évident que la détection de parole/non-parole est une source importante de cette dégradation. Ainsi la robustesse de la détection de parole est un problème crucial à examiner pour améliorer les performances de la reconnaissance pour des communications très bruitées. De nombreuses études ont conduit à améliorer la robustesse de la détection de parole/non-parole pour une utilisation de la reconnaissance de parole dans des conditions difficiles. Ce papier propose des solutions pour l'amélioration de la détection de parole/non-parole en environnement très bruité. Des pré-traitements à la détection de parole sont d'abord considérés. Nous proposons et comparons ensuite deux versions d'un algorithme de détection de parole/non-parole, fondées sur des critères statistiques. Finalement, une technique de post-traitement est introduite dans le but de rejeter les détections de bruits prises pour de la parole.
Le classificateur par décision floue en deux passes (TSFDC) est un réseau de neurones fournissant une première phase de classification suivie d'une post-classification. Cette dernière intègre, pour chaque classe de données considérée, une source d'information provenant d'ensembles de référence flous. Le réseau isole les deux classes auxquelles un vecteur de données a le plus de chance d'appartenir. La post-classification sélectionne la classe gagnante parmi les deux. Le TSFDC applique sa post-classification seulement aux classes que le réseau a du mal à identifier. Trois expériences d'identification automatique de locuteurs (ASI), indépendantes du texte, sont menées dans un cadre médico-légal. Dans ces expériences, le signal est dégradé par un ensemble de facteurs influant sur les canaux de communication. Lorsque les locuteurs sont médiocrement classifies par le réseau, le TSFDC permet d'accroître le pourcentage de trames correctement identifiées de 3.27% en moyenne, sur les trois expériences. Simultanément, la différence entre le nombre de trames identifiées avec un locuteur légitime et un locuteur de second choix augmente de 5.27% en moyenne. Ainsi, la post-classification diminue, de plus de moitié, le nombre de locuteurs que le réseau a classifié avec erreur.
Les partitions musicales sont des documents qui comportent de nombreux symboles constitués de segments de droite. Dans le but d'extraire ces segments, nous avons mis au point un détecteur basé sur la technique du filtrage de Kalman. En appliquant méthodiquement ce détecteur et en utilisant quelques règles simples de classification sur les segments trouvés, on reconnaît les portées, les queues de note, les liaisons, les barres de croche et les têtes noires.
Nous proposons un algorithme amélioré de filtrage du bruit multiplicatif, en traitement d'images numériques basé sur un développement homomorphique spatial. Nous avons adopté une approche simple pour évaluer la statistique locale et supposé que la distribution locale de l'image originale est uniforme, ceci afin de traduire une méconnaissance de la probabilité originale qui peut être quelconque
La modélisation prédictive des usages du web a connu une période intense d'investigation jusque la fin des années 1990. Pourtant, deux caractéristiques du web ont rarement été prises en compte : la présence de bruit et de navigations parallèles. Dans cet article, nous proposons un nouveau modèle, le modèle SBR (Skipping-Based Recommender), qui utilise une technique appelée skipping, et qui est capable de prendre en compte ces caractéristiques de la navigation web. Dans une série d'études expérimentales, nous mettons en avant les diverses contributions que possède ce modèle, et montrons que sa qualité surpasse celle des modèles de l'état de l'art.
En dépit de ressemblances superficielles, la phrase nominale (jumla ismiyya) de la tradition grammaticale arabe n'a que peu à voir avec ce qu'il est convenu de nommer ainsi en linguistique générale depuis au moins Meillet (1906). Elle ne se caractérise pas par l'absence de verbe ou de copule, mais par une structure thème + propos (mubtadaˀ + ḫabar), et regroupe un ensemble assez consistant de faits, tout en permettant d'en donner une explication cohérente. Cet article étudie la manière dont ces faits sont présentés et analysés dans un ensemble de grammaires produites en Europe depuis le XVII e siècle jusqu'à nos jours, posant le problème de l'inter-traductibilité des catégories linguistiques d'une tradition à l'autre.
Nous présentons dans ce papier une approche de l'ingénierie du Web qui prend en compte l'attention au contexte d'une manière compréhensive et intégrée permettant ainsi une meilleure adaptation à l'application de l'utilisateur final. Nous présentons un modèle conceptuel, permettant la combinaison de l'ontologie du domaine avec des paramètres contextuels pertinents et un degré de significativité sur ces paramètres. Nous discutons ensuite l'utilisation d'un tel modèle dans un processus d'ingénierie du Web en incluant un logiciel de modélisation approprié et les prérequis pour en faire un système temps-réel.
Cet article expose de façon générale le service VoiceDialingSM de NYNEX — la première réalisation d'un service téléphonique fondé sur une technique de reconnaissance de la parole à l'intention des abonnés privés et des entreprises. Mis en place sur tout le réseau téléphonique, ce service permet aux usagers de composer leur appel uniquement par la voix, en énonçant le nom de l'appellé ou du lieu qu'ils veulent atteindre. VoiceDialingSM est compatible avec les services multitouches et à cadran, ainsi conçu pour opérer sur tout type d'appareils téléphoniques et donc tout ce qui peut être raccordé chez l'abonné. Cet article décrit l'architecture du réseau, l'interface usager et la technique de reconnaissance de la parole en insistant sur les conditions du succès de la mise en oeuvre du service et de son acceptation par les usagers. L'article présente en introduction une vue générale des activités de recherche et de développement poursuivies à NYNEX Science & Technology dans le domaine du traitement automatique de la parole.
Nous explorons l'utilisation de représentations dérivées de l'analyse multirésolution de la parole et de l'opérateur d'énergie de Teager pour la classification de la parole de conducteurs en condition de stress. Nous appliquons cette analyse à corpus d'énoncés courts pour créer des fonctions discriminantes dépendantes du locuteur pour quatre catégories de stress. En outre nous adressons le problème du choix d'une échelle temporelle appropriée pour catégoriser les données. Ceci mène à deux approches pour la modélisation. Dans la première approche, la dynamique des variables issues de l'analyse d'un énoncé donné est supposée pertinente pour la classification. Ces variables sont alors modélisées au moyen de réseaux bayésiens dynamiques (DBN) ou par un mélange des modèles de Markov cachés (M-HMM). Pour la seconde approche, nous ne gardons que les valeurs moyennes de ces variables pour chaque énoncé. Le vecteur résultant est alors modélisé au moyen d'une machine à support de vecteur et d'un perceptron multicouches. Nous comparons les performances de ces deux approches à un tirage aléatoire (25%), les meilleurs résultats étant obtenus avec le mélange de modèles dépendant du locuteur (96,44% sur les données d'apprentissage, et 61,20% sur un jeu de test distinct). Nous étudions également les performances de modèles indépendants du locuteur. Bien que les performances se dégradent par rapport des modèles spécifiques aux locuteurs, le mélange de modèles surpasse encore les autres modèles et obtient un taux de reconnaissance sensiblement meilleur qu'un tirage aléatoire (80,42 sur les données d'apprentissage, et 51,22% sur le jeu de test).
Dans ce papier on remet en cause l'argument théorique principal qui sous tend les modules de stades pour le développement du langage (voir Gleitman). Plus précisément on critique la proposition que les grammaires précoces sont exclusivement de nature sémantique. On pense que l'utilisation des pronoms référentiels et de verbes infléchis ainsi que le rôle de la distinction animé/non animé dans le développement du genre linguistique peuvent impliquer des généralisations formelles non sémantiques dés leur apparution dans les productions des enfants de deux ans et plus. Le stade précoce de la grammaire de deux mots ne peut être exclusivement 'sémantique'. Puisqu'on trouve des généralisations non-sémantiques aussi bien que des généralisations sémantiques, il n'est pas nécessaire de postuler que les grammaires plus développées nécessitant des changements qualitatifs qui appuieraient un modèle de stades pour le développement du langage.
Dans cet article, des expériences de modélisation de voix utilisant une version récente du système de synthèse de parole du KTH sont présentées. Il contient une source glottique améliorée basée sur le modèle LF de la source vocale, quelques paramètres supplémentaires de contrôle des sources voisée et bruitée, ainsi qu'une paire pole/zero pour le branchement nasal. De plus, les versions du système de synthèse texte-parole présentées dans cet article rendent possibles les manipulations interactives au niveau des paramètres avec référence sur écran à la parole naturelle. Le système de synthèse constitue donc un environnement flexible pour les expériences de modélisation de voix. Les nouveaux modèles et outils de synthèse ont été utilisés dans des expériences de synthèse par analyse. Une locutrice produisait une phrase dont on effectuait une copie stylisée qui employait respectivement l'ancien et le nouveau système de synthèse. A l'écoute, la copie synthétique effectuée avec le nouveau système ressemble fort à la parole naturelle.
Cette perméabilité aux influences extérieures a naturellement entrainé l'assimilation au peul d'une grande quantité d'éléments signifiants provenant d'autres langues. Parmi ces apports, les emprunts faits à l'arabe occupent une place particulière tant de par leur mode particulier de transmission que par leur importance numérique et leur présence dans tous les dialectes de la langue.
Des paramètres articulatoires sont déterminés à partir des cinq premières fréquences et des trois premières amplitudes formantiques par minimisation de l'erreur quadratique dans l'espace acoustique. Les propriétés non linéaires de la transformation relians les paramètres articulatoires aux paramètres acoustiques sont analysées au préalable, grâce à une représentation paramétrique de la fonction d'aire et à un analogue électrique du conduit vocal. Une analyse globale de la transformation est accomplie, de facon à localiser les non linéarités excessives qui induisent la procédure de minimisation en erreur. Une table de couples articulatoires-acoustiques de référence est construite à partir de cette analyse. La procédure d'identification des paramètres articulatoires comprend une estimation initiale à partir de la table de référence et un algorithme des moindres carrés. Des tests sur des valeurs de formants issues du modèle lui-même montrent que la méthode est efficace pour résoudre le problème inverse. Un autre test sur des valeurs de formants correspondant aux fonctions d'aire de Fant produit des résultats qualitativement acceptables mais le manque de précision dénote les limitations du modèle articulatoire utilisé.
L'objet de cet article est d'examiner la méthode classique d'extraction de la fondamentale basée sur l'analyse par autocorrélation à court terme du signal de parole. Il est tenu compte de deux estimateurs communément utilisés et de l'effet de la fenêtre de prélèvement du signal. Il est montré qu'une décomposition similaire de l'autocorrélation estimée vaut pour le cas d'un signal périodique comme pour le cas d'un signal aléatoire. Une telle décomposition permet de prédire les mérites relatifs des estimateurs considérés pour autant qu'il soit question des erreurs grossières et des erreurs de voisement. Le comportement prédit s'avère être en bon accord avec les résultats obtenus en appliquant l'algorithme SIFT à la parole naturelle.
Cet article décrit certaines des implications de l'effet de “centre de gravité spectrale” (SCG) mis en évidence par Chistovich, pour un modèle de la représentation auditive des voyelles de l'anglis. Le travail de Chistovich sur la définition d'une distance critique pour l'effet SCG est étroitement lié à deux des problèmes les plus fondamentaux dans les recherches sur la communication parlée : la relation entre attributs acoustiques et traits phonémiques et le problème de l'invariance en dépit de grandes différences acoustiques entre locuteurs. D'abord, nous passons en revue les découvertes expérimentales liées à l'effet SCG. Ensuite, un modèle qui incorpore ces effects perceptifs est décrit, et enfin, trois aspects du modèle sont discutés : (1) l'analyse résultante en traits, (2) la normalisation et (3) la variation acoustique telle qu'elle est représentée dans le modèle et sa relation avec la théorie quantale de la production de la parole de Stevens.
Une telle simplification permet de transformer le problème d'apprentissage en un problème d'optimisation qui autorise une stratégie gloutonne ne nécessitant qu'une seule passe sur les données. Notre stratégie d'optimisation pénalise la profondeur de l'arbre par le recours à la correction du R2. Les expérimentations ont montré que la précision en généralisation des arbres par niveau n'est pas détériorée par rapport aux arbres usuels.
Il prononce également un petit vocabulaire, appelé vocabulaire d'adaptation. Chaque nouveau locuteur prononce ensuite seulement le vocabulaire d'adaptation. Nous avons comparé deux méthodes d'adaptation, établissant une correspondance entre les codes du locuteur de référence et ceux des autres locuteurs, sur une base de données produite par 20 locuteurs et contenant un vocabulaire d'adaptation de 104 mots. La première méthode utilise un code transposé pour représenter le nouveau locuteur pendant le processus de reconnaissance tandis que la seconde utilise un code obtenu en regroupant les analyses effectuées sur la prononciation du vocabulaire d'adaptation. Le vocabulaire d'adaptation contient 136 mots. La comparaison des performances des deux méthodes montre qu'un nouveau code n'est pas nécessaire pour représenter un nouveau locuteur. En conséquence de quoi nous avons utilisé la première méthode pour effectuer des tests sur un vocabulaire d'application de 5000 mots et sur une base de données produite par 4 locuteurs. L'adaptation est toujours efficace, l'amélioration moyenne étant d'environ 14%, bien que l'amélioration relative n'est plus que de 30% par rapport à celle de 56% obtenue dans l'expérience sur le vocabulaire d'application de 104 mots. D'autres expériences montrent que la précision de la reconnaissance peut être améliorée en augmentant la taille du vocabulaire d'adaptation ainsi que celle du code.
La détection de la fréquence fondamentale reste l'un des problèmes les plus difficiles de l'analyse de la parole. Nous avons développé à cet égard une nouvelle méthode qui diffère des techniques conventionnelles. Elle utilise un banc de filtres passe-bande couplés par paires ; elle est pleinement séquentielle dans le domaine temporel. Cet article décrit l'optimisation paramétrique des filtres pairés pour une base de données et l'intégration de la méthode des filtres pairés par l'addition d'un détecteur de voisement. Comparée aux autres méthodes, la nôtre produit un faible taux d'erreurs grossières.
Cet article expose un modèle qui permet de représenter à peu près n 'importe quelle règle de jeu de table conceptuellement programmable. Ensuite, il s'attache à montrer de quelle manière un tel modèle est effectivement transposable sous la forme d'un code informatique. Il décrit ensuite brièvement une application conçue pour mettre en œuvre ce modèle dans une problématique de confrontation de plusieurs types de moteurs de prises de décisions. Enfin, il fournit un aperçu d'un protocole manipulable par un superviseur et permettant de contrôler et de tester les diverses confrontations des joueurs machines autour des règles autorisées par ce modèle.
Nous traitons dans cet article du problème de la reconnaissance de la parole en environnement bruité. Les informations statistiques locales sur la parole et le bruit sont estimées en ligne, puis utilisées comme entrée pour les estimateurs. Pour un rapport signal à bruit (SNR) de 20 dB, les résultats observés sont comparables à ceux obtenus dans des conditions non bruitées. Une amélioration importante est également obtenue pour des rapports signal à bruit plus défavorables. L'analyse attentive des résultats montre que les estimateurs MLP semblent fonctionner assez mal quand aucun signal de parole n'est pratiquement détectable. Ceci nous a conduit à introduire une modification de la fonction de gain qui a encore augmenté les performances.
Cet article présente un essai d'optimisation du jeu de règles extrait par la technique des motifs fréquents. On définit ensuite des règles « fortuites » par des techniques de simulation. On discute alors du choix de celles qu'il convient de supprimer afin d'optimiser le jeu de règles de départ. Les indices associés à des règles extraites de données s'appuient généralement sur le support et la confiance. On mentionne dans l'article les résultats obtenus avec d'autres indices de qualité des règles utilisés actuellement en fouille de données.
Nous présentons un nouvel outil graphique interactifpour l'exploration des résultats d'arbre de décision, incluant simultanément : notre visualisation radiale, le focus+context, le zoom/pan, le fisheye, la visualisation hiérarchique, la treemap et l'icicletree pour la représentation et l'exploration des résultats des algorithmes d'arbre de décision. L'utilisateur peut ainsi extraire facilement des règles d'induction et élaguer l'arbre obtenu dans une phase de post-traitement. Cela lui permet d'avoir une meilleure compréhension des résultats obtenus. Nous avons utilisé des critères d'intérêt pour évaluer la performance du système avec des ensembles de données réelles.
Cet article propose un principe de normalisation pour la vérification du locuteur en mode dépendant du texte fondée sur une modélisation HMM, principe dans lequel le score sur le modèle du locuteur prétendu et le score sur le modèle de normalisation sont calculés pour un même alignement, effectué sur le modèle du mot de passe indépendant du locuteur. On montre que cette normalisation préserve une part de l'information caractéristique du locuteur contenue dans l'alignement, et augmente la pertinence du score normalisé en insistant sur les parties remarquables du modèle du locuteur. Une procédure d'apprentissage spécifique est proposée. Des évaluations sur une base de donné téléphonique réaliste sont décrites. Enfin, les premiéres expériences sur l'intégration de l'information contenue dans l'alignement temporel dans la prise de décision sont présentées. Tous ces résultats montrent l'intérêt de l'approche et encourage de futures recherches sur la caractérisation du locuteur dans une telle approche.
Nous présentons une méthode d'estimation de la direction d'arrivée de signaux non circulaires par un réseau d'antennes. Basée sur l'algorithme Root-MUSIC (par résolution d'un polynôme), la méthode proposée est limitée aux réseaux d'antennes linéaires uniformes. En revanche, elle permet de réduire considérablement le temps de calcul et d'augmenter le pouvoir de résolution par rapport aux méthodes qui nécessitent une recherche sur l'étendue de l'espace des paramètres (MUSIC et NC-MUSIC). La supériorité de l'algorithme proposé est montrée par des simulations comparant sa performance d'estimation à celle d'algorithmes connus.
L'article décrit une approache phonétique expérimentale de l'étude de la mélodie de la parole développée à l'IPO. La méthode proposée mène à des modèles intonatifs qui sont utiles pour interpréter des données acoustiques et physiologiques concernant la fréquence fondamentale en parole naturelle. Elle constitue également un cadre pour le développement de règles pour la synthèse de l'intonation dans diverses langues.
Cet article passe en revue quelques théories récentes qui rendent compte de la façon dont les informations sensorielles et perceptuelles sont transmises au systéme de reconnaissance de mots par les processus qui sous-tendent la perception de la parole. Dans la premiére partie, nous évoquons quelques problémes que tentent de résoudre depuis une trentaine d'années les chercheurs du domaine. Dans la deuxième partie, nous examinons un cadre théorique de la perception de la parole où les étapes de traitement sont associés à des niveaux d'analyse linguistique. Dans ce cadre on part de l'hypothèse que la parole est traitée dans une série d'étapes analytiques allant du traitement auditoire périphérique, de l'analyse phonétique acoustique et phonologique à la reconnaissance de mots et l'accés lexical. Enfin, dans la dernière partie, diverses approaches des problèmes de la reconnaissance de mots et de l'accès lexical sont évaluées. Nous examinons différentes propositions concernant l'analyse de “bas-en-haut”, les unités perceptuelles postulées et l'interaction entre différents types d'information dans la reconnaissance de mots. Un objectif supplémentaire de ce travail consiste à établir l'importance des représentations segmentales dans la reconnaissance.
On présente ici un nouveau paramètre de fréquence, PSP (Parabolic Spectral Parameter), pour la quantification de la vélocité de volume de l'onde glottique. PSP est basé sur l'adaptation d'une fonction parabolique à la partie basse-fréquence du spectre pitch-synchrone du flux glottique estimé. PSP donne une valeur numérique qui décrit comment la décroissance spectrale d'un flux glottique obtenu se comporte par rapport à la limite théorique correspondant à la décroissance spectrale maximale. Les performances de ce nouveau paramètre, pour l'analyse de signaux de parole caractéristiques de différents types de phonation, sont comparées à celles de trois paramètres d'usage courant, basés sur le temps, ainsi qu'à une méthode fréquentielle développée antérieurement.
Différents types de connaissances peuvent être extraits des données issues d'un questionnaire. Elles dépendent du questionnement de l'analyste mais aussi des méthodes de traitement des données qui sont utilisées. C'est ainsi que l'on peut obtenir le rejet d'une hypothèse nulle, mais aussi une typologie des items du questionnaire, des sujets qui y ont répondu, mais encore une structure graphique de filiation inférentielle, une hiérarchie de règles comportementales, etc. Dans cet article, nous présentons plusieurs approches de traitement possibles d'un questionnaire visant à structurer des traits de personnalité dégagés de comportements de réponse au questionnaire.
Avec notre méthode, la parole–avec l'emotion qui convient–peut être produit synthétiquement en changeant tout simplement entre des bases de données de source crées par le corpus. Les caractéristiques acoustiques de chaque corpus ne sont pas les mêmes et sont reconnaissables par émotion. Les caractéristiques acoustiques de chaque parole émotionnelle produit synthétiquement par notre méthode montrent des corrélations évidentes avec les caractéristiques acoustiques de chaque corpus. Des expériences perceptuelles utilisant la parole produit synthétiquement indiquent que notre méthode réussit à produire synthétiquement la parole émotionnelle de maniére reconnaissable. Nous avons evalué davantage l'intelligibilité et l'impression generale que notre méthode a fait sur les auditeurs. Les résultats montrent que la méthode proposée peut produire synthétiquement la parole avec un niveau élevé d'intelligibilité et donne une impression favorable. Avec ces résultats encourageants nous avons developpé un systéme TTS valable avec la capacité d'émotion pour répondre aux besoins immédiats des individus qui ne peuvent pas parler. Cet exposé décrit la méthode proposée, les caractéristiques acoustiques et de conception du corpus, et les résultats des évaluations perceptuelles.
Nous présentons dans cet article un algorithme d'estimation combinée qui calcule simultanément le spectre lissé du signal de parole ainsi que l'excitation de forme impulsionelle utilisée dans le codage prédictif multipulse (MPLPC). Quoique la forme de l'excitation ainsi obtenue différe de l'excitation à impulsions multiples usuelle, les résultats expérimentaux indiquent que la différence entre les paramètres de codage prédictif optimisés et non optimisés et minimale tant du point de vue numérique que subjectif.
Cet article présente une méthode originale de détermination de la qualité d'une image en niveaux de gris. Un exemple d'application de la méthode sur des images comprimées selon la norme JPEG est présenté. Contrairement à la plupart des méthodes existantes, cette évaluation de qualité est univariante, c'est-à-dire ne nécessite aucune image de référence. La qualité est donnée sous la forme d'une note dont la progression est étalonnée selon l'utilisation qui doit être faite de l'image : visuelle, mathématique, informatique. Pour ce faire, un apprentissage est effectué à l'aide d'un réseau de neurones sur une base d'exemples connus faite d'images dont on a préalablement noté la qualité avec le modèle souhaité. Pour s'assurer de sa fiabilité, la méthode est comparée à des méthodes bivariantes classiques. Elle permet de retrouver avec une erreur inférieure à 7 % les résultats prévus par celles-ci.
Le but de cette étude est de proposer une nouvelle approche pour l'identification automatique des langues, basée sur une modélisation du rythme, ne nécessitant pas de données étiquetées manuellement. Il faut tout d'abord savoir comment apporter des informations sur la prosodie, le rythme pour l'identification automatique des langues. Pour répondre à cette question nous avons introduit une nouvelle unité, la pseudo-syllabe, qui est automatiquement extraite. Des paramètres rythmiques et intonatifs sont alors calculés à partir de cette unité. Des modèles élémentaires pour chaque type de paramètres sont définis en utilisant des mélanges de lois gaussiennes. Ces modélisations de la prosodie sont couplées à une approche plus classique utilisant une modélisation acoustique des systèmes vocaliques. Les expériences sont menées sur les cinq langues européennes du corpus MULTEXT. L'intérêt des paramètres rythmiques, et l'efficacité de chaque système (modèle rythmique, modèle de la fréquence fondamentale et modèle vocalique) sont évalués. L'impact de ces approches sur les performances d'identification est analysé. Nous obtenons des résultats de 91 % d'identification correcte avec des fichiers de 21 secondes.
Des travaux récents ([CHI98], [DEN 98]) ont montré l'intérêt de l'utilisation de procédures de Metropolis dans un cadre bayésien, pour la recherche d'arbres de classification performants. Pour une classe particulière de distributions a priori sur les arbres, nous introduisons un nouvel algorithme d'échantillonnage MCMC, semblable à un échantillonneur de Gibbs, utilisant le principe de l'algorithme de pondération récursive introduit par Willems et al. [WIL 95], ce qui permet de prendre en compte effectivement un nombre de modèles beaucoup plus important. Les arbres ainsi échantillonnés sont moyennés pour obtenir un estimateur agrégé. Nous présentons les résultats de simulations sur trois jeux de données de référence, montrant l'intérêt pratique de cette procédure.
Cette étude présente une analyse inter-linguistique des stratégies utilisées par des enfants coréens, japonais et anglais pour traiter les relatives. Les résultats d'une expérience de comprehension des relatives en Coréen sont comparés avec des résultats obtenus précédemment sur l'acquisition des relatives en Anglais et en Japonais. On a demandé à des enfants coréens de 6 ans de représenter des relatives branchées à gauche ou enchassées au centre de la phrase dans deux conditions d'ordre de mots SOV et OSV et dans deux conditions d'intonation : intonation “claire” motivée par la syntaxe et intonation “en liste”. Les résultats montrent, pour le Coréen, une stratégie fondamentale de gauche à droite et des rôles significatifs pour une stratégie de phrase canonique et pour une stratégie de fonction parallèle. Il est proposé que l'interprétation des relatives dans les langues se fonde sur l'intégration de plusieurs stratégies universelles de traitement dont l'application dépend des propriétés structurales des relatives spécifiques aux langues et au stade de développement de l'enfant.
Les modèles de Volterra sont très utilisés dans de nombreux domaines d'application du fait qu'ils permettent de représenter, avec une précision arbitraire, tout système non linéaire de mémoire finie. Ils possèdent de plus la propriété d'être linéaires vis-à-vis de leurs paramètres, les coefficients des noyaux. Le principal inconvénient de ces modèles est leur complexité paramétrique qui nécessite d'estimer un très grand nombre de paramètres. Cet article présente une nouvelle méthode permettant de réduire cette complexité paramétrique en considérant les noyaux de Volterra d'ordre supérieur à un comme des tenseurs symétriques et en les décomposant à l'aide de la décomposition PARAFAC. Les modèles de Volterra-Parafac ainsi obtenus peuvent être vus comme une série de modèles de Wiener mis en parallèle. En exploitant cette nouvelle formulation des modèles de Volterra, nous proposons un algorithme d'identification récursif basé sur le filtre de Kalman étendu. Des résultats de simulation illustrent le comportement de la méthode d'identification proposée, dans le cas de systèmes de Volterra cubiques.
KEAL est un système de reconnaissance de la parole continue développé au CNET à Lannion. L'une des extensions en cours consiste à en faire un système de compréhension et de dialogue homme-machine. Un dialogue de type question-réponse est mis en oeuvre en vue de fournir un renseignement à l'utilisateur (l'application actuellement étudiée est la simulation d'un centre de renseignements téléphoniques). Cet article montre comment les connaissances syntaxiques, sémantiques et pragmatiques sont utilisées pour réaliser un tel dialogue, et discute des principaux avantages et inconvénients des méthodes retenues. La reconnaissance des phrases est effectuée par un analyseur syntaxique ascendant de gauche à droite, à l'aide d'une grammaire sémantique hors-contexte. On interprète ensuite l'arbre syntaxique, par une méthode analogue à celle des attributs sémantiques, afin d'obtenir une structure sémantique qui représente les informations utiles pour la suite du dialogue. Le module de gestion de dialogue utilise la structure sémantique pour instancier un graphe-modèle qui représente à tout instant l'état du dialogue ; il indique le prochain message à envoyer à l'utilisateur et la manière d'analyser la réponse de celui-ci. On décrit un exemple tiré du centre de renseignements téléphoniques.
Cet article propose une démarche d'intégration de connaissances pour l'amélioration d'un système de reconnaissance de défauts par vision sur des planches de bois. Nous situons le problème de vision qui est à la base de cette étude, puis nous explicitons les connaissances métier nécessaires, aussi bien dans le domaine du métier du bois que dans le domaine de la vision. Nous utilisons pour cela un modèle symbolique basé sur la méthode NIAM/ORM, formalisant ces connaissances métier à partir de leur expression en langage naturel. Puis nous présentons la façon dont nous exploitons ces connaissances métier pour générer les nœuds d'une structure en arborescence pour l'identification des défauts des planches de bois. Chacun des noeuds consiste en un moteur d'inférence à base de règles linguistiques floues. Les résultats obtenus prouvent l'intérêt de cette démarche.
Cet article présente les résultats du développement, du déploiement et du test d'une application à large échelle de dialogue oral destinée au grand-public. Nous avons construit un système oral automatique de questionnaire pour le bureau américain de recensement. Dans la première phase du projet, les systèmes de reconnaissance et de dialogue ont été élaborés en utilisant 4000 appels. Dans la seconde phase, le système a été adapté pour correspondre aux exigences du bureau de recensement puis déployé dans le cadre de la campagne 1995 de tests de nouvelles technologies lancée par cet organisme. Dans la troisième phase, nous avons redéfini le système et avons montré empiriquement qu'un système oral automatique pouvait collecter et reconnaı̂tre les données de recensement avec succès, et que les sujets préféraient le système oral aux questionnaires écrits. Notre collecte d'une quantité importante de données et les deux campagnes d'expérimentation terrain subséquentes ont montré que, quand les questions sont posées correctement, les réponses contiennent l'information attendue dans la catégorie de réponses correspondante dans environ 99% des cas.
Jean Marot a composé, dans La vraye disant Advocate des Dames (1506), un poème-rébus, sous la forme d'un « neuvain picard » . Si les Grands Rhétoriqueurs sont connus, entre autres, pour être des « jongleurs de syllabes » , l'artifice littéraire ici employé n'est pas que le simple fruit d'un divertissement. À travers l'analyse des différents niveaux de lecture du poème (jeu littéraire, poème historique, poème polémique …), l'auteur tente de démontrer l'impact qu'a eu cette oeuvre sur la future carrière du poète. Plus encore sans doute que dans son rébus-rondeau précédemment analysé par Adrian Armstrong, on constate que les relations spatiales spécifiques de la mise en page du neuvain sont significatives à plusieurs niveaux.
Le langage implique une structure et un processus. En rendant à chacun son dû, nous présentons un modèle du processus cognitif et montronse comment sa valeur empirique est reliée aux propositions sur la structure syntaxique. Toutefois, ce qu'on observe dans les expériences n'est pas une structure syntaxique mais l'exécution d'un plan. Nous présentons un langage de processus pour représenter ces plans et fournir une explication unifée de plusieurs phénomènes dans le développement, en incluant les résultats des expériences récentes et ceux de nouvelles expériences suggérées par notre approche. L'explication se fait en termes de resources cognitives requises pour formuler et exécuter un plan. Comme cette explication s'appuie sur un traitement non syntaxique, la syntaxe des entants n'a pas à être tenue pour fautive. La conclusion renforce la proposition que le nombre de structures syntagmatiques disponibles pour les enfants est biologiquement contraint.
Comprendre les bases neurales de la cognition est devenu un problème abordable scientifiquement, et des modèles sont proposés dans le but d'établir un lien causal entre organisation neurale et fonction cognitive. Au cours du développement et chez l'adulte, cette évolution interne est de nature épigénétique : elle ne requiert pas d'altération du génôme. L'activité (spontanée ou évoquée) d'un réseau de neurones au cours du développement stabilise de manière sélective certaines synapses et en élimine d'autres, contribuant, de ce fait, à la mise en place de la connectivité adulte à l'intérieur d'une enveloppe de potentialités définies génétiquement. A un niveau supérieur, la modélisation de représentations mentales par des états d'activité de populations restreintes de neurones est réalisée par les méthodes de la physique statistique : la mémorisation de ces représentations est envisagée comme un processus de sélection parmi des “pré-représentations” variables et instables. Des modèles théoriques montrent que des fonctions cognitives comme la mémoire à courtterme ou la manipulation de séquences temporelles peuvent dépendre de paramètres physiques élémentaires. Une implémentation neuronale et sélectionniste des intentions est envisagée.
L'objectif de cet article est de montrer que l'étude des systèmes socio-techniques complexes peut bénéficier des concepts développés dans le cadre de la théorie de la complexité. Nous prendrons comme exemple celui de la conception d'un service d'urgence médicale.
Dans ce papier, les expériences menées à l'ITC-irst visant à transférer notre système de reconnaissance d'informations télédiffusées en italien vers deux applications de dialogue en parole spontanée sont présentées. Cette étude porte sur l'utilisation des techniques de l'état de l'art pour l'adaptation des modèles acoustiques et linguistiques du système et sur l'évaluation de la relation entre performance et qauntité de données annotées utilisée. Différents niveaux de supervision ont aussi été étudiés pour l'adaptation des modèles acoustiques. Deux heures de parole manuellement annotées ont permis d'obtenir des taux d'erreur en mots de 26,0% et 28,4% avec les systèmes adaptés. Ces résultats sont à comparer avec 22,6% et 21,2% qui oint été obtenus par les systèmes spécifiquement développés pour ces deux tâches avec une plus grande quantité de données. Finalement, une méthode robuste permettant de régler, lors du décodage, l'insertion de phénomènes particuliers à la parole spontanée est présentée.
Un enjeu important de la recherche de formes dans une base d'images est la définition de seuils non supervisés permettant d'éviter une déferlante de fausses détections, ou, au contraire, des rejets de formes qui auraient dû être reconnues. En prenant comme exemple une méthode de reconnaissance de forme proposée par Lisani [15, 16], nous montrons que l'on peut répondre à la question suivante : étant donnée une forme requête et une base d'images, à partir de quelle distance entre la forme requête et une forme détectée est-on sûrs que la forme est reconnue ? Cette assurance est quantifiée par le nombre de fausses alarmes associé à la paire requête - forme candidate. Cette méthode ne considère pour l'instant que des morceaux de forme et permet pourtant déjà d'aboutir à des détections sûres basées sur un seul morceau de forme.
A l'audition, les sons de parole contiennent de l'information à la fois phonétique, individuelle et de transmission. Il ressort de plusieurs études dans différentes languages que les différences entre les fréquences principles des voyelles pronouncees par des hommes, des femmes et des enfants indiquent une tendance assez uniforme. Ces différences sont considérées comme relevant des qualités (timbre) personnelles. Les différences entre les sexes sont principalement dues à la descente du larynx qui a lieu chez les mâles durant la puberte. Nous reproduisons la tendance observée concrnant les fréquences des formants chez les hommes et les femmes par un calcul où nous prenons en considération les conséquences phyiologiques de la descente du larynx, tout en supposant que les commandes nerveuses aux articulateurs, pour chaque voyelle, restent inchangées. La perception du timbre phonétique est vue comme un processus de reconnaissance de figures tonotopique. Nous affirmons et montrons que, dans les voyelles phonétiquement identiques, les distances tonotopiques inférieures à 6 Bark entre les formants sont invariantes. La position absolue des formants permet une variation personnelle. La distance tonotopique entre le premier formant et la fondamentale est moins grande pour la plupart des voyelles éimises par des femmes que chez les hommes et les enfants. En ce qui concerne le rôle du son fundamental par rapport à ces faits, on propose quelques hypothèses alternatives.
Les experts en classification d'images utilisent des caractéristiques variées pour représenter les textures. Nous proposons de choisir les plus pertinentes à l'aide d'une procédure automatique de sélection de caractéristiques. Nous comparons pour cela l'efficacité de plusieurs algorithmes de sélection récents. L'ensemble des algorithmes est évalué à l'aide de critères heuristiques ainsi que de performances de classification. Nous démontrons l'intérêt d'une telle procédure de sélection à partir d'images de Brodatz et d'images satellitaires.
Le marqueur arabe bien connu de l'objet pronominal iyyā- s'acquitte d'autres fonctions au sein de la langue, parmi lesquelles on citera le démonstratif. Celui-ci a été reconnu dans l'arabe dialectal égyptien, mais il passe virtuellement inaperçu dans l'arabe écrit. Néanmoins, il est utilisé plus souvent par les écrivains du monde arabophone oriental que par ceux de l'Occident. En tant que tel, il remplit habituellement quatre rôles dans la structuration de l'information : exprimer le contraste, la réflexivité emphatique et deux degrés de la deixis distale. Alors que les écrivains modernes arabes semblent l'utiliser démonstrativement plus souvent que ceux du Moyen Âge et de l'arabe classique, le recours des écrivains antérieurs laisse penser que sa propriété démonstrative est une caractéristique inhérente. Ceci est confirmé par la comparaison des marqueurs d'objet dans d'autres langues sémitiques – en hébreu et en araméen – où ils peuvent fonctionner comme démonstratifs, et comme réflexifs en syriaque et dans la deixis à distance en langue amharique.
Dans le cadre d'une étude de faisabilité du dénombrement d'épis de blé par imagerie couleur, une méthode d'analyse de textures sur des composantes d'espaces couleurs a été développée. L'objectif agronomique est la prévision de rendement avant la moisson par évaluation du nombre moyen d'épis par unité de surface en tenant compte de la variabilité intra-parcellaire. Pour ce dénombrement par image, nous étudions six paramètres de texture (deux valeurs statistiques et quatre coefficients d'Haralick issus de la matrice de cooccurrence) que nous évaluons sur les composantes d'espaces couleurs utilisées en agronomie. Un nouvel espace hybride permet de créer une représentation d'images de blé prises en milieu naturel dans lesquelles l'extraction d'épis sera améliorée. La méthode basée sur des mesures de distances (Euclidienne, de Mahalanobis) permet d'extraire les épis avec quelques erreurs corrigées par de la morphologie mathématique. Malgré les difficultés dues à la variation de luminosité et à l'entropie élevée des scènes, les résultats permettent de trouver en partie les épis, et les dernières images en court de traitement permettent une meilleure segmentation.
L'utilisation de la reconnaissance automatique de la parole pour l'automatisation des transactions téléphoniques permet de réduire considérablement les coûts de fonctionnement et d'améliorer la qualité du service pour le client. A GTE, nous ayons concentré nos efforts sur le développement de services interactifs à commande vocale, appelés OASIS. Dans cet article, nous exposons la méthodologie utilisée pour le développement des dialogues, nous décrivons le dialogue mis au point pour l'application d'interruption de service téléphonique et nous présentons les résultats d'une expérimentation terrain. Notre méthodologie de développement de dialogues comprend la mise au point d'un modèle de transaction, la définition d'un schéma de dialogue, l'élaboration de structures de langage et la construction du vocabulaire du système. La structure du dialogue et le vocabulaire de reconnaissance sont définis en tenant compte des capacités de reconnaissance et d'interprétation du système. Les principales caractéristiques de cette méthodologie sont les suivantes : une représentation structurée des transactions verbales permettant une acquisition progressive des informations ; une formulation des questions suivant un style de discours qui suscite des réponses prédictibles ; une utilisation des résultats de la reconnaissance et des actions correspondantes du système pour définir l'évolution du dialogue ; et un développement des solutions adaptables. Pour évaluer l'efficacité de notre approche, nous présentons les résultats d'une expérimentation terrain concernant l'interruption de service. Globalement, les usagers ont réagi de façon coopérative, ont adhéré à une interaction structurée, n'ont donné que rarement des informations de façon anticipée et ont fourni des réponses pertinentes aux questions du système.
Nous présentons dans cet article une nouvelle approche de la Reconnaissance de Formes basée sur le Modèle des Croyances Transférables, une interprétation non probabiliste de la théorie des fonctions de croyance de Dempster et Shafer. Le principe de cette méthode consiste à caractériser sous la forme d'une fonction de croyance l'information apportée par un ensemble d'apprentissage, relativement à la classe d'un nouveau vecteur. Différentes stratégies de décision avec coûts arbitraires, généralisant l'approche bayésienne, sont présentées et illustrées à l'aide d'un exemple.
La base de données SUSAS est une collection de phrases enregistrées dans des conditions de stress simulé ou réel dans le but d'étudier l'influence du stress et du style sur le signal acoustique. L'objet de la présente étude était la validation perceptuelle de la partie simulée de la base de données. Sept auditeurs jugeaient que les mots monosyllabiques ou dissyllabiques énoncés par des locuteurs étaient perçus comme étant prononcés de façon Colérique, Claire, Rapide, Forte, Neutre, Interrogative, Lente ou Douce. Les locuteurs ont un accent soit de Boston, de New-York ou plus généralement de type americain. La moyenne des pourcentages de jugements “corrects” étaient soumise à une analyse de la variance, qui montre que le pourcentage des classifications correctes était seulement de 58%, et que ce pourcentage était une fonction de l'accent, du style de parole, et du nombre de syllabes.
Dans cet article, la structure des groupes phonématiques de l'allemand est examinée. La connaissance des groupes phonématiques possibles est indispensable par example pour l'analyse des influences contextuelles sur les indices acoustiques-phonétiques dans un système automatique pour la reconnaissance de la parole. Comme les principaux effets de coarticulation se limitent à la région syllabique finale, il est nécessaire de distinguer la position des phonèmes groupes consonantiques dans la syllabe. Nous avons ainsi obtenu deux graphes pour l'ordre temporel du mode d'articulation dans tous les groupes consonantiques initiaux et finals.
Un système multi-agent est constitué d'un grand nombre d'entités, appelées agents, en interaction entre elles au sein d'un même environnement. Cette technologie aborde de nombreux domaines d'applications comme la vision par ordinateur, la robotique, la simulation de systèmes, le commerce électronique. Nous considérons que les questions abordées en traitement du signal sont très pertinentes dans un cadre multi-agent. Nous présentons d'abord les principaux outils dont disposent les concepteurs de systèmes multi-agents à savoir : des modèles, des plates-formes et des méthodes de développement. Puis, le projet SCALA de simulation de résolution de problèmes par des patrouilles aériennes et un projet de simulation de système de transports illustrent la résolution de problèmes à l'aide de systèmes multi-agents. Ensuite, nous nous intéressons plus particulièrement aux capacités d'adaptation de tels systèmes que nous abordons comme une question de résolution émergente de problèmes. Dans ce cadre nous décrivons en détail la théorie AMAS (Adaptive Multi-Agent System) qui permet de concevoir des systèmes dont la fonction globale émerge à partir d'un processus d'auto-organisation coopérative de ses parties. Une application en prévision de crues donne une indication plus précise des capacités de telles approches.
Un modèle d'identification de voyelles stationnaires à un et deux fromants est présenté. Le modèdele comprend un algorithme de détection de formants et un algorithme de classification. Le signal est représenté dans le modèle par une combinaison de plusieurs configurations de trois types. Chaque configuration se caractérise par sa position sur un axe de tonalité et par un “coeeficient type”. Les positions dese configurations sont déterminées par les positions des pics spectraux détectés. Les coefficients types dépendent des distances entre le pics détectés et le centre de gravité du spectre auditif. Le modèle fournit en sortie une “distribution de réponses” ; un vecteur normalisé de similitudes entre un signal et des classes définies (phonèmes). Une expérience d'identification de signaux à deux formants avec des relations d'amplitude variables entre formants est décrite, et les résultats sont comparés avec les “distributions de réponse” du modèle. Les résultats de la seconde expérience sur l'identification des signaux à un formant sont utilisés pour vérifier les paramètres de l'algorithme de détection de formants.
Une interface cerveau-ordinateur (ICO) est un nouveau type d'interface homme-machine qui permet la communication directe entre l'utilisateur et la machine en décodant l'activité cérébrale. Les potentiels cognitifs évoqués comme le P300 peuvent être obtenus grâce au paradigme oddball - stimulus discordant - où les cibles sont sélectionnées par l'utilisateur. Une nouvelle méthode pour la réduction des capteurs des signaux électroencéphalographiqes (EEG) est proposée. La réduction du nombre de capteurs permet d'accroître le confort de l'utilisateur en diminuant le temps nécessaire à la pose des capteurs. L'approche proposée est basée sur une élimination récursive des capteurs où la fonction de coût est basée sur une évaluation du rapport signal sur signal plus bruit (RSSB), après un filtrage spatial. Nous montrons que cette fonction de coût est plus robuste et moins coûteuse en temps de calcul que d'autres fonctions basées sur l'évaluation de la détection du P300 ou des cibles, permettant ainsi d'éviter une étape de classification. Nous proposons également une fonction de décision qui permet de mieux catégoriser l'importance d'un capteur en fonction du nombre de capteurs désirés. L'approche proposée est testée et validée sur 20 sujets au cours de plusieurs sessions.
Les algorithmes génétiques, la programmation génétique, les stratégies d'évolution, et ce que l'on appelle maintenant en général les algorithmes évolutionnaires, sont des techniques d'optimisation stochastiques inspirées de la théorie de l'évolution selon Darwin. Nous donnons ici une vision globale de ces techniques, en insistant sur l'extrême flexibilité du concept d'évolution artificielle. Cet outil a un champ très vaste d'applications, qui ne se limite pas à l'optimisation pure. Leur mise en œuvre se fait cependant au prix d'un coût calculatoire important, d'où la nécessité de bien comprendre ces mécanismes d'évolution pour adapter et régler efficacement les différentes composantes de ces algorithmes. Par ailleurs, on note que les applications-phares de ce domaine sont assez souvent fondées sur une hybridation avec d'autres techniques d'optimisation. Les algorithmes évolutionnaires ne sont donc pas à considérer comme une méthode d'optimisation concurrente des méthodes d'optimisation classiques, mais plutôt comme une approche complémentaire.
Nous présentons une nouvelle approche expérimentale pour l'étude des lapsus : les sujets doivent intervertir délibérément des phonèmes à des positions spécifiées dans des paires de mots présentées sous la forme d;une liste, les mesures de la performance étant la vitesse et la précision. Dans le cas de mots CVC, les performances de transposition ont été les meilleures pour les phonèmes initiaux et les plus faibles pour les phonèmes finaux. Le degré de facilité de transposition des phonèmes médians dépendait de ce que la voyelle médiane était, ou non, une diphtongue et aussi du fait qu'un échange de lapsus produirait, ou non, un changement orthographique important, à supposer que la réponse purement articulatoire fût effectivement transcrite. Les variables orthographiques apparaissent donc influencer le processus, mm̂e dans une tâche qui se situe vraisemblablement à un niveau purement acoustico-articulatoire. Bien que la performance n'ait pas été affectée par le status de mot/non-mot de la réponse, l'environnment articulatoire des phonèmes adjacents a influencé effectivement la performance d'inversion des phonemes médian. Enfin, les gauchers ont fait preuve d'une habileté supérieure dans la production de tels lapsus sur demande, ce qui pourrait reflécter une habileté supérieure à lire et à écrire en miroir. Ces résultats induisent des hypothesès nouvelles pour l'étude des lapsus spontanés.
Ce texte présente l'approximation simultanée de l'affaiblissement et de la distorsion du temps de propagation de groupe pour les filtres numériques récursifs (à réponse impulsionnelle infinie). La méthode développée est caractérisée par l'utilisation de deux étapes successives : l'approximation portant sur l'affaiblissement seul, faisant appel à un algorithme itératif n'exigeant que la résolution d'un système d'équations linéaires et donc très rapide, suivie par l'approximation simultanée, basée sur la résolution à chaque itération d'un problème de programmation linéaire. La convergence des deux algorithmes est garantie ; leur efficacité est démontrée par application à un exemple test.
Plusieurs sortes de caractére de non-texte apparaissent souvent dans les textes. L'expression orale de ces caractéres peut être changé selon les sens de textes. Ce travail propose un classeur de trois-couches (TLC, three-layer classifier) qui peut efficacement résoudre le probléme ambigu de ces non-texte caractéres dans le mandarin TTC systéme. Ces trois couches sont empoyées en ordre. La premiére couche est composée en deux éléments : le tableau de modéle et l'arbre de décison. Si cette couche peut désambiguı̈ser les sens de caractére prévu, la tâche de désambiguı̈té va arrêter. Sinon les deux couches suivantes va être déclenché. D'aprés l'algorithme de confiance, la troisiéme couche peut exploiter un modéle de remplacement pour améliorer la performance. L'expérience montre que l'approche proposée ici peut avoir une très bonne assimilation même avec très peu de données. Les précisions d'entraı̂nement et d'essai sont respectivement 99.8% et 97.5%.
Dans cet article nous présentons la base de données parole du CTH que nous créons actuellement à l'École Polytechnique Chalmers à Göteborg (Suède). Le matériel comprend aujourd'hui des sons isolés (phones et diphones), des phrases sémantiquement non reliées ainsi que des textes cohérents. Cette collection de données est restreinte à du suédois lu. L'enregistrement du signal de parole a été effectué en chambre sourde en utilisant un enregistreur audio-numérique SONY PCM-F1. La segmentation, la classification et la transcription sont exécutées sur huit niveaux d'analyse linguistique, incluant les niveaux acoustique, phonétique et prosodique.
La méthode DFE (Extraction Discriminante de Paramètres) fournit un formalisme adéquat pour la conception d'un module d'extraction de paramètres pour un système de classification de formes. Au cours des dernières années, cette méthode a été appliquée avec succès à différents problèmes en reconnaissance de la parole tels que la classification de voyelles et de phonèmes ou la reconnaissance de mots isolés. Le formalisme DFE peut être utilisé pour pondérer les contributions des différentes composantes d'un vecteur de paramètres. Cette variante de DFE, que nous appelons DFW (Pondération Discriminante de paramètres), améliore un système de classification de formes en favorisant les composantes assurant la meilleure discrimination interclasses. Cet article est consacré à l'application du formalisme DFW à la reconnaissance de la parole continue par modèles de Markov cachés (HMM). Deux types différents de reconnaisseurs sont étudiés : ceux fondés sur des HMM discrets (utilisant une distance euclidienne) et ceux fondés sur des HMM semi-continus (utilisant des mélanges de gaussiennes). Nous montrons comment les composantes peuvent être pondérées et comment les poids peuvent être appris de façon discriminante. Des résultats expérimentaux sont fournis pour différentes tâches de parole continue. Ces résultats montent l'intérêt du formalisme en reconnaissance de parole continue par HMM.
Traditionnellement le raisonnement à base de cas (CBR) s'appuie sur des expériences décrites dans des formats complètement structurés tels que des objets ou des enregistrements de base de données. Toutefois, d'autres modèles ont été proposés pour surmonter les limitations de cette approche structurelle et rendre possible l'application à des domaines plus variés. Dans cet article, nous passons en revue les extensions du formalisme CBR proposées pour traiter des expériences décrites dans des documents textuels, travaux regroupés sous la bannière CBR textuel. Après une présentation succincte des principes généraux du raisonnement à base de cas, nous décrivons les principaux travaux du CBR textuel et nous les comparons selon différents aspects techniques et applicatifs. Finalement, nous proposons quelques problèmes et avenues de recherche méritant d'être explorés dans des travaux futurs.
On a fait deux expériences pourétudier le ro˛le de la présupposition syntaxique dans la compréhension des phrases. Dans la premiére expérience les sujets doivent vérifier, en fonction de contextes présentés avant les phrases, des phrases clivées, des pseudo-clivées et des phrases avec des compléments factitifs. Les sujets mettent significativement plus de temps pour vérifier les phrases avec des présuppositions fausses que pour vérifier les phrases avec des assertions fausses. Dans l'expérience II, les sujets vérifient les phrases clivées et pseudo-clivées en fonction d'images présentées aprés les phrases. Les temps de vérification pour les phrases avec des présuppositions fausses sont ici aussi significativement plus longs que les temps de vérification pour les phrases avec des assertions fausses. On rend mieux compte de ces données avec une hypothése “structurale” qu'en termes de stratégies ayant pour but de localiser les informations données ou nouvelles.
Les variations de prononciation observées aujourd'hui chez les locuteurs sont parallèles, sur de nombreux points, aux variations de prononciation reportées au cours des siècles (le changement phont́ique). Il est raisonnable de conclure qu'il existe une certaine relation nécessaire entre les deux. Je soutiens que les variations diachroniques émergent, pour la plupart, à partir des variations synchroniques, et donc que des contraintes physiques universelles et atemporelles de la production et de la perception de parole conduisent les auditeurs à mal appréhender le signal de parole. Chacune de ces méprises qui conduisent l'auditeur à prononcer des choses d'une façon différente est potentiellement le début d'une changement phonétique. L'étude de le changement phonétique permet donc bénéficier de certains éclairages sur la façon dont la parole est produite et perçue. Je montre cela sur un exemple, en étudiant toute une série des changements phonétiques portant sur des fricatives sourdes : ce que l'on appelle la nasalisation spontanée, la s-aspiration et l'effacement nasal. Ces changements suggèrent que, pour cette classe de sons, la qualité de voix spécifique sur la portion de la voyelle qui suit immédiatement la fricative constitue un indice.
Trois expériences de décision lexicale cherchent à étudier la séparabilité du traitement syntaxique et sémantique au cours de la reconnaissance auditive des mots. Une quatrième expérience étudie le problème de la mesure des temps de réponse à un stimulus auditif. Les mots utilisés sont du Serbo-croate, chaque stimulus consistant en une racine nominale (qui correspond à un mot attesté ou bien à un pseudo-mot) et d'une flexion casuelle qui véhicule de l'information sur le cas grammatical du nom. La vitesse d'identification des formes fléchies d'un mot dépend de leur sens syntaxique plutôt que de leur forme physique ou de leur fréquence d'apparition. En plus, l'identification d'un nom est facilitée lorsque celui-ci est précédé par un stimulus véhiculant de l'information permettant de prédire le cas du nom, qu'il s'agisse d'un véritable adjectif ou d'un pseudoadjectif. Ces résultats sont analogues à ceux obtenus préalablement pour la perception des mots en présentation visuelle ; ils suggèrent qu'il existe une grande uniformité dans le traitement des suffixes flexionnels pour le langage écrit et parlé. Dans les deux cas, les résultats suggèrent que le traitement des suffixes flexionnels est modulaire, du moins dans la mesure où il est indépendant du traitement sémantique pendant la partie initiale de son déroulement.
Plusieurs activités ont été entreprises en italie dans le domaine de la communication numérique entre moyens mobiles. En particulier pour le codage de la voix, deux codeurs ont été développés et on les a comparés sur un système de transmission du type SCPC (Single Channel Per Carrier). Les codeurs sont décrits dans l'article et leurs caractéristiques sont comparées. La caractéristique principale des deux codeurs réside dans l'emploi de la quantification liée au spectre du signal à envoyer au récepteur. Le codeur SB-APC utilise un post-filtre pour modeler le bruit de quantification de chaque sous-bande. L'article souligne que les deux codeurs présentent presque les mêmes résultats du point de vue de la qualité subjective malgré les différences de structures.
Nous proposons un nouveau modèle du signal glottique. Conventionellement, le signal de source est modélisé en concaténant un faible nombre de segments de courbes afin d'approcher la forme de l'impulsion glottique. Nous proposons une alternative qui développe le signal en une combinaison d'un ensemble de fonctions élémentaires. Celles-ci sont choisies de manière à tenir compte du caractère ponctuel de la source voisée et de la non-linéarité de son fonctionnement. Nous établissons les relations mathématiques entre les poids des fonctions temporelles de base et les coefficients de Fourier du signal à modéliser. Les paramètres de contrôle sont la fréquence et l'amplitude d'une fonction excitatrice cosinusoïdale. L'enveloppe du signal émis (c.-à-d. des impulsions glottiques) évolue avec la fréquence fondamentale et son contenu spectral change avec l'amplitude de la fonction excitatrice.
L'ensemble des traitements est réalisé à l'aide de réseaux de neurones. Ce système est une sorte de robot simulé capable d'agir dans son environnement afin de reconnaître des objets dépà appris. L'un de ses principaux attraits est qu'il permet une communication simple entre les traitements de haut et de bas niveau. Enfin et surtout, il a été conçu pour montrer que l'on n'a pas besoins d'avoir des régions bien fermées ou des contours parfaits pour réaliser une bonne interprétation. Notre robot est un exemple relativement simple de ce que les réseaux de neurones intégrés à une approche cybernétique permettront de réaliser. Malgré cela, il est déjà intrinsèquement capable de reconnaître plusieurs objets dans une scène complexe même s'ils sont bruités, déformés, ou en partie occultés.
Les performances des systèmes actuels de reconnaissance de parole se dégradent rapidement en présence de bruit. Une nouvelle représentation du signal de parole, basée sur la prédiction linéaire de séquence d'autocorrélation unilatérale (One-Sided Autocorrelation Linear Prediction : OSALPC), s'est avérée être intéressante pour la reconnaissance de la parole bruitée, à la fois pour ses bonnes performances (par rapport au codage LPC conventionnel) dans des conditions difficiles de bruit blanc additif et pour sa simplicité de calcul. Le but du travail présenté dans cet article est double : (1) il s'agit de montrer que OSALPC fournit également de bonnes performances pour de la parole bruitée en contexte réel d'usage (en voiture), et (2) d'explorer sa combinaison avec diverses techniques robustes de mesure de similarité, en montrant que ses performances s'améliorent en utilisant une pondération cepstrale, des indices dynamiques et l'étiquetage multiple.
Cet article concerne le probléme de l'intégration temporalle de l'information dans la perception des voyelles ainsi que la nature de cette information. Des stimuli caractérisés, soit par un formant, avec, soit par 2 formants, F1 et F2, soit encore par un formant évolutif produit par trains d'impulsions alternantes de F1 et F2, en proportions différentes, ont été utilisés dans des expériences d'identification de voyelles. Les distributions de réponses correspondant aux stimuli à 2 formants et à ceux avec formant évolutif ont été approchées par des sommes pondérées de deux distributions “de base”, 1 et 2, correspondant aux stimuli à un seul formant. Un accroissement de la proportion d'impulsions F2 dans les stimuli à formant évolutif est accompagné d'un accroissement systématique de la composante 2 de la distribution de réposens. Les stimuli avec formant évolutif n'ont pas suscité les réponses phonémiques caractéristiques des stimuli à 2 formants avec mémes fréquences de F1 et F2. Les données suggérent qu'il y a intégration temporelle des résultats du processus d'idenfication continue du stimulus.
Ce papier décrit une méthode tentant d'extraire l'information de transition entre segments pour les tâches de reconnaissance de la parole. Les caractéristiques dynamiques (variant lentement) des trajectories spectrales contiennent beaucoup d'information discriminante qui est mal modélisée dans les approaches HMM traditionnelles. Dans les approches telles que les réseaux de neurones récurrents, il y a l'espoir, mais pas de démonstration convainquante, que cette information de transition pourrait être utilisée. La méthode présentée ici se base sur un principe assez différent et consistant à modéliser explicitement la trajectoire des paramètres spectaux à court terme dans un sous-espace où l'information temporelle est préservée. Ceci est réalisé en introduisant une contrainte temporelle dans la technique bien connue de l'Analyse en composantes Principales. Dans ce sous-espace, on a alors défini un modèle paramétrique de la trajectoire, et une measure de distances a été utilisée pour effectuer la classification en diphones. En utilisant la méthode de “Principal Curves” de Hastie et Stuetzle et la “Generative Topographic Map” de Bishop, Svensen et Williams une description de l'évolution temporelle en termes de variables latentes a été effectuée. Sur le problème difficile de /bee/, /dee/ et /gee/, il a été possible de conserver l'information discriminante avec un ensemble réduit de paramètres. Des illustrations expérimentales sont présentées sur les bases de données ISOLET et TIMIT.
Le manque de descriptions quantitatives des sons de la parole tant pour les consonnes que pour voyelles pose souvent des problèmes pour la synthèse de la parole. Habituellement, seules les voyelles sont caractérisées à l'aide of fréquences formatiques. Cet article propose une description paramétrique des zones quasi stationnaires de tous les sons non-plosifs à l'aide de centroïdes dans l'espace des coefficients de prédiction linéaire “log area ratio”. Pour chacun des sons un centroïde est calculé comme centre de gravité sur un enxemble de réalisations en situations contextuelles différentes prononcées par un seul locuteur. Les centroïdes sont ensuite comparés à l'aide d'une mesure de distance objective. Le comportement dynamique de certains sons est également analysé dans des essais de destruction et de construction du signal de la parole. Enfin, toutes ces informations servent à discuter plusieurs problèmes phono-acoustiques concernant la délimitation des sons de l'allemand et surtout les relations entre la qualité et la quantité des voyelles.
Dans cet article, nous présentons Strada, une approche globale utilisant l'apprentissage pour la conception automatique de stratégies dans l'environnement de ces jeux. Strada combine de nouvelles idées avec des techniques avancées d'apprentissage automatique. Ces solutions sont intégrées dans un système efficace, dont les performances sont démontrées dans le cadre d'un wargame commercial.
Cet articles décrit les méthodes d'analyse et de synthèse développées au ECL de NTT. Les procédures PARCOR et LSP basées sur un filtre tout pôle sont expliquées à partir de la méthode LPC. Les principes et les interprétations physiques de ces méthodes sont comparés entre elles. Les caratéristiques paramétriques des traints sont clarifiées par diverses expériences. La qualité de la parole synthétisée est également illustrée par des expériences objectives et subjectives. Grâce à ces méthodes, de la parole synthétique de haute qualité peut être obtenue à un faible taux de transmission, au-dessous de 9600 bps.
Dans cet article, nous proposons une méthode de caractérisation d'images d'ouvrages anciens basée sur une approche texture. Cette caractérisation est réalisée à l'aide d'une étude multirésolution des textures contenues dans les images de documents. Ainsi, en extrayant cinq indices liés aux fréquences et aux orientations dans les différentes parties d'une page, il est possible d'extraire et de comparer des éléments de haut niveau sémantique sans émettre d'hypothèses sur la structure physique ou logique des documents analysés. Au travers de ces expérimentations, nous mettrons en avant la pertinence de ces indices et les avancées qu'ils représentent en terme de caractérisation de contenu d'un corpus fortement hétérogène.
La localisation des syllabes est une étape importante pour la plupart des systèmes d'analyse prosodique. Cette localisation est utilisée pour identifier les accents lexicaux ou intonatifs qui servent ensuite de base pour l'analyse du rythme et de l'intonation. Cet article présente un nouveau système de syllabation, utilisant des réseaux neuronaux récurrents, qui fonctionne sur de la parole continue, indépendante du locuteur. Il est appris et testé sur la région dialectale 1 de la base de données TIMIT : il y détecte 94% des syllabes et place la plupart des frontières syllabiques à moins de 20 msec des emplacements souhaités. On présente également diverses méthodes d'optimisation des performances et d'apprentissage des réseaux récurrents.
Dans cet article, nous décrivons l'implantation du synthétiseur à formants de Klatt (série et parallèle) opérant en temps réel sur un seul processeur du signal ST8940 de SGS-Thomson. La simulation de l'algorithme de synthèse en virgule flottante a permis la détermination des conditions optimales de fonctionnement. La simulation en viTgule fixe est réalisée pour l'estimation de la longueur adéquate du mot et la mise à l'échelle de l'ensemble des variables impliquées. La réalisation de ces deux étapes a permis la programmation de l'algorithme de synthèse en langage assembleur du processeur. Notre objectif à court terme est la réalisation d'une carte compatible PC de synthèse de la parole autour du processeur ST18940.
Nous traitons dans cet article du problème de la segmentation d'images à partir de niveaux de gris et sans prise en compte de la notion de texture. Toutes les méthodes peuvent être rendues automatiques, ou non supervisées, en leur adjoignant une méthode d'estimation de mélanges. Des études antérieures ont montré que le choix de la méthode d'estimation a, dans le cas gaussien, peu d'influence sur le résultat final. Cependant, les comportements généraux des méthodes locales et globales sont très différents et aucune famille n'est supérieure à l'autre dans toutes les situations. Le choix de l'algorithme est fait à partir de l'homogénéité de l'image des classes et de la corrélation spatiale du bruit. La pertinence des choix est montrée via simulations et segmentations des images réelles.
On discute le fait que les théories de la mémoire sémantique suivent une divergence parallèle à celle des controverses concernant la représentation de la signification. Le modèle de comparison des traits (Smith, Shoben et Rips, 1974) applique la théorie linguistique de Lakoff (1972) pour prédire le temps de réaction dans la vérification des phrases, alors que le modèle de recherche des marques, décrit ici, utilise le type de représentation sémantique défini par Katz (1972) pour expliquer des donnés analogues. Les deux modèles sont décrits et leur portée est revue. Le modèle de recherche de marques se vérifie bien mais en revanche une prédiction majeure de modèle de comparaison des traits est infirmée. On discute le fait que le modèle de comparaison des traits est inadéquant pour rendre compte de la représentation sémantique tant que sa conception des consituants sémantiques reste inchangée.
Au cours de ces dernières années, la gestion des agro-écosystèmes est devenue un enjeu majeur du développement durable. Cette gestion doit permettre de résoudre des problèmes environnementaux cruciaux et doit prendre en compte les brusques changements de contexte tels que les changements climatiques ou de politique agricole, etc. La réponse à ces problèmes de décisions complexes passe par un recours accru à la modélisation, la simulation et l'expérimentation virtuelle. Dans cet article, nous présentons des travaux récents de l'intelligence artificielle ayant contribué au thème de la modélisation et la simulation de systèmes complexes pour l'analyse des modèles agronomiques et la conception de décision. Nous présentons des formalismes originaux pour la modélisation et la simulation de systèmes complexes ainsi que pour la conception de stratégies basés sur les réseaux de contraintes pondérées ou les processus décisionnels de Markov. Nous abordons ensuite le couplage entre les deux thèmes simulation et décision. Enfin, nous illustrons l'utilisation de ces méthodes et modèles sur plusieurs cas d'études en gestion des agro-écosystèmes.
On présente la théorie de Piaget sur la perception de l'espace par les jeunes bébés dans le cadre d'un systéme hypothético-déductif. Les auteurs définissent 11 hypothèses portant sur : l'agent du changement visuel, des constances de forme et de taille, de la distance et de la perception des relations d'un ordre supérieur entre leséléments spaciaux. Les propositions de Piaget pour chacune de ces hypothèses sont présentées en plusieursétapes : la preuve comportementale, l'interprétation en terme d'états intérieurs, les inférences et généralisations. Enfin, les conclusions générales sont brièvement discutées.
Dans cet article sont étudiées des mesures acoustiques du bruit et des microperturbations du signal de parole en vue de la discrimination entre voix normales et dysphoniques. Uné revue de travaux similaires effectués par d'autres chercheurs japonais est également présentée.
Ce chapitre propose à la discussion, à travers onze questions, un ensemble organisé de principes pour une analyse orientée vers la conception des systèmes technico- organisationnels en tant que systèmes dynamiques, vivants, sociaux et culturels. Après avoir précisé une notion ontologique de complexité adéquate aux systèmes technico- organisationnels, ces questions abordent les divers aspects théoriques, épistémologiques et méthodologiques (à la fois de recueil de données, d'analyse et de modélisation) de la connaissance de cette complexité, ainsi que leurs relations avec la conception. La discussion fait appel à des contributions disciplinaires diverses, tant scientifiques qu 'ergonomiques ou philosophiques, et est en relation avec des idées développées par les auteurs d'autres chapitres de cet ouvrage.
Les phrases grammaticalement incorrectes (paragrammatismes) sont caractéristiques du langage spontané de certains aphasiques. Les paragrammatismes produits par cinq aphasiques a “jargon néologique” ont été compares aux paragrammatismes de quatre sujets normaux de contrôle. Nous montrons que les paragrammatismes des aphasiques sont qualitativement identiques aux erreurs grammaticales des sujets normaux, mais qu'ils sont beaucoup plus frequents. Une explication est proposée en termes de modèles de production de la parole ; nous essayons de montrer que les paragrammatismes sont la consequence d'une défaillance des processus de contrôle.
Cet article contient une étude analytique de dix nouvelles inscriptions thamoudéennes, notées en graphie “thamoudéen E”, rassemblées par les auteurs au cours d'une exploration dans la région d'al-Jafr (sud-est de la Jordanie). L'étude se propose d'analyser les inscriptions, les sens et les structures des mots et noms propres qui y figurent. Ce groupe d'inscriptions met en relief de nouveaux noms personnels mentionnés dans les inscriptions thamoudéennes.
Un MLP a été entraîne à transformer en paramètres de contrôle d'un synthétiseur de parole basé sur un modèle du tube acoustique le spectre de puissance de voyelles et de consonnes nasales produites par un seul locuteur. Les sorties du MLP contrôlent ces onze sections de manière à reproduire une parole synthétique dont les spectre de puissance est semblable à celui présenté à l'entrée du réseau. Après l'apprentissage, on peut synthétiser de la parole, restreinte à ce locuteur et à ces phonèmes, avec une bonne intelligibilité.
Nous proposons un codeur à multi-impulsions de complexité réduite. Une réduction de la complexité de 33% affecte très peu la qualité de la parole produite comme nous le montrons sur base d'un calcul du rapport signal sur bruit et sur base d'une évaluation auditive informelle. Elle permet, par contre, l'implantation du codeur à l'aide de circuits commerciaux peu coûteux. Le TMS32020 a été utilisé pour une implantation de l'algorithme en temps réel à 16 kbit/s en virgule fixe. La méthode étudiée ici peut être considérée comme une alternative à la technique multi-pulse conventionnelle.
Nous étudions la conception d'un joueur artificiel pour le jeu de Tetris. Après une revue des principaux travaux, nous soulignons le fait que comparer différentes performances doit être fait avec le plus grand soin, car les scores ont une grande variance, et de subtils détails d'implémentation ont un effet significatif sur les résultats. Nous considérons ensuite la méthode d'entropie croisée pour optimiser la fonction d'évaluation d'un joueur artificiel, comme suggéré par Szita et al. (2006). Dans ce contexte, nous discutons de l'influence du paramètre bruit, et nous effectuons des expériences avec plusieurs jeux de fonctions de base, comme celles introduites par Bertsekas et al. (1996), par Dellacherie (Fahey, 2003) et des fonctions originales. Cette approche aboutit à un programme de Tetris dont les performances dépassent celles des autres programmes connus. Sur une version simplifiée de Tetris, considérée par la plupart des travaux de recherche, il réalise 35 000 000 ± 20 % de lignes en moyenne par partie.
Dans cet article, nous proposons une approche originale d'estimation séquentielle de densités non paramétriques définies dans des espaces de grande dimension, dans le cadre méthodologique du filtrage particulaire. En exploitant les indépendances conditionnelles de l'espace d'état, nous proposons de permuter des sous-ensembles indépendants de particules de manière à générer un nouvel ensemble échantillonnant mieux cet espace. Nous intégrons cette approche dans deux versions classiques du filtre particulaire : celui avec échantillonnage partitionné et celui à recuit simulé de manière à prouver son efficacité. Nous comparons notre modèle aux approches classiques dans le cadre de l'estimation des densités d'objets synthétiques articulés.
On montre en particulier que le maximum du débit d'entropie correspond au maximum de l'erreur de prédiction. Utilisant alors les coefficients de réflexion, on montre très simplement l'équivalence de la méthode avec celle du modèle autorêgressif. On présente également une interprétation en termes de blancheur, ce qui permet de discuter ce que donnerait le minimum d'entropie.
Dans les systemes recherche d'information vocale, la reconnaissance de la parole est appliquee a une collection pour obtenir certaines information qui correspond aux contraintes des requetes. On a explore la recherche basee sur phoneme de “n-grams”. L'utilisation de ces phonemes concerne le probleme du “vocabulaire exterieure”, et l'utilsation du concept de “n-gram” permet le matching approximatif dans un environnement imprecis de transcription. Les experiences (c'est-a-dire, les tests) on permit d'explorer beaucoup d'aspects, comme par example, “word boundary information”, elimination des points d'arret, expansion des requetes, variation de la longueure des sequence de phonemes, et la combinaison des n-grams. Nos resultat experimentals ont montre qu'il y a une deterioration dans l'efficacite de la rechere, mais pour des cas particulier de matching, cela n'etait pas important parce que la sequencee des phonemes est correcte. Dans les cas ou les suite de phoneme sont directement reconnues, il etait important de selectionner une bonne approache de matching. La combinaison de n-grams de different longueures (3-grams and 4-grams) on permit d'ameliorer l'efficacite de la methode de recherche.
Le manuscrit BnF, fr. 6449 constitue la seule copie connue de la Vie de sainte Katherine de Jean Miélot (1457), biographie fort développée de la sainte, originaire d'Alexandrie en Égypte, que le chanoine bourguignon a voulu encadrer dans l'histoire romaine du IVe siècle. Cet article met en lumière l'intérêt de cette œuvre, par une présentation du manuscrit, une première enquête sur les sources latines du texte, et une analyse linguistique et des techniques de traduction de Miélot ; il offre ainsi une étude préliminaire à l'édition critique qui manque encore.
Cet article présente une description de la base de données POLYCOST qui est dédiée aux applications de reconnaissance du locuteur à travers les lignes téléphoniques. Les caractéristiques de la base de données sont : corpus moyen à contenu varié (>100 locuteurs), anglais parlé par des étrangers, chiffres lus et parole libre, enregistrement à travers des lignes de téléphone internationales, minimum de neuf sessions d'enregistrement pour 85% des locuteurs.
Cet article illustre l'importance de divers facteurs cognitifs dans la perception et la compréhension de la parole de synthèse. Toutefois, cette difficulté décroît avec l'exposition des sujets à la parole de synthèse. Une charge mentale plus importante est requise lors de l'écoute de parole de synthèse et les sujets écoutant des textes en parole de synthèse sont obligés d'être plus attentifs que ceux écoutant de la parole naturelle.
En particulier, les machines qui peuvent reconnaître des images de visage sont très coûteuses. Cet article montre comment un système de reconnaissance des visages peut être réalisé par un réseau de neurones artificiel de type perception multicouche et par un réseau de neurones à spike. Le système à base de spike est développé pour acquérir les importantes caractéristiques du visage, pour simuler le système de la vision humaine et pour optimiser le temps de calcul, ce dernier objectif c'est la principale force derrière le développement des systèmes à base des réseaux de neurones à spike. A noter que l'apprentissage du réseau sur différents ensembles d'images lui force à apprendre comment il se comporte vis-à-vis la variété des visages, un problème commun dans le monde réel…
Cet article décrit un système de vérification automatique du locuteur (ASV) utilisant un modèle de Markov semi-continu (SCHMM) à plusieurs dictionnaires, employant une nouvelle méthode pour la discrimination par modèle de Markov appelée “probabilité d'observation discriminante” (DOP). Cette méthode n'est pas un apprentissage discriminant, mais simplement un moyen de mieux séparer deux HMM standard pour améliorer la discrimination entre les classes qu'ils représentent. La technique DOP peut être superposée à tout système à base de HMM et ne demande pas d'apprentissage complémentaire. On peut envisager de l'appliquer à toute application de classification par HMM, pour un problème à deux classes. On présente des résultats sur des expériences dépendantes du texte avec 24 locuteurs de référence et 100 imposteurs “naïfs”, enregistrés sur le réseau téléphonique britannique.
Cet article décrit notre travail dans le domaine de la reconnaissance multilingue de parole. D'abord nous présenterons les différentes stratégies : portation, reconnaissance à travers plusieurs langues et la reconnaissance simultane des plusieurs langues. Puis nous présentons les résultats obtenus. Ces dernières années nous avons porté notre système de reconnaissance en différentes langues (Italien, Slovaque, Slovène, Tchèque, Anglais et Japonais). Nos expériences montrent que certaines langues sont plus facile a reconnaître, pour la même complexité du domaine. La substitution des sons des langues inclues est de grand intérêt pour la reconnaissance à travers plusieurs langues et la reconnaissance simultane des plusieurs langues. Nous comparons les résultats pour les différents systèmes de base pour la reconnaissance à travers des langues. Nous avons trouvé que la nombre de sons communs est un critère principale pour la qualité de la reconnaissance. Pour la reconnaissance multilingue, la reconnaissance diminue en générale comparé à la reconnaissance monolingue. Dans peu de cas, par exemple, quand il est parlé dans une autre langue que la langue maternelle, la reconnaissance peut être améliorée.
L'objectif de ce travail est de savoir comment un auditeur identifie que deux phrases successives sont prononcées par une ou par deux personnes quand il ne dispose que des informations acoustiques relatives aux caractéristiques individuelles des voix des locuteurs et à l'intonation. Le matériau de test utilisé consistait en fragments d'énoncés successifs, de structure lexicale figée, pouvant former une ou plusieurs répliques d'un dialogue. Lors des expériences, on a fait varier les locuteurs, les types d'énoncés et les types de cohérence communicative. Des paires d'énoncés, avec ou sans pause interne, étaient présentées aux sujets qui avaient pour tâche de les classer dans l'une des trois catégories suivantes : dialogue, monologue ou méta-dialogue (imitation d'un dialogue par un seul locuteur). Les résultats montrent que les facteurs qui influent sur les décisions des auditeurs sont les suivants : les caractéristiques individuelles des voix des locuteurs, la présence ou l'absence de pause et le type communicatif des énoncés. On suggère que deux principes sont mis en oeuvre dans le traitement des signaux. Dans le cas où les énoncés sont séparés par une pause, c'est la comparaison auditive des timbres qui sert de critère de décision.
Nous présentons dans cet article un nouvel algorithme biomimétique permettant de créer des groupes au sein de données et de les visualiser dynamiquement. Cet algorithme s'inspire des insectes volants se déplaçant en nuage en créant des mouvements complexes à partir de règles locales simples. Chaque insecte représente une donnée. Le déplacement des insectes vise à créer des groupes de données homogènes se déplaçant ensemble dans un espace à deux dimensions. Les groupes créés et visualisés en temps réel informent l'expert du domaine qui a fourni les données sur leur structuration en classe, par exemple, le nombre de classes plausible, le regroupement de données similaires, et les données isolées représentant des cas « à part » . Nous présentons des extensions de l'algorithme comme la diminution du temps de calcul ou l'utilisation d'un affichage 3D. L'approche est étudiée sur des données artificielles et réelles. Un algorithme heuristique permet d'évaluer la pertinence des partitionnements trouvés.
On décrit ici l'amélioration d'un système de reconnaissance de mots isolés à base de phonèmes. Ce système utilise une procédure robuste d'extraction des données de référence et fournit de meilleurs taux de reconnaissance. De plus, on présente une nouvelle méthode pour son adaptation à la parole continue. Le système de reconnaissance de mots isolés décrit ici utilise la technique de répertoires multiples ; l'algorithme LVQ, qui fournit des répertoires bien définis et efficaces, minimise l'influence de la coarticulation entre mots et permet l'utilisation de l'information temporelle dans la phase de reconnaissance. La méthode d'adaptation est basée à la fois sur la modification des répertoires de référence à partir d'un petit nombre de données de parole continue, représentatives, et sur des transformations linéaires des principaux paramètres prosodiques (énergie et durée). Des tests approfondis, menés sous diverses conditions (avec des données dépendantes et indépendantes du locuteur, des répertoires simples ou multiples, adaptés ou non-adaptés, reconnaissance par phonèmes ou par mots, etc.), ont montré l'efficacité des méthodes proposées.
Cet article porte sur les deux témoins des Cent Nouvelles Nouvelles qui nous sont parvenus : le manuscrit de Glasgow (University Library, Hunter 252), et l'incunable d'Antoine Vérard (Paris, BnF, Rés. Y2-172). Un rappel des problèmes philologiques concernant la transmission du texte est suivi de l'analyse comparée des deux programmes iconographiques (enluminures et bois gravés), en particulier pour les nouvelles 9, 12, 27, 33, 46.
Chomsky & Halle (1968) soutiennent que l'accentuation et l'intonation d'un énoncé ne sont pas déterminées seulement par les propriétés physiques du signal acoustique mais également par l'organisation syntaxique de l'énoncé. Les résultats obtenus en faisant entendre à des auditeurs la répétition continue d'une suite de mots monosyllabiques appuient tout à fait cette thèse.
spicos II rend possible un dialogue avec une base de données de bureau. C'est un prolongement de spicos I qui était limité, du point de vue linguistique, à un simple schéma de question/réponse. spicos II s'adapte au locuteur et possède un vocabulaire d'environ 1200 mots. Dans le présent article, nous donnons une vue d'ensemble du traitement linguistique de notre système. Un module de dialogue gère les composants linguistiques. Il contrôle le dialogue et évite, grâce à des questions adéquates, les problèmes de communications entre l'utilisateur et le système. L'analyse syntaxique se base sur une grammaire syntagmatique étendue. Parallèlement, un réseau sémantique vérifie les restrictions sémantiques. Dans le but de construire une représentation logique de la signification de la phrase, la structure syntaxique est utilisée en liaison avec les caractéristiques sémantiques, les résultats de la résolution anaphorique et une représentation formelle des référents du discours. Les présuppositions de l'utilisateur sont analysées et représentées. Ces représentations formelles peuvent être transformées en une interrogation de base de données.
Cette étude traite des effets de la coarticulation sur les fréquences formantiques et sur la durée du schwa hollandais, en syllabe ouverte et fermée, à partir de l'analyse de logatomes de la forme C1əC2V et VC1əC2. Dans ces logatomes, les consonnes C1 et C2 appartenaient au groupe /p, t, k, f, s, χ, m, n, η, r, l, j, ν/, et la voyelle V était l'une des 3 voyelles suivantes /i, a : , u/. Les consonnes et voyelles ont été présentées systématiquement dans toutes les combinaisons possibles, ce qui donnait au total 897 mots expérimentaux lus par 3 locuteurs masculins. Il est apparu que les effets de la coarticulation sur le schwa pourraient être décrits par un simple modèle linéaire. Le modéle s'est révélé particuliérement bien adapté pour le suivi de F 2. Ce modèle pour F 2 a pu aussi être utilisé avec succès pour des mots réels. Nous pensons que le schwa doit être interprété comme une voyelle sans cible d'articulation, complètement assimilée à son contexte phonémique. L'idée largement répandue que les fréquences formantiques des voyelles réduites se déplacent vers une position de schwa au centre du triangle vovalique n'est pas très exacte. Dans notre interprétation, la réduction vocalique provoque un déplacement des fréquences formantiques vers une position de schwa qui peut être presque n'importe où dans l'espace vocalique, en fonction du contexte phonémique.
Le suivi de visage par caméra vidéo est abordé ici sous l'angle de la fusion évidentielle. La méthode proposée repose sur un apprentissage sommaire basé sur une initialisation supervisée. Le formalisme du modèle de croyances transférables est utilisé pour pallier l'incomplétude du modèle a priori de visage due au manque d'exhaustivité de la base d'apprentissage. L'algorithme se décompose en deux étapes. Pour fusionner les sources couleur dépendantes, nous proposons un opérateur de compromis inspiré de la règle prudente de Denœux. Pour la phase de suivi, les probabilités pignistiques issues du modèle de visage garantissent la compatibilité entre les cadres crédibiliste et probabiliste. Elles alimentent un filtre particulaire classique qui permet le suivi du visage en temps réel. Nous analysons l'influence des paramètres du modèle évidentiel sur la qualité du suivi.
Un algorithme récemment proposé pour la détermination de la fréquence fondamentale du signal de parole (Dologlou et Carayannis, Speech Communication, Vol. 8, 1989) utilisait un filtrage passe-bas itératif de phase nulle, suivi de mesures du signal filtré entre deux impulsions d'excitation successives. Le filtrage passe-bas itératif était achevé lorsque le signal avait acquis un profil suffisamment sinusoïdal. Le critère d'arrêt choisi était que les fréquences dérivées d'une analyse d'autocorrélation et d'une analyse LPC de second ordre devaient êntre suffisamment proches l'une de l'autre. Les auteurs affirmaient par ailleurs que, à moins que le signal d'entrée ne soit une sinusoïde pure, les deux fréquences ne devaient jamais être égales. Nous discutons ici de ce critère d'arrð proposé et donnons un exemple concernant un signal proche du signal acoustique de la parole, consistant en deux sinusoïdes d'amplitudes comparables.
Les erreurs ont été analysées en référence à : (i) des paramètres structuraux généraux (longueur des nombres …) ; (ii) des troubles comportementaux généraux (persévérations, perturbations de l'organisation séquentielle …) ; (iii) des stratégies cognitives mises en jeu dans cette activité de transcodage. Cette derniére analyse s'est révélée la plus intéressante ; elle a montré que les erreurs systématiques produites relevaient le plus souvent de la mise en oeuvre dans un contexte où elles ne s'appliquent pas de stratégies de transcodage efficaces dans d'autres situations. Ces résultats recueillis en pathologie du langage peuvent aider à comprendre la nature et l'organisation des processus cognitifs utilisés par les sujets normaux.
Nous proposons un algorithme qui évalue à la fois l'excitation et les paramètres d'un modèle dynamique auto-régressif à moyenne adaptée du signal de parole. Les coefficients du modèle auto-régressif et du modèle à moyenne adaptée sont estimés indépendamment et dans le sens des moindres carrés à l'aide de deux treillis récessifs de processus combinés ; l'excitation à l'entrée est évaluée à l'aide d'une méthode “bootstrap” à partir d'un des deux estimateurs. On montre à partir des estimations expérimentales d'enveloppes spectrales de parole naturelle que l'algorithme proposé évalue correctement les paramètres d'un modèle du signal de parole auto-régressif et à moyenne adaptée lentement variable.
Cet article fournit une nouvelle interprétation du “delta-cepstre” ; il étend sa formulation classique en vue de la détermination optimale des caractéristiques du filtre, qui extrait la dynamique caractéristique importante d'une séquence cepstrale. L'algorithme permettant d'obtenir les nouveaux paramètres est présenté sous une formulation utilisant un filtrage par une matrice de coefficients ; il a été testé par des expériences de reconnaissance de la parole en langue japonaise. L'erreur moyenne de reconnaissance dans une expérience de reconnaissance des 24 phonèmes du japonais sur quatre locuteurs a été ramenée de 12.2% à 10.3%.
La maîtrise d'une maladie animale non réglementée est à l'initiative des éleveurs et est parfois incitée par des organisations professionnelles pour améliorer la situation sanitaire ou économique d'une zone. L'enjeu est donc de pouvoir proposer des outils d'aide à la prise de décision et d'évaluer a priori l'impact des décisions proposées sur la propagation d'un agent pathogène en termes épidémiologiques (prévalence de la maladie) et économiques. Dans cet article, nous évaluons l'apport des processus décisionnels de Markov (MDP). Nous proposons un modèle de propagation intertroupeaux où une action de maîtrise est recommandée par un décideur collectif pour optimiser le coût de la maladie et de sa maîtrise au niveau du groupe. Nous supposons que le décideur collectif connaît la proportion d'éleveurs qui vont suivre sa recommandation. L'utilisation d'un MDP intégrant un modèle épidémiologique permet d'indiquer à chaque pas de temps s'il faut faire une recommandation ou non selon la situation épidémiologique. La stratégie obtenue consiste en des recommandations non systématiques. Bien que l'objectif soit d'optimiser les coûts, la prévalence dans la zone est aussi diminuée. La définition d'une stratégie adaptative est un avantage de notre approche qui permet de proposer des stratégies non classiquement proposées et étudiées.
La parole est normalement entendue sur un fond sonore. Cet article examine les travaux récents sur l'aptitude de l'auditeur à séparer la parole des autres sons. Il est montré que des mécanismes de regroupement de bas niveau et une connaissance spécifique de la parole sont utilisées pour résoudre ce problème difficile.
Avec l'accroisssement des applications significatives de la reconnaissance et de la synthèse de parole, l'activité de notre laboratoire couvre maintenant un champ plus large d'activités, depuis les nouvelles approches algorithmiques jusqu'à l'ingéniérie des produits vocaux et le développement d'applications. Cet article présente un bilan des produits développés à partir de nos recherches en technologies vocales.
Ce papier présente une technique fondée sur les propriétés des fonctions retard de groupe afin d'extraire les formants des signaux de parole. L'algorithme est semblable au lissage cepstral utilisant la déconvolution homomorphique. Les différences significatives sont les suivantes : (a) le logarithme est remplacé par un opérateur () r et (b) les propriétés additive et de haute résolution des fonctions retard sont exploitées pour accentuer les crêtes des formants. La fonction retard de groupe (ou la dérivée négative de la phase de la transformée de Fourier) est dérivée pour un signal qui, à son tour, est dérivé de l'amplitude de la transformée de Fourier du signal. Si une valeur convenable de r est utilisée, cette méthode donne des estimations formantiques très cohérentes comparées à celles obtenues par la technique cepstrale ou par la prédiction linéaire. Les effets de l'exposant r et de la largeur de la fenêtre sur la technique proposée ont été étudiés.
Le problème traité est celui de l'estimation d'un signal perturbé par un bruit additif lorsque l'on dispose de deux observations chacune composée d'un signal et d'un bruit additif. On se place dans le cas où les signaux utiles sur chaque voie sont déduits d'un même signal par filtrage linéaire et les bruits complètement décorrélés. Nous cherchons à évaluer l'apport de la deuxième observation pour une meilleure estimation du signal par rapport au cas où une seule observation est disponible. Le filtrage de Wiener vectoriel ainsi que deux structures sous-optimales dites PIS (Prétraitement + Identification entre Signaux) proposées pour l'amélioration de la parole bruitée sont présentés. Une étude théorique (en supposant optimaux les filtres utilisés) est d'abord menée : ces différents systèmes ainsi que le filtrage de Wiener mono-voie sont comparés entre eux en termes de distorsion, bruit résiduel et erreur globale sur le signal à estimer. Un classement de ces méthodes est donné en fonction des valeurs relatives des rapports signal à bruit sur chaque voie. Nous montrons l'intérêt des deux structures PIS par rapport au filtrage de Wiener mono-voie lorsque le rapport signal à bruit de l'observation sur laquelle est présent le signal à estimer est faible. Après une présentation des différents algorithmes effectivement utilisés dans ie cadre du débruitage de la parole, nous les appliquons à des signaux réels enregistrés dans une voiture. Une comparaison des algorithmes est faite suivant des critères objectifs et des tests d'écoute. Les résultats indiquent une supériorité des deux méthodes PIS par rapport aux filtrages de Wiener mono-voie et bi-voie.
On décrit ici un nouveau système de reconnaissance de parole qui exploite les structures articulatoires multi-dimensionnelles er incorpore des idées-clé de la phonologie auto-segmentale et de la phonologie articulatoire. La nouveauté consiste dans la définition des unités atomiques de la parole afin de pouvoir rendre compte, d'une façon unifiée et économique, des mécanismes de dépendance du contexte observés au niveau acoustique. Au coeur du système de reconnaissance, on trouve une procédure qui a été développée pour convertir automatiquement une observation probabiliste de recouvrement entre cinq dimensions articulatoires en un automate à états-finis qui sert de composant phonologique pour le système de reconnaissance. Le module d'interface phonétique du système, basé sur le modèle de Markov caché à états non-stationnaires est également décrit. On fournit également quelques résultats de reconnaissance phonétique obtenus sur la base de données TIMIT.
La vérification des énoncés (UV) est le processus par lequel la sortie d'un système de reconnaissance est vérifiée pour déterminer si la parole émise inclut réellement le(s) mot(s)-clé. La sortie de ce module de vérification est une décicion binaire d'acceptation ou de rejet de l'énoncé reconnu basée sur le taux de confiance de la vérification. Dans cet article, nous étendons la notion de vérification de l'énoncé en présentant une méthode qui va être utilisée pour trois tâches : (1) détecter les séquences qui ne sont pas des mots-clé (fausses alarmes), (2) détecter les erreurs de substitution sur les mots-clé, et (3) corriger sélectivement les erreurs de substitution quand les N meilleures hypothèses de séquences sont disponibles. La méthode de vérification d'énoncés que nous présentons ici emploie un ensemble de modèles de vérification spécifiques qui sont indépendants des modèles utilisés dans le processus de reconnaissance. Les modèles de vérification sont entraı̂nés en utilisant une procédure d'apprentissage discriminante qui cherche à minimiser l'erreur de vérification en maximisant simultanément le rejet des non-mots-clé reconnus à tort tout en minimisant le rejet des mots-clé correctement reconnus. La correction d'erreur est obtenue en ré-ordonnant les hypothèses produites par le système de reconnaissance N-best basé sur un score de confiance UV.
Dans le cadre des travaux sur la détection des pathologies laryngées par analyses acoustiques, plusieurs traits acoustiques ont été proposés. L'évaluation de leur pouvoir discriminatif a été effectuée, soit par des méthodes statistiques classiques, soit par inspection visuelle. A notre connaissance, la performance discriminative d'un ensemble d'attributs acoustiques a toujours été évalueée en se référent explicitement à un modèle de décision. Par ailleurs, tout laisse supposer que les distributions soushacentes à l'espace des traits sont multimodales. En vue d'évaluer quantitativement et sans référence à un modèle statistique, le pouvoir de séparation de ces traits, nous effectuons une analyse typologique sur un ensemble de six attributs. Les calculs sont établis à partir du signal acoustique associé à la voyelle stable /a/, prononcée par 37 locuteurs normaux et 24 locuteurs dysphoniques. Les résultats de l'analyse confirment les bonnes performances des indices de perturbation de la périodicité (en durée et en amplitude). Par contre, les attributs propes au signal résiduel ne font preuve que d'un faible pouvoir de séparation.
Dans cet article, nous proposons un modèle hybride MLP/HMM dans lequel les vecteurs d'entrée sont transformés par des prédicteurs non-linéaires basés sur les perceptrons multi-couches (MLPs) affectés à chaqueé tat d'un modèle de Markov caché (HMM). Les vecteurs d'erreur de prédiction sur les états sont modélisés par des mélanges de densités gaussiennes. L'utilisation d'un modèle hybride est motivée par le besoin de modéliser les erreurs de prédiction résultant du modèle neuronal de prédiction classique (NPM) : celles-ci varient en fonction des différents contextes et de l'identité du locuteur. Le modèle hybride MLP/HMM présente deux avantages : la corrélation entre les trames du signal d'entrée est exploitée par les prédicteurs MLP, et la variabilité de l'erreur de prédiction est explicitement modélisée. Nous présentons les algorithmes d'apprentissage basés sur un critère de maximum de vraisemblance (ML) et sur un critère discriminant de minimisation de l'erreur de classification. Des expériences de reconnaissance de parole continue en mode indépendant du locuteur onté té menées. Avec un apprentissage ML du modèle hybride, nous avons obtenu des performances nettement supérieures á celles obtenues avec un NPM classique ne modélisant pas explicitement l'erreur de prédiction. Avec un apprentissage utilisant le critère de discrimination, la confusion entre modèles différents était réduite de façon significative et le taux d'erreur sur les mots était réduit de 56% par rapport á celui obtenu avec un apprentissage ML.
Dans cet article, nous nous intéressons à la détection d'objets dans des scènes complexes, par des méthodes basées sur des modèles statistiques d'apparence globale. L'approche proposée associe, dans un cadre bayésien, une représentation standard des images d'apprentissage par espace propre à des modèles de bruit et à des modèles a priori non gaussiens. Ce modèle permet d'unifier les méthodes de détection classiques rencontrées dans la littérature et conduit, de façon naturelle, à la définition d'une nouvelle classe de détecteurs statistiques, intégrant des modèles de distribution quelconque pour les images d'apprentissage. La comparaison des caractéristiques opérationnelles des récepteurs (courbes COR) sur des bases de données communes, illustre les contributions de l'approche bayésienne. Elle montre également que l'adoption de modèles non gaussiens permet de dépasser significativement les performances des algorithmes faisant actuellement référence dans le domaine [2, 14].
Nous présentons un paradigme pour la reconnaissance de la parole basé sur un réseau d'activités d'analyse à profondeur variable. Le paradigme produit des descriptions des propriétés du signal de parole qui sont liées aux unités phonétiques au travers de modéles de Markov. Des résultats en reconnaisance indépendante du locuteur de chiffres et lettres isolés sont présentés.
Ce papier présente un travail sur la comparaison entre un modèle utilisateur et le comportement réel de l'utilisateur reposant sur trois prémisses : 1) tout système interagissant avec un utilisateur possède un modèle de celui-ci ; 2) la représentation externe des utilisateurs dépend de l'utilisation qui est faite du système par l'utilisateur ; 3) connaître le type d'utilisation du système dépend du contexte dans lequel la tâche doit être exécutée. L'explicitation du contexte en vue de son utilisation conduit à utiliser les graphes contextuels pour capturer les comportements effectifs des utilisateurs dans une activité de recherche d'information sur un site web scientifique. Cette approche permet de composer avec un système capable d'acquérir de manière incrémentale de nouvelles connaissances de l'utilisateur, et ainsi apprendre de nouvelles pratiques développées par les utilisateurs quand il est en échec.
Ainsi qui'il est bien connu, la plupart des mal-entendants perçoivent une quantité natable d'information verbale grâce à la lecture aux lèvres. Notre article présente quelques résultats d'une analyse structurale des contours labiaux de plusieurs locuteurs ayant articulé différentes voyellesisolées. Notre méthode est basée sur l'analyse de Fourier des fonctions de contours. Une telle analyse est d'une grand intérêt par rapport à la génération artificielle èt à la reconnaissance en temps réel de schemes de parole visible.
Les théries psychologiques de traitement des langues naturelles ont habituellement supposé que le processeur de phrases résolvait les ambiguités syntaxiques locales en sélectionnant une seule analyse sur la base de critéres structurels comme le principe de l'“attachement minimal” de Frazier (1978). D'après ces théories, les analyses alternatives seront seulement envisagées si l'analyse initiale se révèle être inconsistante avec le contexte. (voir aussi Ferreira & Clifton, 1986 ; Ford, Bresnan, & Kaplan, 1982 ; Rayner, Carlson, & Frazier, 1983). Cependant, une autre hypothèse est possible : si les phrases sont comprises de façon progressive, plus ou moins mot à mot (Marlsen-Wilson 1973, 1975), alors le traitement syntaxique peut en principe exploiter le fait que les interprétations sont disponibles, et les utiliser de façon “interactive” pour sélectionner parmis les différentes analyses syntaxiques en fonction de leur plausibilité par rapport au contexte. Cet article considère les architectures possibles pour de tels processeurs de phrases interactifs et progressifs, et argumente en faveur d'une architecture telle que les différentes analyses sont offertes en parallèle, et sont distinguées par un appel immédiat au processus de compréhension, selon une interaction sélective ou “faible”, par opposition à l'interaction directive ou “forte”. Nous notons qu'une telle architecture ne compromet en aucune façon l'hypothése de modularité de Fodor (1983). Nous faisons la revue les données expérimentales présentées comme suggérant que le système de traitement des phrases humain était non-interactif et reposait sur des critères purement structurels. Nous présentons de nouveaux résultats qui semblent incompatibles avec la proposition structurelle, et qui soutiennent l'hypothèse interactive. Nous suggérons des raisons qui permettent d'écarter les résultats contraires obtenus auparavant, et concluons que le mécanisme de traitement des phrases humain résoud les ambiguités de type modifieur-attachment en ayant recours á des informations contextuelles et réferentielles de plus haut niveau sous l'intéraction faible.
Ce papier commence par décrire les nouvelles directions d'applications aux télécommunications de la reconnaissance automatique de la parole et de la synthèse vocale à partir du texte au Japon. Les applications de la reconnaissance automatique de la parole se focalisent sur les services publics tels que l'automatisation du travail des opérateurs, l'assistance aux opérateurs, la commande vocale des serveurs d'information, et la numérotation vocale. Les applications majeures de la synthèse vocale incluent les services d'information par la voix et la lecture des messages électroniques (e-mail). On estime que l'utilisation de la reconnaissance de la parole et de la synthèse vocale à partir du texte va fortement augmenter dans un avenir proche avec la pénétration des terminaux téléphoniques mobiles et des portables, en particulier dans des domaines comme la diffusion de textes et la communication numérique. Deuxièmement, ce papier décrit le paramètrage expérimental du système vocal interactif de NTT qui comporte (1) une reconnaissance de la parole hautement performante en mode indépendant du locuteur et grand vocabulaire, basée sur une modélisation par HMM des phonèmes en contexte dont les paramètres sont appris sur des données parole provenant de plus de 10 000 locuteurs et collectées à travers le réseau téléphonique, (2) une synthèse de parole à partir du texte de haute qualité qui génère de la parole en concaténant des segments de signal représentant des triphones, (3) une configuration logicielle qui ne demande aucune architecture matérielle spécifique autre qu'un PC équipé d'une carte son et d'un modem vocal, (4) un prototypage facile et rapide qui permet à l'utilisateur de construire un système en écrivant certains types de scénarios du service.
Dans cet article, une classe générale de filtres adaptatifs non linéaires basés sur des réseaux de neurones artificiels (ANN) à simple couche cachée et unidirectionnels est proposée pour le traitement de signaux limités en fréquence dans une approche de rehaussement du signal basée sur une méthode multi-microphone et adaptative en sous-bandes. Les premiers résultats comparatifs obtenus en utilisant des données automobiles réverbérantes réelles et simulées montrent que le système de rehaussement de la parole proposé utilisant le traitement ANN en sous-bande est capable de surpasser les méthodes plus conventionnelles d'annulation de bruit.
L'article est consacré au problème de la sélection d'indices pour la reconnaissance automatique de la parole. La comparaison des indices a été effectuée sur base d'un modèle de reconnaissance de mots isolés par mise en correspondance avec des patrons de référence. Les expériences ont été basées sur des chiffres en serbo-croate prononcés par 109 locuteurs. Le taux de reconnaissance a été établi pour chaque ensemble d'indices. Le taux et le type d'erreurs commises ont été mis en rapport avec le vocabulaire-test.
Les techniques de planification sous incertitudes sont difficiles à appliquer à des problèmes de robotique autonome : l'effort de modélisation est parfois pénible voire rédhibitoire lorsque l'espace d'états est très grand. Les représentations factorisées, basées sur des variables d'état, sont plus compactes, mais elles gèrent mal les variables qui ont un grand nombre de valeurs possibles, comme par exemple les variables de localisation du robot. Les problèmes de recherche et sauvetage de personnes en danger combinent ces variables et celles de mission. Nous proposons un modèle abstrait hiérarchique pour simplifier la phase de modélisation des problèmes de planification en robotique sous incertitude des actions. Un algorithme ins- tancie automatiquement notre modèle abstrait, que nous présentons et évaluons sur plusieurs instances de problèmes de recherche et sauvetage par un drone hélicoptère autonome.
Nous explorons dans cet article l'utilisation de moindres généralisés corrects comme apprenant dans des techniques de boosting (Freund et al., 1996). Les premières expérimentations sur des problèmes classiques montrent qu'ADABOOST instancié avec un apprenant à base de moindres généralisés obtient des taux d'erreur plus faibles que C4.5, GLOBO (Torre, 1999) et ADABOOST muni d'un apprenant plus classique.
Cet article étudie la réalité psychologique des traits distinctifs. Vu l'approche non-cognitive des linguistes et l'approche concrète des phonéticiens, il n'est pas du tout clair si la représentation psycholinguistique emprunte aux deux, à l'une des deux ou à aueune de ces disciplines. Une divergence d'opinion entre phonéticiens et linguistes sur un cas permet d'éclaircir ce problème. Alors que les premiers considèrent [f] et [v] comme des fricatives labio-dentaled, les derniers les traitent en tant que pronènems bilabauz au niveau sous-jacent. Dans le but de vérifier si [f] et [v[se comportent comme des consonnes bilabiales ou labio-dentales du point de vue psychololinguistique, une analyse des interactions entre ces fricatives et les autres phonèmes dans deux corpus importants de lapsus anglais et allemands a été effectuée. Les résultats inoiquent que [f] et [v] ne different pas des consonnes bilabiales, c'est-à-dire qu'ils se substituent aux autres consonnes autant que [p], [m] ou [w]. Trois hypothèses pourraient rendre compte de ce résultat. Selon l'hypothèse de labialité et celle de bilabialité, il n'y a pas de noeud labio-dental dans le réseau mental. L'alternative part de l'hypothèse que les traits distinctifs sont représentés par des vecteurs dans un système spatial de coordonnées. Ce modèle comprent un vecteur pour la bilabialité ainsi qu'un autre pour la labio-dentalité. Nous proposons que ces vecteurs soient plus rapprochés l'un de l'autre que ne le suggère la distance phonétique réelle. Il y a moins de support pour l'hypothèse de vecteur que pour celle de bilabialité. Les données empiriques mettent en évidence que la représentation des traits phonétiques ne correspond pas nécessairement à celle des traits psycholinguistiques.
Les techniques d'alignement temporel (DTW) et de Quantification Vectorielle (VQ) ont été appliquées avec un grand succès au problème de la vérification du locuteur. Il est d'usage courant de les utiliser pour calculer une mesure unique de distance, avant de seuiller cette mesure pour prendre une décision de vérification. Dans cet article, nous examinons l'application d'une pondération statistique à un certain nombre de paramètres calculés à partir du chemin d'alignement DTW et des mécanismes de décision de la VQ. On présente des résultats qui montrent que l'extraction de ces paramètres supplémentaires permet de prendre en compte des informations complémentaires sur le locuteur et peuvent être utiles pour améliorer les performances des systèmes classiques de vérification. On a également étudié l'effet d'une normalisation de la mesure de distance, ce qui revient à comparer les scores DTW et VQ entre le locuteur dont l'identité est à vérifier et les autres locuteurs. Les résultats de la méthode de base et de ces améliorations sur les algorithmes DTW et VQ sont estimés sur une population de 42 locuteurs.
Cet article traite du problème de la modélisation de la parole pour la génération de parole sous stress en utilisant le cadre “source generator framework”. D'une manière générale, le terme stress dans ce contexte se rapporte à la condition du locuteur qui peut être émotionnelle ou induite par une tâche spécifique. Dans cette étude, l'accent est mis sur la parole criée ou produite dans des conditions de colère ou d'effet Lombard. A l'origine, la théorie de génération de source a été développée pour l'égalisation de la parole sous stress afin d'effectuer une reconnaissance robuste (Hansen, 1993, 1994). Elle a été ensuite utilisée pour la génération d'occurrences d'apprentissage avec un stress simulé (Bou-Ghazale, 1993 ; Bou-Ghazale and Hansen, 1994). L'objectif de ce travail est de générer de la parole sous stress à partir de parole normale, en utilisant un “source generator framework” préalablement utilisé pour la reconnaissance de parole sous stress. L'approche est basée sur (i) le développement d'un modèle mathématique représentant l'effet du stress sur la production de la parole, et (ii) l'utilisation de cette modélisation pour produire les effets du stress et des émotions sur des mots isolés prononcés en parole naturele. L'algorithme de perturbation simulant les effets du stress est basé sur la structure de synthèse de parole par CELP (“code-excited linear prediction”). Cet algorithme a été évalué sur quatre ensembles de paramètres exprimant la perturbation dans la parole. Les évaluations effectuées dans cette étude montrent que le pitch est capable de refléter l'état émotionnel du locuteur, alors que l'information sur les formants n'est pas aussi bien corrélée au stress. Néanmoins, dans le cadre d'une modélisation CELP de la parole, c'est la combinaison de la localisation des formants, du pitch et de l'énergie qui produit l'indicateur le plus fiable du stress émotionnel. Les résultats des évaluations, basées sur l'écoute de parole sous stress générée par le système, montrent des taux de classification correcte de 87% pour la parole produite avec l'effet de la colère, 75% pour la parole avec l'effet Lombard et 92% pour la parole criée.
Il existe une importante littérature traitant du problème de la conception d'un quantificateur pour un système de détection ou de classification. A l'origine, les travaux menés dans ce domaine - notamment par Kassam, Poor, Picinbono et Bucklew - ont pour but de concevoir un quantificateur qui optimise une règle de décision basée sur l'information quantifiée. Rompant avec cette approche classique, ces dernières années ont vu l'émergence d'une approche alternative dont l'objectif est d'optimiser conjointement les opérations de quantification et de classification. Dans cet article, nous proposons de comparer l'approche conjointe à l'approche classique, plus courante, de Picinbono et Duvaut.
Cet article présente MAS4AT, un système multi-agent coopératif et auto-adaptatif pour le déclenchement d'alertes lors de la détection de comportements suspects dans le cadre de la surveillance maritime. Ce système est conçu et développé dans le cadre du projet européen I2C qui vise à mettre en oeuvre une nouvelle génération de systèmes de surveillance maritime, capables d'aider les opérateurs humains (i) à identifier les comportements anormaux de navires, (ii) à évaluer la suspicion associée à ces comportements et (iii) à déclencher des alertes s'ils représentent des menaces. Cet article introduit le projet I2C puis se consacre plus particulièrement à la présentation de MAS4AT et à ses capacités d'apprentissage par renforcement.
Une série d'expériences a été réalisée pour déterminer comment la durée d'un mot prononcé dans une phrase est influencée 1) par la catégorie grammaticale à laquelle ce mot appartient et 2) par la position de ce mot dans un constituant. Dans l'expérience I des homophones Nom-Verbes (ex., “I saw the coach” — Nom (J'ai un rôti) “I saw him coach” — Verbe (je l'ai rôti)) sont présentés dans des phrases dont on a appareillé le contexte phonétique et le schéma d'accentuation. Les résultats indiquent que les noms sont plus longs que les verbes dans des phrases typiques. Les résultats des expériences II et III appuient une interprétation liant l'allongement à la position terminale du constituant et élimine l'effet dû à un emplacement ou l'effacement serait possible. Les résultats de l'expérience IV étendent l'interprétation donnée pour l'allongement du constituant final des Noms et Verbes à deux catégories supplémentaires s'appuyant sur la comparaison de la durée de l'adjectif du syntagme initial two (deux) et de l'adverbe du syntagme too (aussi). Enfin l'expérience V teste la distinction entre catégories mineures et majeures. Les résultats montrent que la préposition to (à) est à 50% plus courte que l'adjectif two (deux). En prenant l'ensemble des résultats on voit qu'il suffit d'une distinction binaire entre les catégories majeures et mineures pour ce que demande une théorie de la mesure temporelle de la parole et de sa synthèse. On peut rendre compte de durée traditionnellement attribuée aux différences entre les classes de catégories majeures en termes de frontières de constituants déjà requise dans une théorie qui rend compte de trois autres classes de phénomènes.
Le problème de l'extraction de la voix chantée dans des enregistrements musicaux monophoniques, c'est-à-dire la séparation voix / musique avec un seul capteur, est étudié. Les approches utilisées sont basées sur des modèles statistiques a priori des deux sources (musique et voix), notamment sur des Modèles de Mélange de Gaussiennes (MMG). Une méthode d'adaptation des modèles aux caractéristiques des sources mélangées est proposée, et une étude comparative des différents modèles et estimateurs est effectuée. Les résultats montrent que l'adaptation du modèle de musique sur les parties non-vocales des chansons permet d'obtenir de bonnes performances dans un cadre réaliste.
Différents critères de sélection sont étudiés. Le critère de la Fréquence d'occurrence choisit les k transcriptions les plus fréquentes dans l'ensemble des décodages phonétiques du mot, alors que le critère du Maximum de Vraisemblance choisit les k transcriptions les plus vraisemblables dans cet ensemble. Avec les deux critres k est le même quelque soit le mot, et chacune des k transcriptions “décrit” toutes les occurrences du mot sans exception. Ensuite, une procédure de partitionnement permettant de déterminer le nombre “optimal” de transcriptions pour chaque mot est développée et évaluée. Cette procédure part du principe que dans l'ensemble de transcriptions sélectionnées, chaque transcription doit “décrire” une partie des prononciations du mot. Le but est donc de trouver les “bonnes” transcriptions et d'associer chacune d'elles à un sous-ensemble de prononciations. Deux algorithmes itératifs sont développés et évalués, et un compromis est recherché entre vraisemblance et nombre d'éléments de l'ensemble à déterminer. Les expériences menées en reconnaissance indépendante du locuteur ont montré la supériorité du critère du Maximum de vraisemblance par rapport au critère de la Fréquence d'occurrence.
Cette étude propose une nouvelle méthode de prédiction, la Prédiction Linéaire Séparée (PLS), pour l'analyse spectrale de la parole. La valeur x(n) prédite pour le signal est calculée à partir des p + 1 échantillons précédents, en privilégiant, parmi les échantillons précédents, celui qui est situé immédiatement avant l'échantillon x(n). Les p échantillons x(n − 2) àx(n − (p + 1)) sont extrapolés linéairement à l'aide de x(n − 1) pour obtenir p nouvelles valeurs, qu'on utilise pour la prédiction. L'optimisation des coefficients de filtrage est calculée au moyen du critère d'autocorrélation, comme dans la prédiction linéaire conventionnelle. La Prédiction Linéaire Séparée donne un filtre à pôles seuls d'ordre p + 1 avec p inconnues dans les équations normales. La précision de la Prédiction Linéaire Séparée a été comparée à celle de la prédiction linéaire conventionnelle, en analysant les voyelles produites par deux femmes et quatre hommes. Les résultats montrent que la méthode que nous préconisons donne en général une modélisation plus précise des formants supérieurs, et des résiduels de plus faible énergie et plus plats.
Pendant un dialogue semi-spontané, les sujets étaient obligés de répéter la même correction d'un chiffre dans une série de trois chiffres qui se compose de “five” ou “nine” suivi de “Pine Street”. Les signaux articulatoires et acoustiques de quatre parleurs de l'anglais américain général furent enregistrés par la X-ray Microbeam (la radiographie au micro-faisceau) de l'Université de Wisconsin. En faisant l'analyse des movements de la mâchoire, les valeurs de magnitude et réglage syllabique étaient evalués pour inférer un enchaı̂nement linéaire des pouls syllabiques pour représanter l'organisation rythmique de la énonciation. Les résultats préliminaires suggérent non seul que la magnitude de la syllabe corrigée augmente par la correction du chiffre, mais aussi qu'il y a en plusieurs cas quelque augmentation systématique de la magnitude de la syllabe, à la fois pour le chiffre corrigé et pour les autres chiffres de la même énonciation, quand la même correction est répétée. La variation considérable parmi les parleurs est observée et discutée sou forme de la magnitude syllabique et les modèles de réglage.
La communauté scientifique de visualisation d'information possède des solutions pour la navigation au sein des bases de connaissances. L'objet usuel de ces actions de visualisation et de navigation est celui des graphes. L'objectif de notre démarche est de comparer des techniques d'affichage et de manipulation de graphes sur l'apport cognitif quelles procurent aux utilisateurs. Nous avons développé un graphe (3 000 nœuds, 10 000 arêtes), portant sur des noms communs. Cette structure est déclinée selon trois modes d'affichage : deux modes graphiques (coloré et monochrome), et un mode textuel (par hyperliens). Ce matériel est proposé à des utilisateurs pour une étude expérimentale de leurs préférences et performances sur des tâches de navigation dirigée (recherche de chemins dans un graphe). Si les utilisateurs préfèrent naviguer sur un affichage graphique coloré, leurs performances (en temps et actions), ne sont pas significativement meilleures dans ce mode. Il en ressort qu 'une combinaison de deux modes d'affichage serait une solution intéressante : une représentation globale et graphique de la structure manipulée, couplée avec une représentation locale, textuelle et plus détaillée de la zone d'intérêt de cette même structure.
L'utilisation de la couleur en vision par ordinateur est un sujet de recherche qui suscite un intérêt croissant. Ce papier fait le point dans ce domaine, en essayant de répondre aux questions : Qu'est-ce que la couleur ? Quelles en sont les représentations adéquates ? Comment la déterminer ? Que peut-on en faire ? Pour cela, nous faisons une revue approfondie et très à jour de l'ensemble de la littérature consacrée à ce sujet en cernant les axes de recherche et les problématiques importantes et en tentant de les évaluer.
Cet article présente un algorithme d'autocalibration d'une antenne multicapteur. Cet algorithme permet d'estimer le gain et la phase des capteurs, dont la connaissance précise est nécessaire pour localiser les sources en présence. L'originalité de notre approche réside dans la prise en compte de la non circularité des sources. L'exploitation de cette caractéristique permet d'augmenter la dimension de l'espace des observations, et de localiser des sources en nombre supérieur à celui des capteurs. Des simulations montrent que la performance de cet algorithme en terme de rapidité de convergence et de précision des estimations est satisfaisante.
Cet article présente une méthode de segmentation et de classification phonétique primaire de la parole continue.
Dans ce papier, nous présentons une approche générique pour le développement de moteurs de reconnaissance de symboles manuscrits en ligne. Nous présentons en détail notre approche et faisons le lien avec d'une part les modèles de Markov hiérarchiques et d'autre part les réseaux bayésiens dynamiques. Nous évaluons ensuite les propriétés fondamentales de notre approche qui lui confèrent une grande flexibilité. Puis nous montrons que l'on peut, avec cette approche générique, concevoir aussi bien des systèmes omni-scripteur rivalisant avec les meilleurs systèmes actuels sur des caractères alphanumériques usuels, que des systèmes mono-scripteur pour des symboles graphiques quelconques, nécessitant très peu d'exemples d'apprentissage et peu gourmands en ressources machine.
Si les règles naturelles de la phonologie, comme par exemple celle qui efface une consonne finale devant une consonne initiale, sont fréquentes dans les langages non structurés, ce doit être parce que ces règles concernent les traits universaux de production et/ou de perception du langage. La présente expérience a pour but de voir, à partir d'une tâche d'apprentissage, si des sujets na ïfs ont davantage tendance à utiliser une règle naturelle que la réciproque (effacement de la consonne devant une voyelle). On doit ensuite combiner avec chacun des quatre noms trois adjectifs nouveaux, pour l'un des groupes de sujets suivant la règle naturelle, pour l'autre siuvant la règle non-naturelle. Les sujets ayant appris le corpus non-naturel ont tendance à donner des réponses naturelles alors que la réciproque n'est pas vraie. En conséquence ces sujets font, au cours de la tâche, beaucoup plus d'erreurs que les autres même si la régle opératoire leur est donnée au premier essai par une présentation systématique de chaque adjectif siuvi des quatre noms correspondants. Même si un tel processus n'a pas un rôle signiticatif en anglais, il semble que nos sujets ont une connaissance implicite de la régle naturelle.
Ce papier porte sur la modélisation de séries temporelles ou de régression à l'aide de réseaux de neurones. En nous appuyant sur des résultats récents sur l'estimation des moindres carrés pour les séries temporelles non linéaires, nous proposons une méthodologie complète et explicite pour l'estimation des paramètres (processus d'apprentissage) et pour le choix du modèle (sélection d'architecture). En particulier, nous donnons une solution au problème de l'élagage dans un perceptron multicouches au moyen d'une méthode pas à pas utilisant un critère de type BIC dont on démontre la consistance.
Dans ce papier, nous présentons une approche de reconnaissance du locuteur basée sur une projection spécifique à chaque utilisateur. Cette projection est réalisée au moyen d'un réseau de neurones multi-couches. Le but de la projection est de capturer les informations spécifiques au locuteur en transformant un ensemble de paramètres représentant l'information linguistique en un ensemble de paramètres caractérisant l'information linguistique ainsi que l'information propre au locuteur. Dans cette étude, les paramètres les plus appropriés pour faire cette tranformation sont également évalués. On montre aussi que la normalisation des scores, ainsi que l'utilisation du critère d'erreur du réseau de neurone pour la sélection des vecteurs acoustiques, augmentent les performances du système. Nous montrons également que le fait de laisser tomber les composantes haute fréquence du signal résulte en une déterioration des performances du système. Sur un ensemble de 630 locuteurs de la base de données TIMIT, un égal taux d'erreur de 0.5% et 100% d'identification sont obtenus par l'approche proposée ici. Sur un ensemble de 38 locuteurs de la région dialectale “dr1” de la base de données NTIMIT, un égal taux d'erreur de 6.6% est obtenu.
Le système utilise des diphones produits par un circuit intégré de synthétiseru à formant. Une notation semi-phonétique pour l'entrée du message dans le système. Des contours d'intonation utilisant une ligne de déclinaison et diverses montées et chutes sont générés à partir des signés à partir des signes de ponctuation et d'accentuation que comporte le message d'entrée. Un appareil autonome, portable et de faible encombrement a été conçu. Une rapide évaluation du système a été menée avec des utilisateurs potentiels.
Cette introduction passe en revue des développements récents dont la connaissance est indispensable pour comprendre la recherche actuelle sur l'acquisition de la lecture. L'accent est mis sur les rapports entre l'étude de la performance adulte, celle des effets des lésions neurologiques et celle du développement de la lecture. Le problème central de ces recherches est d'identifier les causes des difficultés spécifiques auxquelles semble se heurter l'acquisition de la lecture. En général, ce problème a été abordé par des méthodes correlationnelles, fondées sur la comparaison des performances des bons et des mauvais lecteurs. Les mérites et les défauts de cette approache sont discutés, et on insiste sur le besoin de rattacher les études différentielles à une conception théorique générale de processus de lecture et de son développement. On examine le courant d'études issu de l'hypothèse selon laquelle une des difficultés majeures de l'acquisition de la lecture alphabétique réside dans la manipulation du language au niveau des segments phonémiques, et on discute la manière dont les résultats de ces études peuvent être reliés aux théories actuelles de l'accès lexical. Les limites de l'approche qui consiste à tirer des hypothèses sur le développement à partir de théories relatives au stade adulte sont décrites et illustrées par des données sur la performance d'enfants normaux et dyslexiques. Enfin, on discute la possibilité que les difficultés d'acquisition de la lecture trouvent leur source à des niveaux supérieurs à celui de la reconnaissance des mots.
Cet article présente une nouvelle approche de la reconnaissance des mots parlés. Nous discutoon d'abord les exigences à satisfaire par les unités linguistiques appropriées, ensuite nous exposons quelques résultats obtenus lors de l'utilisation de superensembles de phones pour la reconnaissance de mots. Finalement, nous développons sur la base d'indices phonétiques binaires des techniques de classification robuste, de segmentation et d'accès lexical.
Dans les conversations de personne à personne, les locuteurs adaptent continuellement les aspects prosodiques et structurels de leur parole aux besoins perçus de leurs auditeurs, tant en fonction de leur évaluation des effets de masquage potentiel dus aux bruits transitoires ou ambiants qu'en réponse à des requêtes explicites de répétition de la part de leurs auditeurs. Des stratégies d'adaptation à la répétition mettent en oeuvre un changement de certaines caractéristiques prosodiques de la parole, tels que le registre et la moyenne de la hauteur de la voix, l'intensité moyenne et le tempo général de la parole, ainsi qu'une restructuration de l'intonation. De telles répétitions font usage de stratégies de redémarrage basées sur des connaissances structurelles linguistiques.
Les réseaux bayésiens sont des outils privilégiés pour les problèmes de diagnostic. Nous dressons dans cet article un panorama des algorithmes utilisés classiquement pour la mise en œuvre des réseaux bayésiens dans le cadre du diagnostic, et plus particulièrement du diagnostic médical. Pour cela, nous passons en revue un certain nombre de questions méthodologiques concernant le choix de la représentation des densités de probabilité (faut-il discrétiser les variables continues ? utiliser un modèle gaussien ?) et surtout la détermination de la structure du réseau bayésien (faut-il utiliser un réseau naïf ou essayer d'apprendre une meilleure structure à l'aide d'un expert ou de données ?). Une étude de cas concernant le diagnostic de cancer de la thyroïde nous permettra d'illustrer une partie de ces interrogations et des solutions proposées.
La tendance récente à utiliser des méthodes basées sur des harmoniques/sinusoïdes exploitant la structure fine de la parole voisée est évidente. Cet article discute le stade actuel des connaissances dans ce domaine sous le point de vue des méthodes d'analyse-synthèse et aussi de applications au codage. Ses aspects principaux en sont : • - Le modèle harmonique est un outil très efficace pour les régions voisées : il produit de la parole synthétique de très haute qualité mais il est aussi perméable aux erreurs de pitch et de décision voisé-non-voisé. Le plus grand désavantage du codage harmonique provient de ce qu'il nécessite une méthode alternative pour traiter les régions non voisées. ATC est l'option naturelle. Nous présentons une simulation à 8 kbit/s, qui utilise une commutation rigide entre codage harmonique et ATC. • - Le modèle par sinusoïdes, en levant la restriction sur la relation harmonique entre sinusoïdes, étend le cadre d'analyse-problèmes aux régions non voisées et de transition. En ce qui concerne le codage il y a, néanmoins, encore beaucoup de problèmes à résoudre. Quelques indications pour une recherche future sont discutées.
Le travail décrit dans cet article a été réalisé au sein du projet SPEAK ! (génération de la parole dans les systèmes informatiques multimodaux). Le projet avait pour but l'amélioration de la qualité de la parole synthétique devant être utilisée, dans des systèmes de dialogue homme-machine, comme un module additionnel d'interface multimodale. L'analyse de l'interaction du texte et du dialogue en allemand (partie théorique de cette recherche) a permis d'établir la prédiction du groupe tonal (TG), des frontières du syntagme à l'intérieur de la phrase et de la place du focus dans le syntagme. Les groupes tonaux représentent la structure générale de l'intonation du syntagme lorsque le niveau de l'intonation du mot n'est pas pris en compte. Les résultats de cette étude sont les marqueurs de l'intonation décrits dans (Teich et al., 1997). Le synthétiseur CTS construit les principaux patrons intonatifs à partir du texte étiqueté par ces marqueurs additionnels. Cet article décrit, pour le système MULTIVOX-SPEAK !, les résultats des travaux sur l'intonation de l'allemand et l'établissement des règles intonatives ainsi que sur l'organisation temporelle et de la génération des pauses (aux niveaux segmentai et suprasegmental), importantes pour le rythme. Nous présentons également les règles détaillées ainsi qu'un nouveau module de génération de la prosodie (basé sur le groupe tonal) qui ont été intégrés au système MULTIVOX TTS. Les résultats préliminaires de l'évaluation sont présentés.
Le système de règles est construit au fur et à mesure en tenant compte des constraintes phonotactiques implicites de l'italien. Le système est organisé conformément au modèle mathématique des automates finis, qui a été généralisé et complété afin d'obtenir un schéma simple de traduction syntaxiquement orienté. Aucune information supplémentaire relative à leur appartenance à une classe grammaticale n'est donnée. Enfin, nous discutons les avantages et désavantages d'une approche faisant appel à la théorie mathématique des graphes ainsi que les développements futurs possibles.
On décrit un algorithme qui transforme des paramètres acoustiques du signal de parole en éléments abstraits permettant de transcrire automatiquement l'accent de phrase et les mouvements intonatifs. Les paramètres acoustiques utilisés sont la durée, l'énergie et la fréquence fondamentale. Les traits abstraits qui en sont dérivés visent à isoler, au sein de ces paramètres, les variations prosodiquement imposées. On présente une méthode de syllabification à partir des paramètres acoustiques. La prominence de chaque syllabe est déterminée de façon automatique et la transcription résultante est comparée à une transcription manuelle. Le taux de concordance de 61.6% suggère que l'étiqueteur humain utilise probablement d'autres paramètres que ceux pris en compte par l'algorithme.
La performance des systèmes de reconnaissance se trouve dégradée de manière significative en présence de bruit. Pour résoudre ce problème lié au bruit, il est nécessaire de reconsidèrer les approaches classiques en prenant en compte cette nouvelle contrainte. Nous envisageons, en premier lieu, deux représentations cepstrales (paramétriques et nonparamétrique) du signal de parole et proposons une vision unifiée de ces deux schémas. Nous introduisons un domaine de pseudo-autocorrelation qui peut être interprété comme un domaine “Root cepstral”, et nous montrons comment l'analyse cepstrale non-paramétrique et l'analyse par prédiction linéaire convergent vers la même solution optimale. Les expériences sont developpées, utilisant un système de reconnaissance de mots isolés mono- et multilocuteur dans un environnement de bruit voiture.
Bien que la langue tamoule possède une longue tradition de description « grammaticale » , qui remonte à la première moitié du premier millénaire de notre ère, avec une acception large de « grammatical » , qui inclut la poétique et la métrique, dans un champ où sont présentes la phonétique, la morphologie et la syntaxe, cette langue a été décrite, à nouveaux frais, et dans une nouvelle perspective (qui incluait l'enseignement de la langue courante), à partir du xvi e siècle, par des missionnaires chrétiens, qui apportaient avec eux un modèle latin de description grammaticale, qu'ils tentaient d'adapter, de façon créative, à une réalité linguistique qui était pour eux nouvelle. Pour cette raison, il sera ici fait référence au corpus de leurs productions comme étant celui des Grammatici Tamulici, bien que les premiers d'entre eux aient utilisé le Portugais comme métalangue pour décrire le tamoul. Ne se trouvant pas dans la situation de certains linguistes de terrain, confrontés à une langue qui n'a jamais été écrite, ces missionnaires se rendirent progressivement compte du fait que le syllabaire tamoul était un outil beaucoup plus efficace pour noter les sons et les mots tamouls que l'alphabet latin, même enrichi par les extensions développées pour la notation de langues européennes diverses. Ils découvrirent aussi que leur capacité de convaincre et de convertir dépendait en grande partie de leur adoption des hiérarchies langagières qui gouvernaient (et gouvernent toujours) la diglossie tamoule, comme nous le verrons dans cette exploration préliminaire, qui couvre cinq auteurs, actifs pendant une période qui va jusqu'à 1739.
Différentes règles du type plus proche voisin sont d'usage courant dans les applications des méthodes de reconnaissance de formes. Dans cet article, des variantes de ces algorithmes sont utilisées pour reconnaître des mots isolés indépendants du locuteur afin de sélectionner les mots-références. On montre que cette approache améliore le taux de reconnaissance par rapport à celui obtenu par une analyse typologique, avec désavantage cependant d'ètre plus coûteuse.
Dans cet article, un nouveau système pour la segmentation et l'étiquetage automatique de la parole est présenté. Notre système est capable de transcrire des paroles d'origines diverses sans demander une connaissance linguistique extensive ou une base de données démesurée (segmentée et étiquetée manuellement). A cause de la taille limitée des réseaux neuronaux, la segmentation et l'étiquetage requièrent bien évidemment une limitation des temps de calcul et une capacité d'adaptation rapide á des nouvelles tâches. Le système est évalué en utilisant cinq corpus de mots isolés, élaborés pour le développement de systèmes TTS néerlandais, français, anglais-américain, espagnol et coréen. Les résultats montrent que la précision de notre système est comparable à celle d'experts humains. Pour obtenir des résultats concernant la segmentation et l'étiquetage, qui soient comparables avec des résultats publiés dans la littérature, des tests additionnels onté té effectués sur TIMIT et les parties anglaise, danoise et italienne de EUROM0. La performance de notre systéme se compare favorablement avec celles des autres systèmes automatiques.
Les fourmis présentent un intérêt grandissant pour la classification automatique vu la richesse et la diversité de leurs comportements. La plupart des méthodes proposées à cet effet étendent l'algorithme de base de Lumer et Faieta (Lumer et al., 1994) s'inspirant du tri du couvain chez les fourmis. D'autres propriétés biologiques des fourmis réelles et notamment les formes de communication qu'elles utilisent sont des sources d'inspiration intéressantes pour le partitionnement des données. Dans ce travail, nous proposons un nouvel algorithme de classification automatique par des fourmis artificielles.
Après avoir fourni quelques indications sur la fortune de la Commedia de Dante en France autour des XVeet XVIesiècles, cet article se concentre sur la traduction anonyme de l'Enfer, en alexandrins et en rime tierce, conservée actuellement à la Biblioteca Nazionale Universitaria de Turin (ms L. III. 17). Celle-ci est à présent considérée comme la plus ancienne traduction française de la Commedia, mais la transcription fournie à la fin du XIXesiècle n'est pas fondée sur des critères philologiques solides et nécessite d'être remplacée par une édition critique scientifiquement fiable ; quelques questions préliminaires sont abordées dans les pages qui suivent, après avoir rapidement passé en revue les études précédentes. Premièrement, cet article fournit quelques éléments, à la fois textuels et iconographiques, susceptibles de contribuer à dater le manuscrit ainsi qu'à identifier la source du texte italien transcrit en regard dans le codex turinois, vraisemblablement utilisé comme base pour la traduction. Dans la deuxième partie, il sera question d'abord de la possibilité de déterminer l'origine du traducteur à partir de quelques éléments lexicaux, et ensuite de l'analyse de quelques-unes des stratégies de traduction utilisées, qui pourra servir de base pour des études ultérieures sur les aspects littéraires de cet ouvrage.
Un nouveau codeur à faible délai est proposé. Il fait appel à une quantification vectorielle du filtre de synthèse dépendante de la mémoire. Les échantillons transformés sont considérés comme une séquence de variables aléatoires de Laplace quantifiées vectoriellement de façon efficace en utilisant un quantificateur á réseau gémétrique. Le codeur a été testé à un débit de 8625 bit/s et avec un délai de 8 ms.
On étudie ici le contrôle de la fréquence fondamentale (F0) en utilisant à la fois un modèle stochastique de séries temporelles et une analyse de système basée sur un modèle vectoriel auto-régressif (VAR). On utilise des séries de données sur F0 bi-dimensionnelles (ff0 et sf0), obtenues par un système de retour auditif transformé, développé par l'un des auteurs. Les valeurs sf0 sont extraites de données de parole qui contiennent une prononciation prolongée de la voyelle /a/, et le signal ff0 est extrait de la parole modulée en amplitude par du bruit blanc gaussien. La plupart des données ont des caractéristiques moyennes non-stationnaires. La procédure stochastique décompose les composantes non-stationnaires et les autres en une seule étape, sans prétraitement des données. Les composantes cycliques qui entourent les composantes moyennes non-stationnaires sont supposées être générées par le modèle VAR. Une analyse stochastique du système, utilisant les estimations du modèle VAR nous permet d'analyser les caractéristiques physiques des données. Une étude de simulation, utilisant les estimations fournies par le modèle, a également été menée pour découvrir le rôle du contrôle de F0 dans des situations où les capacités auditives sont totalement perdues. Les résultats montrent clairement quelles sont, par segments, les propriétés dynamiques du contrôle de F0 qui apparaissent avec chaque respiration prise durant l'émission d'un son soutenu.
On a montré précédemment que les 'spoonerismes' du type comme “barn door → darn bore” peuvent être provoqués chez les sujets en faisant précéder le stimulus cible à articuler (barn door) d'un item biaisé contenant au moins le phonème initial (d) de l'erreur attendue. Etant donné que certaines caractéristiques linguistiques de l'erreur sont différentes de celles du stimulus, on peut montrer que les variables qui affectent systématiquement ce résultat seul, sont induits par des processus préarticulatoires, indépendants des propriétés perceptives du stimulus-cible lui-même. L'étude présentée montre que la fréquence de base des erreurs provoquées par la technique de biais phonétique peut augmenter de manière dramatique lorsqu'on ajoute aux paires de mots précédant le stimulus-cible quelques items sémantiquement synonymes de l'erreur attendue. De cette manière, on démontre rigoureusement que le biais sémantique qui constitue l'une des propriétés du lapsus dit 'Freudien', accroit remarquablement son apparition. On discute ensuite les implications de ce phénomène.
L'étude présentée ici porte sur la modélisation des émotions extrêmes manifestées dans des situations anormales. L'application visée est la sécurité civile et plus précisément la surveillance dans les lieux publics. Un corpus fiction (le corpus SAFE) montrant des contextes riches et variés avec la présence d'émotions extrêmes, principalement de peur, a été sélectionné. Une stratégie d'annotation adaptée à l'application est ensuite développée : elle incorpore à la fois des descripteurs génériques et spécifiques. Enfin, un système de détection des émotions de type peur basé sur des indices acoustiques est mis en place à titre d'évaluation. D'une part, le système s'avère robuste aux changements de source contextuelle. D'autre part, l'évaluation de l'influence du choix d'un support multimodal à l'annotation sur les performances du système est mineure. Les performances issues des différents protocoles d'évaluation mis en œuvre restent inchangées : la classe peur est reconnue à 67 %.
Cette étude traite de l'effet de l'accent de phrase, de l'accent de mot et des classes de mots (mots fonctionnels versus mots de contenu) sur les propriétés acoustiques de 9 voyelles hollandaises énoncées en parole continue. Une liste de phrases a été lue par 15 locuteurs masculins. Nous nous sommes seulement intéressés à une syllabe dans chaque phrase. Soit un mot fonctionnel monosyllabique, soit une syllabe inaccentuée ou une syllabe accentuée dans un mot de contenu. Au total 3465 voyelles ont été segmentées et analysées. Les résultats ont montré que les facteurs linguistiques ont tous les trois eu un effet distinct sur la durée et les fréquences formantiques stables (F 1 and F 2) des voyelles. L'accent de mot et la classe de mot ont eu un effet plus fort que l'accent de phrase sur la qualité spectrale des voyelles. Une expérience d'écoute a démontré la signification perceptive des mesures acoustiques. Il est apparu que la réduction spectrale des voyelles pouvait être mieux interprétée comme le résultat d'une assimilation contextuelle accrue que comme une tendance à la centralisation. Nous nous sommes également penchés sur les changements dynamiques dans les traces formantiques causées par les conditions expérimentales. Il est apparu que les traces formantiques des voyelles réduites devenaient plus planes, ce qui soutient l'idée d'une assimilation accrue. Trois modèles de réduction vocalique sont discutés.
Nous présentons un réseau multicouches à connexion partielle (Partial Connection Multilayered Network, PCMN), fondé sur une technique de connexions partielles et superposées entre les couches. L'apprentissage de ce réseau peut se faire automatiquement par l'algorithme de rétro-propagation du gradient (gradient back-propagation algorithm, GBP). Un réseau général fondé sur GBP a été implanté sur une configuration d' anneau de la machine Hypercube F.P.S. T20. Une parallélisation efficace de l'algorithme a été assurée. Cette implantation a Fourni un éventail de possibilités de configuration du réseau. Dans notre expérience, le réseau a été utilisé pour la reconnaissance de mots isolés. Les résultats montrent les advantages de la technique de connexions partielles par rapport à la connexion compléte. Cette technique permet de traiter efficacement des informations temporelles qui sont trés importantes pour le traitement de la parole, à la différence du traitement d'images. Cette expérience permet aussi de mieux comprende descaracteristiques de réseau dans l'application à la parole. La connexion partielle permet d'introduire des contraintes de contete temporel et des connaissances implicites dans le réseau et peut aussi permettre un apprentissage efficace avec une petite base de données. Un résultat satisfaisant de reconnaissance a été obtenu.
La déconvolution de tels signaux est un problème de détection-estimation, ce qui exclut un traitement purement linéaire des données. Les formes ARMA conduisent a un problème non standard de détection-estimation d'un bruit d'état dont la résolution est complexe et coûteuse en temps calcul. Les formes AR et l'utilisation des techniques de codage multi-impulsionnel ne permettent pas de modéliser les systèmes à phase non minimale, et présentent les inconvénients des méthodes du type « erreur de sortie » . De plus, aucune de ces approches n'autorise un traitement en ligne des données. De plus, cette procédure peut être mise en œuvre sous forme rapide à l'aide d'équations de Chandrasekhar modifiées. Les résultats obtenus sur données synthétiques sont satisfaisants, et ne nécessitent qu'un volume de calcul très inférieur aux méthodes proposées jusqu'ici.
Cet article décrit un système de vision temps réel permettant de localiser des visages dans des séquences vidéo ainsi que de reconnaître leur identité. Ces processus sont effectués en combinant des techniques de traitements d'images et des méthodes de réseaux de neurones. La robustesse du système a été évaluée quantitativement sur un corpus de 8 séquences vidéo. Dans le but de comparer les performances avec les autres méthodes existantes, nous avons également testé notre modèle en utilisant la banque de visages standard ORL. Le système a aussi été implanté sur deux architectures électroniques à base de composants spécialisés ZISC et de FPGA. Nous analysons la complexité de l'algorithme et nous présentons les résultats des implantations architecturales en termes de ressources matérielles et de vitesse de traitement.
L'une des capacités humaines les plus développées est la communication par la parole. Au cours des années, la recherche sur la perception de la parole a démontré que les humains sont bien adaptés á l'extraction d'informations linguistiques hautement codées á partir d'un signal vocal. La nature sophistiquée de ces capacités et leur apparence précoce au cours du développment suggérent l'existence d'un riche substrat biologique permettant la perception de la parole. Dans le présent article, nous décrivons, quelques unes de ces importantes capacités et examinons des recherches dans différents domaines pouvant aider á éclaircir la nature de leurs fondements biologiques.
Récemment, de nombreux algorithmes de minimisation de fonctions non convexes ont été proposés pour résoudre des problèmes de vision bas niveau. Il existe plusieurs méthodes de relaxation. Les techniques stochastiques, telles que le recuit simulé, convergent asymptotiquement, sous certaines conditions, vers le minimum global, mais sont très coûteuses en temps de calcul. Les méthodes de relaxation déterministes sont sous-optimales, mais donnent de bons résultats et sont plus rapides que les méthodes stochastiques. Dans cet article, nous présentons la mise en œuvre parallèle de deux algorithmes déterministes de détection de contours et de lissage d'image : le GNC ( « Graduated Non-Convexity » ) proposé par Blake & Zisserman et le recuit par champs moyens (MFA) introduit par Geiger & Girosi et étendu aux champs de Markov composés anisotropes par Zerubia & Chellappa. Ces deux méthodes sont fondées sur le modèle de la membrane à contraintes de continuité lâches et sont séquentielles : à chaque pas est produit une image qui est utilisée au pas suivant. Pour le GNC, nous avons utilisé une méthode de minimisation de l'énergie appelée « successive over-relaxation (SOR) » et plus précisément une variante parallèle de cette technique. En ce qui concerne l'algorithme MFA, nous avons utilisé une méthode de descente de gradient conjugué à pas optimal.
La capacité compensatoire du système de contrôle articulatoire a été examinée chez des patients laryngectomisés. Des mesures radiographigues et acoustiques ont été effectuées sur trois personnes avant et après l'opération. Deux semaines après l'opération, les fréquences des formants des voyelles russes /a, u, i/ prononcées par ces patients étaient plus proches de la norme phonétique qu'avant, et deux ans après, deux patients prononçaient ces voyelles avec des paramètres phonétiques presque normaux. On a mesuré des caractéristiques acoustiques pour 14 patients après l'opération. 1 à 2 ans après l'opération, 4 patients étaient capables de faire des distinctions voisé/non voisé. Un patient a retrouvé le contrôle entiér de sa source vocale. Les résultats obtenus peuvent signifier que le processus d'adaptation du système de contrôle articulatoire a des conditions dégradées de génération de la voix peut dépendre non seulement des caractéristiques acoustiques (comme les fréquences des formants) mais aussi d'élément phonétique aussi complexe que l'indice de voisement de la sonorité. Le système de contrôle a montré sa capacité de réorganisation de l'activité des muscles, participant à l'articulation, ainsi que de transmission des fonctions des muscles laryngaux éliminés, aux muscles qui n'ont jamais été utilisés pour le contrôle de la voix. On discute de l'importance de ces phénomènes par rapport au concept de modèle interne.
Les systèmes de classeurs sont des systèmes à base de règles de production qui construisent leur ensemble de règles de façon automatique. Initialement, ces systèmes visaient à modéliser l'émergence de capacités cognitives à l'aide de mécanismes adaptatifs, en particulier évolutionnistes. Suite à un renouveau de la problématique mettant davantage l'accent sur l'apprentissage, les systèmes de classeurs ont été vus ensuite comme des outils capables de traiter des problèmes de décision séquentielle de façon compacte, en représentant l'état comme composé d'observables différenciées qu'un agent peut choisir de prendre en compte ou non. Enfin, beaucoup plus récemment, les systèmes de classeurs se sont avérés très efficaces pour résoudre des problèmes de classification automatique, ce qui dynamise le champ de recherche correspondant. Dans ce contexte, l'objet de cette contribution est de présenter l'état de la recherche sur les systèmes de classeurs en insistant sur les développements les plus récents, en insistant sur la décision séquentielle plutôt que sur la classification automatique.
La plupart des approches utilisées pour la caractérisation des sédiments marins est fondée sur l'utilisation des méthodes d'analyse de la texture. En effet, les images sonar présentent différentes zones homogènes de sédiments qu'on peut considérer comme des entités de texture. En général, les paramètres texturaux extraits sont nombreux et ne sont pas tous pertinents, une extraction et/ou réduction de ces paramètres parait nécessaire avant l'étape de la classification. Nous présentons dans cet article une chaîne complète de classification des images sonar en essayant d'optimiser les différentes étapes de cette chaîne. Pour l'élaboration de cette chaîne, nous nous fondons sur le processus d'extraction de connaissance à partir de données. L'environnement sous-marin a un caractère incertain, ce qui se reflète sur les images obtenues à partir des capteurs utilisés pour leur élaboration. Il est donc important de développer des méthodes robustes afin de lutter contre ces imperfections. Dans ce cadre, nous résolvons ce problème de deux façons différentes en utilisant dans un premier temps des méthodes de classification classiques comme les machines à vecteurs de support ou les A"-plus proches voisins et dans un deuxième temps des méthodes de classification floues ou crédibilistes. L'approche de la régression par SVM que nous avons introduite permet une modélisation des imperfections des données. Nous présentons alors les résultats obtenus en utilisant différentes approches pour l'analyse de la texture et pour la classification. Nous utilisons des approches fondées sur les théories de l'incertain pour pallier au problème des imperfections présentes sur les images sonar.
En Amérique du Nord, les gens appellent le service d'assistance annuaire pour obtenir le numéro de téléphone d'une entreprise ou d'une résidence. L'infrastructure et la maintenance du service d'assistance annuaire nécessitent une dépense importante pour les compagnies de téléphone. Une automatisation complète ou partielle du service d'assistance réduirait substantiellement les coûts des compagnies de téléphone. Nortel Networks a un produit appelé 'Automated Directory Assistance System (ADAS) Plus' qui automatise partiellement le service d'assistance à l'aide d'une technologie de reconnaissance vocale automatique. Ce système a été déployé au travers tout le Québec, ainsi que pratiquement toute la région couverte par US West et BellSouth. ADAS Plus automatise principalement la réponse à la question “pour quelle ville ?” à l'aide de la reconnaissance vocale. Nous fournissons ici les détailles concernant ce système de reconnaissance vocale ainsi que les performances de ce système dans les régions déployées.
Le travail coopératif se réalise à travers des interactions communicatives qui permettent d'atteindre un certain niveau de compréhension mutuelle pour coordonner les actions ou aboutir à des décisions négociées. La compréhension mutuelle est complexe de par l'hétérogénéité des participants qui entraine l'imprédictabilité et l'incertitude des interprétations. Nous posons ici que la coopération chronique est encore plus complexe parce que le souvenir des interactions coopératives précédentes est une source supplémentaire de différence entre les contextes cognitifs des participants. Nous avons étudié le souvenir d'interactions coopératives dans quatre situations collaboratives différentes. L'analyse indique un oubli massif du contenu verbal et un rappel plus aisé des positionnements relationnels, des structures interactionnelles et des émotions.
Dans ce papier, un aperçu d'une approche statistique de reconnaissance de la parole est présentée dans laquelle less sources de connaissances phonétiques et phonologiques, extraites à partir des connaissances actuelles du système de communication humain, sont intégrées dans la structure d'un modèle stochastique de la parole. Un formalisme statistique est présenté dans lequel les sous-modèles du processus phonologique basé sur des caractéristiques discrétes, ainsi que le processus dynamique phonétique du système de production humain, interagissent. Leur interface permet l'optimisation globale d'un ensemble de paramètres qui caractérisent de façon précise les composants symboliques, dynamiques et statiques de la production de la parole, et séparent de façon explicite les sources distinctes de la variabilité de la parole observable au niveau acoustique. Le formalisme est fondé sur une base mathématique rigoureuse, faisant intervenir la phonologie informatique, l'analyse bayesienne etla théorie de l'estimation statistique, les séries temporelles non stationnaires et la théorie des systèmes dynamiques, et finalement la théore de l'approximation de fonctions nonlinéaires (par réseaux de neurones). Deux méthodes principales de mise en oeurve du modèle et du reconnaisseur de parole sont présentées. La première méthode est basée sur le modèle de Markov caché dirigé, ou du modèle de trajectoire définie de façon explicite, alors que la deuxième approche est basée sur des unités phonologiques définies récursivement ou basées sur l'espace des états. La continuité et la structure paramétrique du modèle dynamique ainsi défini permetune caractérisation jointe des variations contextuelles et du style de parole qui se manifestent dans le signal acoustique, offrant ainsi la possibilité d'éviter certaines des limitations de la technologie de reconnaissance de la parole actuelle.
Le manque de modèles conceptuels dans la conception de systèmes attentifs au contexte limite sérieusement le développement de systèmes plus généraux et plus complexes. De plus, on ne connaît pas clairement quelles sont les conséquences des décisions précoces dans la conception pour la qualité de l'implémentation finale, ce qui rend la conception difficile, conduisant à des erreurs qui ne seront perçues qu'une fois le système implémenté et utilisé. Dans ce papier, nous présentons une classification des aspects architecturaux du développement de systèmes attentifs au contexte. Nous donnons par ailleurs un cadre de qualité qui décrit les conséquences des aspects architecturaux sur la qualité de tels systèmes. Nous montrons finalement l'utilité de ce cadre de qualité par une modélisation de l'architecture d'un système attentif au contexte.
Dans cet article, nous étudions le problème de la segmentation automatique du signal de parole enregistré dans un environnement bruité. Des techniques de rehaussement de la parole et de compensation de paramètres basées sur les modèles de Markov cachés (HMM), et récemment proposées pour la reconnaissance robuste de la parole, sont évaluées et comparées afin d'améliorer la segmentation automatique dans le cas de bruit coloré. Les techniques de rehaussement de la parole considérées ici sont : la Soustraction Spectrale Généralisée, la Soustraction Spectral Non Lineaire, le Rehaussement MMSE d'Ephraim–Malah, et le Filtrage Itératif de Wiener avec Contrainte Auto-LSP. De plus, la technique de Combinaison Parallèle de Modèles (PMC) est également comparée dans le cas de la compensation de bruit additif. Pour les applications téléphoniques, nous comparons les techniques de normalisation du canal de transmission, Normalisation de la Moyenne Cepstrale, annulation du biais du signal (SBR), et considérons une méthode de couplage de compensation du canal de transmission avec le rehaussement de la parole dans l'étage de pré-traitement afin d'améliorer la segmentation automatique. La qualité de la segmentation résultante est évaluée pour chaque méthode de compensation sur base des données TIMIT dégradées par du bruit additif coloré (à savoir, poste de pilotage d'un avion, autoroute, etc.), les données NTIMIT de parole transmise sur ligne téléphonique, et finalement CTIMIT correspondant à la transmission à partir de téléphones cellulaires.
Nous présentons des résultats provenant de l'application de l'algorithme “Approximating and Eliminating Search Algorithm” (aesa) à des données multi-locuteurs. Des résultats antérieurs mono-locuteurs avaient montré que la performance du aesa était peu sensible à des accroissements de la taille du dictionnaire, tandis que une performance d'autant meilleure est observée que les paroles pronunciées sont proches de leurs prototypes correspondants. Nous montrons dans cet article qu'à la fois le taux d'erreur et le nombre de calculs de distance diminuent lorsque le nombre d'échantillons est augmenté dans un dictionnaire à plusieurs entrées par mot.
Les algorithmes d'apprentissage pour la reconnaissance de la parole continue ont besoin de très grandes quantités de données sous forme de parole transcrite. Les livres sur cassette, disponibles commercialement, représentent une source de telles données, abondante mais difficile à exploiter avec les algorithmes d'apprentissage actuels, car ceux-ci exigent que les données soient d'abord segmentées, à la main, en blocs assez petits pour être traités en mémoire. Pour résoudre ce problème, nous avons mis au point un algorithme d'apprentissage capable de traiter des fichiers de données de longueur arbitraire ; les besoins en calculs de cet algorithme sont linéairement proportionnels à la longueur des données et la quantité de mémoire requise est constante.
Cet article passe en revue les concepts fondamentaux de l'analyse spectrale par Prédiction linéaire (LP) et par Entropie Maximale (ME), et dégage les raisons de leur importance pratique dans l'univers des signaux réels. Le principe puissant du Minimum d'Inter-Entropie (MCE) est ensuite introduit. Il permet d'incorporer de l'information antérieure au processus d'analyse d'un signal. Dans une nouvelle approche de l'analyse du signal de parole, l'application du principle MCE permet de réduire le nombre moyen de coefficients prédicteurs (pôles) à spécifier par tranche temporelle pour une résolution spectrale donnée, en se basant sur une information spectrale préalable. Celle-ci peut être fournie par les caractéristiques de la source glottique et du rayonnement aux lévres, par les réponses fréquencielles du microphone et de la chaîne de transmission et par de l'information spectrale de segments temporels antérieurs, en particulier dans les régions stables ou lentement variables d'une séquence verbale. Ce travail met surtout l'accent sur les principes généraux plutôt que sur les détails du calcul.
Cet article présente une étude comparative entre quatre dispositifs de scolarisation des élèves allophones au collège en France. Notre problématique consiste à interroger les éléments facilitateurs de la réussite des élèves allophones parmi lesquels figure la question des modalités d'accueil et de leurs effets sur les apprentissages des élèves. Nous analyserons leur prise en charge au sein des dispositifs cibles à partir de deux focales : l'intérêt intrinsèque de chacun des dispositifs et leur articulation avec « la classe ordinaire » . Les conclusions de cette recherche qualitative qui consiste en des entretiens semi-directifs menés auprès d'élèves allophones et d'enseignants tendent à soutenir que le seul véritable parcours personnalisé et adapté aux apprenants allophones s'inscrit dans les dispositifs d'accueil spécifiques qui leur sont réservés qu'elle qu'ait été leur structure.
Pour interpréter et analyser des signaux de parole, on emploie diverses représentatiions temps-fréquence (par exemple spectrogramme, distribution de Wigner-Ville, ondellettes). Dans cet article nous construisons dans la classe de distributions temps-fréquence de Cohen la distribution la mieux appropriée à la représentation des signaux de parole. Pour cela, on prend en compte des connaissances de la structure temps-fréquence du signal de parole exprimée dans l'Elementary Waveform Speech Model (EWSM, d'Alessandro, 1990). Comme application nous présentons un algorithme qui réduit un signal de parole, en utilisant la distribution optimisée, à un ensemble de points dans le plan temps-fréquence. Ainsi on produit une représentation simple du signal qui peut être interpreté très bien non seulement dans le cas stationnaire, mais aussi pour des segments non-stationnaires. De plus cette représentation pourra servir de base à d'autre analyses (par exemple classification).
Dans beaucoup de centres de recherche sur la parole, des travaux sont en cours qui ont pour but de récolter et d'étiqueter un grand nombre de signaux de parole. Comme la complexité de ces bases de données augmente, il devient important de porter l'attention sur certains aspects de leur gestion, et plus particulièrement sur leur accès. Nous présentons un formalisme convivial qui peut être utilisé pour formuler des requêtes auprès d'une base de données de parole. Ce formalisme est lié au domaine acoustico-phonétique de telle manière qu'un chercheur puisse formuler des requêtes spécifiques sans être un informaticien chevronné.
Cet article explore la dynamique de la bourse à partir d'un point de vue comportemental en utilisant une simulation multi-agent. L'objectif de cet article est d'étudier le comportement des investisseurs au sein du marché boursier afin de trouver un modèle qui se rapproche le plus de la réalité. La problématique principale est de comprendre, à travers un nouveau modèle qui inclut les attitudes comportementales et cognitives des investisseurs, le fonctionnement de ce marché et de déterminer les sources de sa complexité. Des expériences de simulation sont menées pour observer plusieurs faits stylisés des séries temporelles financières. Ces expériences montrent qu'à partir de la représentation d'un modèle comportemental, centré agent, nous observons des phénomènes socio-économiques émergents.
Nous nous intéressons à la reconnaissance d'objets volumiques par mise en correspondance d'indices visuels. Nous supposons que les objets à reconnaître sont représentés à l'aide de modèles tridimensionnels, composés d'indices visuels. Cela constitue l'originalité et la force de la méthode que nous proposons. Nous présentons de nombreux résultats expérimentaux illustrant l'utilisation de notre approche pour la reconnaissance d'objets.
Herbert Simon est à l'origine de la « découverte scientifique » (Scientific Discovery en anglais). Ce courant de recherche dont les plus illustres représentants sont Pat Langley, Jan Zytkow et Douglas Lenat, vise à reconstruire rationnellement des découvertes anciennes de façon à les reproduire au moyen d'un ordinateur. L'intérêt est double. D'un côté, au plan épistémologique, cela modélise l'activité scientifique jusque dans ses aspects les plus énigmatiques. D'un autre côté, au plan pratique, s'ouvre une perspective exaltante dans laquelle l'ordinateur épaule l'homme dans sa quête de nouveaux savoirs. Voici, en hommage à Herbert Simon, quelques aperçus sur la découverte scientifique.
Le miroir des princes connu sous le titre de Naṣīḥat al-mulūk et attribué à al-Māwardī, sans doute un texte du dixième siècle, comprend maintes références à des sources identifiées par l'auteur comme « indiennes » . Un grand nombre de ces textes apparaît également dans la Waṣiyyat Arisṭāṭālīs li-l-Iskandar ; quelques exemples ne sont pas sans rappeler Kalīla wa-Dimna et Bilawhar wa-Būḏāsaf. Ces coïncidences ouvrent la porte à plusieurs possibilités : primo, que la source « indienne » de l'auteur représente un ouvrage d'origine indo-européenne traduit à partir du sanskrit ou d'une autre langue indienne vers l'arabe, probablement à l'époque où les Barmécides encourageaient ces traductions à grande échelle ; secundo, qu'elle fut transmise d'une langue indienne en moyen perse (pahlévi) à la période sassanide, puis en arabe dans les premiers siècles de l'Islam ; tertio, que le texte fut composé en moyen perse et acquit une généalogie indienne « forgée » à l'instar de tant d'attributions prétendument grecques, comme cela s'avéra ultérieurement le cas pour le Testament du pseudo-Aristote. Cet article examine les trois hypothèses et — sur la base de considérations textuelles comme contextuelles — suggère que, dans l'état actuel de la recherche, c'est la deuxième qui semble la plus vraisemblable.
On s'intéresse dans cette étude à la détection et à la localisation de sources en acoustique sous-marine à l'aide d'une antenne longue tractée. Cette information permet de redonner à l'antenne son gain maximal par exemple en reconstituant une antenne rectiligne, ce qui facilite l'utilisation des méthodes de traitement d'antenne classiques. Pour cela, nous rappelons les critères de détection AIC et MDL utilisés afin de déterminer le nombre de sources présentes à la fréquence d'analyse. Puis nous décrivons brièvement la méthode de localisation de type MUSIC utilisée pour identifier ces sources supposées à bande étroite et situées à grande distance du réseau de réception. Nous appliquons cette suite de traitements sur des signaux expérimentaux. Les résultats obtenus sont comparés à ceux provenant de la transformée de Fourier bidimensionnelle. Les résultats de ce mode de représentation spatio-temporel, dont on donne rapidement un rappel théorique, confirment l'importance de la connaissance de la forme d'antenne.
En moyen français, la continuité référentielle et le choix des expressions anaphoriques – formes nominales, pronominales ou 'zéro' appuyées par la morphologie verbale – au sein de la chaîne anaphorique sont gouvernés en récit et discours par cinq règles syntactico-sémantiques : une, de concurrence référentielle, trois, 'valentiello-référentielles' et une, syntactico-valentielle. Notre objectif est de voir quelle est leur fréquence d'application sur un texte en prose de traduction de moyen français, le Decameron de Boccace traduit par L. de Premierfait (1411–1414), et potentiellement d'observer l'influence que peut avoir la langue d'origine du texte dans la traduction médiévale.
Dans cet article, nous présentons une étude sur l'emploi de différents types de modèles de Markov en reconnaissance de l'écriture. La reconnaissance est obtenue par calcul de la probabilité a posteriori de la classe d'une forme. Ce calcul fait intervenir plusieurs termes qui, suivant certaines hypothèses de dépendance liées à l'application traitée, peuvent se décomposer en probabilités conditionnelles élémentaires. Si l'on suppose que la forme suit un processus stochastique uni- ou bidimensionnel qui de plus vérifie les propriétés de Markov, alors la maximisation locale de ces probabilités permet l'atteinte d'un maximum de la vraisemblance de la forme. Nous avons étudié plusieurs cas de conditionnement des probabilités élémentaires des sous-formes. Chaque étude est accompagnée d'illustrations pratiques relatives au domaine de la reconnaissance de l'écriture imprimée et/ou manuscrite.
Cet article décrit un aperçu général d'une approche permettant à la fois de prédire en vue d'applications spécifiques les performances d'un système de reconnaissance de la parole, qui a été caractérisé précédemment, et d'analyser les effets de la variabilité de la parole sur les performances. La méthode a le mérite potentiel d'ouvrir une voie au développement d'une base de données pour des buts d'évaluation. La méthode “Recogniser Sensitivity Analysis (RSA)” a été développée chez Logica dans le cadre du programme Alvey “Evaluation des technologies de la parole” (STA n°NMI/132). La méthode repose principalement sur la caractérisation des sources de variabilité dans le système de reconnaissance par un petit nombre de paramètres mesurables. Les expériences conduites pour déterminer la validité de la méthode et les résultats sont décrits. Sa pertinence pour prédire la performance d'un système dans le cas d'applications particulières ainsi que l'influence des variations inter- et intra-locateurs sur la performance sont discutées. Les résultats préliminaires indiquent une corrélation significative entre les valeurs des paramètres du signal et la performance du système de reconnaissance. L'article s'achève par une discussion sur les extensions futures de la méthode RSA.
Nous présentons dans cet article quatre codeurs de parole de la famille CELP (Code Excited Linear Predictive). La qualité de la parole est améliorée en remplaçant la prédiction à long terme par une séquence d'auto-excitation (dictionnaire) de codage adaptatif), ainsi qu'en substituant un dictionnaire de codage réparti à l'ensemble des vecteurs codes à bruit gaussien couramment employé. Les codeurs sont entièrement quantisés à 5 et 7 kbit/s, c'est-à-dire à des vitesses de transmission intéressantes pour d'éventuelles applications telles que les systèmes GSM à demi débit et INMARSAT-M. Les performance de ces systèmes de codage sont évaluées grâce à un test conventionnel d'écoute et présentées par leur “Mean Opinion Scores (MOS)”. Un ensemble de taux d'erreurs binaires tolérables est fourni pour le codeur dont les performances en fonction de la qualité et de la complexité sont maximales. Il est montré que la présence de bruit de fond acoustique ne modifie en rien la qualité du codeur et que dans ce cas les erreurs binaires seront partiellement masquées par le bruit de fond, grâce à la robustesse du codeur. Compte tenu des performances en présence de ces perturbations, le codeur semble approprié pour être utilisé dans des systèmes qui ont recours à des liaisons par satellite.
Quand, vers le milieu du XIII e siècle, les grammaires coptes apparurent pour la première fois, leurs auteurs ne pouvaient recourir qu'au modèle linguistique arabe dominant : terminologie et catégories grammaticales. La langue copte n'appartient pourtant pas à la même famille que l'arabe ; elle était par ailleurs en voie de disparaître comme langue vivante. À partir de quelques exemples typiques, ayant trait à l'écriture, à la phonologie et à la morphologie, nous essayons de donner une idée de la méthode suivie pour appliquer ou adapter les outils conceptuels et terminologiques arabes dans la description de l'ancienne langue égyptienne à sa dernière phase et de démontrer que, d'une manière générale, les philologues coptes du Moyen Âge ont bien mené leur tâche. Si l'on peut relever des lacunes, celles-ci ne sont pas nécessairement imputables à la tradition linguistique qui a servi de modèle, mais plutôt aux conditionnements externes qui ont présidé au labeur intellectuel des protagonistes.
Un appareillage d'affichage de contours intonatifs de phrases contrôlé par micro-ordinateur a été développé depuis 1976. Il a été montré qua pour différents groupes de sujets (néerlandophones apprenant l'anglais et Turcs apprenant le néerlandais), ceux qui reçoivent un feedback audio-visuel fournissent de meilleurs performances que ceux qui ne reçoivent qu'un feedback auditif. On n'a pas trouvé d'effets d'apprentissage différentiels en fonction du niveau de compétence en L2 ou de l'âge des sujets.
L'article présente une méthodologie de simulation d'échos de cibles radar en environnement marin. La procédure est basée sur un nouveau modèle, appelé « Ensemble de Points Brillants en Représentation Unifiée » (EPB-RU), qui permet d'approcher le signal écho d'une cible radar pour l'ensemble de ses orientations. Ce modèle est rapide à calculer et a l'avantage de prendre en compte le masquage partiel ou total de la cible par les vagues de la mer. Il associe à chaque orientation de la cible un ensemble de points brillants (EPB). Pour chaque point brillant du modèle, une carte d'amplitude prend en compte son anisotropie et sa visibilité en fonction de l'angle de visée. Un modèle virtuel combiné mer-navire est utilisé pour décrire le mouvement de la cible et le masquage introduit par les vagues de la mer. L'influence du fouillis de mer est également prise en compte. Les signatures radar utilisées dans nos simulations correspondent à quatre maquettes de cibles navales mesurées dans la chambre anéchoïde de l'ENSIETA. L'article présente aussi quelques résultats d'imagerie radar et de classification, qui illustrent l'aspect inverse du problème de la caractérisation des cibles navales dans leur environnement.
Cet article décrit les techniques de traitement de parole essentielles pour les applications vocales interactives dans le domaine des télécommunications. Ces techniques comprennent la reconnaissance et la synthèse de la parole qui visent à rendre plus naturelle la communication orale interactive entre l'homme et la machine. La détection de mots-clé, les techniques de réduction des effets du bruit environnant et l'adaptation au locuteur et/ou aux lignes téléphoniques sont considérées comme des caractéristiques essentielles des technologies de reconnaissance de parole pour permettre une entrée vocale plus naturelle et une robustesse adéquate face aux variablités de l'environnement. En ce qui concerne la synthèse à partir du texte, on présente ici une méthode de synthèse à base de règles appliquée au Japonais qui vise à fournir une parole de très haute qualité. Le système commercial ANSER, résultat d'un projet antérieur, est également décrit comme exemple d'un système de traitement vocal interactif. Enfin, un serveur vocal récemment développé et incluant une fonction de reconnaissance flexible est décrit pour illustrer le concept des techniques de mise en oeuvre de systèmes permettant d'étendre aisément les champs d'application tout en s'adaptant aux changements rapides dans le domaine des Télécommunications.
Cet article décrit deus algorithmes qui séparent deux signaux qui se chevauchent. Ces algorithmes dépendent des mesures précises de la hauteur de la voix-cible. Le premier algorithme utilise un seul microphone et le trait important consiste à exploiter le début du voisement pour extraire sa hauteur en la présence d'interférences. Le deuxième algorithme utilise deux microphones et sa caractéristique majeure consiste aussi à exploiter la direction de la voix-cible.
L'auto-correction dans le discours se fait typiquement en trois temps. Dans un premier temps, le locuteur contrôle sa propre parole et l'interrompt lorsqu'il rencontre un problème. Une analyse de 959 corrections spontanées indique que l'interruption suit de très près la perception du problème, à l'exception près que le locuteur a tendance à finir les mots corrects. Les résultats de cette analyse indiquent d'autre part que la perception du problème s'améliore vers la fin des constituants. Le deuxième temps se caractérise par des hésitations, des pauses, mais surtout par l'utilisation de ce qu' on peut appeler les 'commentaires rédactionnels'. La présence immédiate du problème est signalée par l'utilisation de 'uh'. Dans le troisième temps a lieu la correction elle-même. La bonne-formation des corrections ne dépend pas de ce que le locuteur respecte l'intégrité des constituants, mais plutôt de la relation structurelle qui existe entre le premier énoncé et la correction. Cette relation est liée à la relation correspondante entre les éléments conjoints d'une coordination par une règle de bonne formation bi-conditionnelle. On peut également suggérer qu'il existe une relation semblable entre questions et réponses. Dans ces trois cas, le locuteur respecte les contraintes structurelles de son premier énoncé. Enfin, l'analyse démontre que l'ensemble formé par le 'commentaire rédactionnel' et le premier mot de la correction elle-même contient presque toujours des éléments d'information permettant à l'interlocuteur de décider comment il faut relier la correction au premier énoncé. De ce point de vue, les locuteurs ne produisent presque jamais d'énoncés qui pourraient induire leur interlocuteur en erreur. Ces résultats indiquent que le locuteur a peu ou pas du tout d'accès au processus de production d'énoncés ; l'auto-contrôle se fait plutôt à partir de la compréhension de sa propre parole intérieure ou extérieure.
Inputs and outputs are not independent phenomena in interactive systems in general and more particularly in multimodal interaction. We present the results of a Wizard of Oz experiment which shows that output modalities used by a multimodal system have an influence on the input modalities for a large category of users. A part of the subjects, however, has a favorite input modality and thus cannot be influenced. This kind of environment does not require any particular knowledge about computers and their use and thus allowed us to study the behavior of ordinary people including subjects who are not familiar with computers. The experiment also shows that speech is a favorite modality within smart room environments for a large part of users, except when graphics modality is used by the system : pointing on a touch screen is then preferred to speech.
La conception et l'évolution de l'algorithme de codage bas debit 16 kbit/s LD-CELP (recommandation CCITT G.728) a représenté un important effort de recherche entre 1988 et 1992. Cet article donne un historique de cet effort de quatre ans, en insistant sue les performances techniques des nombreuses variantes algorithmiques qui oat été explorées. Dans le cadre de cette discussion, nous expliquons pourquoi nous avons retenu certaines de ces techniques dans la version finale due codeur G.728 et pourquoi nous avons écarté les autres. Nous espérons que cet article montrera comment l'algorithme G.728 a été conçu à partir de concepts mitiaux tres simples, puis a été modifié et amélioré peu à peu du fait des contraintes d'implantation en temps réel, jusqu'à ce que la version finale satisfasse les exigences de performance qui semblaient inaccessibles au départ.
PADIS, le système de standard téléphonique automatique et d'information annuaire de Philips offre une interface utilisateur en langage naturel pour accéder à une base de données téléphoniques. En utilisant les technologies de reconnaissance de la parole et de compréhension de langage, le système permet d'obtenir les numéros de téléphone, les numéros de fax, les adresses électroniques, les numéros de pièces ainsi que l'établissement direct d'appel vers le numéro désiré. Dans cet article, nous présentons le cadre probabiliste sous-jacent, l'architecture du système, et les modules individuels de reconnaissance de parole, de compréhension du langage, de contrôle du dialogue, et de sortie vocale. De plus, nous rapportons des résultats sur les performances et le comportement des usagers obtenus à partir d'un test terrain réalisé dans notre laboratoire de recherche avec une base de données de 600 entrées. Nous dérivons une nouvelle règle de décision basée sur le critère de maximum a posteriori qui incorpore des connaissances sur la base de données et sur l'historique du dialogue comme des contraintes pour la reconnaissance de la parole et la compréhension du langage. Ceci a permis d'améliorer la compréhension de la parole de 19% (en termes de taux d'erreur), et de réduire de 38% les erreurs de substitution des attributs (par exemple reconnaissance d'un nom erroné). La règle de décision est implantée dans une approche multiniveaux correspondant à une combinaison d'une reconnaissance de parole au niveau de l'état de l'art, d'une recherche grammaticale partielle dans une grammaire à attributs hors contexte et stochastique, et d'un algorithme de recherche des N-meilleures solutions, qui est également décrit dans cet article.
Le projet d'un répertoire des « mises en prose » qui mettra à jour le célèbre ouvrage de Georges Doutrepont (1939) a été lancé lors du IIIe Colloque International de l'AIEMF (Gargnano, mai 2008) ; sont présentées ici les grandes lignes de cette initiative, la fiche modèle qui sera remplie par les collaborateurs, et deux notices : la Manequine de Jean Wauquelin et la Belle Hélène de Constantinople anonyme.
De nombreux réseaux du monde réel peuvent être modélisés par des grands graphes. Réduire la complexité d'un graphe de manière à ce qu'il puisse être facilement interprété par l'oeil humain est une aide précieuse pour comprendre et analyser ce type de données. Nous comparons ici deux approches de regroupement de sommets en communautés et proposons une visualisation interactive multi-échelle de grands graphes basée sur ces classifications hiérarchiques des sommets qui nous permettent de représenter ces graphes de manière lisible et interprétable. Nous appliquons ensuite notre méthodologie à un réseau de blogs francophones afin d'illustrer rapidement les avantages et inconvénients de cette approche.
Dans le cadre des applications mobiles, diffuses et omniprésentes, la détermination et l'explicitation du contexte sont nécessaires pour fournir des solutions IT personnalisées à un utilisateur donné dans une situation donnée. Dans ce papier, le contexte est considéré comme une relation n-aire. Le contexte est supposé contenu dans des ontologies qui sont utilisées pour structurer les connaissances spécifiques des applications. Nous présentons une approche basée sur une modélisation de cas pour exprimer le contexte et sa gestion. Nous discutons l'incorporation d'un raisonnement et la génération d'explications basées sur le contexte. Nous montrons finalement comment appliquer notre approche dans la gestion de la confiance.
Il s'agit de l'étude et édition d'un bref traité de morpho-syntaxe latine, transmis par le ms. Londres, B.L., Add. 10352. Manuel destiné à des élèves ayant déjà appris l'Ars minor de Donat, ce texte anonyme organisé par questions/réponses aborde trois sujets : construction de la phrase latine, régime, accord. Son intérêt réside entre autres dans la terminologie adoptée (premières attestations et/ou acceptions techniques).
La modélisation et la simulation ont longtemps été dominées par les approches basées sur les équations, jusqu 'à l'avènement récent des approches orientées agents. Pour freiner l'augmentation de complexité des modèles que peut entraîner l'utilisation de cette nouvelle approche, la tendance est à la sursimplification des modèles. Des modèles plus descriptifs ont cependant été développés pour une variété de phénomènes, mais la cognition des agents est encore trop souvent négligée alors qu'elle a une grande importance dans certains domaines, en particulier en sciences humaines et sociales. La solution que nous proposons dans cet article est d'utiliser des agents BDI. Nous montrons qu 'il s'agit d'un paradigme expressif, réaliste et simple qui apporte de nombreux bénéfices à la simulation à base d'agents.
Wir stellen eine robuste rekursive procedure vor, die Identifikation des nichtstationären AR-Model für Sprache produktion erlaubt und auf gewichteten rekursiven Kleinsten-Quadrate-Algoritmus (weighted recursive least squares – WRLS) mit VFF (variable forgetting factor) basiert ist und sowohl quadratische Klassifikator mit gleitenden Training Daten. Die Bewertung des Verfahrens haben mittels die Sprach-Analyse stimmhaften und gemischten Anregungen durchgefürt. Die Ergebnisse von Simulationen haben gezeigt dass vorgeschlagene robuste rekursive procedure eine bessere AR-Parameter Schätzung ermöglicht und die Verfolgung erheblich verbessert.
Cet article propose une nouvelle méthode de représentation et de visualisation en couleur d'images multispectrales ou hyperspectrales. Le problème de la visualisation de telles données est en effet problématique dès que le nombre de bandes spectrales est supérieur à trois, i.e., la représentation triviale RVB (Rouge, Vert, Bleu) n'est plus directe. Le principe consiste ici à utiliser une carte de segmentation préalablement obtenue, a priori, et à réaliser une analyse factorielle discriminante permettant de distribuer au mieux l'information dans l'espace des couleurs TSL (Teinte, Saturation, Luminance). L'information apportée par la carte de segmentation (chaque site est associé à une classe) peut se révéler judicieuse comme le montrent les résultats obtenus sur des lots d'images de tailles croissantes dans le cadre de l'imagerie astronomique. Cette méthode est générale et s'applique également à d'autres domaines manipulant des images multicomposantes ou multivariées comme en télédétection ou en imagerie polarimétrique.
L'extraction d'information est guidée par une ressource termino-ontologique qui exploite des patrons d'extraction et un lexique. Elle a été intégrée dans un assistant guidant l'expert pour remplir la base de données.
La conception initiale d'un système de codage d'image par analyse-synthèse basé sur un modèle (MBASIC) est décrite et une méthode de construction du modèle facial tridimensionnel (3-D) qui inclut les méthodesdes synthèses pour les expressions faciales est présentée. Le système proposé MBASIC est une méthode de codage d'images qui utilise un modèle tridimensionnel d'un objet qui doit être reproduit. Une image d'entrée est d'abord analysée et une image de sortie utilisant le modèle 3-D est ensuite synthétisée. Une transmission à très faible débit peut être réalisée car le codeur transmet seulement les paramètres d'analyse requis. Les images de sorties peuvent être reconstruites sans l'effet perturbateur du bruit qui réduit l'aspect naturel, parce que le décodeur synthétise des images à partir d'un modèle 3-D similaire. Pour construire le modèle 3-D de la face d'une personne, une méthode qui utilise un modèle 3-D de face à trame de fil est développée. Une image complète de face est projetèe sur ce modéle de trame de fil. Pour la synthèse des expressions faciales, deux méthodes différentes sont proposées : une méthode de tonte et de collage et une méthode de déformation des structures faciales.
Nous étudions ici les aspects temporels de la syllable et du mot en Italien parlé. En ce qui concerne les syllables, nous avons testé les effects de la composition syllabique sur la durée acoustique des voyelles et des consonnes. Les effets de la structure du mot sur les durées segmentales ont été testés en variant la longueur du mot et la position de l'accent lexical. Les résultats indiquent que tant la structure de la syllabe que celle du mot ont des effets systématiques sur la duréee des voyelles et des consonnes. La structure syllabique et la longueur du mot ont surtout des effets anticipatoires et tendent à pŕeserver la duréee totale de ces deux unités. Dans notre recherche, deux points sont mis en avant : 1. Les données syllabiques suggèrent que l'unité tendant à être constante en durée est l'intervalle temporel entre les débuts de deux voyelles consécutives ; 2. Les données relatives à la syllable et au mot indiqueraient que les variations de durée dues à ces deux variables sont réalisèes par deux stratégies articulatoires différentes. Quelques observations sur le rythme syllabique et accentuel sont présentées.
Un des problèmes les plus urgents de la recherche actuelle des systèmes de reconnaissance de la parole automatique est leur robustesse déficiente envers du bruit additif et la réverbération. Le modèle de perception auditive (PEMO) réalisé par Dau et al. (T. Dau, D. Püschel, A. Kohlrausch, J. Acoust. Soc. Am. 99 (6) (1996) 3615–3622) pour une application dans le domaine psychoacoustique peut partiellement surmonter ces difficultés, s'il est appliqué comme prétraitement pour la reconnaissance de la parole automatique. Afin de perfectionner la performance de ce système auditif de reconnaissance de la parole automatique en bruit d'environnement, plusieurs méthodes de débruitage de la parole furent examinées, qui étaient évaluées comme composants des prothéses auditives dans le passé. La réduction monaurale de bruit comme proposée par Ephraim and Malah (Y. Ephraim, D. Malah, IEEE Trans. Acoust. Speech Signal Process. ASSP-32 (6) (1984) 1109–1121) fut comparée avec le filtre binaural et l'algorithme de réverbération d'après Wittkop et al. (T. Wittkop, S. Albani, V. Hohmann, J. Peissig, W. Woods, B. Kollmeier, Acustica United with Acta Acustica 83 (4) (1997) 684–699). Tous les deux algorithmes de réduction de bruit améliorent la performance de reconnaissance correspondant à une amélioration de jusqu'à 10 dB de rapport signal/bruit pour tous les bruits d' environnement étudiés, pendant que les résultats obtenus pour la parole présentée sans bruit ne furent pas diminués considérablement. M me dans un environnement réel sans réverbération ces méthodes de réduction de bruit améliorent la performance de reconnaissance correspondant à une amélioration de jusqu'à 5 dB de rapport signal/bruit. Ces résultats dépassent les prévisions, parce que dans des anciennes études on n'avait pas obtenu une augmentation de l'intelligibilité de la parole pour des patients avec des déficiences auditives.
Les erreurs systématiques trouvées pendant le développement phonologique peuvent fournir, au même titre que les erreurs de production et les processus phonologiques des adultes, des preuves sur les mécanismes de production du langage. Une recherche détaillée des contextes dans lesquels les plosives velaires sont avancées ('fronted') chez un enfant phonologiquement retardé montre que le 'fronting' dépend du stress et des frontiéres du mot, présente des exceptions lexicales et se produit en production uniquement. Ces caractéristiques suggérent que des représentations lexicales de sortie de l'enfant sont indépendantes des représentations lexicales à entrée et que les erreurs de 'fronting' ne se produisent que dans les représentations de sortie. Cela suggére aussi que les traits prosodiques sont essentiels pour l'identification des traits articulatoires dans les représentations. Une telle analyse a des implications pour les théories de l'accès lexical et pour le développement de l'accès lexical chez les enfants.
A la suite de la minimisation du travail des articulateurs, la problème de l'inversion pour l'obtention de la forme et de la fonction d'aire du conduit vocal a été résolu. On a utilisé les valeurs de la fréquence des quatre formants du signal de la parole. La forme de la langue d'un homme et d'une femme a été mesurée à l'aide de microrayons X. Les formes du conduit vocal et les valuers des fréquences formantiques mesurées et calculées sont très proches pour l'homme et assez proches pour la femme.
Cet article tente de dresser le bilan de ce que les réseaux sémantiques ont apporté à la terminologie. Il s'appuie sur le formalisme des graphes conceptuels et, plus marginalement, sur celui des logiques de description. Nous avançons néanmoins l'idée que ce type de formalisme a un rôle à jouer dans le processus de modélisation, un rôle d'intermédiaire entre la sémantique d'une langue naturelle et un modèle opérationnel utilisé dans un processus automatique.
L'utilisation d'un modèle de série chronologique rend compte des faits suivants : les cycles glottiques sont produits séquentiellement et il existe des liens entre les perturbations de cycles voisins. Le modèle représente la perturbation de la durée du cycle présent comme une somme pondérée des perturbations passées et d'un bruit blanc. Le modèle est ajusté à des séries de perturbations observées, à l'aide de méthodes linéaires conventionnelles. Une analyse discriminante de séries extraites de 279 vocoı̈des [a] [i] [u] montre que des indices qui décrivent isolément les composantes prédictibles et aléatoires des perturbations caractérisent mieux locuteurs dysphoniques et sains qu'un indice conventionnel. La conclusion est que les relations entre perturbations de cycles voisins constituent un aspect indépendant de la dispersion des microperturbations décrite à l'aide des indices conventionnels.
Dans ce travail nous présentons un nouvel algorithme d'extraction de la forme par la texture appliqué à l'analyse des scènes naturelles. L'originalité de cette approche est basée sur la structure du cortex visuel primaire (V1) dont elle modélise les fonctions. L'algorithme est capable d'analyser une grande variété de textures présentant différents types d'irrégularités. Tout d'abord pour réaliser l'échantillonnage du spectre d'amplitude, nous proposons de nouveaux filtres, appelés filtres log-normaux, inspirés du fonctionnement des cellules complexes de l'aire V1, en remplacement des filtres de Gabor classiques. Ces filtres s'avèrent particulièrement appropriés aux techniques de reconnaissance de forme de part leurs différentes propriétés théoriques, notamment leur profil en fréquence radiale (adapté à la décroissance en 1/f des scènes naturelles) et leur séparabilité en orientation et en fréquence. Nous utilisons ensuite une méthode d'estimation de la fréquence moyenne locale appliquées sur des signaux naturels. Celle-ci ne nécessite pas la recherche d'une échelle adaptée à l'analyse et tire avantage de l'ensemble des fréquences du banc de filtres utilisé. Finalement, à partir de l'estimation locale, l'orientation et la forme sont extraits en utilisant les propriétés géométriques de la projection perspective. La précision de la méthode est évaluée sur différents types de textures, à la fois régulières et irrégulières, et sur des scènes naturelles. La méthode présentée permet d'obtenir des résultats se comparant favorablement aux meilleures techniques existantes tout en conservant un faible coût de calcul. Enfin le modèle peut être adapté à d'autres applications telles que l'analyse de textures, l'extraction de points caractéristiques ou l'indexation d'images par le contenu.
Une des plus frappantes caractéristiques typique du langage des aphasiques de Broca est l'agrammatisme caractérisé par l'ommission des mots “fonctionnels” et des morphèmes indiquant des inflexions. L'agrammatisme est le plus souvent considéré comme symptomatique d'un déficit syntaxique. Nous pensons que cette optique manque de rigueur grammaticale et que seule une interprétation de ce déficit en termes de structure phonologique peut être cohérente et systématique. Une classe naturelle composée de mots de fonction et de certains morphèmes liés, peut être définie par référence aux propriétés de frontières des phrases lesquelles définissent les mots phonologiques. C'est cette classe d'éléments qui tend à disparaître dans le discours agrammatical. Le but de cet article n'est pas seulement de fournir une hypothèse permettant d'interpréter un syndrome aphasique, mais aussi de tester et d'illustrer l'idée qu'il est efficace de considérer attentivement les universaux substantifs de la structure grammaticale lorsqu'il s'agit de rendre compte des déficits linguistiques.
Une version modifiée de l'algorithme SEARMA est proposée pour l'estimation du spectre du signal de parole en présence d'un bruit de fond coloré. Les hypothèses suivantes sont utilisées pour la mise en œuvre de l'algorithme. Le processus de génération du signal de parole est modélisé par un modèle ARMA. Compte tenu de ces hypothèses le signal de parole peut alors être représenté par un modèle ARMA étendu. Dans cette formation, une estimation unique des paramètres AR de la fonction de transfert du conduit vocal peut être effectuée séparément si les paramètres MA du modèle du bruit peuvent être estimés séparément, mais l'estimation des paramètres MA du modèle de signal de parole nécessite l'hypothèse supplémentaire d'un rapport signal sur bruit élevé. La validité de la méthode proposée est illustrée par l'estimation spectrale à la fois de signaux de parole synthétique et naturelle en présence de bruit additif coloré et en comparant les résultats avec ceux obtenus par la technique LPC.
Dans ce papier, une méthode est présentée pour déterminer un index utile à la recherche dans des documents audio. La tâche diffère de l'indexation traditionelle de documents textuels, parce que les grandes bases de données sonores sont décodées par la reconnaissance automatique de la parole, et des erreurs de décodage s'y produisent fréquemment. L'idée centrale dans cet article est de profiter de la taille de la base de données pour choisir les meilleures termes d'indexation pour chaque document et ce en considérant les autres documents qui lui sont proches dans un espace vectoriel sémantique. Pour ce faire, le signal acoustique est d'abord converti en texte par un système de reconnaissance de la parole. Ensuite, le texte de chaque document est représenté par un vecteur qui est la somme normalizée des vecteurs des mots du document. Une grande collection de vecteurs de document est employée pour former une carte de Kohonen qui permet une classification des documents et une découverte des structures sémantiques dans la collection. Comme les documents des nouvelles lues sont courts et incluent des erreurs de reconnaissance de la parole, l'idée de lisser les vecteurs de document en utilisant les classes thématiques déterminées par la carte d'auto-organisation de Kohonen est introduite pour obtenir une meilleure indexation. Dans cet article, l'approche précédente est appliquée à l'indexation et à la recherche dans les documents de nouvelles télévisées et de radio. Les résultats expérimentaux sont donnés en utilisant les données d'évaluation de TREC pour la tâche de recherche dans les documents sonores.
Cet article propose trois types d'algorithmes d'adaptation au bruit qui permettent d'améliorer les performances des systèmes de reconnaissance de la parole en présence de bruit. Ce sont des techniques de correspondance de paramètres basées sur la quantification vectorielle qui transforment hiérarchiquement les vecteurs de paramètres bruités en vecteurs de paramètres pour des conditions normales. Le premier algorithme a déjà été utilisé dans le cadre de l'adaptation au locuteur non dirigée. Il est fondé sur une technique de classification catégorique qui adapte itérativement les données bruitées à un petit volume de données représentant la parole normale. Le deuxième algorithme est une version modifiée du premier. Il redéfinit la fonction de correspondance en utilisant la notion de portée d'une classe. Le dernier algorithme propose une classification floue à la place d'une classification catégorique. Dans le cadre de la base de données de chiffres NATO, ces techniques améliorent de façon importante les performances du système de reconnaissance de la parole du CRIM.
La méthode EXPULSE pallie l'une des principales limitations des techniques traditionnelles d'Analyse Spectrale à Haute Résolution ASHR (MUSIC, Norme minimale, etc.) à savoir la faible robustesse vis-à-vis d'une méconnaissance de leur nombre. Son originalité repose sur l'interprétation d'un périodogramme mis en œuvre sur un processus de raies pures noyées dans un brait additif, comme la convolution, à un bruit près, d'un processus composite Bemoulli-Gaussien avec une fonction spectrale parfaitement connue qui dépend de la calibration retenue du périodogramme (type de fenêtre d'apodisation, lissage temporel ou fréquentiel, etc.). Les fréquences discrètes où le processus de Bemoulli prend la valeur 1 sont des raies potentielles de l'espace signal ; le processus gaussien caractérise quant à lui l'amplitude des raies.
Depuis que les études d'impact des changements climatiques ont montré que le milieu marin pourrait être énormément fragilisé par la disparition de certaines espèces parmi la faune et la flore ainsi que par le vieillissement rapide des infrastructures sous-marines, de nouveaux outils d'observation efficaces et robustes deviennent nécessaires. Dans cet article, l'utilisation de caméras acoustiques comme outil novateur d'acquisition de données sousmarines est proposée en compagnie d'un cadre conceptuel qui permet de mettre en œuvre une reconstruction tridimensionnelle pertinente et complète de l'environnement sous-marin à partir de séquences d'images acquises par ces caméras acoustiques. Les différentes données et informations extraites, utilisables et utilisées pour élaborer ce travail ainsi que quelques résultats préliminaires sont abordés.
Une base de données d'environ 6500 syllabes et segments correspondants a été analysée pour développer un modèle de durée segmentale et syllabique pour l'Anglais Australien. La durée segmentale a été analysée en fonction du contexte prosodique. Les syllables ont été étiquetées suivant leur contexte prosodique, leur longueur (nombre de segments), et la nature des pics syllabiques. La durée syllabique a été modélisée en utilisant un réseau neuronique à trois couches qui a été entrainé et testé sur des portions différentes de la base de données. Les durées segmentales ont été étirées ou compressées pour correspondre aux durées syllabiques prédites par le réseau. Ce modèle syllabique relativement simple a permis de rendre compte de près de 80% de la variance des durées syllabiques observées dans la base de données.
La performance des systèmes actuels de reconnaissance de la parole automatique est considérablement compromise par des niveaux d'interférence acoustique (telle que du bruit additif et de la réverbération) qui sont représentatifs de conditions réelles. Des études sur la perception de la parole par des êtres humains et une analyse des bandes fréquencielles critiques suggèrent que la robustesse des systèmes de reconnaissance pourrait être améliorée en se focalisant sur la structure temporelle du signal qui apparaı̂t comme des modulations d'amplitude de basse fréquence (moins de 16 Hz) dans les sous-bandes. Une représentation de la parole soulignant cette structure temporelle, appelé “spectrogramme de modulation” (modulation spectrogram), a été développée. Des visualisations de la parole utilisant le spectrogramme de modulation sont relativement stables, malgré des niveaux élevés de bruit de fond et de réverbération. L'utilisation du spectrogramme de modulation apporte une amélioration de performance importante en présence de beaucoup de réverbération. La combinaison du spectrogramme de modulation avec le codage log-RASTA-PLP (log RelAtive SpecTrAl Perceptual Linear Predictive analysis) permet d'obtenir des améliorations significatives pour de nombreuses conditions de bruit et de réverbération.
Dans cet article, on présente une technique de pondération pour effectuer l'analyse LPC d'un signal de parole voisée. Les échantillons sont pondéres sur base de leur conformité au modèle de production de parole voisée. Dans les deux techniques de pondération présenées, la première choisit comme fonction de poids la fonction d'énergie à court-terme du signal de parole préaccentué, tandis que la seconde s'obtient par seuillage de cette même fonction d'energie. Dans les deux cas, la méthode proposée a pour effet de pondérer sélectivement les échantillons de parole qui correspondent bien au modèle de production. En conséquence, on obtient par cette méthode une estimation des paramètres LPC qui est à la fois plus précise et aussi moins sensible à la fréquence fondamentale que celle fournie par l'analyse LPC classique.
On sait que les performances des systèmes de reconnaissance peuvent être dégradées lorsqu'ils ont à traiter de la parole rapide. Si l'on peut détecter le fait que la parole est rapide, par des mesures de débit d'élocution, les modèles acoustiques et les modèles de langage peuvent être adaptés pour compenser les effets liés à cette parole rapide. Nous avons étudié diverses mesures de débit d'élocution qui ont l'avantage de pouvoir être faites avant la reconnaissance. Les mesures que nous proposons ont été comparées aux mesures conventionnelles, à savoir les débits de mots et de phonèmes sur la base de données TIMIT. Certaines des mesures proposées sont corrélées de façon significative avec le débit des phonèmes et la durée des voyelles. Nous avons montré que les écarts entre les durées réelles et attendues des voyelles test peuvent être réduits si les modèles de durée des voyelles sont adaptés au débit d'élocution, tel qu'estimé par les mesures proposées. Ces mesures peuvent être calculées à partir des indices employés communément en reconnaissance de parole.
La segmentation des images ROS (Radar à Ouverture Synthétique) consiste à produire une partition de l'image initiale en classes possédant certaines caractéristiques d'homogénéité au sens de la rétrodiffusion. A cet effet, un modèle statistique des images ROS polarimétriques est utilisé pour les segmenter en classes homogènes ayant chacune des caractéristiques de rétrodiffusion similaires. Cette segmentation utilise l'estimateur MAP (Maximum A Posteriori) que nous avons implémenté soit par l'algorithme déterministe ICM Modifié (Iterative Conditional Modes), soit par l'algorithme stochastique RS (Recuit Simulé). Pour cela un champ aléatoire de Markov représentant la distribution des étiquettes des classes est combiné avec un modèle (distribution Gaussienne ou distribution-K) représentant la distribution des données polarimétriques pour chacune des classes données. Les résultats de partition initiale et de segmentation obtenus sur une image mono-vue polarimétrique de la forêt des Landes, démontrent l'aptitude de l'algorithme proposé CMFMLAP-NSO à fournir une partition de bonne qualité d'une part et la capacité de l'algorithme ICM à affiner cette partition et à produire une segmentation de meilleure qualité d'autre part.
Six types de synthèse de la parole ont été évalués du point de vue de la compréhensibilité : analyse-synthèse LPC normale ; analyse-synthèse synchrone ; analyse synthèse synchrone à excitations multiples ; et trois techniques PSOLA. La compréhensibilité relative des types de synthèse fut testée en utilisant la parole synthétisée pour communiquer aux sujets l'information nécessaire pour remplir un questionnaire à choix multiples basé sur un diagramme.
L'application de ces théories aux réseaux bayésiens est incomplète et nous proposons une contribution, essentiellement via les nombres de couverture. Nous en déduisons de nombreux corollaires et notamment une approche non-fréquentiste pour l'apprentissage de paramètres et un score prenant en compte une mesure d'entropie structurelle qui affine les classiques mesures basées sur le nombre de paramètres seulement. Nous proposons alors des méthodes algorithmiques pour traiter de l'apprentissage qui découle de nos propositions, basées sur BFGS et l'affinage adaptatif du calcul du gradient.
Afin de faciliter l'accès et l'utilisation par les personnes du grand public des applications et services en informatique qui se répandent rapidement en particulier sur l'internet, il est nécessaire de proposer de nouveaux outils d'assistance qui offrent une interaction naturelle afin d'être mieux acceptés. L'approche des agents conversationnels semble prometteuse mais les agents ne peuvent pas se contenter d'opérer un raisonnement de type rationnel sur la structure et le fonctionnement des applications assistées. Ils doivent aussi exprimer des comportements psychologiques incluant des relations sociales, des traits de personnalité, des affects. Dans la première partie de l'article, nous proposons un cadre flexible pour modéliser les relations entre les réactions rationnelles et comportementales d'un agent assistant. Ensuite ce cadre est utilisé pour implémenter une première étude de cas, fondée sur la notion de biais cognitif.
Les systèmes de reconnaissance vocale sont maintenant utilisés dans des applications où ils doivent fournir une reconnaissance satisfaisante dans différentes conditions de bruit. Cependant, un écart entre les conditions d'entraı̂nement et de test est souvent à l'origine d'une serieuse baisse de performance des systèmes. Le succès de cette technique a été verifiée pour plusieurs expériences utilisant différents bruits de fond et microphones. La méthode proposée appliquée à la reconnaissance de chiffres indépendante du locuteur et dans un environement multiple a réduit le taux d'erreur de plus de 16%.
Ce papier présente un bilan des travaux comparant les performances des systèmes de reconnaissance de parole modernes à celles des locuteurs humains. Les comparaisons sont basées sur six types de corpus de parole avec des vocabulaires allant de 10 à plus de 65000 mots et des contenus allant des mots isolés à des conversations spontanées. Les taux d'erreurs des machines sont souvent supérieures de plus d'un ordre de grandeur à celles des humains pour la parole lue en atmosphère calme et transmise en large-bande. Les performances des machines se dégradent encore par rapport à celles des humains dans les contextes bruités, ou de qualité de transmission variable et pour la parole spontanée. Les locuteurs humains peuvent également reconnaitre, avec peu d'information linguistique de haut-niveau, des syllabes ou des phrases sans signification quand elles sont prononcées clairement dans des atmosphères calmes. Ces comparaisons suggèrent que l'écart important qui subsiste entre les performances des machines et celles des humains peut être réduit par des recherches de base sur les sujets suivants : l'amélioration de la modélisation acoustico-phonétique de bas-niveau, l'amélioration de la robustesse au bruit et à la variabilité des conditions de transmission, et la modélisation plus précise de la parole spontanée.
Cet article présente une contribution au domaine de la reconnaissance de locuteurs. Il traite de l'analyse de la parole par prédiction linéaire et examine la contribution en reconnaissance de ses deux composantes principales, le filtre de synthèse d'une part et le résidu d'autre part. Cette étude se fonde sur la propriété d'orthogonalité ainsi que l'importance physiologique de ces deux composantes, qui suggèrent que la reconnaissance du locuteur se basant exclusivement sur le filtre de synthèse peut être améliorée. En particulier, nous proposons une nouvelle représentation du résidu et nous examinons ses propriétés de reconnaissance au moyen d'expériences conduites dans un contexte de vérification du locuteur indépendante du texte. Ces expériences, utilisant à la fois des méthodes connues et nouvelles, nous permettent de comparer les contributions des deux composantes au succès de la reconnaissance. Nous commençons par comparer les méthodes séparément, puis conjointement. Nous conduisons ces expériences en utilisant la même base de données et la même méthodologie, caractérisée par la stricte séparation des ensembles d'apprentissage et de test. Les résultats obtenus démontrent l'utilité propre du résidu, même si elle apparaît moindre que celle du filtre de synthèse. Cependant, le résidu se montre particulièrement utile quand ces deux composantes sont combinées. Dans le cas reporté ici, un taux d'erreur de 5.7% a pu être réduit à 4.0%.
La possibilité de faire varier le type de locuteur et le style langagier sera un trait caractéristique de la prochaine génération de systèmes de conversion texte-parole. Déjà actuellement, la nécessité de telles possibilités se fait sentir dans les systèmes de dialogue et lorsque la synthèse de parole est utilisée comme prothèse pour les personnes souffrant d'un handicap de communication. Une grande part de l'information nécessaire n'est pas encore disponible. Dans cette contribution, nous prétendons que la synthèse de parole elle-même est un outil efficace pour étudier et comprendre la variabilité de la parole. Différentes méthodes sont passées en revue, représentant aussi bien les techniques d'analyse/synthèse et de manipulations du signal que de conversion texte-parole. Parmi les travaux du KTH, l'accent est mis sur l'étude de la variation du locuteur et des styles langagiers dans le contexte de notre système de conversion texte-parole.
Cet article propose une méthode originale de programmation des robots fondée sur l'inférence et l'apprentissage bayésien. Cette méthode traite formellement des problèmes d'incertitude et d'incomplétude inhérents au domaine considéré. La principale difficulté de la programmation des robots vient de l'inévitable incomplétude des modèles utilisés. Nous exposons le formalisme de description d'une tâche robotique ainsi que les méthodes de résolution. Nous l'illustrons en utilisant ce système pour programmer une application de surveillance pour un robot mobile : le Khepera. Pour cela, nous utilisons des ressources génériques de programmation appelées « descriptions » . Nous montrons comment définir et utiliser de manière incrémentale ces ressources (comportements réactifs, fusion capteur, reconnaissance de situations et séquences de comportements) dans un cadre systématique et unifié.
L'article présente une nouvelle approche dans le domaine fréquentiel à l'implémentation de postfiltres adaptatifs pour l'amélioration de la parole bruitée. Le postfiltre est décrit par un ensemble de coefficients TFD qui atténuent le bruit das les vallées spectrales et qui tolèrent plus de bruit dans les régions formantiques où il est masqué par le signal de parole. D'abord, nous effectuons une analyse LPC du signal bruité et nous calculons le spectre d'amplitude logarithmique de la parole á l'entrée. Après avoir identifié les formants et vallées (à l'aide d'une nouvelle méthode), le spectre d'amplitude logarithmique est modifié afin d'obtenir les coefficients du postfiltre. Le filtrage est aussi effectué dans le domaine fréquentiel à l'aide d'une TFR et d'une stratégie chevauchement-addition pour obtenir le signal postfiltré. Les résultats expérimentaux obtenus sur de la parole échantillonnée à 8 kHz montrent que cette nouvelle méthode fréquentielle produit de la parole améliorée d'une qualité perceptive meilleure que celle obtenue par une méthode temporelle. La nouvelle méthode est particulièrement efficace pour éliminer du bruit à haute fréquence et pour préserver les faibles formants à fréquence élevée des sonantes.
Des recherches antérieures ont montré que les attentes rythmiques jouaient un rôle important dans les langues présentant un contraste entre syllabes accentuées et syllabes non-accentuées, alors que le traitement perceptif des langues comme le français qui ne présentent pas ce contraste et dont les frontières syllabiques sont claires prendrait appui sur la syllabe. L'étude a porté sur la segmentation de mots disyllabiques contenant deux monosyllabes enchâssés. Deux expériences ont étudié l'effet sur les segmentations de la présence du schéma iambique usuel ou du schéma inverse. Le schéma iambique a entrainé plus souvent la reconnaissance des disyllabes, sans qu'apparaisse un effet de la fréquence des monosyllabes ou de leur structure syllabique. Le schéma trochaïque a fortement augmenté le nombre de segmentations. Dans l'expérience 2, la focalisation de l'attention sur la structure temporelle des séquences a renforcé ces effets. On en concluera que les auditeurs français ont utilisé une stratégie de segmentation métrique. Par contre, le traitement de spondées (expérience 3) a mis en évidence l'effet des paramètres structuraux sur les segmentations, ce qui suggère l'emploi d'une procédure de segmentation à base syllabique en l'absence d'information sur le rythme. L'apport de ces résultats à l'étude des modèles de la reconnaissance de la parole est précisé.
Le problème du conflit, intrinsèque à la fusion d'informations, a poussé à de nombreuses réflexions ces dernières années, en particulier dans le cadre de la théorie des fonctions de croyance. Nous pouvons résumer les solutions apportées par trois façons de considérer le problème : premièrement, nous pouvons chercher à réduire voire supprimer le conflit avant la combinaison d'informations, deuxièmement nous pouvons gérer le conflit de façon à ce qu'il n'intervienne pas lors de la combinaison et ne le considérer que lors de la prise de décision, et troisièmement nous pouvons prendre le conflit en compte lors de l'étape de combinaison. Si la première solution paraît la meilleure elle n'est pas toujours réalisable ou suffisante. Il peut être difficile de chercher à départager philosophiquement les deux dernières stratégies. c'est donc dans cette optique que nous comparons ces approches. Nous proposons ici une nouvelle règle qui a pour principe de répartir le conflit proportionnellement sur les éléments produisant ce conflit. Nous comparons les différentes règles à partir de données réelles en imagerie Sonar et en classification de cibles Radar.
Ce papier présente le développement d'une interface parole pour la commande d'un répondeur ou d'une messagerie vocale respectivement. La reconnaissance automatique de la parole a été intégrée pour faciliter la commande à distance et le tri des messages vocaux depuis n'importe quel téléphone et ce, en dialogue oral. Le but de ce développement était que les utilisateurs perçoivent l'interface parole comme bénéfique par rapport aux commandes DTMF plus classiques. Dans cet article, nous décrivons d'abord la technologie vocale utilisée dans le système. Ensuite on montre comment, se basant sur cette technologie, l'interface utilisateur a été conçue dans une approche descendante. Nous avons commencé par un premier développement que nous avons testé en utilisant la simulation Wizard-of-Oz. Après avoir perfectionné le concept dans un développement parallèle, celui-ci a été implanté dans un prototype “haute fidélité”. La conception a été améliorée en se basant sur trois itérations de tests qualitatifs auprès d'utilisateurs. L'atteinte de l'objectif de ce développement a été finalement validée par des tests utilisateurs dans deux pays.
Il est connu que la distorsion acoustique introduite par l'environnement ambiant ainsi que la variabilité résultant du stress induit détériorent énormément les performances des algorithmes de reconnaissance. Dans cet article, on explore les diverses causes de dégradation de ces performances. On suggère que les études récentes effectuées sur l'approche appelée Source Generator Framework produisent un fondement viable pour développer des techniques robustes de reconnaissance de la parole. L'étude décrite s'articule autour de trois axes corrélés : (i) l'analyse et la modélisation de la parole produite soit sous l'effet de stress du à la charge de travail et/ou à l'émotion, soit dans le bruit, (ii) les méthodes de traitement adaptatif du signal pour le débruitage de la parole et la réduction de l'effet du stress, et (iii) la formulation de nouveaux algorithmes robustes de reconnaissance. Une analyse statistique d'une base de données (SUSAS) de parole sous stress simulé et réel est présentée. Cette analyse a été menée sur plus de 200 paramètres relatifs au pitch, à la durée, à l'intensité, à la source glottique et aux variations des spectres du conduit vocal. Ces études ont motivé le développement de l'approche appelée Source Generator Framework qui permet de modéliser la dynamique de la parole sous stress. Ce cadre offre des moyens intéressants pour effectuer l'égalisation des paramètres de la parole sous stress. Dans la seconde moitié de l'article, trois nouvelles approches pour le débruitage de la parole et la réduction de l'effet du stress sont considérées. La première méthode utilise la technique itérative contrainte (Auto : I,LSP : T) de débruitage et une égalisation par maximum de vraisemblance de la parole à travers la localisation des formants et leurs bandes passantes. Pour la reconnaissance de mots clés, la seconde méthode utilise un réseau de neurones qui transforme les vecteurs de paramètres de la parole sous stress pendant la phase de paramétrisation. La dernière méthode applique une technique de rehaussement des paramètres basée sur des contraintes morphologiques pour effectuer le débruitage et utilise un algorithme adaptatif sur les cepstres-Mel pour égaliser les effets du stress. Les performances de reconnaissance sont données pour la parole produite dans plusieurs conditions de stress, avec plusieurs rapports signal/bruit, et pour différents types de bruit ambiant.
Dans ce papier, nous proposons un algorithme pour la communication entre agents dans le but d'apprendre quoi, à qui et quand communiquer. Nous nous appuyons pour cela sur l'utilisation d'agents introspectifs capables de raisonner sur leurs actions et sur leurs états afin de construire les actes de communication. Nous proposons une extension d'algorithmes d'apprentissage par renforcement définis sur les PDMpour la prise en compte de la communication multi-agent. Nous montrons comment il est possible de résoudre les problèmes liés à l asynchronisme et à la non-markovité des SMA par l'utilisation d'une mémoire des actions et des interactions de l'agent.
L'algorithme hybride DCT/PCM à compensation de mouvement a été adopté avec succès dans plusieurs standards de codage vidéo tels que H.261, H.263, MPEG-1 et MPEG-2. Toutefois, sa robustesse est mise à l'épreuve en cas d'allocation inadéquate des bits, soit globalement pour la séquence entière, soit localement comme résultat d'une distribution inappropriée des bits disponibles. Dans l'une ou l'autre situation, le compromis entre qualité et disponibilité des bits a pour résultat une détérioration de la qualité de la séquence vidéo décodée, à la fois en termes de perte d'information et d'introduction d'artefacts de codage. Ces distortions sont un facteur important dans les domaines du filtrage, de la conception du codec, et de la recherche de métriques de qualité objectives basées sur des concepts psycho-visuels ; de ce fait, cet article présente une analyse approfondie et une classification des nombreux artefacts de codage introduits dans la séquence vidéo reconstruite en utilisant l'algorithme de codage hybride MC/DPCM/DCT. Les artefacts qui ont déjàété brièvement décrits dans la littérature, tels que l'effet de bloc, le tremblement, l'effet moustique, le mésalignement MC, le flou, et le bavage des couleurs sont analysés en profondeur. Additionnellement, nous présentons des artefacts ayant des propriétés uniques et qui n'ont pas encore été identifiés dans la littérature.
La prochaine génération de systèmes de synthèse à partir du texte devra être plus sensible aux variations socio-linguistiques. Dans ce contexte, on a étudié plusieurs paramètres socio-linguistiques qui ont une influence sur la réalisation de la négation dans le langage parlé, en examinant leurs effets sur l'accentuation des négatives lors de la lecture de prose anglaise. Conformément aux observations faites lors d'une étude antérieure, cette analyse a montré que la prominence intonative n'est pas fréquente dans la lecture de prose et encore moins fréquente dans des dialogues lus. Les résultats montrent une étonnante absence de conformité avec les prédictions linguistiques 'théoriques'.
Quand nous communiquons par la parole (naturelle), nous ne disons pas explicitement tout. Tant le locuteur que l'auditeur utilisent des informations liées à la situation de communication qui incluent les états mentaux des deux interlocuteurs. Des cas intéressants sont fréquemment observés lors de l'usage du Japonais dans des situations de dialogue. Les contraintes syntaxiques (ou configurationnelles) du Japonais sont plus faibles que celles de l'Anglais : le locuteur japonais peut omettre presque n'importe quel élément de l'enoncé. Dans cet article, on présente une modélisation de l'auditeur en phase de raisonnement dépendant de la situation e'on montre comment l'information manquante peut être fournie par la situation. Bien que ce modéle capture, à notre avis, les caractéristiques essentielles de la communication, il est peut-être trop naïf pour servir de modéle de la cognition humaine. Ce modéle vise plutôt à être utilisé dans l'élaboration d'agents logiciels communiquant entre eux d'une façon mécanique mais flexible et efficace.
L'évidence d'un contrôle syntaxique sur la structuration prosodique d'un énoncé en français a été exploitée dans de nombreux modèles de génération. Pourtant, des modèles sans connaissances syntaxiques, basés seulement sur des contraintes de type rythmique peuvent générer des structures prosodiques acceptables. Le modèle présenté ici montre que les stratégies dirigées par la syntaxe et celles dirigées par le rythme peuvent être considérées comme des cas extrêmes d'un modèle plus complexe intégrant à la fois des contraintes syntaxiques et rythmiques. Ce modèle de génération a été intégré dans divers systèmes de synthèse à partir de texte. Des tests perceptifs comparatifs ont montré l'amélioration de qualité par rapport à un système guidé par une connaissance syntaxique élémentaire.
Cet article décrit l'implémentation d'un nouveau modèle paramétrique de la géométrie de la glotte qui a pour but d'amélioration, la synthèse de voix masculines et féminines dans le cadre d'une analyse/synthèse articulatoire. Ce modèle est inclu dans un système d'analyse/synthèse articulatoire visant une simulation articulatoire de la parole. Pour introduire dans les ondes synthétiques du flux glottique des détails que l'on observe au naturel, deux types de fuite différents ont été modélisés : la fuite couplée et la fuite parallèle. Alors que la première correspond, en principe, à une fermeture incomplète de la glotte, la deuxième correspond à la modélisation d'un conduit glottique supplémentaire, indépendant de la partie membranique (vibratoire) de la glotte. Ces deux types de fuite ont pour trait caractéristique commun d'augmenter le flux DC et l'interaction source/conduit vocal. Toutefois, une fuite couplée produit une pente plus forte du spectre du flux glottique, alors qu'une fuite parallèle réduit l'énergie plus fortement dans les basses fréquences que dans les hautes fréquences. En fait, pour une fuite parallèle, la pente dans les hautes fréquences est à peu près la même que celle qu'on observe dans les cas sans fuite.
Dans les systèmes de reconnaissance de la parole, la robustesse à l'environnement par adaptation des paramètres peut être obtenue de deux façons complémentaires. Une première approche consiste à modifier les paramètres acoustiques de la parole dégradée par l'environnement de façon à ressembler aux paramètres de la parole (habituellement non dégradée) qui a été utilisée lors de l'entraı̂nement. La deuxième solution est de modifier les paramètres statistiques internes au reconnaisseur de façon à mieux représenter les caractèristiques de la parole dégradée dans un environnement cible particulier. Le présent papier tente d'unifier ces deux approches de reconnaissance robuste de la parole en présentant plusieurs techniques qui partagent les mêmes hypothèses de base et la même structure, tout en différant dans le choix de savoir si elles modifient les paramètres d'entrée ou les paramètres statistiques du reconnaisseur. Nous présentons ici la famille d'algorithmes basés sur la normalisation cepstrale gaussienne multi-variable (RATZ) qui modifient les caractéristiques cepstrales d'entrée, ainsi que les algorithmes STAR (re-estimation statistique), qui modifient les paramètres internes du reconnaisseur. Les deux types d'algorithmes sont basés sur les données et utilisent une certaine quantité de donnée d'adaptation pour estimer les paramètres de compensation. Les algorithmes ont été évalués en utilisant le système de reconnaissance SPHINX-II sur un sous-ensemble de la base de donnée Wall Street Journal. Bien que tous les algorithmes conduisaient une amélioration des performances en comparaison des algorithmes précédents, la famille d'algorithmes STAR donnait généralement des taux d'erreur plus faibles que la famille d'algorithmes RATZ lorsque le rapport signal/bruit diminuait.
Le matériel décrit et les résultats d'essais présentés sont ceux de l'équipement testé dans le cadre du concours européen qui s'est déroulé à Turin en Italie. Ce codeur-décodeur offre une bonne qualité vocale et plusieurs avantages importants comme par exemple un faible temps de propagation, une faible complexité des calculs et une bonne tolérance en présence d'erreurs de transmission. Ce codeur-décodeur fait appel à un algorithme de codage en sous-bandes, à 8 bandes, avec quantification et prédiction, toutes deux adaptatives vers l'arrière. Le matériel dont la mise en ocuvre est décrite fait appel à une paire de dispositifs de traitement des signaux numériques, ce qui lui permet d'être très compact. Ce document récapitule également le résultat des essais subjectifs et objectifs.
Cet article concerne les relations prosodiques perçues dans la prose, dans la poésie et dans la musique, en mettant l'emphase sur les caractéristiquesde durée. Pour approfondir notre compréhension de la prosodie du langage parlé, nous nous sommes pour l'instant attachés à comparer les relations temporelles observables dans des activités telles que la lecture de la poésie et l'exécution musicale, activités où l'on observe habituellement une structure rythmique très marquée des séquences de sons produites. On peut aussi trouver des parallèles très intéressants en comparant les notations formelles de la prose, de la poésie et de la musique. En général, il n'y a aucune relation simple entre la notation formelle et l'exécution et, de plus, les systèmes de notation ont varié avec la tradition et suivant des besoins spécifiques. Pourtant, il y a là un défi : essayer de lier plus étroitement les systèmes descriptifs aux contraintes humaines de production et de perception des sons.
Cet article présente une méthode basée sur la décomposition harmonique du spectre de Hildebrand–Prony. Cette analyse spectrale de Hildebrand–Prony est appliquée pour sa haute résolution et sa précision. Des tests comparatifs avec des indices LP et LP-cepstraux ont été réalisés sur 50 sujets provenant de la base de données slovène SNABI (corpus de mots isolés) et sur 50 sujets allemands provenant de la base de données BAS Siemens 100 (phrases). Sur ces deux bases de données les avantages des indices harmonique ont été observés surtout pour l'identification des locuteurs.
Cet article présente une méthodologie pour quantifier la distorsion apportée par un codeur de parole à bas ou moyen débit. Puisque c'est l'acuité perceptive de l'être humain qui fixe la précision avec laquelle on doit traiter le signal de parole, celui-ci est transformé en une représentation perceptive ; on utilise pour cela le modèle cochléaire (auditif) de Lyon, dont les sorties représentent la probabilité d'excitation des fibres nerveuses à un instant donné. Nous utilisons dans ce travail un modèle de Markov caché pour modéliser le processus élémentaire d'excitation/non excitation opératoire dans le système auditif. Un modèle d'ordre un, à deux états et complètement connecté est associé à chaque canal neuronal ; les deux états du modèle représentent les événements d'excitation et de non-excitation. En supposant les modèles stationnaires sur une durée fixe, leurs paramètres sont calculés à partir des représentations perceptives du signal original. Ensuite, les représentations perceptives de la parole codée passent à travers les modèles correspondants et les probabilités associées sont calculées. Ces scores permettent de définir une mesure de distorsion à partir d'une “cochlée markovienne caché” (CHM). Cette méthode prend en compte la succession temporelle des profils de l'excitation neuronale. La mesure CHM, qui prend en compte l'information contextuelle présente dans le profil d'excitation, est robuste vis à vis du délai de codage.
Nous présentons ici un prototype complet et opérationnel intégrant la compression et la reconnaissance de gestes dansés issus d'un ballet contemporain. Les données traitées sont des trajectoires de mouvement suivies par les articulations d'un corps dansant. Nous proposons un outil efficace pour le sous-échantillonnage non uniforme de signaux spatio-temporels. Notre approche utilise une approximation polygonale des contours pour construire une représentation compacte et efficace des trajectoires de mouvement. Notre méthode de reconnaissance de gestes dansés repose sur un ensemble de Modèles de Markov Cachés (MMC) chacun étant associé à la trajectoire d'un marqueur. Nous avons validé notre système de reconnaissance sur 12 mouvements de base effectués par 4 danseurs d'un ballet contemporain.
Les techniques de recherche d'information s'appuient sur l'extraction de termes dans les documents, termes qui servent de base pour l'accès à ces documents. Nous proposons dans cet article une approche pour permettre une extraction plus riche sémantiquement en intégrant des connaissances issues d'un thesaurus et de corpus de domaine. Plus spécifiquement, nous proposons une méthodologie visant à transformer un thesaurus préexistant en une ontologie légère de domaine qui sera utilisée pour indexer sémantiquement une collection de documents. Nous proposons également des techniques assurant cette transformation et une évaluation dans le domaine de l'astronomie.
Nous rapportons les résultats d'une étude EPG que montrent qu'on ne peut interpréter l'organisation des gestes articulatoires comme la simple concanténation de segments assimilés.
Entre 1399 et 1400, Christine de Pizan rédige son Epistre Othea. Soixante ans plus tard, Jean Miélot rédige un remaniement de cette œuvre à succès pour la cour des ducs de Bourgogne. Outre une mise au point sur les véritables particularités de Jean Miélot sur ses contemporains tels Jean Wauquelin ou David Aubert, le présent article entend contextualiser à la fois le texte-source et le texte cible, pour tenter de répondre à la question de l'émergence du remaniement de Miélot, mais aussi des possibles explications de son absence de diffusion. Au final, on constate que l'approche traditionnelle, textuelle et philologique, ne rend pas compte entièrement de la réception d'un texte dans un contexte, et que celle-ci doit dès lors se doubler d'une approche factuelle et contextualisée.
Les caractéristiques spectrales sont décrites par les vecteurs cepstraux et les vecteurs cepstraux normalisés ; leur vitesse de variation par les vecteurs des coefficients orthogonaux de premier ordre. Ces vecteurs ont été employés, soit séparément, soit unifiés dans un seul vecteur, dans des procédures de vérification qui se basent sur un algorithme DTW. Les expériences effectusées sur une population de 22 locuteurs (conditions acoustiques favorables), ont montré qu'en éliminant de la phrase d'essai la partie du spectre constante dans le temps, ce qui a lieu explicitement par la normalisation cepstrale et implicitement par le calcul des coefficients orthogonaux de premier ordre, on obtient une réduction des taux d'erreurs. De plus, la performance de la vitesse de variation des caracteéristiques spectrales est comparable à celle des caractéristiques spectrales elles-mêmes, tandis qu'une combinaison des deux types d'information spectrale ne donne pas d'améliorations ultérieures.
La communication présente un modéle pour l'analyse du signal de parole fondé sur les aspects déjà connus du système auditif périphérique. L'objectif principal de ce travail est de formuler des transformations de signal qui préservent et accentuent les caractéristiques du signal de parole indispensables a la perception. On présente un modèle d'ordinateur du système auditif périphérique qui incorpore les phénomènes de synchronisation, de suppression à deux tons, et d'adaptation additive. Les recherches récentes sur la physiologie de l'audition ont mis en lumière l'importante contribution de ces phénoménes à la perception normale de la parole. Le modéle proposé peut accentuer les régions spectrales dynamiques telles qu'on les trouve dans la parole conversationnelle normale.
Cet article présente des méthodes d'évaluation de la qualité pour les postes téléphoniques mains-libres, à partir de différents exemples. Des résultats de mesures “instrumentales” (objectives) obtenus avec les différents postes mains-libres testés sont présentés, avec les méthodes de mesure correspondantes.
Nous présentons dans cet article une stratégie de recherche génétique pour un moteur de recherche. Nous commençons par montrer que des relations importantes existent entre les études statistiques des propriétés du Web. Les moteurs de recherche fondés sur les approches à base d'agents, et les techniques utilisées classiquement en optimisation : le Web est un graphe qui peut être exploré à l'aide d'une fonction d'évaluation et d'opérateurs fondés sur la création ou l'exploration locale. Il devient alors possible de définir une fonction d évaluation qui est une formulation mathématique de la requête de l'utilisateur et de définir un algorithme génétique qui fait évoluer une population de pages avec des opérateurs spécifiques. La création d individu consiste à interroger des moteurs classiques. La mutation consiste à explorer le voisinage d'une page grâce à ses hyperliens. Nous présentons des résultats comparatifs obtenus avec un protocole de tests directement calqués sur ceux utilisés en optimisation.
Cet article présente un modèle pour la création d'un agent synthétique pouvant exprimer des performatifs à l'aide d'expressions faciales. Le performatif d'un acte parlé ou d'un acte communicatif est l'intention communicative particulière que celui qui parle a envers son interlocuteur, la relation sociale que celui-ci veut établir avec celui-là. Les performatifs sont décomposés suivant leur signification et leur signal : du point de vue de la signification, un performatif est représenté par un ensemble d'unités cognitives, qui à leur tour incluent des sous-structures sur le but général de celui qui parle (informer, demander, solliciter), sur la relation de pouvoir entre celui qui parle et celui qui écoute, sur l'état émotif du premier, et sur d'autres informations particulières liées à des performatifs spécifiques ; pour le signal, les expressions faciales sont décomposées en Unités d'Action. Le système proposé ici calcule le performatif approprié pour un acte communicatif en considérant le contexte de la communication, plus particulièrement la capacité cognitive, les relations sociales et la personalité de l'interlocuteur. Ensuite le système exprime les performatifs calculés par des expressions faciales.
L'article se centre sur les différences vocaliques entre parole spontanée et parole de laboratoire en espagnol. Les premier et second formants de 954 réalisations vocaliques ont été mesurés (477 en parole de laboratoire et 477 en parole spontanée). Ils constituent des agrégats dans l'espace F 1/F 2. L'article décrit les variabilités inter et intra agrégat induites par le changement de situation de communication. En parole spontanée, les valeurs formantiques présentent (1) une tendance marquée vers schwa ; (2) une augmentation de la variabilité intra cluster. Les deux phénomènes produisent une diminution de la différenciation des sons en parole spontanée.
Un système automatique de reconnaissance du locuteur, indépendant du texte, est présenté. Le système est basé sur la localisation de voyelles dans la parole testée, l'extraction des vecteurs de paramètres et leur classification en utilisant un ensemble de références dépendant du locuteur. Cet ensemble contient L prototypes par locuteur, qui représentent les voyelles de la langue. Les prototypes sont formés par l'application d'un algorithme “k-means” à L groupes aux vecteurs de voyelles extraits du texte d'apprentissage du locuteur. Le système a été testé pendant quatre mois sur une population de 15 locuteurs masculins et féminins et avec des textes non corrélés aux textes d'apprentissage. L'exactitude mesurée du système (91.39% pour la vérification, 90.19% pour l'identification dans un ensemble fermé de locuteurs et 92.28% dans un ensemble ouvert) est satisfaisante en considérant que les énoncés de l'apprentissage ont une durée inférieure à 50 sec et les énoncés testés une durée moyenne de 1.3 sec. L'exactitude est significativement accrue quand on augmente la dureé de l'énonce testé (p.e. 93.75% pour la vérification avec des énoncés de 4 sec de moyenne). D'autres avantages du système sont la petite mémoire exigée et sa rapidité.
Il s'agit de déterminer l'appartenance effective de points de contour obtenus par une méthode de segmentation par contour actif au cortical. Plusieurs paramètres associés à chacun de ces points sont pris en compte (niveau de gris, niveau de gris moyen et écart type sur un voisinage, distance entre points appartenant à des coupes voisines). L'architecture est basée sur le formalisme de la théorie de l'évidence. Nous discutons des résultats obtenus, de leur validité et nous donnons les perspectives envisagées de la suite de ce travail.
L'analyse temps-fréquence des signaux magnétiques, générés par des objets ferromagnétiques sous-marins, est utilisée afin de trouver un ensemble de paramètres discriminants pour leur classification. Après l'étape de sélection de caractéristiques, une étude étendue est menée pour comparer différentes structures de classifieurs, en fonction du taux moyen de bonne classification et de la capacité de généralisation.
Si les SVM (Support Vector Machines, ou Séparateurs à Vaste Marge) sont aujourd'hui reconnus comme l'une des meilleures méthodes d'apprentissage, ils restent considérés comme lents. Nous avons choisi de coder cet algorithme dans l'environnement Matlab afin de profiter de sa convivialité tout en s'assurant une bonne efficacité. La comparaison de notre solution avec l'état de l'art dans le domaine SMO (Sequential Minimal Optimization), montre qu'il s'agit là d'une solution dans certains cas plus rapide et d'une complexité moindre.
Nous proposons dans cet article une méthode 3D d'estimation du flot optique conduisant à un recalage non-rigide monomodalité de volumes cérébraux. La formulation énergétique du problème est enrichie par l'utilisation d'estimateurs robustes. De plus un schéma d'optimisation efficace, multirésolution et multigrille, est proposé afin d'accélérer la recherche et d'améliorer la qualité de l'estimation. Les apports de cette méthode sont démontrés sur des données réelles et ses performances sont quantitativement évaluées sur des données simulées.
A partir d'un corpus de logatomes de type CVCVCV où la consonne est [b] ou [m] et la voyelle [a i u], nous avons étudié le comportement des muscles orbicularis oris superior et levator veli palatini. L'importance de la préplanification globale de la séquence (rôle de la position initiale servant de référence) et du rééquilibrage intrasegmental du timing a étéévaluée dans le cadre d'une théorie de l'encodage moteur basée sur les notions de “sequencing” et de “phasing”. D'autre part, nos données confirment que la synchronisation musculaire constitue bien une règle de base.
Dans de nombreux domaines (biologie, médecine, psychologie, etc.), des outils de fouille de textes efficaces permettraient d'économiser un temps de travail énorme. Afin d'avoir un outil utilisable par des spécialistes du domaine, ce dernier doit couvrir les différentes étapes de la fouille de textes. L'approche que nous proposons dans cet article consiste à extraire les règles d'associations propres au domaine à partir d'un ensemble de textes homogènes spécialisés. Notre approche est composée de différentes étapes dans lesquelles l'expert du domaine joue un rôle essentiel. La première étape consiste à extraire les termes dans les textes et à les associer à un concept, c-à-d. un ensemble de termes ayant la même sémantique. En utilisant cette nouvelle connaissance propre au domaine, le corpus initial est réécrit sous forme matricielle. La dernière étape de notre approche, consiste à discrétiser la matrice obtenue à l'étape précédente afin d'en extraire les règles d'association propres au domaine.
Cette contribution traite le problème de l'apprentissage par renforcement inverse (ARI), défini comme la recherche d'une fonction de récompense pour laquelle le comportement d'un expert (connu par le biais de démonstrations) est optimal. Nous introduisons SCIRL, un nouvel algorithme qui utilise la grandeur dénommée attribut moyen de l'expert comme la paramétrisation d'une fonction de score pour un classifieur multiclasse. Cette approche donne une fonction de récompense pour laquelle la politique de l'expert est (nous le démontrons) quasi optimale. Contrairement à la plupart des algorithmes d'ARI existants, SCIRL n'a pas besoin de résoudre le problème direct de l'apprentissage par renforcement. De plus, en utilisant une heuristique, il fonctionne avec uniquement des trajectoires échantillonnées par l'expert. Nous illustrons cela sur un simulateur de conduite.
Cet article introduit une nouvelle méthode de tatouage pour la protection d'images fixes. La méthode permet de cacher une signature dans une image, sous la forme de w paquets de r bits. Le schéma de tatouage est additif, et la marque elle-même est calculée par addition de produits de couples de fonctions orthogonales. Nous montrerons comment le choix des fonctions orthogonales peut être fait, de façon à rendre le tatouage robuste face à différents types d'attaques.
La structure de base du codeur comporte un prédicteur à long terme qui est implanté comme un dictionnaire adaftatif, tandis qu'un dictionnaire Gaussien creux avec des vecteurs non recouvrants est utilisé pour l'excitation stochastique. Pour satisfaire les contraintes d'implantation, nous avons adopté plusieurs méthodes de recherche de codes. Avec ces méthodes, la charge de calcul du codeur de base peut être réduite à 12.4 MIPS, avec un dictionnaire de codes stochastiques à 7 bits. Nous ètudions une recherche hiérarchique á deux étages dans le dictionnaire adaptatif. Cette méthode de recherche ŕeduit la charge de calcul, au prix d'une dégradation légére des performances du codeur. La qualité du codeur CELP est jugée voisine de celle du codeur G.722 à 48 kbit/s.
Sacadeau-Software est un logiciel d'aide à la décision destiné aux agronomes travaillant sur la pollution de l'eau dans les bassins versants et aux personnes en charge de la gestion de ces bassins versants. Cet outil se focalise sur la maîtrise de la contamination des eaux par les pesticides apportés sur les cultures de maïs. Il s'appuie sur un modèle incluant la représentation, d'une part, des processus biophysiques de transfert des pesticides à l'échelle d'un bassin versant et, d'autre part, des processus de décision dans le cadre de la culture du maïs. Sacadeau-Software permet de lancer des simulations des cultures pour toutes les exploitations de l'ensemble d'un bassin versant et d'obtenir le taux de transfert des polluants à l'échelle du bassin versant. Des règles caractérisant les sous-parties du bassin versant ayant une pollution de l'eau à l'exutoire, et les sous-parties sans pollution, sont inférées automatiquement à partir des simulations effectuées. Un outil de visualisation permet alors de faire le lien entre les règles apprises et les exemples caractérisés par ces règles. Enfin, un outil de recommandation d'actions propose, à partir des règles apprises, des actions propres à améliorer une situation de pollution.
Les variations dans la production de parole dues au stress induit contribuent de manière significative à la réduction des performances des systèmes de traitement de parole. Pour estimer ces variations, une approche consiste à établir une classification objective du stress du locuteur, basée sur le signal acoustique. Cette étude propose un algorithme pour l'estimation de la probabilité du stress induit. Le taux de stress prédit par cet algorithme peut être intégré dans des algorithmes de traitement de parole afin d'augmenter leur robustesse dans des environnements difficiles. Les résultats d'une étude précédente sur la classification du stress sont d'abord utilisés pour sélectionner un ensemble de paramètres de parole relatifs au phonème et au type de stress. Une analyse des paramètres articulatoires, d'excitation et cepstraux est conduite sur une base de données de parole sous stress (“Speech Under Simulated and Actual Stress” (SUSAS)). Les paramètres sensibles au stress sont ensuite sélectionnés pour dix conditions de stress (incluant le cockpit d'un hélicoptère Apache, la colère, la parole claire, l'effet Lombard, la voix forte, etc.) et sont incorporés dans un réseau de neurones appris pour classifier le degré de stress. Sur un ensemble fermé de locuteurs et pour un ensemble ouvert de stimuli de parole, il produit un taux de bonne classification de 91.0%. Finalement, l'algorithme de classification du stress est incorporé dans un système de reconnaissance de parole où un modèle de Markov est appris pour chaque condition de stress. Avec cette nouvelle approche de reconnaissance “dépendante du stress”, on obtient une amélioration des performances de 10.1% et de 15.4%, respectivement, par rapport aux systèmes de reconnaissance appris avec de la parole neutre et avec différents styles de parole.
Il est possible de différencier, à l'écoute, la parole lue et la parole spontanée. La prosodie semble être essentielle pour faire cette distinction. Dans cet article, on étudie l'importance des distributions et réalisations des frontières prosodiques. Des monologues spontanés (appelés monologues “d'instruction”), émis par cinq locuteurs masculins, ont été enregistrés. Les transcriptions de ces monologues ont été lues à haute voix par les mêmes locuteurs. Une expérience de perception a été menée pour obtenir des scores de classification sur les phrases isolées extraites des énoncés spontanés et lus. Des transcriptions prosodiques de l'ensemble des monologues spontanés et lus ont permis d'évaluer la distribution et la réalisation des frontières prosodiques sous-jacentes dans les deux types de parole. La structure prosodique sous-jacente a été estimée en utilisant un systm̀ee automatique de synthèse de parole. Les différences, entre parole lue et parole spontanée, observées dans la production des frontières prosodiques ont été reliées aux scores de classification perceptive par une analyse de régression multiple.
Cet article décrit un algorithme performant et efficace pour la reconnaissance en parole continue de larges vocabulaires. II est basé sur un analyseur LR à deux niveaux et utilise des modèles de Markov comme modèles de phonèmes. Pour améliorer les performances de reconnaissance, il utilise la probabilité des treillis avant et arrière. Pour améliorer l'efficacité de la recherche, il utilise des fenêtres variables, combine en un seul les candidats qui présentent les mêmes séquences d'allophones et ont le même état grammatical et combine ensuite les candidats au niveau du sens. Pour évaluer ses performances en mode indépendant du locuteur, cet algorithme a été utilisé dans un système d'accès à un annuaire téléphonique comportant plus de 70 000 noms (environ 80 000 mots). Pour 8 locuteurs, cet algorithme fournit un taux de 65% de compréhension de la parole spontanée. Ces résultats montrent que le système est efficace malgré la grande perplexité du vocabulaire. Cet article décrit également un système de dialogue multi-modal qui utilise ce système de reconnaissance de grands vocabulaires.
L'utilisation de transformations du signal est une étape nécessaire pour l'extraction de traits dans des systèmes de reconnaissance des formes. Ces transformations doivent prendre en compte le but pricipal de la reconnaissance des formes : la minimisation du taux d'erreur. Dans cet article, nous proposons une nouvelle méthode pour obtenir des transformations de l'espace des traits, basée sur le critère de minimisation de l'erreur de classification. Le but de ces transformations est d'obtenir un nouvel espace de représentation dans lequel la distance euclidienne est optimale pour la classification. La méthode proposée est testée dans le cadre d'un système de reconnaissance de parole utilisant divers types de Modèles de Markov. La comparaison avec des techniques de prétraitement standard montre que notre méthode fournit une réduction du taux d'erreur dans tous les contextes expérimentaux étudiés.
Nous étudions plusieurs méthodes pour accomplir la deuxième tàche, en insistant sur les avantages et désavantages d'une approche par diphones basée sur la prédiction linéaire. Les diphones nécessitent plus de mémoire ordinateur afin de representer toutes les transitions possibles eentre couples de phonèmes, mais ils incorporent en grande partie les effets de coarticulation qui sinon devraient étre modélisés lors de la synthèse phonémique. Les règles d'interpolation sont simples parce qu'au niveau spectral les frontières entre diphones sont similaires.
Cet article traite de la prédiction de la qualité vocale transmise par une ligne téléphonique. On commence par présenter une définition du terme `qualité' qui prend en compte aussi bien des facteurs de communication que des facteurs relatifs au service téléphonique, et on propose un nouveau schéma de classification. Ce schéma considère les paramètres d'entrée et de sortie du modèle, les composants du réseau considérés et les domaines d'applications pour lesquels un modèle est utilisé, ainsi que des données psychoacoustiques et de jugement. Selon ce schéma, les modèles de prédiction de la qualité peuvent être classifiés sous trois classes : les mesures comparatives à base de signaux, les modèles de planification de réseau, et les modèles de surveillance de réseau. Les mesures comparatives étant discutées amplement dans la littérature, on se limite aux deux dernières types de modèle. Les bases psychoacoustiques des deux modèles de planification les plus connus (le modèle E et le modèle SUBMOD) sont discutées en détail, et – en combinaison avec d'autres modèles – utilisées pour développer des approches de surveillance. On discute des extensions potentielles de ces modèles, qui incluent la transmission à large bande, la modélisation de la qualité de la voix transmise, les prédictions pour les perturbations non-stationnaires, ainsi que l'application des modèles à la prédiction des effets de la transmission téléphonique sur la reconnaissance et la synthèse vocale.
Nous proposons une méthode de discrimination non paramétrique conçue pour favoriser l'interprétabilité de la prédiction. D'une part, l'utilisation d'un modèle additif généralisé permet de représenter graphiquement l'effet de chaque variable d'entrée sur la variable de sortie. D'autre part, les paramètres de ce modèle sont estimés par vraisemblance pénalisée, où le terme de régularisation généralise la pénalisation h aux fonctions splines. Cette pénalisation favorise les solutions parcimonieuses sélectionnant une partie de l'ensemble des variables d'entrée, tout en permettant une modélisation flexible de la dépendance sur les variables sélectionnées. Nous étudions l'adaptation de différents critères de sélection analytiques à ces modèles, et nous les évaluons sur deux jeux de données réelles.
Cet article présente un aperçu des recherches entreprises au Japon, relatives à l'information individuelle véhiculée par l'onde de parole. Alors que les corrélats physiques des traits perceptifs de l'identité de la voix ont été étudiés du point de vue psychologique, la recherche menée du point de vue de l'ingénieur se rattache à la reconnaissance automatique du locuteur, à la reconnaissance de la parole indépendante du locuteur, et aux algorithmes d'apprentissage en reconnaissance de la parole. La recherche en reconnaissance du locuteur peut être cataloguée en deux classes, selon que le texte est prédéterminé ou non. Cependant, il a été mis en évidence que, même si le texte n'est pas prédéterminé, l'information individuelle dépendante du texte peut être utilisée et ce, sur base de la reconnaissance explicite ou implicite du phonème. Divers exemples de méthodes de reconnaissance du locuteur sont classées ici selon ces variantes et leurs performances sont présentées. En particulier, cet article éclaire la variabilité à long terme des paramètres intra-locuteur comme l'un des problèmes les plus cruciaux en reconnaissance du locuteur. En plus, cet article présente une étude des méthodes destinées à réduire les effets de la variabilité spectrale à long terme sur la précision de la reconnaissance.
Cet article présente un algorithme d'apprentissage non supervisé par chaînes de Markov cachées (CMC) et algorithmes génétiques (AG). Deux des problèmes rencontrés lors de l'utilisation des CMC sont de déterminer les probabilités de la CMC et le nombre d'états de cette chaîne. Bien souvent, ce nombre d'états est déterminé soit par expériences successives, soit à l'aide de connaissances a priori du domaine. L'algorithme présenté ici emploie un algorithme génétique afin de déterminer le nombre d'états cachés de la CMC ainsi que les différentes probabilités qui la constituent. Cet algorithme est couplé à l'algorithme de Baum-Welch qui permet une réestimation efficace des probabilités de la CMC. Différents algorithmes, hybrides ou non, sont comparés entre eux sur une application d'apprentissage et de reconnaissance d'images représentant des visages. Les résultats montrent la supériorité de l'approche génétique pour ce type de problème.
Un algorithme hybride de codage, consistant en une prédiction intertrame compensée en mouvement et en une quantification vectorielle adaptative pour le gain et la forme, est proposé pour le codage vidéo à faible débit. Un système de codage vidéo utilisant l'algorithme proposé et ces caractéristiques de codage sont également décrits. La prédiction intertrame compensée en mouvement est une technique efficace pour réduire la redondance temporelle contenue dans les images en mouvement. Dans la méthode proposée, des blocs d'amplitude constante (blocs de niveaux de gris) sont aussi inclus dans les vecteurs cherchés pour augmenter l'efficacité de codage pour des mouvements rapides d'objects ou de changement de scène. La quantification vectorielle adaptative pour le gain et la forme, avec un livre de code à recherche arborescente, est utilisée pour coder les signaux de différences intertrames compensés en mouvement. Elle peut correspondre aux changements de statistique de la source car le livre de code est indépendant des composantes de gain des vecteurs d'entrée. L'algorithme de codage proposé a été évalué par simulation sur ordinateur et apparaît efficace pour la transmission de vidéo à faible débit. Un système de codage de vidéo à 64 kbit/s basé sur cet algorithme de codage a été implanté. Le système de codage développé peut transmettre des données numériques, de l'audio et du vidéo multiplexé à la cadence de base du RNIS et peut être appliqué au vidéotéléphone aussi bien qu' à la vidéoconférence.
Cette introduction a pour but d'élaborer le cadre général auquel appartiennent les articles rassemblés ci-dessous. Elle s'adresse à deux problèmes importants dans l'étude du traitement lexical : l'identification des différentes étapes dans la reconnaissance de mots et la caractérisation des divers types d'influences contextuelles sur ces étapes. Nous essayons de décomposer les processus de reconnaissance de mots en plusieurs étapes ayant des conséquences aux niveaux théorique. Nous adoptons également une approche analytique en traitant des influences dues au contexte, en distinguant plusieurs types de contexte (lexical, intra-lexical, syntaxique, sémantique et interprétatif). Une telle démarche est nécessaire si nous voulons rendre explicite le rapport entre tel ou tel type d'information contextuelle et l'étape oùs'exerce son influence.
Le cadre général de ce travail est celui de l'analyse et de la synthèse de la parole par ordinateur. Le signal de parole peut être scindé en deux composantes principales : (1) une composante périodique (constituée des éléments quasi-périodiques (ou voisés) produits par une vibration quasi-régulière des cordes vocales) ; (2) une composante apériodique ou de bruit (constituée des éléments de nature aléatoire pouvant survenir durant un son voisé (i.e. bruit fricatif dans le phonème /v/) ou en l'absence de vibration des cordes vocales (i.e. bruit fricatif dans /s/, /t/, etc.)). Le but de ce travail est d'apporter une contribution à une modélisation précise de cette seconde composante et notamment des signaux de bruits modulés. Tout d'abord, une méthode de synthèse s'inspirant du bruit de grenaille, est introduite. Cette technique consiste à utiliser des processus ponctuels aléatoires qui définiront des instants d'occurrence d'événements spectraux (représentés par des Formes d'Ondes Formantiques ou FOF). Puis, s'appuyant sur un support théorique (représentation de Rice, théorie de la modulation aléatoire), un algorithme d'analyse/synthèse est proposé. Des tests de perception ont montré que cette méthode permet d'obtenir des signaux synthétiques jugés très naturels. De plus, cette approche apporte de nombreuses possibilités pour la modification de la qualité vocale (modifications temporelles, effort vocal, etc.).
Notre étude associe une approche linguistique et psycholinguistique du phénomène « métaphore » basée sur des énoncés spontanés d'enfants de 2-4 ans ainsi que sur des productions d'adultes dans des textes scientifiques pour large public. Nous voudrions montrer en quel sens ces énoncés, généralement considérés soit comme « déviants » soit comme « ordinaires » , peuvent apporter un éclairage à la fois de la structuration du lexique des verbes chez le jeune enfant et l'organisation du lexique des verbes chez l'adulte. Concernant les énoncés produits par les jeunes enfants, nous développons des arguments qui vont à l'encontre des notions d' « erreur » ou de « métaphore » qui sont quasi systématiquement investies.
On propose aussi une extension de cette formulation afin d'obtenir une modélisation optimale des variations de la prononciation. Puisque de différents mots n'exposent pas, en général, le même degré de variation de la prononciation, cette méthode permet une représentation des mots par un nombre varié d'entrées lexicales. La méthode améliore la description d'unités de parole des mots du vocabulaire, chose qui a démontré une amélioration de la performance de la reconnaissance en ce qui concerne la tâche de la DARPA Resource Management.
La reconnaissance automatique de textes saisis à l'aide d'une tablette à digitaliser ouvre la voie à une nouvelle génération d'ordinateurs « nomades » , dépourvus de clavier comme de souris et dialoguant avec l'utilisateur à l'aide d'un outil que ce dernier maîtrise depuis son plus jeune âge : le stylo. Dans cet article nous étudions différents moyens de coopération entre un analyseur de contexte, et deux expert- classifieurs traitant les données de manières différentes. Les résultats obtenus sur une base de données de 7 000 lettres et 12 scripteurs sont encourageants puisqu'ils permettent une amélioration globale des performances de 20 %, portant le taux de reconnaissance global à 84,2 % en lettres et 64 % en mots.
Cet article tente d'apporter quelques éléments de réponses à la question de savoir quels procédés formels et sémantiques les Camerounais mettent en œuvre pour créer des appellatifs et quelles fonctions les appellatifs (créés) remplissent dans la gestion des relations sociales.
Parmi les méthodes de débruitage du signal de parole, la règle d'atténuation spectrale d'Ephraı̈m et Malah (EMSR) a prouvé son efficacité à réduire efficacement le niveau du bruit de fond tout en se prévenant d'un artefact couramment rencontré : le bruit musical. Afin de prendre en considération certains facteurs psychoacoustiques, une réalisation de la méthode EMSR sur une échelle de fréquence perceptuellement pertinente est présentée. Cette méthode utilise un banc de filtres non-uniforme et sans décimation. Cependant, le découpage en fréquence réalisé est uniforme sur l'échelle de fréquence ERB. Une comparaison objective et subjective a été réalisée entre cette méthode, l'implémentation classique de l'EMSR et une implémentation en banc de filtres uniformes avec échantillonnage critique.
De nouvelles techniques sont décrites ayant pour objectif la reconnaissance automatique du locuteur à partir de parole transmise par téléphone. La reconnaissance se fonde sur une analyse spectrale de phrases-code ayant une durée fixe. A partir de l'énoncé complet, une séquence de spectres à court terme est extraite de manière à former un spectrogramme évolutif. Des procédures de normalisation tenant compte des distorsions spectrales introduites par la ligne téléphonique et des variations d'amplitude sont ensuite appliquées. On aboutit à l'identité du locuteur en comparant le spectrogramme d'un échantillon de l'énoncé avec des spectrogrammes de référence et en calculant une mesure de dissimilitude entre eux. Pour effectuer ces comparaisons, il est nécessaire de tenir compte des différences de débit et de synchroniser avec précision les phénomènes phonétiques qui se correspondent. L'alignement temporel s'effectue au moyen d'un algorithme de programmation dynamique qui minimise les différences temporelles entre les segments de parole correspondants. Pour l'évaluation du système, on a utilisé un ensemble de phrases prononcées par des locuteurs coopératifs et transmises via des lignes téléphoniques conventionnelles. Différentes versions de la procédure de reconnaissance ont été testées et comparées entre elles. Tant pour l'identification que pour la vérification des locuteurs, on a obtenu des taux d'erreur de 2% et moins.
On présence ici un panorama des recherches en prosodie menées au Département de Linguistique et Phonétique de l'Université de Lund depuis 1950. Il montre que la question des accents de mots a été un moteur essentiel dans le dévelopment de ces travaux. L'intérêt s'est d'abord focalisé sur les configurations de Fo liées aux accents distinctifs et à leurs variations contextuelles et dialectales ainsi qu'aux indices perceptifs permettant leur identification. Ensuite, l'analyse des aspects plus globaux a conduit à l'élaboration d'un modèle compositionnel de la prosodie du Suédois dans lequel les contours d'accents locaux sont considérés comme superposés à l'intonation globale. On indique ensuite certains domaines de recherche négligés, comme la perception et les effets possibles de règles générales d'économie. Cet exposé se termine par un appel à la construction d'un cadre plus unifié pour l'analyse prosodique.
Quelques 550 segments vocaliques ont été extraits d'un texte lu par un locuteur néerlandais à deux débits, normal et rapide. La durée de chaque segment est mesurée ainsi que les caractéristiques statiques et dynamiques des formants, telles que les fréquences au centre des formants, les descriptions des évolutions de formants utilisant 16 points équidistants par formant ou des fonctions polynomiales de Legendre. Ces caractéristiques formatiques ont été examinées en fonction de la durée des voyelles mais aucune indication d'“undershoot” dépendant de la durée n'a été mis en évidence. Par contre, ce locuteur montrait un comportement de coarticulation dépendant des consonnes très consistant et adaptait son style d'élocution au débit de manière à toujours atteindre la même valeur fréquentielle au centre des formants. Différentes évolutions formantiques (stylisées par des paraboles) ont été synthétisées pour diverses durées, en isolation ou dans des contextes CVC puis présentées pour identification à des auditeurs. Les décalages nets dans les réponses vocaliques, par rapport aux stimuli stationnaires, ne montraient aucune indication d'“overshoot” perceptif. Une méthode de movennage pondéré attribuant le plus grand poids aux fréquences formantiques de la partie finale des voyelles rend mieux compte des résultats.
Les tests ont été réalisés sur des signaux obtenus à partir d'environnements acoustiques simulés ou réels et avec différents rapports signal/bruit (SNR). Le traitement étudié vise à tirer profit des canaux binauraux d'entrée pour effectuer l'annulation du bruit. Les deux signaux à large bande de fréquence sont d'abord décomposés en sous-bandes distribuées linéairement ou selon une caractéristique cochléaire, et sont ensuite traités selon les caractéristiques des signaux sous-bandes. Les resultats de tests d'intelligibilité sont discutés dans lesquels les données de parole et de bruit, provenant de conditions simulées ou réelles, sont présentées à des volontaires selon différents rapports signal/bruit, différentes distributions en sous-bande et différents espacements des sous-bandes. Les résultats obtenus sur des environnements acoustiques simulés ou réels prouvent que l'approche MMSBA améliore de façon significative à la fois le SNR et l'intelligibilité.
L'article décrit une méthode d'acquisition de connaissances morphologiques constructionnelles (dérivationnelles) à partir de dictionnaires de synonymes. Cette méthode, destinée à la création semi-automatique de bases de données constructionnelles, exploite de différentes manières la structure paradigmatique du lexique. Elle repose sur l'identification de quadruplets analogiques (morpho-synonymiques) qui permettent de croiser des contraintes sémantiques définies au moyen de relations synonymiques et des contraintes morphographiques. Elle a été utilisée avec succès pour des dictionnaire de synonymes français et dictionnaires. Nous proposons en outre un typage des quadruplets morpho-synonymiques qui rend explicite le fait que certains couples de lexèmes sont soumis à davantage de contraintes que d'autres.
Les surfaces de type papier, lorsqu'elles ne présentent pas de pli franc, sont mathématiquement décrites par des surfaces développables. Ces dernières sont difficiles à paramétrer de manière minimale car le nombre de degrés de liberté significatif dépend de la déformation. Les modèles existants sont incomplets ou dépendent de grands jeux de paramètres redondants. Notre première contribution est un modèle génératif contrôlé par un jeu quasi-minimal de paramètres intuitifs. Le principe est de plier une surface plane autour de règles de guidage. Notre deuxième contribution est un algorithme d'estimation du modèle proposé à partir de plusieurs images. Tout d'abord, les caméras et une structure 3D éparse de la surface de l'objet sont reconstruites. Une paramétrisation 2D de ces points est ensuite calculée par une méthode non-linéaire de réduction des dimensions. Cette paramétrisation est essentielle pour évaluer la courbure d'une surface passant par les points reconstruits, nécessaire à l'initialisation des paramètres du modèle. Enfin, un ajustement de faisceaux ajuste les paramètres du modèle afin de raffiner la surface en minimisant l'erreur de reprojection.
Plusieurs expériences ont été produites afin d'étudier et de compenser pour les variations à même un locuteur lors de la vérification du locuteur. Afin de d'encourager les variations à même un locuteur, un logiciel stimulant un tel comportement parlé a été créé. À l'aide de ce logiciel, une base de donnée contenant 50 locuteurs avec variations volontaires et involontaires a été enregistrée. Cette base de donnée a été utilisée pour analyse acoustique et pour tests de vérification automatique du locuteur (VAL). Les variations volontaires de la parole sont utilisées comme ensemble d'inscription au système de VAL. Un tel ensemble est appelé entraı̂nement structuré et est comparé à un entraı̂nement neutre consistant seulement de parole normale. Les deux ensembles contiennent le même nombre de phrases. Il est montré qu'en testant sur un style de parole mixte, la performance du VAL système est ameliorée sans que la performance de tests avec parole normale ne dégrade.
Cet article décrit le protocole expérimental retenu par les participants au projet européen SAM (Projet ESPRIT no. 2589 : Multilingual Speech Input/Output : Assessment, Methodology and Standardisation) pour l'évaluation d'intelligibilité des synthétiseurs de parole au niveau de la phrase. Le SUS test consiste à mesurer l'intelligibilité moyenne d'un jeu de “phrases sémantiquement imprédictibles” (Semantically Unpredictable Sentences), générées aléatoirement à partir de quelques lexiques des mots minisyllabiques les plus fréquents dans chaque langue, selon cinq structures syntaxiques élémentaires. L'avantage de ce corpus de phrases est de ne pas être figé, puisque les mots sont extraits aléatoirement des lexiques pour former de nouvelles phrases à chaque nouveau test. De nombreux synthétiseurs de parole à partir du texte ont été évalués, au moyen de ce test, dans plusieurs langues. Les résultats obtenus ont montré que le SUS test est efficace et permet des comparaisons fiables entre synthétiseurs à condition de respecter un certain nombre de contraintes dans la définition et le déroulement du test lui-même. Ce sont les recommendations issues de l'expérience accumulée pendant le projet SAM et au-delà qui sont présentées ici, de façon à ce que les utilisateurs de ce test puissent se servir d'un outil de mesure “standardisé”.
Cet article aborde le problème de l'extraction automatique de caractéristiques pour la classification de signaux et de textures. De plus, un nouvel algorithme de résolution est proposé pour traiter ce problème. Enfin, notre approche a été testée sur des exemples de signaux et de textures et comparée à des méthodes de l'état de l'art avec des résultats compétitifs sur des jeux de données de textures.
Cet article met en question la simple notion d'analogie, entendue comme entièrement basée sur les associations phonologiques, ainsi que l'idée selon laquelle les effets de fréquence sont incompatibles avec l'opération de règles symboliques telles qu'elles sont appliquées dans l'étude des traitements morphologiques. Il discute les résultats de trois expériences sur le traitement de morphologie inflexionnelle complexe effectué par des adultes russes et des adultes américains apprenant le russe comme langue étrangère - deux expériences sur la génération de verbes nouveaux et une expérience sur la décision lexicale.
Dans cet article on traite de la question de savoir si et comment on peut dire que les grammaires proposées par les linguistes peuvent être actualisées en modèles adéquats de traitement de phrases. On étudie d'abord les postulas qui guident les expériences s'appuyant sur la théorie dite de complexité dérivationnelle (DTC). Ces expériences ont été censées montrer que la théorie de la Grammaire Transformationelle (TG) connue comme Théorie Standard n'était que partiellement adéquate pour rendre compte de l'analyse humaine. En particulier, on a pensé (voir Fodor, Bever et Garrett, 1974) que les expériences DTC démontraient que, tandis que l'analyseur utilisait les descriptions structurelles implicites dans les dérivations transformationnelles, les computations qu'il faisait ressemblaient peu aux transformations proposées par une TG. Les principales propositions sous-tendant la DTC étaient que 1) le modéle de calcul (ou analyseur) elfectue les opérations de façon linéaire et sérielle et que 2) il incorpore une grammaire plus ou moins représentable sous une forme semblable à une grammaire de compétence. Si l'on fait l'hypotheses d'une sérialité, stricte, il parait plus facile d'inclure dans le modéle d'analyse une grammaire lexicale étendue telle que celle proposée par Bresnan (1978) comme opposée à une TG. Cette conjoncture joue un rôle important dans la critique que fait Bresnan à la TG en tant que partie pertinente d'une théorie d'utilisation du langage. Fodor, Bever et Garrett (1974) ainsi que Bresnan (1978) cherchent à rendre les règles grammaticales compatibles avec les données psycholinguistiques et avec la proposition (1). Ils proposent des modéles qui limitent la part de traitement actif réalisé en temps réel. Nous montrons que le calcul en temps réel n'est pas nécessairement associé à une complexité supplémentaire de temps de réaction. C'est à dire que nous montrons qu'un analyseur qui relie la SP à la SS par des régles de transformation (ou plus précisément par des règles d'analyse de forme très proche des règles d'un modéle transformationnel) peut s'accorder avec les données de la psycholinguistique si l'on fait simplement varier le postulat (1). Plus précisément nous montrons qu'en enchassant TG dans une architecture de calcul parallèle (qui peut être justifiée comme raisonnable pour l'usage du langage) on peut saisir les différences de complexité dans le calcul des phrases qu'avaient relevées les expérimentateurs DTC La proposition (2) permet aussi d'évaluer les grammaires candidates pour une théorie de l'utilisation du langage. On montre d'abord que Bresnan (1978) peut affaiblir cette proposition pour rendre l'Extended Lexical Grammar compatible avec les résultats de la psycholinguistique. Ensuite on analyse la position de Tyler et Marslen Wilson (1977–1980) selon laquelle leurs expériences montrent qu'on ne peut instancier une TG dans un modèle d'analyse sans changer la proposition (2). Ceci est lié au fait qu'ils insistent sur le fait que leurs expériences supportent un “mode interactif” d'analyse dont ils pensent qu'il est compatible avec la Thèse de l'Autonomie de la Syntaxe. On montre que la Thèse de l'Autonomie est sans relation avec ce modèle interactif. Adopter ce modèle n'empêche donc pas d'inclure directement le TG dans un analyseur. En outre, nous montrons pourquoi en allant dans le sens de la proposition (2), une condition que nous appellons le TTH n'est pas un critère absolu pour juger de l'utilité d'une théorie grammaticale en vue de construire une théorie d'analyseur. Nous soutenons que les grammaires ne doivent pas être envisagées comme fournissant directement et de façon transparente (proposition 2 ci-dessus), un algorithme d'analyse. Cependant, nous insistons sur le fait que la théorie de la grammaire a une place centrale dans le développement d'un mode d'utilisation du langage même si le Type de Transparence est affaibli selon nos suggestions. Enfin, nous montrons que toutes ces remarques servent à l'évaluation comparative des modèles d'analyses possibles qui incorporent la grammaire transformationnelle, la grammaire lexico-fonctionnelle et les propositions de Tyler et Marslen-Wilson.
Les variations de vitesse d'élocution (ROS) affectent les indices spectraux du signal vocal et la prononciation ; les systèmes de reconnaissance automatique de la parole y sont donc exposés. Afin de combattre ces effets, nous proposons d'utiliser en parallè le deux groupes de modèles acoustiques et de prononciation, adaptés en fonction de la vitesse d'élocution. Le choix entre ces deux groupes peut basculer à la frontière des mots afin de rendre compte en cours d'énoncé des variations de cette vitesse, courantes en parole conversationnelle. Grâce au parallélisme des deux groupes de modèles et à la méthode de décodage basée sur le maximum de vraisemblance, notre approche ne demande pas l'estimation de la vitesse d'élocution avant décision de reconnaissance, ce qui serait difficile à réaliser. Nous évaluons nos modèles sur une tâche de reconnaissance automatique de la parole téléphonique grand vocabulaire. Les expériences sur une configuration de développement NIST 2000 Hub-5s montrent que notre modélisation obtient 2,2% d'amélioration du taux de reconnaissance de mots comparé à un système de base ne comportant pas de traitement de la dépendance à la vitesse d'élocution. Par rapport à un système de base amélioré où la coarticulation et les élisions sont modélisées dans un dictionnaire de multi-mots, notre modélisation dépendante de la vitesse d'élocution obtient 1,5% d'amélioration. Nous avons de plus introduit une nouvelle modélisation des réductions phonétiques, fréquentes dans la parole à débit rapide, où les phones courts peuvent être omis en tant que segment mais préservés en tant que contexte phonétique pour les phones adjacents. Cette approche a également permis une légère amélioration s'ajoutant à celle qu'obtient la prise en compte des variations de vitesse d'élocution.
Le débat de l'entre-deux tours de la présidentielle française de 2017 est révélateur des ambiguïtés du fact-checking quand il prétend dénoncer les mensonges propagés par les acteurs publics. Drapées dans un discours de vérité, les pratiques de fact-checking visent d'abord à identifier le faux plus qu'à dire le vrai. Elles délèguent l'établissement de la vérité à des sources fiables que le fact-checker pourra mobiliser. L'analyse révèle toutefois qu'il s'agit d'abord de sources institutionnelles considérées comme collectivement légitimes. Le fact-checking déploie ainsi une approche potentiellement conservatrice de l'information journalistique qu'il applique ensuite à l'ensemble des propos tenus dans l'espace public.
Cet article propose une méthode pour extraire le signal voulu à partir d'un signal bruité addressant ainsi le problème de ségrégation de deux sources acoustiques comme modèle de ségrégation de sources acoustiques basé sur l'analyse de la scène auditive. Comme le problème de ségrégation de deux sources acoustiques est un problème mal-inversé il est nécessaire d'utiliser des contraintes afin de déterminer une solution unique. La méthode proposée adopte les quatres règles proposées par Bregman comme contraintes physiques et utilise comme propriétés des sources acoustiques, l'amplitude instantannée et la phase des composants du signal bruité après son passage par une banque de filtres. Le modèle proposé peut alors extraire l'amplitude instantannée et la phase du signal voulu. Des simulations pour la ségrégation du ton harmonique complexe à partir d'un ton harmonique bruité et la comparaison des résultats obtenus lors de l'utilisation de tous ou d'une partie des contraintes ont été effectuées. Les resultats montrent que la méthode proposée peut effectuer une ségrégation précise du ton harmonique complexe lors de l'utilisation de toutes les contraintes en relation avec les quatres règles de Bregman et une diminution de la précision lors de l'utilisation de seulement une partie de ces contraintes.
Dans cet article, nous étudions un ensemble de problèmes qui ont été identifiés chez des enfants qui éprouvent des difficultés de lecture, et nous essayons de les expliquer en tenant compte des propriétés du système de traitement du langage. Le fait de considérer les troubles de lecture du point de vue de la structure linguistique et de l'acquisition du langage nous permet de faire des hypothèses spécifique sur leurs causes. Ces hypothèses sont ensuite examinées à la lumière d'une analyse des exigences de la tâche de lecture et de l'évaluation de l'état du lecteur qui ne parvient pas à satisfaire à ces exigences. Le reste de l'article étudie plus en détail une proposition quant à la source des troubles de lecture, dans laquelle le système de mémoire de travail joue un rôle central. Cette proposition est évaluée à la lumière d'investigations empiriques qui ont essayé de séparer le savoir structural et la capacité de mémoire chez des enfants normaux et chez des enfants éprouvant de sérieuses difficultés de lecture.
Nous présentons dans cet article en nouveau modèle de l'intonation en anglais. L'intonation y est décrite en termes de “descentes” (rise), “montées” (fall) et “lignes de connexion” (connection). Les accents et les montées de continuation sont représentés par les éléments de “montée” et de “descente” ; les lignes de connexion sont utilisées partout ailleurs. Un système d'équations permet de reconstruire le contour de la fréquence fondamentale à partir de ces éléments. Nous décrivons ensuite un système d'étiquetage automatique qui associe à toute phrase une représentation en descentes/ montées/ connexions, sans connaissance a priori, ni analyse descendante. Une série d'expériences portant sur un corpus de phrases prononcées par 6 locuteurs de langue anglaise et d'accents variés valide ce modèle : l'erreur de modélisation est comprise entre 3.6 et 7.3 Hz. Par ailleurs, une comparison des étiquetages automatiques et manuels montre une correspondance de 72% à 92%. Nous concluons par une comparison du modèle proposé avec lex modèles existants et en discutons les applications pratiques.
Ce papier décrit la première étape de notre recherche, un système (que nous appelons VEST) qui reconnaît deux locuteurs de langue espagnole et deux de langue anglaise, et qui est limité à quatre cents mots. L'idée clé novatrice est que la reconnaissance de la parole et l'analyse de la langue sont intimement liées du fait qu'elles reposent toutes deux sur le même modèle de langage, c'est-à-dire une grammaire augmentée de structures de phrases.
Dans cet article, nous décrivons plusieurs méthodes objectives et subjectives permettant d'évaluer le comportement d'un système d'interaction vocale et de ses composantes. Nous nous focalisons sur l'évaluation de l'interaction homme-machine notamment celui de recherche d'informations.
Cet article décrit notre contribution à l'effort entrepris par le CEPT pour la définition d'un standard européen pour le radio téléphone numérique cellulaire.
Nous proposons un modèle descriptif des formes de la résolution coopérante de problèmes en dyade, avec les mécanismes d'apprentissage qui y sont associés. La résolution coopérante de problèmes est analysée selon trois dimensions fondamentales et graduelles : la symétrie, l'alignement et l'accord. La première dimension renvoie à la distribution de rôles transactionnels, la deuxième à la coordination des actions, et la troisième à la résolution de désaccords. La combinaison des trois dimensions produit un espace de huit formes principales de coopération, au sein desquelles nous situons " la collaboration ". Des analyses comparatives de séquences d'interactions illustrent les relations entre les dimensions. Enfin, nous discutons des mécanismes d'apprentissage associés aux formes de coopération, et nous proposons des extensions du modèle pour analyser des groupes plus étendus.
Les paramètres articulatoires, la forme du conduit vocal et la fonction d'aire sont extraits de spectres de fricatives. Un modèle de la génération des fricatives a été employé pour déterminer les contraintes acoustiques pour une procédure d'optimisation dans laquelle le travail musculaire est pris pour critère. Une distance interspectrale a été mesurée en utilisant l'inégalité de Cauchy-Boujakovsky. Il est nécessaire d'initialiser correctement l'approximation des paramètres articulatoires pour obtenir une solution précise et stable du problème inverse.
Dans le domaine de la recherche en Reconnaissance Automatique de la Parole (RAP), il est devenu habituel de poursuivre en priorité les approches réduisant le taux d'erreurs au niveau du mot. Les auteurs émettent cependant quelques réserves à l'égard d'une telle stratégie qui, bien qu'apparemment raisonable, conduit souvent à un manque d'innovation. En effet, d'énormes efforts ont été consentis pendant plusieurs années sur les approches aujourd'hui prédominantes en RAP et celles-ci ont été développées et testées sur des données standards de référence, convergeant donc ainsi vers un minimum local dans l'espace des techniques disponibles. Dans ce cas, il est clair que pratiquement n'importe quelle nouvelle approche suffisamment différente ne pourra pas se comparer favorablement aux systèmes existants et résultera souvent initialement en une augmentation du taux d'erreurs. D'un autre côté, il est également probable que les problèmes restant à résoudre nécessiteront de nouvelles approches. Dans ce papier, nous discutons certaines directions de recherche qui ne conduiront peut-être pas toujours à une diminution immédiate et garantie du taux d'erreurs, alors qu'elles pourraient ultimement s'avérer bénéfiques aux performances de nos systèmes. Les thèmes qui seront abordés dans se papier concernent notamment : la discrimination entre modèles, le rôle de l'information a priori en reconnaissance de la parole, le couplage du modèle acoustique et du modèle de language, l'extraction des caractéristiques et information temporelle, et quelques procédures de reconnaissance reflétant mieux les propriétés perceptuelles chez l'homme.
L'inférence de réseaux de régulation de gènes s'oriente actuellement vers l'utilisation conjointe d'informations biologiques complémentaires. Nous utilisons ici des données de marqueurs génétiques en plus des classiques données d'expression dans le cadre des réseaux bayésiens statiques discrets. Nous comparons les qualités de di_érents scores ainsi que l'impact d'un a priori lié à la connectivité des réseaux. Nous proposons et comparons deux modélisations aux approches existantes pour l'inférence de réseaux de régulation. Sur des données simulées, l'un de nos modèles obtient les meilleurs résultats dans le cas d'échantillons de petites tailles. Nous utilisons ce même modèle sur des données réelles d'Arabidopsis thaliana.
Il est bien connu que la variabilité inter-locuteur liée à l'accent est un facteur important de la dégradation des performances des systèmes de reconnaissance. Si l'on peut faire une estimation précise de l'accent d'un locuteur, alors un ensemble de modèles de reconnaissance modifiés pour prendre en compte cet accent peut être utilisé pour améliorer les scores de reconnaissance. Dans cette étude, on traite de la question de l'identification de l'accent en Anglais Américain. Une base de données d'accents étrangers a été établie : elle comporte des mots et des syntagmes connus pour être sensibles à l'accent. Des algorithmes de classification d'accent ont ensuite été développés, basés sur des mots isolés ou sur des phonèmes. L'ensemble des traits considérés comprend les coefficients cesptraux en Mels et l'énergie, ainsi que leurs dérivées du premier ordre. On montre que la précision de la classification augmente avec la longeur de la phrase test. Des séquences de 7 à 8 mots isolés donnent lieu à un taux de classification correcte d'accent de 93%, dans un ensemble de quatre type d'accents différents. Un test d'écoute subjectif a également été mené pour comparer les performances humaines et automatiques sur cette tâche. Les résultats montrent que la classification automatique donne, de façon cohérente, des performances supérieures à celles des réponses humaines pour cette tâche de classification. Toutefois, on montre que certains auditeurs sont capables d'égaler les performances des algorithmes pour la détection d'accent. Enfin, une étude expérimentale a été menée pour étudier l'influence de l'accent étranger sur la reconnaissance. On montre que la précision de la reconnaissance peut être améliorée de façon notable en faisant un apprentissage séparé des modèles pour chaque accent plutôt qu'en utilisant un modèle unique pour chaque mot.
Le projet de cet article est de rendre compte de l'histoire et de la sociologie d'un groupe de fonctionnaires singuliers – les sténographes parlementaires – dont le métier est intimement lié à l'histoire du parlementarisme dans la plupart des démocraties du monde. Conduite à partir d'un matériau sociologique et historique original, cette enquête vise à questionner la façon dont les institutions sont façonnées, produites et reproduites par les savoirs et les faire, dont des valeurs s'incarnent, dont les institutions prennent forme. Au-delà de l'institution de la publicité des débats, l'article s'intéresse aux conditions techniques, matérielles et sociales de définition de l'Assemblée nationale comme institution politique.
Le modèle statistique de propagation de l'erreur d'étape y est donné. Par itération sur l'ensemble des étapes, cette analyse mène à l'estimation de l'énergie des trois contributions d'erreur — erreurs d'entrée, arithmétique et de coefficients — qui sont comparées à l'expérience.
Ceci est principalement du à la difficulté d'identifier et de catégoriser les facteurs liés à l'émotion dans la parole, puis à les utiliser dans les systèmes de synthèse. De tels modèles pourraient aussi être utilisés comme des outils efficaces pour la validation de modèles de l'émotion et des autres facteurs de stress altérant la parole.
Atteindre des performances robustes pour un système de reconnaissance vocale est un problème pifficile à résoudre surtout lorsqu'un tel systéme est utilisé comme fonction de composition vocale dans les radiotéléphones mobiles de voiture. La nécessité de telles fonctions devient primordiale dans la mesure òu l'utilisateur d'un radiotéléphone mobile peut se concentrer sans risques sur la conduite de son véhicule tout en composant le numéro de son correspondant et discuter avec ce dernier en mode “mains-libres”. Le travail présenté dans cet article pose le problème de la reconnaissance mono-locuteur de most isolés dans un environnement bruité. Dans ce contexte toute la difficulté réside dans le fait qu'il existe des différences importantes entre les conditions d'apprentissage (généralement dans le silence) et celles de reconnaissance (généralement dans le bruit, lorsque le véhicule roule). Une nouvelle technique de réduction du bruit est proposée : la Soustraction Spectrale Non linéaire (NSS). Dans un système de reconnaissance utilisant les Modèles de Markov Cachés (HMM), des estimateurs robustes de variances (lissage) et de densités de probabilités d'observation (projection) sont également introduits et combinés avec la Soustraction Spectrale Non linéaire. Nous montrons aussi que les limites courantes d'application de la Projection (RSB inférieurs à 0 dB) peuvent être repoussées grâce à l'utilisation de NSS. Le système de reconnaissance (HMM) voit ses performances s'élever de 56%, sans traitement, à 98%, après réduction du bruit par NSS. Plus de 3000 mots à reconnaître ont été employés pour l'évaluation des différents systèmes considérés (trois bases de données, deux langues europénnes). De telles performances ont été atteintes en ayant recours à des techniques robustes d'apprentissage et de reconnaissance ainsi qu'à prétraitement des mots bruités à l'aide de NSS.
Afin d'évaluer les différents algorithmes de propagation d'incertitude, nous avons réalisé des expérimentations en utilisant les algorithmes de propagation développés dans le contexte des réseaux possibilistes basés sur le produit et l'algorithme de propagation pour la logique possibiliste quantitative mis au point dans cet article.
On évalue l'histoire de l'utilisation de la psychologie dans le contrôle social et l'accroissement vraisemblable de son importance dans le futur. Les effets du financement militaire de la recherche psychologique et les conséquences du chômage sont plus particulièrement étudiés. La psychologie et les disciplines reliées aux sciences cognitives et aux neurosciences pourraient être plus pertinentes en participant au développement des composantes techniques des pratiques de contrôle social plutôt qu'en fournissant les justifications idéologiques de leur utilisation.
Une nouvelle fonctionnelle pour l'estimation du mouvement d'objets déformables est proposée dans le cadre de l'étude des images de milieux continus où la valeur des pixels est proportionnelle à la densité d'une grandeur. Cette nouvelle fonctionnelle repose sur le concept de l'énergie de déformation élastique et les principes de conservation des milieux continus. L'introduction a priori d'un modèle physique de déformation, permet une nouvelle interprétation de la fonctionnelle proposée par Song et Leahy [Song 91]. Des résultats obtenus à partir de simulations montrent la possibilité de prise en compte du caractère compressible ou non de la déformation. Des résultats sur séquence d'images réelles sont également présentés.
Cet article présente des algorithmes bayésiens pour le démélange d'images hyperspectrales. Chaque pixel de l'image est décomposé selon une combinaison linéaire de spectres de référence pondérés par des coefficients d'abondances. Dans un cadre supervisé, nous supposons connus les spectres de références. Le problème consiste alors à estimer les coefficients du mélange sous des contraintes de positivité et d'additivité. Une loi a priori adéquate est choisie pour ces coefficients qui sont inférés à partir de leur loi a posteriori. Un algorithme de Monte Carlo par chaîne de Markov (MCMC) est développé pour approcher les estimateurs. Dans un cadre semi-supervisé, les spectres participant au mélange sont supposés inconnus. Nous faisons l'hypothèse qu'ils appartiennent à une bibliothèque spectrale. Un algorithme MCMC à sauts réversibles permet dans ce cas de résoudre le problème de sélection de modèle. Enfin, dans un dernier cadre d'étude, les algorithmes précédents sont étendus au démélange non-supervisé d'images hyperspectrales, c'est-à-dire au problème d'estimation conjointe des spectres et des coefficients de mélange. Ce problème de séparation aveugle de sources est résolu dans un sous-espace approprié.
Dans cet article, nous nous intéressons à la structuration des termes d'un domaine, c'est-à-dire à l'acquisition de relations entre termes. En effet, les terminologies ne peuvent plus se contenter de recenser les termes et les organiser brièvement sous forme d'une hiérarchie. Elles doivent également proposer toute une gamme de relations qui reflètent au mieux les connaissances du domaine et répondent de manière adaptée aux besoins des applications. Nous confrontons la place accordée traditionnellement par la théorie terminologique aux relations avec les besoins réels qui apparaissent lors de la constitution, l'utilisation et la réutilisation de ressources terminologiques. Nous présentons également un panorama des approches proposées pour l'acquisition de relations entre termes à partir de corpus spécialisés.
La reconnaissance de mots (dans la chaîne parlée) englobe trois fonctions fondamentales : l'accès, la sélection et l'intégration. L'accès se réfère à l'appareillement de l'onde sonore avec les représentations de formes lexicales ; la sélection, désigne la discrimination du meilleur “pareil” (match) lexical avec le stimulus, et l'intégration recouvre l'appareillement de l'information syntaxique et sémantique avec les niveaux de traitement supérieures. Cet article décrit comment deux versions d'un modèle (de type “cohorte”) rendent compte de ces processus, en traçant son évolution à partir d'une première version comportant un principe d'interaction partielle où l'accès est strictement autonome mais où la sélection est soumise à des contrôles “de haut en bas” vers une deuxième version (à fonctionnement entièrement “de bas en haut”) où le contexte n'intervient plus dans les processus d'accès et de sélection. Par conséquent, le contexte n'intervient qu'á l'interface entre les représentations supérieures et l'information générée en temps réel sur les propriétés syntaxiques et sémantiques des membres du cohorte. Ce nouveau modéle garde intactes les caractéristiques essentielles d'un processus de reconnaissance de type cohorte. Il intégre les notions d'accés et d'évaluation multiples permettant ainsi un processus de reconnaissance optimal fondé sur le principe de contingence de choix perceptif.
Cet article présente un système de segmentation qui découpe automatiquement un ensemble de mots manuscrits en lettres. L'objectif de cette opération est de constituer une base d'apprentissage pour un système de reconnaissance en ligne de mots manuscrits. Les tracés de mots à segmenter ont été saisis sur une tablette à digitaliser puis convertis en une suite de vecteurs. Enfin, à chacun de ces tracés de mot, est associé le mot alphabétique correspondant. La description de notre système de segmentation est suivie d'un test expérimental portant sur le découpage en lettres d'une base de 10000 mots qui proviennent de 10 scripteurs différents.
Par simulation informatique, on a engendré des réponses impulsionnelles entre des points d'une pièce rectangulaire et deux points opposés sur une “tête sphérique”. Des sons ont été convolués avec ces réponses impulsionnelles pour fabriquer des stimuli, en vue d'étudier les effets de la réverbération sur la capacité des locuteurs à utiliser les différences de fréquence fondamentale (Δ Fo) pour discriminer entre des voyelles différentes. L'expérience 1 a permis de vérifier la validité de la simulation en montrant qu'elle fournissait (i) des perceptions correctes de latéralisation, (ii) une plus grande contribution du temps que de l'amplitude dans la latéralisation due aux différences interaurales, et (iii) un effet nul de la réverbération sur la latéralisation. Les expériences 2 à 5 ont mesuré les seuils de masquage pour des voyelles “cible” harmoniques synthétiques en présence de sons de masquage. Dans l'expérience 2 des locuteurs avaient à identifier les cibles en présence d'un masquage par du bruit rose. Cette expérience a défini une géométrie et un degré de réverbération pour lesquels les auditeurs n'ont plus d'indices binauraux dûs à la géométrie des sources. L'expérience 3 a montré que la même configuration ne détruisait pas la capacité à utiliser les Δ Fo pour séparer les cibles de sons de masquage de type vocalique, quand les deux ont des contours de Fo statiques ; mais elle empêche les auditeurs d'utiIiser les Δ Fo relatifs à des contours de Fo qui changent de façon cohérente. L'expérience 4 a montré qu'une largeur de modulation de ±1,45% était suffisante pour empêcher l'emploi des Δ Fo, mais que cet emploi n'est pas éliminé tant que la largeur de la modulation ne dépasse pas les Δ Fo. On démontre que ces résultats sont compatibles avec les modèles proposés de la capacité à utiliser les Δ Fo pour séparer les voyelles concurrentes, et que la réverbération détruit cette capacité pour des Fo mobiles en mélangeant les harmoniques des sources en concurrence. Finalement, l'expérience 5 démontre que la réverbération n'a pas d'effet sur la capacité à séparer une voyelle modulée d'un bruit rose. Donc, dans ces expériences, la réverbération doit exercer ses effets en mélangeant les harmoniques des sons de masquage plutôt que celles des cibles. Pour finir, les expériences démontrent que les Δ Fo peuvent être des indices plus robustes de séparation de sons concurrents que les indices binauraux. L'application de ces résultats à la perception de la parole continue naturelle est discutée.
Le premier, constitué de réseaux neuronaux, d'une part, transforme les paramètres cepstraux classiques en un ensemble de valeurs échelonnées attribuées à des traits acoustico-phonétiques pour chaque échantillon, et par ailleurs, divise le signal de parole en segments acoustico-phonétiques. La sortie de cette première étape, obtenue en combinant les sorties de ces deux traitements, donne une première estimation de la suite des phonèmes composant le message. La deuxième étape est basée sur un système-expert composé de règles allophoniques, d'un lexique de transcriptions phonétiques des mots appartenant au vocabulaire de l'application choisie, de règles syntaxiques et du système de contrôle général. Ce système-expert, pour traiter la chaîne des phonèmes provenant de la première étape, utilise un lexique et un système d'analyse grammaticale basé sur le principe des “îlots de confiance”. Le vocabulaire actuel se compose de 35 mots provenant d'une application de type CAO.
Cet article présente une étude comparative de la relation entre le timing d'un mouvement mélodique montant ou descendant et la syllabe qu'il accentue pour trois langues : le néerlandais, le français et le suédois. Dans une expérience perceptive, des stimuli de 5 syllabes /mamamamama/ et / a a a a a/ furent synthétisés avec un mouvement mélodique montant ou descendant relativement rapide. Le timing du mouvement fut systématiquement varié de manière à accentuer la troisième ou la quatrième syllabe. Il était demandé aux sujets d'indiquer la syllabe perçue comme accentuée. La frontière d'accentuation (AB) entre la troisième et la quatrième syllabe est définie comme le moment avant lequel plus de la moitié des sujets indiquent la troisième syllabe comme accentuée et après lequel plus de la moitié indiquent la quatrième. Les résultats montrent qu'il existe des différences significatives entre les trois langues concernant la position de la AB. En général, pour les mouvements mélodiques montants, les ABs sont clairement définies. Elles sont situées au milieu de la voyelle de la troisième syllabe pour les sujets français, et plus tard dans la voyelle pour les sujets suédois et néerlandais. En ce qui concerne les mouvements mélodiques descendants, il est obtenu une AB clairement définie uniquement pour les sujets suédois et néerlandais. Elle est située à la fin de la troisième syllabe. Pour les sujets français en revanche, ce type de mouvement ne permet pas de définir une AB. Cela confirme l'absence d'accentuation par mouvements mélodiques descendants en français. En faisant varier la durée du mouvement mélodique, il a pu être montré (dans les cas ou la `AB' est clairement définie), que la notion d'accentuation est liée à la perception d'une variation mélodique située au début du mouvement.
Nous développons dans cet article un algorithme de codage linéaire de Walsh (WLC) qui donne une approximation comprimée du spectre de puissance de Walsh dans une fenêtre temporelle. Cet algorithme est plutôt interpolatif que prédictif. Il minimise l'erreur d'interpolation moyenne carrée et il donne le modèle de spectre WLC. Son utilisation pour des systèmes de reconnaissance de parole est explorée. Deux mesures de distorsion de gain unité sont incorporées dans un système de reconnaissance de mots isolés basé sur une déformation temporelle dynamique et dépendant du locuteur.
Trần Đức Thảo et Jean Piaget partagent une même volonté de révolutionner la méthode de la philosophie de la connaissance en la fondant sur la mise en parallèle de l'évolution de l'intelligence humaine et du développement des compétences cognitives des individus. Cette combinaison fait écho à la théorie biologique de la récapitulation dont le caractère obsolète et erroné semble les condamner. Nous montrerons au contraire qu'elle est la marque de l'actualité de leur projet théorique.
Une méthode de simulation du conduit vocal dans le domaine temporel est décrite. Le modèle adopté comporte une source de pression d'air constante, une section étroite variable dans le temps représentant la glotte et un tube correpondant au conduit vocal couplé à la cavité nasale, Les équations qui gouvernent la génération et la propagation de l'onde sonore dans le modèle sont transformées en une représentation en variables discrètes par l'application de certaines règles : la règle rectangulaire dans l'espace et la régle trapézoîdale dans le temps. Discrétiser de cette manière particulière introduit une distortion spectrale due à une déformation fréquentielle. Une analyse théorique indique que cette déformation peut être interprétée comme une manifestation de la dépendance fréquentielle de la vitesse de phase dans le système discrétisé. Son amplitude dépend à la fois de la fréquence (f s) d'échantillonnage spatial (X). Onze voyelles françaises, synthétisées avec f s = 20 kHz et X = 1 cm présentent un haut degré de naturel et d'intelligibilité même si une trace de distorsion fréquentielle est relevée dans la région du 3° formant. Pour f s = 40 kHz, l'effet de la distortion spectrale devient pratiquement négligeable aux fréquences inférieures à 4 kHz.
Cet article traite d'un module de synthèse de parole qui a été utilisé pour présenter des informations de trafic par radio de voiture, dans le cadre du système RDS-TMC de Contrôle de Messages de Trafic. Une des idées de base de ce service visant à être pan-européen est de pouvoir fournir des informations de trafic dans la langue maternelle du conducteur, indépendamment de la langue utilisée dans l'endroit géographique oú il se trouve, ou utilisée par la radio-diffusion. La synthèse de la parole est indispensable pour réaliser ce type de service, pour un ensemble illimité de noms de lieux. Un prototype a été développé pour l'allemand. L'ouverture à d'autres pays et d'autres langues est prévue pour 1998.
Cet article prône une approche orientée individu pour la résolution du problème classique des mariages stables. Selon cette approche, la solution émerge de négociations entre agents. L'agentification de l'algorithme séminal de Gale-Shapley revient à distinguer deux comportements d'agents (proposant et disposant) qui négocient pour aboutir à une solution stable mais inéquitable. Le comportement d'agent CASANOVA que nous proposons ici consiste à jouer simultanément ces deux rôles dans une multitude de négociations bilatérales. Les agents mettent en oeuvre une stratégie de concession minimale maximisant leur bien-être individuel. Les solutions qui émergent sont équitables et elles ne peuvent pas être atteintes par les méthodes multi-agents existantes.
Un modèle à trois dimensions de la langue a été élaboré à partir des images obtenues par Résonance Magnétique (IRM) sur un sujet prononçant 44 articulations suédoises. En s'appuyant sur la différence entre les contours de la langue mesurés pour les différentes articulations et une position de référence, six paramètres de contrôle de la mâchoire et la langue ont été déterminés par application d'une analyse factorielle sur des mesures articulatoires. Les cinq premiers facteurs ont expliqué 88% de la variance des contours de la langue dans le plan sagittal et 78% de la variance tri-dimensionnelle. Ce modèle à six paramètres est capable de reconstruire les articulations mesurées avec une erreur moyenne de 0,13 cm et peut également prendre en compte les différences latérales et les asymétries des contours de la langue. En vue de corriger l'hyper-articulation résultant des expositions prolongées durant l'acquisition d'IRM, les valeurs des paramètres ont été ajustées en comparant les contacts linguopalataux virtuels et ceux mesurés par électropalatographie. Des données de mouvement ont été mesurées pour des séquences voyelle-fricative à l'aide d'un articulographe électromagnétique, afin de déterminer le contrôle cinématique du modèle.
Les systèmes SAS (Sonar à Antenne Synthétique) sont activement utilisés pour l'imagerie du fond marin. En effet, la haute résolution des images SAS est d'un très grand intérêt pour la détection, la localisation ou encore la classification d'objets présents sur le fond marin. Mais ces images sont fortement entachées d'un bruit granulaire multiplicatif, connu sous l'appellation de bruit de speckle, qui réduit les résolutions spatiale et radiométrique. Si bien que l'interprétation automatique de ces images présente quelques difficultés. Une solution peut consister en un pré-traitement visant à réhausser le signal d'intérêt, sans pour autant altérer la résolution spatiale. Nous proposons dans cet article d'utiliser conjointement le filtrage adapté stochastique et un filtre moyenneur auto-adaptatif. Par ailleurs, afin de préserver au mieux la résolution spatiale, le critère utilisé pour mettre en oeuvre le filtrage adapté stochastique est celui de la minimisation de l'écart entre l'une des caractéristiques statistiques du speckle et celle du bruit estimé, entraînant une adaptation sur la taille de la fenêtre glissante. Des expérimentations sur données réelles sont proposées et les résultats comparés avec ceux obtenus par différentes techniques de débruitage à base de filtrage adapté stochastique.
Le lexique de désignation des procès tarde sur celui de la désignation des entités aux étapes précoces de l'acquisition de la langue première (L1), mais également dans l'acquisition ultérieure de langues étrangères (L2). Le traitement sémantique des verbes par les enfants et les adultes manifeste une plus grande flexibilité que celui des noms, ce qui est expliqué par le caractère relationnel des verbes, et par le fait que la catégorisation des événements en unités lexicalisées est moins déterminée par la perception que structurée par des schèmes de lexicalisation spécifiques à chaque langue. Lorsque le lecte de l'enfant (ou de l'apprenant d'une L2) est peu pourvu en verbes, la flexibilité sémantique des verbes sera sollicitée, notamment par des processus analogiques.
La situation actuelle au Japon à propos du développement et des applications de l'électro-palatographie est revue. Les données sur l'articulation linguale par rapport aux différences individuelles et aux caractéristiques des enfants sont ensuite fournies. Ces données ont été obtenues en combinant les mesures tri-dimensionnelles des empreintes en plâtre des palais durs de cinquante adultes, de trente enfants et de deux enfants à différentes étapes de leur développement dentaire avec l'observation électro-palatographique des formes de contact lingual des palais durs de sujets adultes et de quatre enfants pendant la prononciation de consonnes japonaises.
Dans cet article, nous proposons une technique de détection et de segmentation de zones de couleur de peau. La méthode utilise les techniques de data mining pour produire les règles de prédiction, suivie d'une phase de segmentation en régions cohérentes de peau en utilisant les règles déjà produites. Les expérimentations réalisées sur une base d'images importante montre l'efficacité et la faisabilité de notre approche.
Une méthode est décrite pour l'extraction de vecteurs de caractéristiques robustes aux distortions provenant du type de téléphone utilisé dans des applications de reconnaissance du locuteur. La technique transforme les vecteurs de caractéristiques tels que le Mel-cepstre, le log-spectre et les caractéristiques basées sur la prosodie, à l'aide de réseau de neurones non-linéaire. Le réseau de neurones est entraîné de manière discriminante pour maximiser la performance du système de reconnaissance du locuteur, spécifiquement dans des conditions où des types de téléphone différents sont utilisés lors de l'entraînement et de la vérification. L'algorithme ne requiert, ni enregistrement stéréo de la session d'entraînement, ni étiquettage manuel des types de téléphone utilisés à l'entraînement et à la vérification. Les résultats sur le corpus 1998 NIST Speaker Recognition Evaluation montrent une amélioration relative atteignant avec les nouvelles caractéristiques basées sur le réseau de neurones. Le système de référence utilise des vecteurs de caractéristiques basés le MEL-cepstre avec soustraction du cepstre moyen ainsi que des modèles d'imposteurs dépendant du type de téléphone.
Dans cet article sont présentés de manière synthétique les résultats du projet ANR DESAM (Décompositions en éléments sonores et applications musicales). La plupart des aspects abordés dans le projet ont donné lieu à de nouvelles méthodes et algorithmes qui sont regroupés au sein d'une boîte à outils, la DESAM Toolbox. Celle-ci rassemble un ensemble de fonctions Matlab® dédiées à l'estimation de modèles spectraux très utilisés pour les signaux musicaux. Les méthodes étudiées dans ce projet peuvent bien sûr être utiles pour la recherche automatique d'informations dans les signaux musicaux, mais elles constituent avant tout une collection d'outils récents pour décomposer les signaux selon différents modèles, avec pour résultat des représentations mi-niveaux variées, pouvant être utiles dans d'autres domaines d'application.
Cet article propose un algorithme de prédiction, sur la base des contours de F0, des frontières de mots et des mots grammaticaux en Hindi. Il utilise des propriétés des contours de F0 comme la tendance à la déclinaison, la remise à niveau, et les formes de type montant-descendent. Les unités syllabiques sont identifiées à partir du contour d'énergie, de F0 et du coefficient de prédiction linéaire du premier ordre. A chaque syllabe est assignée une valeur d'accent L (bas), H ou h (haut) en (i) comparant la valeur de F0 au centre de chaque noyau syllabique avec celle de l'unité syllabique précédente et (ii) en comparant les valeurs de F0 en deux points différents au sein de chaque unité syllabique dans une séquence ayant une valeur d'accent L. Les frontières de mots sont placées entre les unités syllabiques adjacentes H et L, h et L, L et L, L et h, H et h. Une évaluation menée sur un corpus de 50 phrases en Hindi lues par cinq locuteurs natifs dans un environment de bureau montre que environ 74% des frontières de mots et environ 28% des mots grammaticaux sont identifiés correctement. Les résultats de cette prédiction peuvent être utilisés pour améliorer les performances des modules de décodage acoustico-phonétique, d'analyse lexicale ou syntaxique d'un système de transcription parole-texte. La robustesse de l'algorithme dans le cas de parole bruitée est également discutée.
Cet article décrit PEGASUS, une interface de dialogue oral pour la réservation immédiate de voyages aériens PEGASUS exploite les technologies de traitement du langage naturel que nous avons développées dans le cadre de ATIS et permet aux utilisateurs du système EAASY SABRE de American Airlines de faire des réservations de vols. La demande de l'utilisateur est transformée par le système de compréhension de parole en un schéma (frame) qui représente sa signification. La tâche du module de gestion du systéme consiste à transformer la représentation sémantique en une commande de EAASY SABRE, à la transmettre au module de l'application, à mettre en forme et interpréter l'information résultante et à gérer le dialogue. Les résultats d'évaluation préliminaires suggèrent que les utilisateurs peuvent apprendre à utiliser PEGASUS de façon productive pour faire des réservations de vols, même si beaucoup de travail reste encore à faire pour rendre le système vraiment convivial.
Les dernières années ont été très intéressantes chez AT&T dans le domaine des applications avancées du vocal en télécommunications : des progrès techniques et des avancés au niveau des processeurs/plateformes ont permis l'identification, le développement et le test d'un ensemble de nouveaux services. Pendant cette période, et avant la séparation d'AT&T, de Lucent Technologies et NCR, AT&T rassemblait, sous un même `toit', un laboratoire de recherche engagé sur les technologies vocales avancées, des organisations d'affaires construisant des plateformes pour pousser ces technologies dans des applications en télécommunications, et d'autres organisations d'affaires ayant la responsabilité du déploiement de services à technologies vocales pour faciliter l'usage et réduire le coût des services de télécommunications pour les abonnés et les professionnels. Maintenant que cette période de notre histoire commune prend fin, nous pouvons regarder en arrière pour dresser une vue d'ensemble sur comment les progrès techniques, les avancées au niveau des plateformes et les besoins et occasions au niveau des services centralisés (à travers un réseau téléphonique) ont interagi pour que la technologie vocale devienne une expérience quotidienne pour des millions de gens – et pour décrire quelques leçons que nous avons appris au cours de ce chemin.
Travuas antérieurs ont démontré la possibilité d'entraîner un perceptron à niveaux multiples pour l'estimation de la période fondamentale (Tx) de signaux produits par différents locuteurs parlant dans des conditions de bruit intense. L'algorithme a été implanté en temps réel et réalisé sur un système de dévloppement TMS320C25. Un prototype portatif incorporant le logiciel a été construit. Il servira de base à une nouvelle génération de prothèses auditives à traitement de signal pour les sourds profonds. Grâce à une très faible consommation, l'autonomie de l'appareil est de 12 heures sans recharge. L'algorithme a été amélioré afin d'augmenter sa résolution temporelle ce qui le rendra intéressant pour une large série d'autres applications.
Cet article présente ¡'implémentation d'un réseau bayésien dynamique avec variable exogène continue, appliquée à la classification d'évènements discrets irrégulièrement espacés, organisés en séquence. La modélisation des tables de probabilités conditionnelles, qui sont fonction d'une variable exogène codant un vecteur de distances entre événements, s'appuie sur les mélanges de lois gaussiennes estimés par l'algorithme EM. La classification de points singuliers des rails du métro de Paris est le cadre applicatif de cette étude. La parcimonie de l'approche proposée est également démontrée dès que l'ordre du modèle est supérieur ou égal à deux. Cette implémentation permet, à terme, d'améliorer la décision fournie par un capteur spécifique de défaut de rail.
Récemment, des techniques motivées par la perception auditive, sont appliquées dans de principales technologies courantes de la parole. Il semble y avoir un regain d'intérêt à l'exploitation de plus de connaissance du processus de la parole humaine dans la conception de systèmes de reconnaissance de la parole. Le papier discute l'expérience de l'auteur dans l'application de connaissances auditives à la reconnaissance automatique de la parole. Il avance l'idée que la raison d'appliquer des connaissances de la perception auditive humaine à l'ingénierie de la parole devrait être la capacité de la perception à supprimer quelques parties de l'information contenue dans le message de la parole. L'article plaide contre l'exploitation aveugle de connaissance accidentelle dispersée qui peut être non pertinente pour une tâche de reconnaissance de la parole. Trois propriétés de perception humaine de la parole sont discutées : • reśolution spectrale limiteé, • utilisation de l'information contenue dans des segments de longueur d'une syllabe environ, • possibilité d'ignorer les composantes altérées ou non pertinentes de la parole. L'auteur montre, en se référant à certains travaux publiés, que l'utilisation sélective de la connaissance auditive optimisée en fonction et dans certains cas provenant de vraies donneés de parole, peut être compatible avec les approches stochastiques actuelles de la reconnaissance automatique de la parole et pourrait avoir des avantages pour des applications pratiques d'ingénierie.
Cette étude concerne la production des consonnes de l'anglais par des locuteurs de langue maternelle italienne. Les 240 locuteurs adultes de langue maternelle italienne concernés par cette étude ont commencé à apprendre l'anglais quand ils ont émigré au Canada, âgés de 2 à 23 ans. Les occlusives et constrictives de l'anglais ont étéétiquettées en consonne initiale, médiane et finale de mots puis soumises à un jugement auditif par choix forcé auprès d'auditeurs de langue maternelle anglaise. Les résultats montrent que l'âge d'apprentissage (AOL) de l'anglais par les sujets de langue maternelle italienne exerce un effet systématique sur leur production des consonnes anglaises, même quand ils vivent au Canada depuis 32 ans en moyenne, et qu'ils parlent anglais davantage qu'italien. Dans tous les cas sauf deux, au moins un des sous-groupes constitué sur la base de l'AOL a obtenu des résultats significativement différents de ceux du groupe de contrôle (NE) formé de sujets de langue maternelle anglaise. Pour ce qui concerne l'identification des consonnes et des frontières syllabiques, l'AOL à partir duquel on note une différence entre le premier sous-groupe de sujets de langue maternelle italienne et les sujets du groupe de contrôle (NE) varie. Les résultats sont discutés par rapport aux hypothèses proposées dans la littérature concernant les erreurs segmentales liées à la production d'une seconde langue.
Pour la reconnaissance des voyelles, la normalisation des fréquences formantiques a souvent été utilisée pour éliminer des différences inter-locuteurs. Cependant, l'estimation de ces fréquences devient difficile sous certaines conditions, comme la transmission téléphonique par exemple. Cet article présente une approche de la normalisation des voyelles basée sur un alignement spectral par distorsion fréquentielle. Une distance normalisée en fréquence entre spectres expérimentaux et spectres de référence est définie sur la base d'une différence quadratique moyenne sur tous les choix possibles de fonctions de distorsion fréquentielle soumises à des contraintes non-linéaires et à des conditions aux limites. Une fois que les différences au niveau de la pente spectrale dues aux caractéristiques glottiques individuelles sont éliminées adaptivement, la distance spectrale est calculée par programmation dynamique. Les expériences sur l'identification des voyelles ont été effectuées sur les neuf voyelles de l'anglais américain dans des environnements /hVd/ produites par 12 locuteurs masculins et 12 locuteurs féminins. Les résultats montrent que la méthode de distorsion spectrale augmente considérablement les identifications correctes pour les voyelles féminines lorsque les voyelles masculines sont utilisées comme références. Bien que l'amélioration de l'identification soit attribuée principalement à l'alignement fréquentiel linéaire, une amélioration supplémentaire est obtenue pour la voyelle /ae/ grâce à une légère distorsion fréquentielle non-linéaire. Une application à la normalisation de locuteurs pour la détection de mots dans de la parole continue est aussi discutée.
Parmi les modèles bien adaptés pour classer des séquences figurent les chaînes de Markov d'ordre fixe. Le lissage de probabilités ou les chaînes de Markov d'ordre variable sont des améliorations de ce modèle qui ont permis d'en augmenter le pouvoir de généralisation pour un coût de stockage moindre. Dans cet article, nous proposons une autre extension, basée sur un test statistique, qui permet de contrôler la présence de motifs différents dans le modèle sous-jacent à une séquence et dans celui de sa classe d'affectation. A titre d'illustration, nous comparons les résultats fournis par ces différents modèles sur le benchmark de séquences DNA d'E. coli du répertoire de l'UCI et montrons l'influence du choix des paramètres sur leurs performances.
Cet article propose une nouvelle méthode pour la construction automatique de hiérarchies sémantiques adaptées à la classification et à l'annotation d'images. L'objectif est de fournir une mesure qui est plus proche de la sémantique des images. Nous proposons ensuite des règles, basées sur cette mesure, pour la construction de la hiérarchie finale qui encode explicitement les relations hiérarchiques entre les différents concepts. La hiérarchie construite est ensuite utilisée dans un cadre de classification sémantique hiérarchique d'images en concepts visuels. Nos expériences et résultats montrent que la hiérarchie construite permet d'améliorer considérablement les résultats de la classification.
Cet article discute quelques points importants de la recherche actuelle en synthèse de la parole. La modélisation des caractéristiques du locuteur et les émotions sont utilisées comme exemples des nouvelles tendances dans le domaine de la synthèse de la parole. L'accent est mis sur les relations avec la reconnaissance de la parole. De nouvelles méthodes, comme l'apprentissage automatique, et l'utilisation de nouvelles techniques sont aussi discutées.
Nous présentons un système de reconnaissance de parole continue multi-locuteurs, appliqué aux occlusives du français dans tous les contextes vocaliques. L'architecture du système est fondée sur les résultats de plusieurs expériences de perception auditive et d'analyse acoustique du bruit d'explosion. Ces expériences nous ont permis d'apprécier le pouvoir de discrimination du bruit d'explosion par rapport à la reconnaissance du lieu d'articulation des occlusives, de montrer que la connaissance, à l'avance, de la voyelle permet de meilleurs performances d'identification de l'occlusive. Par conséquent, nous avons conçu et évalué un décodeur acoustico-phonétique des occlusives qui tient compte des informations sur la nature de la voyelle pour reconnaître l'occlusive. Des expériences ont été effectuées sur deux corpus et montrent un taux de reconnaissance de 90% sur de nouveaux locuteurs et locutrices.
La plupart des difficultés dans un système de compréhension de la parole proviennent de la grande incertitude propre au signal acoustique. Comme aucun décodeur phonétique ne semble en mesure de fonctionner parfaitement à plus ou moins breve échéance, nous allons devoir utiliser un maximum de connaissances en provenance des niveaux superieurs. Nous présentons ici une solution possible pour intégrer certaines de ces informations dans le domaine particulier de l'interrogation d'une base de données administratives. Tout d'abord, nous exposons comment des connaissances contextuelles peuvent être extraites de représentations locales
Lors du séminaire ESCA-NATO “Speech Under Stress” (Lisbonne, Portugal, Septembre 1995), les discussions ont été centrées sur la définition et la modélisation du stress et de ses effets. Sur la base de ces discussions, l'article présenté ici essaie de produire une définition du stress et propose plusieurs modèles du stress visant á clarifier certains enjeux du domaine et qui pourraient être adoptés par la communauté de recherche en parole. La notion de stress est assez vague et est utilisée de manière différente dans différents domaines de recherche : il n'y a donc pas de définition précise de stress. On propose une séparation plus nette entre les “Stressors” (les causes du stress) et le “strain” (les effets du stress) et des méthodes pour relier les “Stressors” au “dstrain” sont présentées, Finalement, on propose des axes de recherche future dans le domaine.
Dans cet article, nous nous intéressons à l'extraction automatique des traits de visages (yeux, sourcils, nez, bouche, menton) ainsi qu'à la reconnaissance des six expressions faciales définies par Ekman [19]. Nous exploitons pour cela des versions modifiées du modèle actif d'apparence initialement proposé par Cootes et al. [11] qui permet de représenter à la fois la forme et la texture d'un visage. L'extraction des traits faciaux est faite à l'aide d'un modèle actif d'apparence hiérarchique, calculé à partir des réponses de visages à des bancs de filtres de Gabor. Deux modèles d'expressions faciales sont ensuite proposés, calculés à patir du modèle d'apparence standard (non hiérarchique), pour reconnaître puis supprimer ou modifier l'expression d'un visage inconnu.
L'hippocampe et l'amygdale sont deux structures cérébrales intervenant dans plusieurs fonctions cognitives fondamentales. Leur segmentation, à partir de volumes d'imagerie par résonance magnétique (IRM), est un outil essentiel pour mesurer leur atteinte dans certaines pathologies neurologiques, mais elle est rendue difficile par leur géométrie complexe. Nous considérons leur segmentation simultanée par une méthode de déformation homotopique compétitive de régions. Celle-ci est guidée par des connaissances anatomiques relationnelles ; ceci permet de considérer directement des structures atrophiées. Rapide, l'algorithme donne, pour les deux structures, des résultats comparables à la segmentation manuelle avec une meilleure reproductibilité. Ses performances, concernant la qualité de la segmentation, le degré d'automatisation et le temps de calcul, sont parmi les meilleures de la littérature.
Le recalage non supervisé d'images médicales volumiques reste un problème difficile en raison de l'importante variabilité et des grandes différences d'information pouvant apparaître dans des séquences d'images de même modalité ou dans des couples d'images multimodales. Nous présentons dans cet article des méthodes robustes de recalage rigide d'images 2D et 3D monomodales et multimodales, reposant sur la minimisation de mesures de similarité inter-images. Les méthodes proposées s'appuient sur la théorie de l'estimation robuste et mettent en œuvre des M-estimateurs associés à des techniques d'optimisation stochastique multigrilles rapides. Ces estimateurs robustes sont évalués à travers le recalage d'images médicales volumiques monomodales (IRM/IRM) et multimodales (IRM/TEMP). Elles permettent de plus de recaler des couples d'images sur lesquels les méthodes classiques échouent.
Cette étude porte sur l'analyse, la modélisation et la simulation de capacités humaines de planification et d'interaction. Les protocoles expérimentaux ont été analysés des points de vue de la planification et des interactions. Les modèles proposés de planification et d'interaction sont intégrés de façon homogène à une nouvelle architecture d'agent appelée BDIggy. Le modèle de l'interaction humaine 1) s'appuie sur la théorie des actes de langage pour modéliser les énoncés, à l'aide d'un ensemble de performatives appliquées à des états mentaux 2) utilise un modèle du discours, représenté par des automates temporisés, pour décrire la dynamique des conversations humaines. Dans BDIggy, l'interaction et la planification s'entrelacent grâce aux concepts BDI. L'architecture BDIggy est validée par un test « à la Turing » .
La télésurveillance médicale est une branche de la télémédecine qui vise à surveiller à distance les paramètres d'un patient. Cet article décrit les principes de ces dispositifs et cite les projets qui ont bénéficié à des patients.
Cet article s'intéresse à l'étude des propriétés de l'Analyse en Composantes Principales Relationnelle (ACPR) qui analyse un vecteur aléatoire conditionnellement à la réalisation d'un paramètre induisant une relation binaire sur l'espace probabilisé de référence. Nous détaillons les propriétés de la covariance et de l'espérance relationnelles qui sont à la base de cette technique d'analyse connue mais finalement peu étudiée. L'article présente quelques illustrations des propriétés que nous mettons en évidence, et qui éclairent les interprétations en ACPR.
Souvent, les processus de prise de décision sont incorporés dans des procédures « officielles » pour prendre en compte le focus dans tous les cas. Cependant, les procédures mènent souvent à des solutions sous-optimales pour des prises de décisions spécifiques, et les acteurs sont obligés de développer des pratiques pour prendre en compte la spécificité du contexte dans lequel la décision est prise. Ce fossé entre les procédures et les pratiques est connu dans différents domaines (tâches effectives et prescrites, logique de fonctionnement et logique d'utilisation, etc.). Nous avons montré quelles sont les différences dans un formalisme basé sur le contexte, nommé les graphes contextuels. Dans ce papier, nous discutons la possibilité d'arguer de manière explicite l'utilisation de « bonnes » ou « mauvaises » pratiques pour la formation d'apprenti humain, ceci grâce à une acquisition incrémentale de la connaissance et de l'apprentissage de nouvelles pratiques par un système. Nous discutons ces aspects dans le cadre d'une application de taille réelle, la sécurité routière (modélisation de comportements de conducteurs), mais ces idées peuvent être facilement applicables à d'autres domaines.
Cet article présente un modèle de modulation AM–FM pour l'analyse, la synthèse, et le codage de la parole. Le modèle AM–FM décrit le signal de parole comme la somme de différents signaux représentant les fréquences formantiques, modulés en fréquence et amplitude. Un filtrage multibandes et une démodulation basée sur un algorithme de séparation d'énergie sont utilisés pour analyser le signal. Une analyse par démodulation multibandes (ADM) est tout d'abord employée afin d'estimer la fréquence fondamentale du signal, en se basant sur la fréquence instantanée moyenne comme estimation des harmoniques du pitch. Cet algorithme de suivi du pitch conduit à une estimation lisse et précise de la fréquence fondamentale. Un vocoder utilisant une modulation AM–FM est ensuite mis en oeuvre pour modéliser le signal par la somme de ses harmoniques. Un banc de filtres adaptatif permet d'extraire les bandes de fréquence formantiques et un algorithme fondé sur la séparation d'énergie est utilisé pour démoduler les harmoniques des formats en signaux instantanés modulés en amplitude et en fréquence. Différents algorithmes sont proposés conduisant à un codage efficace à 4.8–9.6 kbits/sec de l'enveloppe et la fréquence instantanée des résonances formantiques. Enfin, l'importance perceptive de la modulation des résonances du signal de parole est étudiée et démontre que la modulation d'amplitude ainsi obtenue est indépendante du locuteur et du phonème.
Dans cet article sont présentés les résultats d'une expérience de reconnaissance indépendante du locuteur effectuée sur un corpus de parole continue pour l'italien. Le système de reconnaissance utilise des unités phonétiques modélisées par des chaînes de Markov cachées multi-gaussiennes. Différents ensembles d'unités phonétiques ont été évaluées, en allant des modèles indépendants du contexte aux triphones les plus spécifiques : des unités propres aux mots outils ont également été évaluées. La reconnaissance a été effectuée sans contrainte syntaxique sur un vocabulaire de 979 mots, c'est-à-dire avec un facteur de branchement de 979. Les résultats confirment l'intérêt des modèles dépendants du contexte, pour lesquels le taux de mots reconnus est proche de 80% sur un ensemble de 300 phrases.
Le problème de l'extraction des règles d'association est un problème majeur en fouille de données. De nombreuses connaissances sont représentées sous la forme de règles d'association et la recherche exhaustive de ces règles est souvent très coûteuse en temps lorsque les données sont volumineuses et très corrélées. Nous proposons une nouvelle approche basée sur une recherche non exhaustive des règles d'association dans une base de données. L'algorithme proposé permet (i) d'extraire les meilleures règles d'association, étant donnée une mesure de qualité, (ii) d'extraire des "pépites" de connaissances dans les données (c-à-d., des règles d'association ayant un faible support et une forte confiance).
Nous passons en revue dans cet article une série de méthodes utilisées pour l'évaluation des systèmes de conversion texte-parole et commentons leurs avantages et désavantages respectifs. Ce panorama se limite aux méthodes subjectives, à savoir celles utilisant des auditeurs humains. Nous ne traiterons pas ici des méthodes objectives qui tentent d'évaluer la qualité par des techniques basées sur le traitement de signal. Dans la section 1, nous discutons de quatre facteurs influençant les caractéristiques de l'évaluation : les composants du système de conversion texte-parole, le niveau du texte, aspects de la parole et la fonction. Dans lessections 2 et 3, nous présentons des méthodes en relation avec les modules linguistique et acoustico-phonétique. Enfin, dans la section 4, nous tirons quelques conclusions générales.
Deux expériences concernant la détection de l'accent lexical dans des mots isolés en anglais sont présentées. Une méthode non statistique basée sur les variation de la fréquence fondamentale est proposée. Ses résultats sont meilleurs que ceux obtenus par l'utilisation de valeurs statiques du fondamental. Pour éviter le problème de la segmentation syllabique, on présente deux méthodes qui déterminent des régions d'accentuation dans un mot. Les régions trouvées peuvent etre considérées comme étant des régions de fiabilité phonétique. Dans la deuxième expérience, l'accent lexical est analysé dans des mots prononcés avec une montée de la voix. Le maximum d'énergie est le meilleur indicateur d'accent, suivi par la durée des syllabes. Enfin, il est proposé que l'étude de l'accent lexical en parole continue tienne compte de l'utilisation générale des variables prosodiques dans les phrases.
Les interfaces cerveau-machine (BMI : Brain-Machine Interface) sont des systèmes de communication directe entre un individu et une machine ne reposant pas sur les canaux de communication standard que sont nos nerfs périphériques et nos muscles. Dans une BMI, l'activité cérébrale de l'utilisateur est enregistrée, analysée et traduite en commandes destinées à la machine. Nous présentons enfin un état de l'art des différentes interfaces BMI développées jusqu'alors, en nous attachant plus particulièrement à celles dédiées à l'aide aux personnes atteintes d'un handicap moteur sévère dans leur tâche de communication ou de contrôle de machines.
Tenir compte de l'interdépendance des paramètres articulatoires permet de réduire la taille du dictionnaire de codage et d'améliorer les conditions de recherche optimale. Les approximations initiales des vecteurs articulatoires pour la résolution du problème d'inversion sont calculées le long des trajectoires des paramètres articulatoires sur des syllabes synthétisées. La prise en compte d'une transformation linéaire par morceaux de l'espace des paramètres articulatoire en l'espace des paramètres articulatoire ainsi que de la valeur minimale de l'aire sagittale du conduit vocal et du nombre de Reynolds permet d'accélérer le processus d'optimisation d'un facteur supérieur à 100.
Ce papier est consacré essentiellement à notre mesure heuristique, nommée HVS (Heuristique for Variable Selection)[YAC 97], que nous utiliserons pour la sélection de variables. HVS ne demande que peu de calculs simples, faciles à implémenter. Nous testerons son efficacité sur un problème de discrimination et un problème de régression, après avoir montré sa capacité de détection et de quantification de pertinence.
Ce papier illustre l'utilisation de techniques de traitement d'image pour segmenter le plan temps-fréquence (et temps-échelle). Cette étude est appliquée à la séparation d'ondes sismiques. On considère des données issues d'une rangée de capteurs. Pour chaque signal enregistré, l'application d'une transformée temps-fréquence décrit l'information dans une image sur laquelle les différentes ondes sont localisées et séparées. La segmentation par Ligne de Partage des Eaux (LPE) de ces représentations à deux dimensions permet une caractérisation automatique des filtres temps-fréquence menant à la séparation des différentes ondes. Ensuite, pour appliquer cet algorithme de séparation à l'ensemble des signaux issus des différents capteurs, on utilise la continuité d'un signal à l'autre pour effectuer le suivi des différentes ondes d'une image à l'autre. Hormis une phase d'initialisation, on obtient ainsi un algorithme automatique. Cet algorithme est validé et comparé à une méthode classique en sismique sur un jeu de données réelles. En comparaison, l'algorithme proposé a l'avantage de séparer toutes les ondes simultanément, et sans introduire d'artefacts. Les limites de l'algorithme sont atteintes lorsque les motifs caractérisant chacune des ondes ne sont plus convenablement séparés dans la représentation temps-fréquence.
Nous présentons un nouvel algorithme qui contribue à étendre le formalisme de l'Apprentissage par Renforcement (RL) aux Processus Décisionnels Markoviens Partiellement Observés (POMDP). L'idée principale de notre méthode est de construire une extension d'état, appelée observable exhaustif, qui permet de définir un nouveau processus qui est alors markovien. Nous démontrons que résoudre ce nouveau processus, auquel on peut appliquer les techniques classiques de RL, apporte une solution optimale au POMDP original. Nous appliquons l'algorithme déduit de ce résultat sur plusieurs exemples pour en tester la validité et la robustesse.
Le Programme Archivage du LACITO (Laboratoire de Langues et Civilisations à Tradition Orale du CNRS) a pour but la pérennisation, l'exploitation et la diffusion de documents linguistiques intégrant texte et son, en particulier les enregistrements faits et transcrits sur le terrain par les chercheurs du laboratoire. L'annotation (transcription, analyse, gloses interlinéaires, traductions) est balisée selon la norme XML et synchronisé phrase par phrase avec l'enregistrement numérisé, pour donner accès simultanément au texte et au son. Dans la mesure du possible des outils logiciels génériques et librement disponibles sont utilisés. Les documents produits sont consultés à l'aide des browsers les plus courants sur Internet. Le texte balisé est manipulé à l'aide d'outils génériques XML. Une centaine de documents dans une vingtaine de langues ont été préparés, dont certains sont disponibles sur Internet.
Nous présentons un environnement et des techniques élaborées pour la représentation et le traitement de connaisances acoustiques, phonétiques et lexicales pour la reconnaissance de la parole. Les outils proposés permettent d'effectuer de manière uniforme, continue et dynamique le codage et le traitement de données de type numérique (signal, paramètres, formes, etc.) et d'informations de nature symbolique (mots, phonèmes, syllables, traits, indices, etc.). La mise en oeuvre de ces méthodes est décrite à partir d'une application concernant la reconnaissance multi-locuteur des 26 mots correspondant aux lettres de l'alphabet énoncées en français. Malgré la difficulté bien connue de ce vocabulaire, les résultats obtenus valident parfaitement cette approche du problème, particulièrement dans le cas des mots acoustiquement très proches.
Ce papier va d'abord donner un bref aperçu des recherches de Simon en psychologie, et va ensuite se concentrer sur ses travaux concernant la psychologie des experts.
Dans cet article, nous présentons une nouvelle technique de traitement pour réseaux de microphones ayant pour but la déréverbération aveugle des signaux de parole altérés par l'acoustique de salle. La méthode repose sur le traitement séparé des composantes en phase-minimale et passe-tout des signaux de sortie des microphones. Les composantes en phase-minimale sont traitées dans le domaine cepstral, où l'on effectue un moyennage spatial suivi d'un filtrage passe-bas. Les composantes passe-tout, qui contiennent l'information de position de la source, sont traitées dans le domaine fréquentiel en effectuant une formation de voie suivie de l'extraction d'une composante en phase-minimale. Puisqu'elle repose sur le traitement spatio-temporel d'un ensemble de trames synchronisées provenant de plusieurs microphones, cette technique peut être utilisée dans des environnements acoustiques variants tels que l'on rencontre en pratique. Des réponses impulsionnelles de salles synthétisées au moyen d'un ordinateur sont utilisées afin d'évaluer la nouvelle technique et de la comparer à une formation de voie conventionnelle sous des conditions contrôlées. Les résultats indiquent une augmentation significative du gain d'antenne et un effet de déréverbération marqué.
On présente les résultats d'une recherche cognitive sur les déficits de langage d'un patient avec un aphasie de Wernicke. La compréhension de ce patient, R.D. est très pauvre en ce qui concerne la langue parlée, sa compréhension de la langue écrite est bonne. On trouve de nombreux néologismes et paraphrases verbales dans ses productions spontanées ainsi que dans ses lectures à voix haute. A la suite de Butterworth (1979) on pense que les néologismes découlent de difficultés pour reactiver les spécifications phonologiques dans le lexique de sortie pour la parole. On trouve que la fréquence des mots influe sur le taux de succès dans les recherches tandis que la distinction syntaxique entre mot de la classe fermée et mot de la classe ouverte est sans influence. R.D. épelle mieux qu'il ne dénomme et peut épeller des mots qu'il est incapable de dire correctement. Quand il épelle, ses erreurs découlent d'essais vers un mot cible à partir d'une information orthographique partielle (les neologismes semblent dépendre de rappels partiels de l'information phonologique). Nous pensons que les sujets normaux commettent dans certaines circonstances des erreurs de même type dans le langage parlé et écrit. Le modèle de Garrett (1982) est utilisé pour discuter de la facon dont on peut interpréter les aphasies avec jargon et d'autres formes de Wernicke. L'analyse des déficits de R.D., conjointe aux analyses d'autres patients fournis par la littérature, permer d'avancer certaines propositions valables pour les théories de traitement du langage. En outre, 1) la compréhension et la production de mots écrits familiers n'est pas obligatoirement médiatisée par la phonologie ; 2) les lexiques phonologiques et orthographiques sont distincts ; 3) les morphèmes sont représentés séparément dans le lexique phonologique ; 4) la fréquence d'usage affecte l'aisance et la rapidité de réactivation des items dans le lexique phonologique ; 5) pour les deux lexiques cette reactivation ne se fait pas en tout ou rien.
Les quantificateurs vectoriels ont traditionnellement été utilisés dans les systémes de reconnaissance de parole comme pré-processeurs pour des algorithmes sophistiqués tels que la modélisation markovienne sous-jacente (HMM) ou l'alignement dynamique temporel (DTW). Récemment, des systèmes plus simples basés plus directement sur la quantification vectorielle (VQ) ont été proposés pour la reconnaissance de mots isolés dans de petits vocabulaires. Le problème crucial avec de tels systèmes réside dans le manque d'information temporelle dans l'algorithme de reconnaissance. De nouvelles variantes de systèmes VQ incorporant cette information sont décrites. La principale nouveauté consiste en une technique d'histogramme conditionnel incluant les probabilités relatives de mots-codes successifs dans la mesure de distorsion utilisée dans l'algorithme de reconnaissance VQ. Plusieurs algorithmes de ce type sont appliqués à la reconnaissance de lettres énoncées extraites de l'alphabet anglais, sous-ensemble du vocabulaire orthographique d'IBM. Les résultats de nos simulations éclairent les mérites relatifs de ces algorithmes.
Les systèmes automatiques de dialogue téléphonique contiennent généralement un module de compréhension chargé de traiter les sorties du module de reconnaissance automatique de parole. Ce traitement consiste à extraire non-seulement le type de requête exprimée par l'utilisateur mais aussi les paramètres de cette requête tels que les expressions numériques, temporelles ou bien encore les noms propres. Ces expressions sont généralement appeleés des Entités Nommées et leurs définitions peuvent être génériques ou bien liées à un domaine d'application particulier. Détecter et extraire de telles entités dans le cadre d'un système automatique de dialogue téléphonique à initiative mixte tel que How May I Help You ? sm,tm (HMIHY) est le sujet de cette étude. Après avoir passé en revue les méthodes habituelles basées sur des grammaires écrites manuellement ou bien sur des étiqueteurs statistiques, nous proposons une nouvelle approche permettant de combiner leurs avantages respectifs. Nous proposons également une nouvelle architecture, pour les systèmes automatiques de dialogue téléphonique, qui utilize les résultats du module de compréhension afin d'améliorer la transcription des requêtes des utilisateurs. Toutes les méthodes proposées sont évaluées sur un corpus contenant de réels dialogues entre des utilisateurs et une application mise en service sur une large échelle.
Cet article décrit un système de transcription orthographique-phonétique bidirectionnel basé sur une stratégie combinant des techniques basées sur les données et un formalisme de règles. Notre approche fournit une analyse hiérarchique des mots, incluant la position de l'accent, sa morphologie et sa structure syllabique. La génération est réalisée par une technique d'analyse syntaxique probabiliste où les probablilitiés sont apprises à partir d'un lexique. Nos corpus d'apprentissage et de test sont constitués d'épellations et de prononciations des 10 000 mots les plus fréquents du Brown Corpus. L'étiquetage phonétique a été enrichi par des marqueurs indiquant la morphologie et l'accentuation. Les résultats sont fournis sur deux grammaires distinctes, correspondant à deux stades d'évolution du travail. Notre travail antérieur avec la première grammaire nous a incitéà modifier le formalisme de la grammaire, ce qui a abouti à des contraintes plus fortes avec moins de règles, Nous avons évalué les performances de notre système tant au niveau du mot entier que du phonème. Pour le corpus de test, la précision atteinte au niveau du mot est de 69.3% ; elle est de 91.7% au niveau du phonème, en utilisant un répertoire de 52 phonèmes. Bien que cet article traite essentiellement de la transcription orthographique-phonétique, notre système est également un système de génération dans l'autre sens, comme décrit dans un article antérieur (Meng et al., 1994a). Nous pensons que notre formalisme sera applicable en particulier pour entrer vocalement des mots inconnus dans un système de reconnaissance.
La méthode proposée repose sur le couplage de contraintes de type “n-grammes” conventionnelles, avec des contraintes grammaticales autorisant certaines déviations, au cours d'une stratégie de décodage multi-passes. Les segments à grande fiabilité correspondent aux séquences de mots satisfaisant à la fois les contraintes n-grammes et les contraintes grammaticales. Pour une plus grande efficacité, la grammaire hors contexte exprimant les contraintes grammaticales est approximée au moyen d'un automate à état fini. Par ailleurs, les possibilités de déviations telles que les insertions, les éliminations, et les substitutions sont considérées lors de l'application de ces contraintes. En conséquence, l'application des contraintes grammaticales s'avère plus robuste que dans le cas des analyseurs de syntaxe robustes conventionnels qui n'autorisent, comme déviations, que des insertions. Nos expériences confirment que la méthode proposée permet la reconnaissance partielle d'un énoncé avec une plus grande fiabilité que les méthodes de reconnaissance de la parole continue exclusivement basées sur des contraintes de type n-grammes. Enfin, nos résultats indiquent que le fait d'autoriser un nombre accru de déviations par rapport aux contraintes grammaticales permet d'améliorer les performances des analyseurs robustes conventionnels.
L'ajustement d'une ellipse sur des données 2D est un très vieux sujet en estimation et en RDF, qui a donné lieu à de nombreuses études [2,6,10,15,16,21] et en suscite encore aujourd'hui [12,17,19,24]. Un peu moins étudiée [5], la représentation polaire de l'ellipse constitue une alternative plus coûteuse car elle nécessite l'optimisation de sa paramétrisation. D'une représentation nécessitant au plus 5 paramètres à une autre définie par 5 + N (N étant le nombre de données), le choix semble évident. Cependant, nous proposons dans cet article de nouvelles idées sur la question. Tout d'abord, nous montrons que l'estimation séparée des paramètres et de la paramétrisation de l'ellipse permet de simplifier le problème en aboutissant respectivement à une inversion directe pour les premiers et à la recherche des racines d'un polynôme du 4ième ordre pour la seconde. Nous montrons également que la paramétrisation est « porteuse » de l'information dimensionnelle de l'ellipse et qu'en la « perturbant » correctement dans le processus de minimisation il est possible de forcer la solution à rester dans un espace paramétrique préétabli. Ce résultat nouveau permet de fournir une solution sans biais dimen- sionnel même dans un contexte fortement bruité et incomplet. Une enveloppe de confiance est ensuite estimée assurant à la fois un encadrement plus large de la solution et le rôle de filtre pour la recherche des segments voisins candidats potentiels pour affiner l'estimation. Enfin, nous proposons une stratégie de regroupement/ajustement suivie d'une phase de décision floue constituant ainsi un schéma robuste de détection de formes elliptiques dans les images.
Les difficultés d'interaction émotionnelle intrinsèques à l'autisme en font un domaine d'application opportun pour les interfaces homme-machine émotionnelles. Cet article traite des problèmes liés à l'assimilation d'expressions faciales émotionnelles survenant au cours d'un dialogue. Nous avons développé une interface homme-machine qui associe des expressions faciales émotionnelles à chaque réplique d'un dialogue. Les expressions faciales peuvent être représentées dans deux styles graphiques différents, l'un étant plus caricatural que l'autre. Nous décrivons un protocole expérimental pour évaluer l'apport de cette interface avec 10 adolescents autistes et 10 enfants non autistes. Les résultats montrent que les sujets sans autisme réussissent mieux que les sujets avec autisme à utiliser conjointement les expressions faciales et la parole pour désambiguïser un dialogue.
Dans l'étude présente, nous avons examiné les unités et les stratégies qui enclenchent l'organisation de l'information phonétique, spécifique aux premiers mots de l'enfant. Pour ce faire, nous nous basons sur les données transcrites longitudinales, recueillies sur huit enfants unilingues germanophones L1, dans le cadre du projet kielois sur l'acquisition phonique précoce. Ces données ont été saisies chaque semaine sur des enfants âgés de sept à treize mois au début de l'expérience. Nous en tirons, après analyse, les résultats suivants : L'enfant n'emploie au début qu'un répertoire limité de modèles articulatoires, qui peuvent déterminer la structure phonétique de la plupart de ses premiers mots, en tant qu'unités de codage basiques. Ces modèles sont manifestement construits sur la base des modes articulatoires préférés de l'enfant, et aussi à partir des caractéristiques acoustique et auditive les plus frappantes des mots cibles du langage adulte. Il y a globalement cinq types d'évolution de ces modèles au cours du temps.
La linguistique de l'énonciation développée par Antoine Culioli est une théorie des opérations prédicatives et énonciatives. Les deux concepts d'opération et de représentation sont ainsi au cœur du modèle épistémologique et de la méthode d'analyse, qui cherche à démêler les relations en jeu dans la construction des énoncés pour les rapporter à l'activité symbolique de représentation et au processus mental qu'elle présuppose. Un examen critique du modèle des trois niveaux de représentation nous amène à distinguer la fonction de représenter du mode de représenter. Le retour à Saussure nous permet de revoir le modèle en y intégrant, au niveau des représentations notionnelles, ce que celui-ci nomme des figures. Une brève étude de cas illustre, pour finir, le développement théorique.
Cet article présente une étude expérimentale sur le “déplacement d'accent” dans des énoncés ambigus et non-ambigus. Des séquences ambiguës comme Chinese fan fournissent des caractéristiques phonologiques pouvant correspondre à deux structures différentes. Si la séquence est un syntagme syntaxique, Chinese étant un adjectif venant modifier le nom fan, alors fan présente une proéminence relative plus grande. Si Chinese est un nom et que la séquence est un composé, alors fan est déssacentué et c'est Chinese qui présente la plus grande proéminence. De plus, le fait que Chinese soit un item dont l'accent peut être déplacé laisse supposer que le déplacement d'accent intervient dans l'interprétation syntagmatique. Les mots à catégories ambiguës avec déplacement d'accent potentiel pourraient donc contenir, plus que les items non-soumis au déplacement d'accent, des indices précoces pour la catégorisation syntaxique, sous la forme de patrons prosodiques modifiés. Les données de production montrent que les patrons de déplacement d'accent correspondent en effet aux catégories syntaxiques, mais seulement si le deuxième élément de la séquence n'est pas branché à droite. Une expérience de compréhension avec des énoncés a catégories ambiguës suggère que les patrons de proéminence de syntagmes ou d'expressions composées ainsi que le déplacement d'accent facilitent le traitement syntaxique. Une deuxième expérience de compréhension a permis de dupliquer cette observation et d'élargir l'analyse à des énoncés non-ambigus comme Torquay College. Dans les énoncés non-ambigus, de nouveau, I'accent de syntagme apparait comme affectant le traitement, ce qui n'est pas le cas pour le déplacement d'accent.
Cet article traite de la détection de cibles mobiles sur fond de fouillis dans le cadre de radar aéroporté monostatique utilisant trois formes d'antennes : linéaire uniforme (ALU) ; courbée uniforme (ACoU) et circulaire uniforme (ACU), en visée non latérale. Outre le fait que ces méthodes sont très coûteuses en calculs, leurs performances ne sont pas optimales (l'estimateur de la matrice de covariance des interférences plus bruit est biaisé) dans le cas où les données ne sont pas iid. C'est le cas, par exemple, pour les radars utilisant une ALU en visée non latérale et ceux utilisant une ACoU ou ACU. En effet, dans ces configurations, la densité spectrale du fouillis présente une dépendance en distance qui introduit une non stationnarité des données.
Un nouvel algorithme de codage multibandes synchrone au pitch appelé PSMB (“pitch synchronous multi-band”) est proposé. Pour chaque trame cet algorithme génère un signal représentatif d'un cycle de pitch (PCW) (“pitch-cycle waveform”) en utilisant un modèle d'excitation multibandes MBE (“multi-band excitation”). Selon si une trame est liée ou pas à la trame précédente, le signal PCW correspondant est quantifié sur deux parmi trois “codebooks”. Dans le cas contraire, le signal PCW est codé utilisant le même “codebook” stochastique et un “codebook” d'excitation à une impulsion à bande limitée BSPE (“bandlimited single pulse excitation”). Cette nouvelle approche définit un codage basé sur la période du pitch. De ce fait, le nouvel codeur réduit les faiblesses de l'algorithme MBE amélioré (IMBE). Le codeur PSMB développé fonctionne à 4 kbps et produit une meilleure performance que le codeur IMBE Inmarsat à 4.15 kbps. Les tests d'écoute effectués montrent une légère amélioration au niveau perceptuel par rapport au codeur CELP (“code excited linear predictive”) FS1016 à 4.8 kbps. Des algorithmes de recherche rapide dans les trois “codebooks” sont développés dans le cadre du codeur PSMB proposé. Cette recherche rapide a rendu la complexité de calcul du codeur PSMB comparable à celle du codeur FS1016.
Cet article décrit le travail récent effectué au MIT pour développer des systèmes de dialogue oral homme-machine multilingues. Notre aproche est basée sur l'hypothèse qu'une représentation sémantique commune peut être extraite des énoncés quelle que soit la langue, au moins dans des domaines restreints. Dans notre conception de ces systèmes, l'information dépendante de la langue est séparée le plus possible du noyau du système et encodée dans des structures de données externes. Le gestionnaire interne du système, les modules d'analyse du discours et de dialogue, et les bases de données sont tous maintenues dans un état indépendant de la langue. Dans cet article, nous décrivons plus particulièrement le système de dialoque oral multilingue Voyager qui peut gérer des dialogues concernant la région géographique de Cambridge, MA, aux Etats-Unis. Le système peut fournir des informations concernant les distances, les durées de trajets ou les directions entre des objets situés dans cette zone (par exemple, les restaurants, hotels, banques, bibliothèques, etc.). On fournit des résultats d'évaluation des versions en anglais, japonais et italien. D'autres recherches multilingues annexes sont également brièvement mentionnées.