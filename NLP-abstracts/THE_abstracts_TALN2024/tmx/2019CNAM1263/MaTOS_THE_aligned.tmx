<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2019CNAM1263. segId begin by 1, tuid = segId</note>
        <docid>2019CNAM1263</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, nous proposons une nouvelle approche de l'apprentissage profond pour la classification des flux de données de grande dimension.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this thesis, we propose a new deep-learning-based approach for online classification on streams of high-dimensional data.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Au cours des dernières années, les réseaux de neurones sont devenus la référence dans diverses applications d'apprentissage automatique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In recent years, Neural Networks (NN) have become the primary building block of state-of-the-art methods in various machine learning problems.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Cependant, la plupart des méthodes basées sur les réseaux de neurones sont conçues pour résoudre des problèmes d'apprentissage statique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Most of these methods, however, are designed to solve the static learning problem, when all data are available at once at training time.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Effectuer un apprentissage profond en ligne est une tâche difficile.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Performing Online Deep Learning is exceptionally challenging.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>La principale difficulté est que les classificateurs basés sur les réseaux de neurones reposent généralement sur l'hypothèse que la séquence des lots de données utilisées pendant l'entraînement est stationnaire ; ou en d'autres termes, que la distribution des classes de données est la même pour tous les lots (hypothèse i.i.d.).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The main difficulty is that NN-based classifiers usually rely on the assumption that the sequence of data batches used during training is stationary, or in other words, that the distribution of data classes is the same for all batches (i.i.d. assumption).</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Lorsque cette hypothèse ne tient pas les réseaux de neurones ont tendance à oublier les concepts temporairement indisponibles dans le flux.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>When this assumption does not hold Neural Networks tend to forget the concepts that are temporarily not available in the stream.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Dans la littérature scientifique, ce phénomène est généralement appelé oubli catastrophique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the literature, this phenomenon is known as catastrophic forgetting.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Les approches que nous proposons ont comme objectif de garantir la nature i.i.d. de chaque lot qui provient du flux et de compenser l'absence de données historiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The approaches we propose in this thesis aim to guarantee the i.i.d. nature of each batch that comes from the stream and compensates for the lack of historical data.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Pour ce faire, nous entrainons des modèles génératifs et pseudo-génératifs capable de produire des échantillons synthétiques à partir des classes absentes ou mal représentées dans le flux, et complètent les lots du flux avec ces échantillons.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To do this, we train generative models and pseudo-generative models capable of producing synthetic samples from classes that are absent or misrepresented in the stream and complete the stream's batches with these samples.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Nous testons nos approches dans un scénario d'apprentissage incrémental et dans un type spécifique de l'apprentissage continu.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We test our approaches in an incremental learning scenario and a specific type of continuous learning.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Nos approches effectuent une classification sur des flux de données dynamiques avec une précision proche des résultats obtenus dans la configuration de classification statique où toutes les données sont disponibles pour la durée de l'apprentissage.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our approaches perform classification on dynamic data streams with the accuracy close to the results obtained in the static classification configuration where all data are available for the duration of the learning.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>En outre, nous démontrons la capacité de nos méthodes à s'adapter à des classes de données invisibles et à de nouvelles instances de catégories de données déjà connues, tout en évitant d'oublier les connaissances précédemment acquises.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Besides, we demonstrate the ability of our methods to adapt to invisible data classes and new instances of already known data categories, while avoiding forgetting the previously acquired knowledge.</seg>
            </tuv>
        </tu>
    </body>
</tmx>