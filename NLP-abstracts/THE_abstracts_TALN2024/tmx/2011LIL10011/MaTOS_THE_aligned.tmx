<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2011LIL10011. segId begin by 1, tuid = segId</note>
        <docid>2011LIL10011</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Avec l'augmentation exponentielle de nombre d'images disponibles sur Internet, le besoin en outils efficaces d'indexation et de recherche d'images est devenu important.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>With the availability of massive amounts of digital images in personal and on-line collections, effective techniques for navigating, indexing and searching images become more crucial.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, nous nous baserons sur le contenu visuel des images comme source principale d'informations pour leur représentation.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this thesis, we rely on the image visual content as the main source of information to represent images.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Dans un premier temps, nous améliorons l'approche des sacs de mots visuels en caractérisant la constitution spatio-colorimétrique d'une image par le biais d'un mélange de n Gaussiennes dans l'espace de caractéristiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>First, we enhance the BOW representation by characterizing the spatial-color constitution of an image with a mixture of n Gaussians in the feature space.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Cela permet de proposer un nouveau descripteur de contour qui joue un rôle complémentaire avec le descripteur SURF.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This leads to propose a novel descriptor, the Edge Context, which plays a role as a complementary descriptor in addition to the SURF descriptor.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Dans un deuxième temps, nous introduisons un nouveau modèle probabiliste basé sur les catégories : le modèle MSSA (Multilayer Semantic Significance Analysis ou Analyse multi-niveaux de la pertinence sémantique) dans le but d'étudier la sémantique des mots visuels construits.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Second, we introduce a new probabilistic topic model, Multilayer Semantic Significance Analysis (MSSA) model, in order to study a semantic inference of the constructed visual words.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Ce modèle permet de construire des mots visuels sémantiquement cohérents (SSVW - Semantically Significant Visual Word).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Consequently, we generate the Semantically Significant Visual Words (SSVWs).</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Enfin, nous proposons un nouveau schéma de pondération spatiale ainsi qu'un classifieur multi-classes basé sur un vote.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Finally, we propose a new spatial weighting scheme and a Multiclass Vote-Based Classifier (MVBC) based on the proposed SSVIG representation.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Nos résultats expérimentaux extensifs démontrent que la représentation visuelle proposée permet d'atteindre de meilleures performances comparativement aux représentations traditionnelles utilisées dans le domaine de la recherche, la classification et de la reconnaissance d'objets.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The large-scale extensive experimental results show that the proposed higher-level visual representation outperforms the traditional part-based image representations in retrieval, classification and object recognition.</seg>
            </tuv>
        </tu>
    </body>
</tmx>