<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-1999NAN10300. segId begin by 1, tuid = segId</note>
        <docid>1999NAN10300</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>L'objet de cette thèse est l'étude de la reconnaissance automatique de parole.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The framework of this thesis is speaker-independent automatic speech recognition.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Ce document débute avec la description des traitements acoustiques les plus répandus en vue de reconnaître la parole.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This document begins with a short survey of speech signal processing applied to speech recognition.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Nous décrivons ensuite les diverses architectures qui ont été utilisées : comparaison dynamique de formes acoustiques, systèmes experts, réseaux neuro-mimétiques et modèles de Markov.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Then, we describe several common architectures: dynamic time warping of acoustic shapes, artificial intelligence, neural networks and hidden Markov models.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Puis ce document se divise en deux parties.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This document is made of two main parts.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Pour cela, nous utilisons des automates qui modélisent le vocabulaire.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The first part is devoted to the recognition of words.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Celui-ci comporte les dix chiffres anglo-saxons, dont deux prononciations différentes pour le zéro.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We are using finite state automata for modeling the eleven American spoken digits.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Le corpus de parole TiDigits a été utilisé par d'autres laboratoires ce qui nous permet de comparer nos résultats.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>As the speech database TiDigits has been used by other teams we can compare our results against thoose obtained with other approaches.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>La première étape est consacrée à la reconnaissance de mots isolés.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The first step is concerned with isolated word recognition.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Puis nous présentons une méthode de segmentation de séquences de chiffres.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Then, we describe how sentences of the database have been segmented.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>La fin de ce chapitre est consacrée à la reconnaissance de mots enchaînés et à une discussion sur les mérites et les faiblesses de notre approche.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Last sections of this part describe continuous speech recognition of word sequences, as well as a discussion about strong and weak points of our approach.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>La deuxième partie traite de l'utilisation d'un modèle de production qui pourrait être utilisé pour le reconnaissance de la parole.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The second part treats of the use of production models for speech recognition.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Nous commençons par présenter les équations acoustiques régissant l'écoulement de l'air dans le conduit vocal et divers modèles articulatoires.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We begin with a description of the acoustic equations which drive the air flow inside the vocal tract and we present several articulatory models.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Ensuite nous justifions le choix du modèle articulatoire de Maeda.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Then, we justify the choice of Maeda's model.</seg>
            </tuv>
        </tu>
        <tu tuid="14">
            <tuv xml:lang="FR">
                <seg>Nous décrivons comment nous avons adapté le modèle à un locuteur masculin.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We describe the adaptation of this model to a male speaker.</seg>
            </tuv>
        </tu>
        <tu tuid="15">
            <tuv xml:lang="FR">
                <seg>Puis nous présentons la méthode variationnelle utilisée pour retrouver les trajectoires des articulateurs en fonction de la parole prononcée.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Next, we describe the variational method used for recovering articulatory trajectories from the speech.</seg>
            </tuv>
        </tu>
        <tu tuid="16">
            <tuv xml:lang="FR">
                <seg>Une dernière section présente les logiciels réalisés.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Finally, the software we built, is described.</seg>
            </tuv>
        </tu>
        <tu tuid="17">
            <tuv xml:lang="FR">
                <seg>En conclusion, nous résumons les résultats obtenus et donnons quelques perspectives en vue de reconnaître la parole continue quel que soit le locuteur.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the conclusion, we give the results obtained and we exhibit sorne perspectives for future work towards a better speaker indepedent continuous speech recognition system.</seg>
            </tuv>
        </tu>
    </body>
</tmx>