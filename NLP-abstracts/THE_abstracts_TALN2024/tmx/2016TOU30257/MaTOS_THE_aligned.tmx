<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2016TOU30257. segId begin by 1, tuid = segId</note>
        <docid>2016TOU30257</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Les systèmes de recommandation actuels ont besoin de recommander des objets pertinents aux utilisateurs (exploitation), mais pour cela ils doivent pouvoir également obtenir continuellement de nouvelles informations sur les objets et les utilisateurs encore peu connus (exploration).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Current recommender systems need to recommend items that are relevant to users (exploitation), but they must also be able to continuously obtain new information about items and users (exploration).</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Il s'agit du dilemme exploration/exploitation.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This is the exploration / exploitation dilemma.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Un tel environnement s'inscrit dans le cadre de ce que l'on appelle " apprentissage par renforcement ".</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Such an environment is part of what is called "reinforcement learning".</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Dans la littérature statistique, les stratégies de bandit sont connues pour offrir des solutions à ce dilemme.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the statistical literature, bandit strategies are known to provide solutions to this dilemma.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Les contributions de cette thèse multidisciplinaire adaptent ces stratégies pour appréhender certaines problématiques des systèmes de recommandation, telles que la recommandation de plusieurs objets simultanément, la prise en compte du vieillissement de la popularité d'un objet ou encore la recommandation en temps réel.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The contributions of this multidisciplinary thesis the adaptation of these strategies to deal with some problems of the recommendation systems, such as the recommendation of several items simultaneously, taking into account the aging of the popularity of an items or the recommendation in real time.</seg>
            </tuv>
        </tu>
    </body>
</tmx>