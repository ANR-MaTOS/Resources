<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2016GREAM080. segId begin by 1, tuid = segId</note>
        <docid>2016GREAM080</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Dans cette dissertation, nous proposons des méthodes d'apprentissage automa-tique aptes à bénéficier de la récente explosion des volumes de données digitales.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this dissertation, we propose methods and data driven machine learning solutions which address and benefit from the recent overwhelming growth of digital media content.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Premièrement nous considérons l'amélioration de l'efficacité des méthodes derécupération d'image.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>First, we consider the problem of improving the efficiency of image retrieval.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Nous proposons une approche d'apprentissage de métriques locales coordonnées (Coordinated Local Metric Learning, CLML) qui apprends des métriques locales de Mahalanobis, puis les intègre dans une représentation globale où la distance l2 peut être utilisée.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We propose a coordinated local metric learning (CLML) approach which learns local Mahalanobis metrics, and integrates them in a global representation where the l2 distance can be used.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Ceci permet de visualiser les données avec une unique représentation 2D, et l'utilisation de méthodes de récupération efficaces basées sur la distance l2.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This allows for data visualization in a single view, and use of efficient ` 2-based retrieval methods.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Notre approche peut être interprétée comme l'apprentissage d'une projection linéaire de descripteurs donnés par une méthode a noyaux de grande dimension définie explictement.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our approach can be interpreted as learning a linear projection on top of an explicit high-dimensional embedding of a kernel.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Cette interprétation permet d'appliquer des outils existants pour l'apprentissage de métriques de Mahalanobis à l'apprentissage de métriques locales coordonnées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This interpretation allows for the use of existing frameworks for Mahalanobis metric learning for learning local metrics in a coordinated manner.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Nos expériences montrent que la CLML amé-liore les résultats en matière de récupération de visage obtenues par les approches classiques d'apprentissage de métriques locales et globales.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our experiments show that CLML improves over previous global and local metric learning approaches for the task of face retrieval.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Nous explorerons différentes stratégies d'apprentissage de métriques locales à partir des couches intermédiaires d'un CNN, afin de faire le rapprochement entre des images de sources différentes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We explore different metric learning strategies over features from the intermediate layers of the networks, to reduce the discrepancies between the different modalities.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Dans nos expériences, la profondeur de la couche optimale pour une tâche donnée est positivement corrélée avec le changement entre le domaine source (données d'entraînement du CNN) et le domaine cible.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In our experiments we found that the depth of the optimal features for a given modality, is positively correlated with the domain shift between the source domain (CNN training data) and the target domain.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Les résultats montrent que nous pouvons utiliser des CNN entraînés sur des images du spectre visible pour obtenir des résultats meilleurs que l'état de l'art pour la reconnaissance faciale hétérogène (images et dessins quasi-infrarouges).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Experimental results show the that we can use CNNs trained on visible spectrum images to obtain results that improve over the state-of-the art for heterogeneous face recognition with near-infrared images and sketches.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Troisièmement, nous présentons les "tissus de neurones convolutionnels" (Convolutional Neural Fabrics) permettant l'exploration de l'espace discret et exponentiellement large des architectures possibles de réseaux neuronaux, de manière efficiente et systématique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Third, we present convolutional neural fabrics for exploring the discrete andexponentially large CNN architecture space in an efficient and systematic manner.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Au lieu de chercher à sélectionner une seule architecture optimale, nous proposons d'utiliser un "tissu" d'architectures combinant un nombre exponentiel d'architectures en une seule.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Instead of aiming to select a single optimal architecture, we propose a “fabric” that embeds an exponentially large number of architectures.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Le tissu est une représentation 3D connectant les sorties de CNNs à différentes couches, échelles et canaux avec un motif de connectivité locale, homogène et creux.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The fabric consists of a 3D trellis that connects response maps at different layers, scales, and channels with a sparse homogeneous local connectivity pattern.</seg>
            </tuv>
        </tu>
        <tu tuid="14">
            <tuv xml:lang="FR">
                <seg>Les seuls hyper-paramètres du tissu (le nombre de canaux et de couches) ne sont pas critiques pour la performance.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The only hyperparameters of the fabric (the number of channels and layers) are not critical for performance.</seg>
            </tuv>
        </tu>
        <tu tuid="15">
            <tuv xml:lang="FR">
                <seg>La nature acyclique du tissu nous permet d'utiliser la rétro-propagation du gradient durant la phase d'apprentissage.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The acyclic nature of the fabric allows us to use backpropagation for learning.</seg>
            </tuv>
        </tu>
        <tu tuid="16">
            <tuv xml:lang="FR">
                <seg>De manière automatique, nous pouvons donc configurer le tissu de manière à implémenter l'ensemble de toutes les architectures possibles (un nombre exponentiel) et, plus généralement, des ensembles (combinaisons) de ces modèles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Learning can thus efficiently configure the fabric to implement each one of exponentially many architectures and, more generally, ensembles of all of them.</seg>
            </tuv>
        </tu>
        <tu tuid="17">
            <tuv xml:lang="FR">
                <seg>La complexité de calcul et de taille mémoire du tissu évoluent de manière linéaire alors qu'il permet d'exploiter un nombre exponentiel d'architectures en parallèle, en partageant les paramètres entre architectures.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>While scaling linearly in terms of computation and memory requirements, the fabric leverages exponentially many chain-structured architectures in parallel by massively sharing weights between them.</seg>
            </tuv>
        </tu>
        <tu tuid="18">
            <tuv xml:lang="FR">
                <seg>Nous présentons des résultats à l'état de l'art pour la classification d'images sur le jeu de données MNIST et CIFAR10, et pour la segmentation sémantique sur le jeu de données Part Labels.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We present benchmark results competitive with the state of the art for image classification on MNIST and CIFAR10, and for semantic segmentation on the Part Labels dataset</seg>
            </tuv>
        </tu>
    </body>
</tmx>