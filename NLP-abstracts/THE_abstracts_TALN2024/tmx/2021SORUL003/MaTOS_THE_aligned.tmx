<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2021SORUL003. segId begin by 1, tuid = segId</note>
        <docid>2021SORUL003</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Les problèmes éthiques liés à l’arrivée de formes d’intelligence artificielles différentes a sollicité beaucoup d’attention aussi bien académique que publique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The ethics of emerging forms of artificial intelligence has become a prolific subject in both academic and public spheres.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Cependant, ces inquiétudes se concentrent sur un problème particulier : comment assurer que les décisions prises par les agents artificiels comme des voitures autonomes ne nuisent pas aux êtres humains présents dans leur environnement ?</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>A great deal of these concerns flow from the need to ensure that these technologies do not cause harm—physical, emotional or otherwise—to the human agents with which they will interact.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Cette question a incité la création de ceux qui sont communément appelés les agents moraux artificiels dans la littérature, la prise de décision desquels est contrainte par une moralité artificielle : un système de principes normatifs implémenté dans le processus de raisonnement de la machine.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the literature, this challenge has been met with the creation of artificial moral agents: embodied or virtual forms of artificial intelligence whose decision procedures are constrained by explicit normative principles, requiring the implementation of what is commonly called artificial morality into these agents.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>A ce jour, la forme que prend cette moralité artificielle relève de deux approches différentes : soit une forme maximalement éthique, qui dépend de l’implémentation stricte des théories morales préexistantes comme la déontologie Kantienne ou l’Utilitarisme, soit une forme minimaliste, qui applique des techniques de l’IA stochastique à l’analyse et agrégation de données portant sur les préférences morales d’une population, afin d’en tirer des principes généraux mobilisés ensuite dans la prise de décision des machines.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To date, the types of reasoning structures and principles which inform artificial morality have been of two kinds: first, an ethically maximal vision of artificial morality which relies on the strict implementation of traditional moral theories such as Kantian deontology or Utilitarianism, and second, a more minimalist vision which applies stochastic AI techniques to large data sets of human moral preferences so as to illicit or intuit general principles and preferences for the design of artificial morality.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Nous proposons une approche alternative à la moralité artificielle, la théorie des valences éthiques, qui s’efforce d’accommoder ce genre de pondération, et nous l’appliquons au cas du véhicule autonome.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We provide an alternative approach to the design of artificial morality, the Ethical Valence Theory, whose purpose is to accommodate this balance, and apply this approach to the case of autonomous vehicles.</seg>
            </tuv>
        </tu>
    </body>
</tmx>