<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-s228106. segId begin by 1, tuid = segId</note>
        <docid>s228106</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>La détection de langage abusif en ligne est un problème de classification comportant des défis cruciaux liés à la compréhension automatique du langage naturel et à la variété des contextes complexes et riches par lesquels le langage naturel se manifeste.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Detecting abusive language online is a classification problem with critical challenges that depend on machine understanding of natural language and the variety of rich and complex contexts in which natural language occurs.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Les réseaux de neurones et les techniques standard d'apprentissage profond se sont montrés efficaces dans la detection de contenu explicitement offensif dans les conversations mais il est plus difficile de détecter automatiquement des formes plus subtiles, mais aussi plus fréquentes, de *toxicité passive* comme le sarcasme, les comportements passifs-aggressifs et les discours de haine formulés poliment, mais incendiaires.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>It has been shown that neural networks and standard Deep Learning (DL) techniques can detect explicit offensive content in conversations but it is more difficult to make machines detect more subtle, but also more common forms of so called 'passive toxicity'such as sarcasm, passive-aggressive behavior, and politely worded but incendiary hate speech.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Les modèles d'apprentissage automatique traditionnels et plus récemment les réseaux de neurones convolutifs (CNN) basés sur les mots et sur les caractères et les réseaux de neurones récurrents comme les modèles Long Short-Term Memory (LSTM) et les Gated Recurrent Units (GRUs), couplés à du plongement de mots ont été utilisés pour assister la modération de commentaires et pour detecter les discours de haine.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Traditional Machine Learning (ML) models and more recently word-based and character-based Convolution Neural Networks (CNN) and Recurrent Neural Networks (RNN) like Long Short-Term Memory (LSTM) models and Gated Recurrent Units (GRU), coupled with word embedding have been used to assist comment moderation and hate-speech detection.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>De plus, des travaux ont cherché à interpréter ces réseaux de neurones detectant l'agressivité verbale.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Furthermore, some work focuses on interpreting these neural networks detecting verbal aggression.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Dans le cadre de l'initiative de recherche Conversation AI de Google Jigsaw, notre recherche portera sur la façons dont des méthodes novatrices d'apprentissage profond peuvent saisir la toxicité passive.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>As part of the Conversation AI research initiative at Google Jigsaw, our research will focus on exploring how new ground-breaking methods in deep learning can capture passive toxicity.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Conversation AI a de l'expérience dans le développement des modèles théoriques, et des outils pour les utilisateurs et sites web.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Conversation AI has experience in developing both theoretical models and tools for users and websites.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>La thèse s'articulera autour de deux axes complémentaires : les données annotées et les modèles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The proposed thesis will explore two orthogonal directions: labelled datasets and models.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Pour la classification supervisée, nous avons besoin de grandes quantités de commentaires annotés issus de vraies conversations en ligne.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>For supervised classification, we need large datasets of labeled comments from actual online conversations.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Nous prévoyons de partir des ensembles de données publics fournis par l'équipe Jigsaw / Conversation-AI.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We plan to start from the public datasets provided by the Jigsaw/Conversation-AI team.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Ils sont soit annotés manuellement par production participative soit annotés à partir de features comme les tags ou étiquettes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>They can either be manually augmented with labels by crowdsourcing or automatically labeled from linguistic features such as tags.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Ces jeux de données ont montré un nombre significatif de commentaires contenant de la toxicité passive mais caractérisés par une probabilité de toxicité intermédiaire.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>From initial experiments, these datasets contain significant number of passive toxic comments that get intermediate toxicity probabilities.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Nous suivrons l'approche utilisée par l'interface de programmation applicative Perspective, qui consiste à sélectionner un petit nombre de catégories vraissemblables pour annoter les différents types de toxicité passive.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We will follow the approach used by Perspective API of selecting a small number of likely categories for labelling different kinds of passive toxicity.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Nous exploiterons et améliorerons les modèles Transformer et BERT, qui s'appuient sur des mécanismes d'attention et nous observerons leur comparaison à d'autres modèles d'apprentissage profond.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We will leverage and improve the transformer and BERT models based on attention mechanisms for this application and see how they compare to other deep learning models.</seg>
            </tuv>
        </tu>
        <tu tuid="14">
            <tuv xml:lang="FR">
                <seg>Puisque la toxicité passive se base sur l'ambiguité du langage naturel, nous nous concentrerons sur la modélisation de l'impact émotionnel des messages qui, comme Conversation AI l'a découvert, aboutit à de plus forts niveaux d'accords inter-annotateurs (par rapport aux distinctions sémantiques plus complexes que les document de violation de politique tentent d'établir).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Because passive toxicity leverages ambiguity in natural language, we will focus on modeling the emotional impact of messages, which Conversation AI found resulted in higher levels of inter-annotator agreement (compared to more complex semantic distinctions that policy violation documents try to make).</seg>
            </tuv>
        </tu>
        <tu tuid="15">
            <tuv xml:lang="FR">
                <seg>Les méthodes d'apprentissage par renforcement (RL) peuvent également se montrer intéressantes dans ce contexte.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Methods of Reinforcement Learning (RL) may also be explored in this context.</seg>
            </tuv>
        </tu>
        <tu tuid="16">
            <tuv xml:lang="FR">
                <seg>l'autre aspect de cette recherche est l'analyse et la compréhension des origines et des mécanismes du comportement passif-aggressif en ligne.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The other aspect of the research is to analyze and understand the origins and mechanisms of passive aggression.</seg>
            </tuv>
        </tu>
        <tu tuid="17">
            <tuv xml:lang="FR">
                <seg>Ceci peut être fait en mesurant et en visualisant son impact sur les conversations.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This can be done by measuring and visualizing the impact it has on conversations.</seg>
            </tuv>
        </tu>
        <tu tuid="18">
            <tuv xml:lang="FR">
                <seg>Du code source ouvert et des publications dans des conférences et journaux sélectifs seront produits au cours de ce doctorat.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Open Source code and publications in competitive venues will be produced during the PhD program.</seg>
            </tuv>
        </tu>
        <tu tuid="19">
            <tuv xml:lang="FR">
                <seg>Les modèles seront implémentés en Python et avec le cadre de développement TensorFlow.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The models will be implemented in Python, with the TensorFlow framework.</seg>
            </tuv>
        </tu>
        <tu tuid="20">
            <tuv xml:lang="FR">
                <seg>Les métriques utilisées pour comparer les architectures incluent la justesse, la précision, le rappel, la spécificité, le taux de faux positifs, le score F1, la fonction d'efficacité du récepteur et son aire sous la courbe (ROC-AUC).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Metrics used for comparing architectures include accuracy, precision, recall, specificity, fall-out, F1 score, Receiver Operating Characteristic curve Area Under Curve (ROC-AUC).</seg>
            </tuv>
        </tu>
        <tu tuid="21">
            <tuv xml:lang="FR">
                <seg>Au cours de cette recherche, nous prévoyons d'apporter des éléments de réponse aux différentes questions concernant les conversations sur les réseaux sociaux comme par exemple : comment développer des méthodes d'apprentissage profond pour identifier la toxicité passive dans les conversations en ligne ?</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This research is expected to bring answers to various questions pertaining to conversations on social networks, such as: how to develop Deep Learning to identify passive toxicity in online conversations?</seg>
            </tuv>
        </tu>
        <tu tuid="22">
            <tuv xml:lang="FR">
                <seg>L'apprentissage profond peut-il comprendre la pertinence des contributions dans un débat ?</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Can it understand the relevance of posts in a debate?</seg>
            </tuv>
        </tu>
        <tu tuid="23">
            <tuv xml:lang="FR">
                <seg>Qu'est-ce qui déclenche la toxicité passive dans la conversation ?</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>What triggers passive toxicity in conversation?</seg>
            </tuv>
        </tu>
        <tu tuid="24">
            <tuv xml:lang="FR">
                <seg>Que se passe-t-il dans une conversation juste après la détection d'un comportement passif-agressif ?</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>What happens in a conversation right after passive aggression has been detected?</seg>
            </tuv>
        </tu>
        <tu tuid="25">
            <tuv xml:lang="FR">
                <seg>Est-ce un comportement ponctuel ou récurrent des interlocuteurs ?</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Is it a one-time or an ongoing behavior from interlocutors?</seg>
            </tuv>
        </tu>
        <tu tuid="26">
            <tuv xml:lang="FR">
                <seg>Quelles réponses peuvent désamorcer une conversation et l'empêcher de *mal tourner* ?</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>What are the replies to subtle toxicity that can forestall an *awry-turning* conversation?</seg>
            </tuv>
        </tu>
        <tu tuid="27">
            <tuv xml:lang="FR">
                <seg>Dans quelle mesure la détection précoce de toxicité subtile est-elle importante pour garder une conversation en bonne voie ?</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>How does the early detection of it matter for keeping the conversation on track?</seg>
            </tuv>
        </tu>
        <tu tuid="28">
            <tuv xml:lang="FR">
                <seg>Nous espérons que les modèles développés performeront suffisement bien pour être finalement intégrés dans l'interface de programmation applicative Perspective, de sorte qu'ils puissent être utilisés directement dans l'industrie, et soutenir un large éventail d'initiatives de recherche supplémentaires.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We hope the resulting models will perform well enough that they end up being provided through the Perspective API so that they can be directly used by industry, and to support a wide range of other research initiatives.</seg>
            </tuv>
        </tu>
        <tu tuid="29">
            <tuv xml:lang="FR">
                <seg>Afin d'amener les internautes en dehors de leurs bulles de filtres en ligne, ils doivent pouvoir dialoguer sur des plateformes à l'abri de l'agressivité, de la violence et de l'ostracisme (phénomène des boucs-émissaires).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In order to bring people out of their online 'filter bubbles', they need to be able to have conversations on platforms safe from aggressiveness, violence and scapegoating.</seg>
            </tuv>
        </tu>
        <tu tuid="30">
            <tuv xml:lang="FR">
                <seg>Les stratégies d'apprentissage automatique, d'apprentissage profond et de traitement automatique du langage naturel peuvent nous aider à *confronter nos opinions divergentes de manière plus constructive* (The Righteous Mind, Jonathan Haidt).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Machine Learning, Deep Learning and Natural Language Processing strategies can help us to 'disagree more constructively'(The Righteous Mind, Jonathan Haidt).</seg>
            </tuv>
        </tu>
        <tu tuid="31">
            <tuv xml:lang="FR">
                <seg>Ainsi, cette recherche s'inscrit dans une optique d'accroissement de le participation, de la qualité, et de l'empathie dans les conversations en ligne à grande échelle, en développant de nouveaux modèles appliqués à de nouveaux jeux de données, suggérant des comportements non-biaisés, guidant et éduquant les utilisateurs vers plus d'équité.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Therefore, this research should allow to increase participation, quality, and empathy in online conversation at scale by developing new models applied to new datasets suggesting unbiased behaviors, guide and educate users about fairness.</seg>
            </tuv>
        </tu>
        <tu tuid="32">
            <tuv xml:lang="FR">
                <seg>L'utilisation de nouvelles technologie pour permettre un débat plus rationnel et plus éclairé s'inscrit dans un effort de lutte contre le harcèlement en ligne tout en défendant le débat public, la liberté d'expression, la démocratie et le pluralisme.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Using technology to enable more rational and informed debate enters into a goal of fighting against online harassment while defending public debates, freedom of speech, democracy and pluralism.</seg>
            </tuv>
        </tu>
    </body>
</tmx>