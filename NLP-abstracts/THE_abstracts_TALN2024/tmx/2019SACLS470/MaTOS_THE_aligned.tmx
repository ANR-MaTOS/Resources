<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2019SACLS470. segId begin by 1, tuid = segId</note>
        <docid>2019SACLS470</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Les données de type tabulaire contiennent souvent des variables catégorielles, considérées comme des entrées non numériques avec un nombre fixe et limité d'éléments uniques, appelés catégories.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Tabular data often contain columns with categorical variables, usually considered as non-numerical entries with a fixed and limited number of unique elements or categories.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>De nombreux algorithmes d’apprentissage statistique nécessitent une représentation numérique des variables catégorielles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>As many statistical learning algorithms require numerical representations of features, an encoding step is necessary to transform categorical entries into feature vectors, using for instance one-hot encoding.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Pour cela, plusieurs stratégies existent, dont la plus courante est celle de l'encodage one-hot, qui fonctionne bien dans le cadre de l'analyse statistique classique (en termes de puissance de prédiction et d'interprétation) lorsque le nombre de catégories reste faible.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>However, non-curated data give rise to string categorical variables with a very high cardinality and redundancy: the string entries share semantic and/or morphological information, and several entries can reflect the same entity.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Cependant, les données catégorielles non-uniformisées présentent le risque d'avoir une grande cardinalité et des redondances.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Without any data cleaning or feature engineering step, common encoding methods break down, as they tend to lose information in their vectorial representation.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>En effet, les entrées peuvent partager des informations sémantiques et/ou morphologiques, et par conséquent, plusieurs entrées peuvent refléter la même entité.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Also, they can create high-dimensional feature vectors, which prevent their usage in large scale settings.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Sans une étape de nettoyage ou d'agrégation au préalable, les méthodes d'encodage courantes peuvent perdre en efficacité du fait d'une représentation vectorielle erronée.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this work, we study a series of categorical encodings that remove the need for preprocessing steps on high-cardinality string categorical variables.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Même avec des données volumineuses, ces méthodes s'avèrent être performantes, et dans certains cas, elles génèrent des vecteurs facilement interprétables.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Experiments on real and simulated data show that the methods we propose improve supervised learning, are adapted to large-scale settings, and, in some cases, create feature vectors that are easily interpretable.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Par conséquent, nos méthodes peuvent être appliquées à l'apprentissage statistique automatique (AutoML) sans aucune intervention humaine.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Hence, they can be applied in Automated Machine Learning (AutoML) pipelines in the original string entries without any human intervention.</seg>
            </tuv>
        </tu>
    </body>
</tmx>