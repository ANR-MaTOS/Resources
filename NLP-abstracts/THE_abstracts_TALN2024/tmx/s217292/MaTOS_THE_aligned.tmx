<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-s217292. segId begin by 1, tuid = segId</note>
        <docid>s217292</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>L'objectif général de ce projet doctoral est de proposer des nouvelles approches automatiques non- ou faiblement supervisées visant à caractériser une conversation orale à partir de son enregistrement audio et sa transcription (automatique ou manuelle quand elle est disponible).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The main objective of the project is to investigate novel unsupervised or weakly supervised machine learning techniques for the automatic structuring of spoken conversations, given its audio recording and (manual or automatic) speech transcription.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Dans un premier temps, on s'intéressera à l'identification nommée des différents locuteurs.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>First, one will focus on named speaker diarization.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Sans aucune connaissance a priori sur la qualité et le nombre des participants à la conversation, ce problème peut se découper en deux sous-problèmes : la constitution automatique de la liste des participants à la conversation (grâce à des outils de détection d'entités nommées et d'entity linking, par exemple) suivi de l'attribution automatique de leurs tours de parole respectives (en combinant compréhension de dialogue et reconnaissance du locuteur, par exemple).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Without any prior knowledge on the speakers involved in the conversation, this task can be divided into two subtasks: gathering the names of all speakers (thanks to named entity recognition and entity linking, for instance) followed by the attribution of each speech turns to the corresponding speaker (using natural language understanding and speaker recognition, for instance).</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Dans un second temps, on s'interessera à la caractérisation des conversations selon une typologie permettant d'identifier la nature des échanges (argumentation, débat, altercation, etc.).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Then, one will address the problem of classifying conversations according to the content of the exchanges (are speakers arguing, fighting, small-talking?).</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Cette caractérisation pourra se faire en utilisant des techniques de traitement automatique des langues enrichies d'informations acoustiques (informations prosodiques par exemple) afin d'améliorer les performances.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To that end, one could enrich natural language processing techniques with acoustic cues (prosody, rythm, etc.).</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Ces nouvelles approches seront appliquées sur un corpus composé de films (Anna et ses soeurs, les films Harry Potter) et de séries télévisées de différente nature (Lost, Friends, The Big Bang Theory, Game of Thrones, etc.).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The proposed approaches will be applied to movies or TV series, for which a significant amount of annotations are already available.</seg>
            </tuv>
        </tu>
    </body>
</tmx>