<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2020UPASS005. segId begin by 1, tuid = segId</note>
        <docid>2020UPASS005</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Un des principaux pans du traitement automatique des langues (TAL) est l'extraction sous forme structurée des informations contenues dans un document.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The extraction of structured information from a document is one of the main parts of natural language processing (NLP).</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Cette extraction est généralement constituée de trois étapes : l'extraction d'entités nommées, des relations les liant au sein du texte et enfin celle des événements.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This extraction usually consists in three steps: named entities recognition relation extraction and event extraction.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>La notion d'événement recouvre différents phénomènes caractérisés par un nombre variable d'actants.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The notion of event covers a broad list of different phenomena which are characterized through a varying number of roles.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>L'extraction d'événements consiste alors à identifier la présence d'un événement puis à en déterminer les arguments, c'est-à-dire les différentes entités y remplissant des rôles spécifiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Thereupon, Event extraction consists in detecting the occurrence of an event then determining its argument, that is, the different entities filling specific roles.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Les meilleures approches actuelles, reposant sur différents modèles neuronaux, se focalisent sur le voisinage direct du mot dans la phrase.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The current best approaches, based on neural networks, focus on the direct neighborhood of the target word in the sentence.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Les informations présentes dans le reste du document sont alors généralement ignorées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Information in the rest of the document is then usually ignored.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Cette thèse présente donc différentes approches visant à exploiter ce contexte distant au sein du document.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This thesis presents different approaches aiming at exploiting this document-level context.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Nous reproduisons en premier lieu un modèle convolutif obtenant des performances à l'état de l'art et en analysons plusieurs paramètres.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We begin by reproducing a state of the art convolutional neural network and analyze some of its parameters.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Nous réalisons ensuite une expérience permettant d'illustrer le fait que ce modèle, malgré ses bonnes performances, n'exploite effectivement qu'un contexte très restreint au niveau phrastique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We then present an experiment showing that, despite its good performances, our model only exploit a narrow context at the intra-sentential level.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Dans un deuxième temps, nous présentons deux méthodes de production et d'intégration d'une représentation du contexte distant à un modèle neuronal opérant au niveau intra-phrastique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Subsequently, we present two methods to generate and integrate a representation of the inter-sentential context in a neural network operating on an intra-sentential context.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Nous montrons par ailleurs la supériorité de cette approche sur une représentation générique du document.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We also show that this task-specific representation is better than an existing generic representation of the inter-sentential context.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Une seconde contribution, répondant aux limitations de la première méthode, permet d'exploiter dynamiquement, pour chaque cible de prédiction, une représentation des phrases les plus pertinentes au sein du contexte grâce à un modèle de convolution de graphe.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our second contribution, in response to the limitations of the first one, allows for the dynamic generation of a specific context for each target word.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Cette méthode permet d'obtenir les meilleures performances pour un modèle simple sur différents jeux de données.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This method yields the best performances for a single model on multiples datasets.</seg>
            </tuv>
        </tu>
        <tu tuid="14">
            <tuv xml:lang="FR">
                <seg>Enfin, dans un troisième temps, nous considérons une autre approche de la prise en compte du contexte inter-phrastique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Finally, we take a different tack on the exploitation of the inter-sentential context.</seg>
            </tuv>
        </tu>
        <tu tuid="15">
            <tuv xml:lang="FR">
                <seg>Nous cherchons à modéliser plus directement les interdépendances entre les différentes instances d'événements au sein d'un document afin de réaliser une prédiction jointe.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We try a more direct modelisation of the dependencies between multiple event instances inside a document in order to produce a joint prediction.</seg>
            </tuv>
        </tu>
        <tu tuid="16">
            <tuv xml:lang="FR">
                <seg>Nous utilisons pour cela le cadre d'apprentissage PSL (Probabilistic Soft Logic) qui permet de modéliser de telles interdépendances sous forme de règles logiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To do so, we use the PSL (Probabilistic Soft Logic) framework which allows to model such dependencies through logic formula.</seg>
            </tuv>
        </tu>
    </body>
</tmx>