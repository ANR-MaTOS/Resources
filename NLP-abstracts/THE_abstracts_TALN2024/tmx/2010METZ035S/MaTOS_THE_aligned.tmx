<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2010METZ035S. segId begin by 1, tuid = segId</note>
        <docid>2010METZ035S</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Cette thèse présente une méthode générique de reconnaissance automatique des émotions à partir d’un système bimodal basé sur les expressions faciales et les signaux physiologiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This thesis presents a generic method for automatic recognition of emotions from a bimodal system based on facial expressions and physiological signals.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Cette approche de traitement des données conduit à une extraction d’information de meilleure qualité et plus fiable que celle obtenue à partir d’une seule modalité.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This data processing approach leads to better extraction of information and is more reliable than single modality.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>L’algorithme de reconnaissance des expressions faciales qui est proposé, s’appuie sur la variation de distances des muscles faciaux par rapport à l’état neutre et sur une classification par les séparateurs à vastes marges (SVM).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The proposed algorithm for facial expression recognition is based on the distance variation of facial muscles from the neutral state and on the classification by means of Support Vector Machines (SVM).</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>La reconnaissance des émotions à partir des signaux physiologiques est, quant à elle, basée sur la classification des paramètres statistiques par le même classifieur.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>And the emotion recognition from physiological signals is based on the classification of statistical parameters by the same classifier.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Afin d’avoir un système de reconnaissance plus fiable, nous avons combiné les expressions faciales et les signaux physiologiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In order to have a more reliable recognition system, we have combined the facial expressions and physiological signals.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>La combinaison directe de telles informations n’est pas triviale étant donné les différences de caractéristiques (fréquence, amplitude de variation, dimensionnalité).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The direct combination of such information is not trivial giving the differences of characteristics (such as frequency, amplitude, variation, and dimensionality).</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Pour y remédier, nous avons fusionné les informations selon différents niveaux d’application.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To remedy this, we have merged the information at different levels of implementation.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Au niveau de la fusion des caractéristiques, nous avons testé l’approche par l’information mutuelle pour la sélection des plus pertinentes et l’analyse en composantes principales pour la réduction de leur dimensionnalité.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>At feature-level fusion, we have tested the mutual information approach for selecting the most relevant and principal component analysis to reduce their dimensionality.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Au niveau de la fusion de décisions, nous avons implémenté une méthode basée sur le processus de vote et une autre basée sur les réseaux Bayésien dynamiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>For decision-level fusion we have implemented two methods; the first based on voting process and another based on dynamic Bayesian networks.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Les meilleurs résultats ont été obtenus avec la fusion des caractéristiques en se basant sur l’Analyse en Composantes Principales.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The optimal results were obtained with the fusion of features based on Principal Component Analysis.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Ces méthodes ont été testées sur une base de données conçue dans notre laboratoire à partir de sujets sains et de l’inducteur par images IAPS.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>These methods have been tested on a database developed in our laboratory from healthy subjects and inducing with IAPS pictures.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Une étape d’auto évaluation a été demandée à tous les sujets dans le but d’améliorer l’annotation des images d’induction utilisées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>A self-assessment step has been applied to all subjects in order to improve the annotation of images used for induction.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Les résultats ainsi obtenus mettent en lumière leurs bonnes performances et notamment la variabilité entre les individus et la variabilité de l’état émotionnel durant plusieurs jours</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The obtained results have shown good performance even in presence of variability among individuals and the emotional state variability for several days</seg>
            </tuv>
        </tu>
    </body>
</tmx>