<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2019SORUS173. segId begin by 1, tuid = segId</note>
        <docid>2019SORUS173</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Alors que les méthodes de reconnaissance visuelle sont de plus en plus évoluées, la communauté scientifique s'intéresse désormais à des systèmes aux capacités de raisonnement plus poussées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>As image recognition systems are becoming more and more relevant, researchers in artificial intelligence now seek for the next generation vision systems that can perform high-level scene understanding.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, nous nous intéressons au Visual Question Answering (VQA), qui consiste en la conception de systèmes capables de répondre à une question portant sur une image.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this thesis, we are interested in Visual Question Answering (VQA), which consists in building models that answer any natural language question about any image.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Ce problème difficile est habituellement abordé par des techniques d'apprentissage profond.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To tackle this problem, typical approaches involve modern Deep Learning (DL) techniques.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Dans la première partie de cette thèse, nous développons des stratégies de fusion multimodales permettant de modéliser des interactions entre les représentations d'image et de question.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the first part, we focus on developping multi-modal fusion strategies to model the interactions between image and question representations.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Nous explorons des techniques de fusion bilinéaire, et assurons l'expressivité et la simplicité des modèles en utilisant des techniques de factorisation tensorielle.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>More specifically, we explore bilinear fusion models and exploit concepts from tensor analysis to provide tractable and expressive factorizations of parameters.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Dans la seconde partie, on s'intéresse au raisonnement visuel qui encapsule ces fusions.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>These fusion mechanisms are studied under the widely used visual attention framework: the answer to the question is provided by focusing only on the relevant image regions.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Après avoir présenté les schémas classiques d'attention visuelle, nous proposons une architecture plus avancée qui considère les objets ainsi que leurs relations mutuelles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the last part, we move away from the attention mechanism and build a more advanced scene understanding architecture where we consider objects and their spatial and semantic relations.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Tous les modèles sont expérimentalement évalués sur des jeux de données standards et obtiennent des résultats compétitifs avec ceux de la littérature.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>All models are thoroughly experimentally evaluated on standard datasets and the results are competitive with the literature.</seg>
            </tuv>
        </tu>
    </body>
</tmx>