<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2014LYO20025. segId begin by 1, tuid = segId</note>
        <docid>2014LYO20025</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Le travail présenté dans ce mémoire vise à proposer des solutions aux problèmes d'entreposage des données textuelles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The work, presented in this thesis, aims to propose solutions to the problems of textual data warehousing.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>L'intérêt porté à ce type de données est motivé par le fait qu'elles ne peuvent être intégrées et entreposées par l'application de simples techniques employées dans les systèmes décisionnels actuels.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The interest in the textual data is motivated by the fact that they cannot be integrated and warehoused by using the traditional applications and the current techniques of decision-making systems.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Elle couvre les principales phases d'un processus classique d'entreposage des données et utilise de nouvelles méthodes adaptées aux données textuelles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In order to overcome this problem, we proposed a text warehouses approach which covers the main phases of a data warehousing process adapted to textual data.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Dans ces travaux de thèse, nous nous sommes focalisés sur les deux premières phases qui sont l'intégration des données textuelles et leur modélisation multidimensionnelle.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We focused specifically on the integration of textual data and their multidimensional modeling.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Pour mettre en place une solution d'intégration de ce type de données, nous avons eu recours aux techniques de recherche d'information (RI) et du traitement automatique du langage naturel (TALN).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>For the textual data integration, we used information retrieval (IR) techniques and automatic natural language processing (NLP).</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Pour cela, nous avons conçu un processus d'ETL (Extract-Transform-Load) adapté aux données textuelles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Thus, we proposed an integration framework, called ETL-Text which is an ETL (Extract-Transform-Load) process suitable for textual data.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Il s'agit d'un framework d'intégration, nommé ETL-Text, qui permet de déployer différentes tâches d'extraction, de filtrage et de transformation des données textuelles originelles sous une forme leur permettant d'être entreposées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The ETL-Text performs the extracting, filtering and transforming tasks of the original textual data in a form allowing them to be warehoused.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Certaines de ces tâches sont réalisées dans une approche, baptisée RICSH (Recherche d'information contextuelle par segmentation thématique de documents), de prétraitement et de recherche de données textuelles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Some of these tasks are performed in our RICSH approach (Contextual information retrieval by topics segmentation of documents) for pretreatment and textual data search.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Celui-ci étend le modèle en constellation classique pour prendre en charge la représentation des textes dans un environnement multidimensionnel.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>It extends the classical constellation model to support the representation of textual data in a multidimensional environment.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Dans TWM, il est défini une dimension sémantique conçue pour structurer les thèmes des documents et pour hiérarchiser les concepts sémantiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>TWM includes a semantic dimension defined for structuring documents and topics by organizing the semantic concepts into a hierarchy.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Pour cela, TWM est adossé à une source sémantique externe, Wikipédia, en l'occurrence, pour traiter la partie sémantique du modèle.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Also, we depend on a Wikipedia, as an external semantic source, to achieve the semantic part of the model.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>De plus, nous avons développé WikiCat, un outil pour alimenter la dimension sémantique de TWM avec des descripteurs sémantiques issus de Wikipédia.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Furthermore, we developed WikiCat, which is a tool permit to feed the TWM semantic dimension with semantics descriptors from Wikipedia.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Ces deux dernières contributions complètent le framework ETL-Text pour constituer le dispositif d'entreposage des données textuelles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>These last two contributions complement the ETL-Text framework to establish the text warehouse device.</seg>
            </tuv>
        </tu>
        <tu tuid="14">
            <tuv xml:lang="FR">
                <seg>Pour valider nos différentes contributions, nous avons réalisé, en plus des travaux d'implémentation, une étude expérimentale pour chacune de nos propositions.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To validate the different contributions, we performed, besides the implementation works, an experimental study for each model.</seg>
            </tuv>
        </tu>
        <tu tuid="15">
            <tuv xml:lang="FR">
                <seg>Face au phénomène des données massives, nous avons développé dans le cadre d'une étude de cas des algorithmes de parallélisation des traitements en utilisant le paradigme MapReduce que nous avons testés dans l'environnement Hadoop.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>For the emergence of large data, we developed, as part of a case study, a parallel processing algorithms using the MapReduce paradigm tested in the Apache Hadoop environment.</seg>
            </tuv>
        </tu>
    </body>
</tmx>