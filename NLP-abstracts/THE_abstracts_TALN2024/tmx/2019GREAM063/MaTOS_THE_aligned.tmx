<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2019GREAM063. segId begin by 1, tuid = segId</note>
        <docid>2019GREAM063</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Cette thèse traite de l'apprentissage en profondeur appliqu'e aux tâches de classification des images.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This thesis deals with deep learning applied to image classification tasks.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>La principale motivation du travail est de rendre les techniques d’apprentissage en profondeur actuelles plus efficaces et de faire face aux changements dans la distribution des données.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The primary motivation for the work is to make current deep learning techniques more efficient and to deal with changes in the data distribution.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Nous travaillons dans le cadre élargi de l’apprentissage continu, dans le but d’avoir à l’avenir des modèles d'apprentissage automatique pouvant être améliorés en permanence.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We work in the broad framework of continual learning, with the aim to have in the future machine learning models that can continuously improve.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Nous examinons d’abord la modification de l’espace étiquette d’un ensemble de données, les échantillons de données restant les mêmes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We first look at change in label space of a data set, with the data samples themselves remaining the same.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Nous considérons une hiérarchie d'étiquettes sémantiques à laquelle appartiennent les étiquettes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We consider a semantic label hierarchy to which the labels belong.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Nous étudions comment nous pouvons utiliser cette hiérarchie pour obtenir des améliorations dans les modèles formés à différents niveaux de cette hiérarchie.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We investigate how we can utilise this hierarchy for obtaining improvements in models which were trained on different levels of this hierarchy.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Les deuxième et troisième contributions impliquent un apprentissage continu utilisant un modèle génératif.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The second and third contribution involve continual learning using a generative model.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Nous analysons la facilité d'utilisation des échantillons d'un modèle génératif dans le cas de la formation de bons classificateurs discriminants.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We analyse the usability of samples from a generative model in the case of training good discriminative classifiers.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Nous proposons des techniques pour améliorer la sélection et la génération d'échantillons à partir d'un modèle génératif.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We propose techniques to improve the selection and generation of samples from a generative model.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Ensuite, nous observons que les algorithmes d’apprentissage continu subissent certaines pertes de performances lorsqu’ils sont entraînés séquentiellement à plusieurs tâches.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Following this, we observe that continual learning algorithms do undergo some loss in performance when trained on several tasks sequentially.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Nous analysons la dynamique de la formation dans ce scénario et comparons avec la formation sur plusieurs tâches simultanément.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We analyse the training dynamics in this scenario and compare with training on several tasks simultaneously.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Nous faisons des observations qui indiquent des difficultés potentielles dans l’apprentissage de modèles dans un scénario d’apprentissage continu.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We make observations that point to potential difficulties in the learning of models in a continual learning scenario.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Enfin, nous proposons un nouveau modèle de conception pour les réseaux de convolution.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Finally, we propose a new design template for convolutional networks.</seg>
            </tuv>
        </tu>
        <tu tuid="14">
            <tuv xml:lang="FR">
                <seg>Cette architecture permet de former des modèles plus petits sans compromettre les performances.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This architecture leads to training of smaller models without compromising performance.</seg>
            </tuv>
        </tu>
        <tu tuid="15">
            <tuv xml:lang="FR">
                <seg>De plus, la conception se prête facilement à la parallélisation, ce qui permet une formation distribuée efficace.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In addition the design lends itself to easy parallelisation, leading to efficient distributed training.</seg>
            </tuv>
        </tu>
        <tu tuid="16">
            <tuv xml:lang="FR">
                <seg>En conclusion, nous examinons deux types de scénarios d’apprentissage continu.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In conclusion, we look at two different types of continual learning scenarios.</seg>
            </tuv>
        </tu>
        <tu tuid="17">
            <tuv xml:lang="FR">
                <seg>Nous proposons des méthodes qui conduisent à des améliorations.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We propose methods that lead to improvements.</seg>
            </tuv>
        </tu>
        <tu tuid="18">
            <tuv xml:lang="FR">
                <seg>Notre analyse met également en évidence des problèmes plus importants, dont nous aurions peut-être besoin de changements dans notre procédure actuelle de formation de réseau neuronal.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our analysis also points to greater issues, to over come which we might need changes in our current neural network training procedure.</seg>
            </tuv>
        </tu>
    </body>
</tmx>