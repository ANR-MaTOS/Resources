<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2020UPASS134. segId begin by 1, tuid = segId</note>
        <docid>2020UPASS134</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Pour estimer la répartition de la puissance au sein d’un réacteur nucléaire, il est nécessaire de coupler des modélisations neutroniques et thermohydrauliques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Modern nuclear reactors utilize core calculations that implement a thermo-hydraulic feedback requiring accurate homogenized few-group cross sections.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>De telles simulations doivent disposer des valeurs sections efficaces homogénéisées à peu de groupes d’énergies qui décrivent les interactions entre les neutrons et la matière.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>They describe the interactions of neutrons with matter, and are endowed with the properties of smoothness and regularity, steaming from their underling physical phenomena.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Cette thèse est consacrée à la modélisation des sections efficaces par des techniques académiques innovantes basées sur l’apprentissage machine.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This thesis is devoted to the modeling of these functions by industry state-of-theart and innovative machine learning techniques.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>La performance d’un modèle est principalement définie par le nombre de coefficients qui le caractérisent (c’est-à-dire l’espace mémoire nécessaire pour le stocker), la vitesse d’évaluation, la précision, la robustesse au bruit numérique, la complexité, etc.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Convenient is intended in terms of computational performance, such as the model’s size, evaluation speed, accuracy, robustness to numerical noise, complexity,etc; always with respect to the engineering modeling objectives that specify the multidimensional spaces of interest.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, un assemblage standard de combustible UOX REP est analysé avec trois variables d’état : le burnup, la température du combustible et la concentration en bore.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this thesis, a standard UO₂ PWR fuel assembly is analyzed for three state-variables, burnup,fuel temperature, and boron concentration.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Trois techniques d’approximation sont étudiées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>A full grid is used as usually donein the industry.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Les méthodes de noyaux, qui utilisent le cadre général d’apprentissage machine, sont capables de proposer, dans un espace vectoriel normalisé, une grande variété de modèles de régression ou de classification.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Kernel methods, that are a very general machine learning framework able to pose in a normed vector space, a large variety of regression or classification problems.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Les méthodes à noyaux peuvent reproduire différents espaces de fonctions en utilisant un support non structuré, qui est optimisé avec des techniques d’apprentissage actif.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Kernel functions can reproduce different function spaces using an unstructured support,which is optimized with pool active learning techniques.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Les approximations sont trouvées grâce à un processus d’optimisation convexe facilité par "l’astuce du noyau”.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The approximations are found through a convex optimization process simplified by the kernel trick.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Le caractère modulaire intrinsèque de la méthode facilite la séparation des phases de modélisation : sélection de l’espace de fonctions, application de routines numériques, et optimisation du support par apprentissage actif.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The intrinsic modular character of the method facilitates segregating the modeling phases: function space selection, application of numerical routines and support optimization through active learning.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Les réseaux de neurones sont des méthodes d’approximation universelles capables d’approcher de façon arbitraire des fonctions continues sans formuler de relations explicites entre les variables.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Artificial neural networks which are“model free” universal approximators able Artificial neural networks which are“model free” universal approximators able to approach continuous functions to an arbitrary degree without formulating explicit relations among the variables.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Une fois formés avec des paramètres d’apprentissage adéquats, les réseaux à sorties multiples (intrinsèquement parallélisables) réduisent au minimum les besoins de stockage tout en offrant une vitesse d’évaluation élevée.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>With adequate training settings, intrinsically parallelizable multi-output networks minimize storage requirements offering the highest evaluation speed.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Les stratégies que nous proposons sont comparées entre elles et à l’interpolation multilinéaire sur une grille cartésienne qui est la méthode utilisée usuellement dans l’industrie.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>These strategies are compared to each other and to multi-linear interpolation in a Cartesian grid, the industry standard in core calculations.</seg>
            </tuv>
        </tu>
        <tu tuid="14">
            <tuv xml:lang="FR">
                <seg>L’ensemble des données, des outils, et des scripts développés sont disponibles librement sous licence MIT.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The data set, the developed tools, and scripts are freely available under aMIT license.</seg>
            </tuv>
        </tu>
    </body>
</tmx>