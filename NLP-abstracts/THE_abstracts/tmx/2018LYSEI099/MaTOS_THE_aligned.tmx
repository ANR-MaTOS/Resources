<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2018LYSEI099. segId begin by 1, tuid = segId</note>
        <docid>2018LYSEI099</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Le crowdsourcing est une technique qui permet de recueillir une large quantité de données d'une manière rapide et peu onéreuse.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Crowdsourcing has proved its ability to address large scale data collection tasks at a low cost and in a short time.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Néanmoins, La disparité comportementale et de performances des "workers" d'une part et la variété en termes de contenu et de présentation des tâches par ailleurs influent considérablement sur la qualité des contributions recueillies.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>However, due to the dependence on unknown workers, the quality of the crowdsourcing process is questionable and must be controlled.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Par conséquent, garder leur légitimité impose aux plateformes de crowdsourcing de se doter de mécanismes permettant l'obtention de réponses fiables et de qualité dans un délai et avec un budget optimisé.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Indeed, maintaining the efficiency of crowdsourcing requires the time and cost overhead related to this quality control to stay low.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, nous proposons CAWS (Context AwareWorker Selection), une méthode de contrôle de la qualité des contributions dans le crowdsourcing visant à optimiser le délai de réponse et le coût des campagnes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Current quality control techniques suffer from high time and budget overheads and from their dependency on prior knowledge about individual workers.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>CAWS se compose de deux phases, une phase d'apprentissage opérant hors-ligne et pendant laquelle les tâches de l'historique sont regroupées de manière homogène sous forme de clusters.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this thesis, we address these limitation by proposing the CAWS (Context-Aware Worker Selection) method which operates in two phases: in an offline phase, the correlations between the worker declarative profiles and the task types are learned.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Pour chaque cluster, un profil type optimisant la qualité des réponses aux tâches le composant, est inféré ;</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Then, in an online phase, the learned profile models are used to select the most reliable online workers for the incoming tasks depending on their types.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>la seconde phase permet à l'arrivée d'une nouvelle tâche de sélectionner les meilleurs workers connectés pour y répondre.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Using declarative profiles helps eliminate any probing process, which reduces the time and the budget while maintaining the crowdsourcing quality.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Il s'agit des workers dont le profil présente une forte similarité avec le profil type du cluster de tâches, duquel la tâche nouvellement créée est la plus proche.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In order to evaluate CAWS, we introduce an information-rich dataset called CrowdED (Crowdsourcing Evaluation Dataset).</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>En outre, CrowdED rend possible la comparaison de méthodes de contrôle de qualité quelle que soient leurs catégories, du fait du respect d'un cahier des charges lors de sa constitution.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The generation of CrowdED relies on a constrained sampling approach that allows to produce a dataset which respects the requester budget and type constraints.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Les résultats de l'évaluation de CAWS en utilisant CrowdED comparés aux méthodes concurrentes basées sur la sélection de workers, donnent des résultats meilleurs, surtout en cas de contraintes temporelles et budgétaires fortes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Through its generality and richness, CrowdED helps also in plugging the benchmarking gap present in the crowdsourcing community.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Les expérimentations réalisées avec un historique structuré en catégories donnent des résultats comparables à des jeux de données où les taches sont volontairement regroupées de manière homogène.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Using CrowdED, we evaluate the performance of CAWS in terms of the quality, the time and the budget gain.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>La dernière contribution de la thèse est un outil appelé CREX (CReate Enrich eXtend) dont le rôle est de permettre la création, l'extension ou l'enrichissement de jeux de données destinés à tester des méthodes de crowdsourcing.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Results shows that automatic grouping is able to achieve a learning quality similar to job-based grouping, and that CAWS is able to outperform the state-of-the-art profile-based worker selection when it comes to quality, especially when strong budget ant time constraints exist.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Il propose des modules extensibles de vectorisation, de clusterisation et d'échantillonnages et permet une génération automatique d'une campagne de crowdsourcing.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Finally, we propose CREX (CReate Enrich eXtend) which provides the tools to select and sample input tasks and to automatically generate custom crowdsourcing campaign sites in order to extend and enrich CrowdED.</seg>
            </tuv>
        </tu>
    </body>
</tmx>