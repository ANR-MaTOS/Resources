<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2012GRENS015. segId begin by 1, tuid = segId</note>
        <docid>2012GRENS015</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Le travail présenté dans cette thèse vise à étudier la coordination entre gestes manuels et parole lors de la production d'énoncés multimodaux.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The work synthesized in this thesis aims at studying the coordination between manual gestures and speech during multimodal utterances production.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Les études menées s'intéressent plus particulièrement aux relations temporelles entre les deux modalités.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>More precisely, the temporal relationship between the two modalities is considered.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Cette coordination a été étudiée plus précisément dans le cadre de la désignation qui est réalisable à la fois dans la modalité manuelle (geste de pointage) et dans la modalité parole (« montrer avec la voix », en utilisant la focalisation et/ou les démonstratifs par exemple).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The coordination is studied in a designation framework since designating is possible both manually (pointing gesture) and using speech (one can "show with the voice" using focus and/or demonstratives for example).</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Les études présentées ont été menées dans un environnement contrôlé de laboratoire afin d'obtenir des mesures précises et reproductibles en minimisant les facteurs extérieurs de variations intra-et inter-participants.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>All the studies presented in this work are done in a lab setting thus allowing to get precise and reproducible measurements while minimizing potential external sources of variation (either between or within participants).</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Les productions des locuteurs peuvent ainsi être comparées entre-elles en se focalisant sur les facteurs d'intérêt toutes choses maintenues le plus possible égales par ailleurs.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Participants'productions were then compared to each other focusing on factors of interest while keeping other sources of variation as low as possible.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Un travail particulier de mise en place des protocoles a néanmoins permis de maintenir une tâche assez naturelle afin de ne pas induire des productions trop artificielles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>A part of the work consisted in designing rather natural experimental protocols so as to ensure productions were not too artificial.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Les deux premières études se sont intéressées à la production conjointe de gestes manuels et de parole contenant de la focalisation.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The first two experiments studied to co-production of manual gestures and speech containing a focused part.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Plusieurs types de gestes ont été comparés (geste de pointage, geste de battement et geste d'appui sur un bouton) lors d'une tâche de désignation.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Different types of gestures were compared (pointing gesture, beat, button-push) in a designation task.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Il a été montré que la production de focalisation attire le geste manuel quel que soit son type mais que l'attraction est plus « précise » et fine pour le pointage.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>It has been shown that producing focus did temporally attract manual gesture whichever its type but that this attraction was finer and less variable for pointing gesture.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Par ailleurs, l'apex du geste de pointage semble être cooccurent à une cible articulatoire plutôt qu'acoustique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Another interesting finding was that the apex of pointing gesture seems to be cooccurring with articulatory targets rather than acoustic ones.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>La seconde étude manipule le lien de désignation le geste de pointage et la parole.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The second study manipulates the designation link between manual gestures and speech.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Elle montre, en exhibant deux stratégies adoptées par les participants, la complexité des mécanismes mis en jeu dans cette coordination.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>By showing that participants can be split up into two groups using different multimodal coordination strategies, it put forward the complexity of underlying mechanisms of this coordination.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Finalement, une troisième étude s'intéresse à la coordination dans une tâche interactive et collaborative plus naturelle.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The last experiment focuses on the coordination in a more natural interactive and collaborative task.</seg>
            </tuv>
        </tu>
        <tu tuid="14">
            <tuv xml:lang="FR">
                <seg>Les résultats montrent une cooccurrence de la partie du geste qui montre avec l'information qui lui est complémentaire en parole, i.e. avec le nom de l'objet à poser à l'endroit désigné par le geste de pointage, plutôt qu'avec la partie de la parole qui désigne, i.e. le démonstratif.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Results show a co-ocurrence of the part of the gesture that shows and with the complementary information in speech (ie. the name of the object to be placed at the spot pointed at by the manual gesture) rather than with the part of speech that shows (ie. demonstrative).</seg>
            </tuv>
        </tu>
        <tu tuid="15">
            <tuv xml:lang="FR">
                <seg>Ce mémoire propose par ailleurs une exploration des procédés d'annotation multimodaux mis en place pour l'annotation de tâches semi-contrôlées mais applicables à des cas plus généraux.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The work presented in this manuscript moreover put forward a systematic way of labeling semi-constrained interactive tasks which can be generalized.</seg>
            </tuv>
        </tu>
        <tu tuid="16">
            <tuv xml:lang="FR">
                <seg>Le manuscrit se conclut par une mise en perspective des résultats pour l'amélioration de certains modèles de production conjointe gestes manuels/parole et fournit quelques pistes utilisables dans le domaine des agents conversationnels ainsi que pour la détection de pathologies.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The conclusion puts in perspective the results so as to improve some manual gestures/speech co-production models and indicates paths for reflection about embodied conversational agents and early detection of pathological cases.</seg>
            </tuv>
        </tu>
    </body>
</tmx>