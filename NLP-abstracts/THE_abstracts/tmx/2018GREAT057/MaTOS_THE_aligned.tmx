<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2018GREAT057. segId begin by 1, tuid = segId</note>
        <docid>2018GREAT057</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Cette thèse de doctorat traite de la reconnaissance automatique du Langage français Parlé Complété (LPC), version française du Cued Speech (CS), à partir de l’image vidéo et sans marquage de l’information préalable à l’enregistrement vidéo.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This PhD thesis deals with the automatic continuous Cued Speech (CS) recognition based on the images of subjects without marking any artificial landmark.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Afin de réaliser cet objectif, nous cherchons à extraire les caractéristiques de haut niveau de trois flux d’information (lèvres, positions de la main et formes), et fusionner ces trois modalités dans une approche optimale pour un système de reconnaissance de LPC robuste.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In order to realize this objective, we extract high level features of three information flows (lips, hand positions and shapes), and find an optimal approach to merging them for a robust CS recognition system.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Dans ce travail, nous avons introduit une méthode d’apprentissage profond avec les réseaux neurono convolutifs (CNN)pour extraire les formes de main et de lèvres à partir d’images brutes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We first introduce a novel and powerful deep learning method based on the Convolutional Neural Networks (CNNs) for extracting the hand shape/lips features from raw images.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Un modèle de mélange de fond adaptatif (ABMM) est proposé pour obtenir la position de la main.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Theadaptive background mixture models (ABMMs) are also applied to obtain the hand position features for the first time.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Toutes ces méthodes constituent des contributions significatives pour l’extraction de caractéristiques du LPC.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>All these methods make significant contributions to the feature extraction in CS.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>En outre, en raison de l’asynchronie des trois flux caractéristiques du LPC, leur fusion est un enjeu important dans cette thèse.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Then, due to the asynchrony problem of three feature flows (i.e., lips, hand shape and hand position) in CS,the fusion of them is a challenging issue.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Afin de le résoudre, nous avons proposé plusieurs approches, y compris les stratégies de fusion au niveau données et modèle avec une modélisation HMM dépendant du contexte.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In order to resolve it, we propose several approaches including feature-level and model-level fusion strategies combined with the context-dependent HMM.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Pour obtenir le décodage, nous avons proposé trois architectures CNNs-HMMs.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To achieve the CS recognition, we propose three tandem CNNs-HMM architectures with different fusion types.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Toutes ces architectures sont évaluées sur un corpus de phrases codées en LPC en parole continue sans aucun artifice, et la performance de reconnaissance CS confirme l’efficacité de nos méthodes proposées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>All these architectures are evaluated on the corpus without any artifice, and the CS recognition performance confirms the efficiency of our proposed methods.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Le résultat est comparable à l’état de l’art qui utilisait des bases de données où l’information pertinente était préalablement repérée.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The result is comparable with the state of the art using the corpus with artifices.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>En même temps, nous avons réalisé une étude spécifique concernant l’organisation temporelle des mouvements de la main, révélant une avance de la main en relation avec l’emplacement dans la phrase.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In parallel,we investigate a specific study about the temporal organization of hand movements in CS,especially about its temporal segmentation, and the evaluations confirm the superior performance of our methods.</seg>
            </tuv>
        </tu>
    </body>
</tmx>