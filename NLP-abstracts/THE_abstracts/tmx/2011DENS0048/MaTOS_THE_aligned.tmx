<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2011DENS0048. segId begin by 1, tuid = segId</note>
        <docid>2011DENS0048</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>De nombreux domaines issus de l’industrie et des sciences appliquées ont été les témoins d’une révolution numérique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Numerous fields of applied sciences and industries have been recently witnessing a process of digitisation.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Cette dernière s’est accompagnée d’une croissance du volume des données, dont le traitement est devenu un défi technique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This trend has come with an increase in the amount digital data whose processing becomes a challenging task.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Dans ce contexte, la parcimonie est apparue comme un concept central en apprentissage statistique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this context, parsimony, also known as sparsity, has emerged as a key concept in machine learning and signal processing.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Il est en effet naturel de vouloir exploiter les données disponibles via un nombre réduit de paramètres.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>It is indeed appealing to exploit data only via a reduced number of parameters.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Cette thèse se concentre sur une forme particulière et plus récente de parcimonie, nommée parcimonie structurée.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This thesis focuses on a particular and more recent form of sparsity, referred to as structured sparsity.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Comme son nom l’indique, nous considérerons des situations où, au delà de la seule parcimonie, nous aurons également à disposition des connaissances a priori relatives à des propriétés structurelles du problème.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>As its name indicates, we shall consider situations where we are not only interested in sparsity, but where some structural prior knowledge is also available.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>L’objectif de cette thèse est d'analyser le concept de parcimonie structurée, en se basant sur des considérations statistiques, algorithmiques et appliquées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The goal of this thesis is to analyze the concept of structured sparsity, based on statistical, algorithmic and applied considerations.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Nous commencerons par introduire une famille de normes structurées parcimonieuses dont les aspects statistiques sont étudiées en détail.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To begin with, we introduce a family of structured sparsity-inducing norms whose statistical aspects are closely studied.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Nous considérerons ensuite l’apprentissage de dictionnaires, où nous exploiterons les normes introduites précédemment dans un cadre de factorisation de matrices.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We then turn to sparse structured dictionary learning, where we use the previous norms within the framework of matrix factorization.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Différents outils algorithmiques efficaces, tels que des méthodes proximales, seront alors proposés.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Different efficient algorithmic tools, such as proximal methods, will then be proposed.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Grâce à ces outils, nous illustrerons sur de nombreuses applications pourquoi la parcimonie structurée peut être bénéfique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>With these methods in place, we illustrate on numerous real-world applications from various fields, when and why structured sparsity is useful.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Ces exemples contiennent des tâches de restauration en traitement de l’image, la modélisation hiérarchique de documents textuels, ou encore la prédiction de la taille d’objets à partir de signaux d’imagerie par résonance magnétique fonctionnelle.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This includes, for instance, restoration tasks in image processing, the modelling of text documents as hierarchy of topics, the inter-subject prediction of sizes of objects from fMRI signals.</seg>
            </tuv>
        </tu>
    </body>
</tmx>