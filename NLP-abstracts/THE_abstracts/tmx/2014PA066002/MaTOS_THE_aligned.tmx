<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2014PA066002. segId begin by 1, tuid = segId</note>
        <docid>2014PA066002</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Cette thèse, organisée en deux parties indépendantes, a pour objet la sémantique distributionnelle et la sélection de variables.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This thesis, which is organized in two independent parts, presents work on distributional semantics and on variable selection.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Dans la première partie, nous introduisons une nouvelle méthode pour l'apprentissage de représentations de mots à partir de grandes quantités de texte brut.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the first part, we introduce a new method for learning good word representations using large quantities of unlabeled sentences.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Cette méthode repose sur un modèle probabiliste de la phrase, utilisant modèle de Markov caché et arbre de dépendance.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The method is based on a probabilistic model of sentence, using a hidden Markov model and a syntactic dependency tree.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Nous évaluons les modèles obtenus sur des taches intrinsèques, telles que prédire des jugements de similarité humains ou catégoriser des mots et deux taches extrinsèques~ : la reconnaissance d'entités nommées et l'étiquetage en supersens.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We then evaluate our models on intrinsic tasks such as predicting human similarity judgements or word categorization, and on two extrinsic tasks: named entity recognition and supersense tagging.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Dans la seconde partie, nous introduisons, dans le contexte des modèles linéaires, une nouvelle pénalité pour la sélection de variables en présence de prédicteurs fortement corrélés.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the second part, we introduce, in the context of linear models, a new penalty function to perform variable selection in the case of highly correlated predictors.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Cette pénalité, appelée trace Lasso, utilise la norm trace des prédicteurs sélectionnés, qui est une relaxation convexe de leur rang, comme critère de complexité.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This penalty, called the trace Lasso, uses the trace norm of the selected predictors, which is a convex surrogate of their rank, as the criterion of model complexity.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>En particulier, lorsque tous les prédicteurs sont orthogonaux, il est égal à la norme ℓ 1, tandis que lorsque tous les prédicteurs sont égaux, il est égal à la norme ℓ 2.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In particular, it is equal to the ℓ 1-norm if all predictors are orthogonal and to the ℓ 2-norm if all predictors are equal.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Nous proposons deux algorithmes pour calculer la solution du problème de régression aux moindres carrés régularisé par le trace Lasso et réalisons des expériences sur des données synthétiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We propose two algorithms to compute the solution of least-squares regression regularized by the trace Lasso, and perform experiments on synthetic datasets to illustrate the behavior of the trace Lasso.</seg>
            </tuv>
        </tu>
    </body>
</tmx>