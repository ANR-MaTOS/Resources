<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2020GRALM032. segId begin by 1, tuid = segId</note>
        <docid>2020GRALM032</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>La désambiguïsation lexicale (DL) et la traduction automatique (TA) sont deux tâches centrales parmi les plus anciennes du traitement automatique des langues (TAL).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Word Sense Disambiguation (WSD) and Machine Translation (MT) are two central and among the oldest tasks of Natural Language Processing (NLP).</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Bien qu'ayant une origine commune, la DL ayant été conçue initialement comme un problème fondamental à résoudre pour la TA, les deux tâches ont par la suite évolué très indépendamment.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Although they share a common origin, WSD being initially conceived as a fundamental problem to be solved for MT, the two tasks have subsequently evolved very independently of each other.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>En effet, d'un côté, la TA a su s'affranchir d'une désambiguïsation explicite des termes grâce à des modèles statistiques et neuronaux entraînés sur de grandes quantités de corpus parallèles, et de l'autre, la DL, qui est confrontée à certaines limitations comme le manque de ressources unifiées et un champs d'application encore restreint, reste un défi majeur pour permettre une meilleure compréhension de la langue en général.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Indeed, on the one hand, MT has been able to overcome the explicit disambiguation of terms thanks to statistical and neural models trained on large amounts of parallel corpora, and on the other hand, WSD, which faces some limitations such as the lack of unified resources and a restricted scope of applications, remains a major challenge to allow a better understanding of the language in general.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Aujourd'hui, dans un contexte où les méthodes à base de réseaux de neurones et les représentations vectorielles des mots prennent de plus en plus d'ampleur dans la recherche en TAL, les nouvelles architectures neuronales et les nouveaux modèles de langue pré-entraînés offrent non seulement de nouvelles possibilités pour développer des systèmes de DL et de TA plus performants, mais aussi une opportunité de réunir les deux tâches à travers des modèles neuronaux joints, permettant de faciliter l'étude de leurs interactions.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Today, in a context in which neural networks and word embeddings are becoming more and more important in NLP research, the recent neural architectures and the new pre-trained language models offer not only some new possibilities for developing more efficient WSD and MT systems, but also an opportunity to bring the two tasks together through joint neural models, which facilitate the study of their interactions.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, nos contributions porteront dans un premier temps sur l'amélioration des systèmes de DL, par l'unification des données nécessaires à leur mise en oeuvre, la conception de nouvelles architectures neuronales et le développement d'approches originales pour l'amélioration de la couverture et des performances de ces systèmes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this thesis, our contributions will initially focus on the improvement of WSD systems by unifying the ressources that are necessary for their implementation, constructing new neural architectures and developing original approaches to improve the coverage and the performance of these systems.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Ensuite, nous développerons et comparerons différentes approches pour l'intégration de nos systèmes de DL état de l'art et des modèles de langue, dans des systèmes de TA, pour l'amélioration générale de leur performance.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Then, we will develop and compare different approaches for the integration of our state of the art WSD systems and language models into MT systems for the overall improvement of their performance.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Enfin, nous présenterons une nouvelle architecture pour l'apprentissage d'un modèle neuronal joint pour la DL et la TA, s'appuyant sur nos meilleurs systèmes neuronaux pour l'une et l'autre tâche.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Finally, we will present a new architecture that allows to train a joint model for both WSD and MT, based on our best neural systems.</seg>
            </tuv>
        </tu>
    </body>
</tmx>