<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2014PA112080. segId begin by 1, tuid = segId</note>
        <docid>2014PA112080</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Les systèmes de question-réponse renvoient une réponse précise à une question formulée en langue naturelle.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Question answering systems find and extract a precise answer to a question in natural language.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Les systèmes de question-réponse actuels, ainsi que les campagnes d'évaluation les évaluant, font en général l'hypothèse qu'une seule réponse est attendue pour une question.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Both current question-answering systems and evaluation campaigns often assume that only one single answeris expected for a question.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Or nous avons constaté que, souvent, ce n'était pas le cas, surtout quand on cherche les réponses sur le Web et non dans une collection finie de documents.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our corpus studies show that this is rarely the case, specially when answers are extracted from the Web instead of a frozen collection of documents.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Nous nous sommes donc intéressés au traitement des questions attendant plusieurs réponses à travers un système de question-réponse sur le Web en français.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We therefore focus on questions expecting multiple correct answers from the Web by developping the question-answering system Citron.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Pour cela, nous avons développé le système Citron capable d'extraire des réponses multiples différentes à des questions factuelles en domaine ouvert, ainsi que de repérer et d'extraire le critère variant (date, lieu) source de la multiplicité des réponses.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Citron is dedicated to extracting multiple answers in open domain and identifying the shifting criteria (date, location) which is often the reason of this answer multiplicity</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Nous avons montré grâce à notre étude de différents corpus que les réponses à de telles questions se trouvaient souvent dans des tableaux ou des listes mais que ces structures sont difficilement analysables automatiquement sans prétraitement.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our corpus studies show that the answers of this kind of questions are often located in structures such as tables and lists which cannot be analysed without a suitable preprocessing.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>C'est pourquoi, nous avons également développé l'outil Kitten qui permet d'extraire le contenu des documents HTML sous forme de texte et aussi de repérer, analyser et formater ces structures.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Consequently we developed the Kitten software which aims at extracting text information from HTML documents and also both identifying and formatting these structures.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Enfin, nous avons réalisé deux expériences avec des utilisateurs.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We finally evaluate Citron through two experiments involving users.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>La première expérience évaluait Citron et les êtres humains sur la tâche d'extraction de réponse multiples : les résultats ont montré que Citron était plus rapide que les êtres humains et que l'écart entre la qualité des réponses de Citron et celle des utilisateurs était raisonnable.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The first experiment evaluates both Citron and human beings on a multiple answer extraction task: results show that Citron was faster than humans and that the quality difference between answers extracted by Citron and humans was reasonable.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>La seconde expérience a évalué la satisfaction des utilisateurs concernant la présentation de réponses multiples : les résultats ont montré que les utilisateurs préféraient la présentation de Citron agrégeant les réponses et y ajoutant un critère variant (lorsqu'il existe) par rapport à la présentation utilisée lors des campagnes d'évaluation.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The second experiment evaluates user satisfaction regarding the presentation of multiple answers: results show that user shave a preference for Citron presentation aggregating answers and adding the shifting criteria (if it exists) over the presentation used by evaluation campaigns.</seg>
            </tuv>
        </tu>
    </body>
</tmx>