<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2018GREAT076. segId begin by 1, tuid = segId</note>
        <docid>2018GREAT076</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Un robot d'assistance sociale (SAR) est destiné à engager les gens dans une interaction située comme la surveillance de l'exercice physique, la réadaptation neuropsychologique ou l'entraînement cognitif.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>A socially assistive robot (SAR) is meant to engage people into situated interaction such as monitoring physical exercise, neuropsychological rehabilitation or cognitive training.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Alors que les comportements interactifs de ces systèmes sont généralement scriptés, nous discutons ici du cadre d'apprentissage de comportements interactifs multimodaux qui est proposé par le projet SOMBRERO.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>While the interactive behavioral policies of such systems are mainly hand-scripted, we discuss here key features of the training of multimodal interactive behaviors in the framework of the SOMBRERO project.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Dans notre travail, nous avons utilisé l'apprentissage par démonstration afin de fournir au robot des compétences nécessaires pour effectuer des tâches collaboratives avec des partenaires humains.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In our work, we used learning by demonstration in order to provide the robot with adequate skills for performing collaborative tasks in human centered environments.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Il y a trois étapes principales d'apprentissage de l'interaction par démonstration : (1) recueillir des comportements interactifs représentatifs démontrés par des tuteurs humains ; (2) construire des modèles des comportements observés tout en tenant compte des connaissances a priori (modèle de tâche et d'utilisateur, etc.) ; et ensuite (3) fournir au robot-cible des contrôleurs de gestes appropriés pour exécuter les comportements souhaités.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>There are three main steps of learning interaction by demonstration: we should (1) collect representative interactive behaviors from human coaches; (2) build comprehensive models of these overt behaviors while taking into account a priori knowledge (task and user model, etc.); and then (3) provide the target robot with appropriate gesture controllers to execute the desired behaviors.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Les modèles multimodaux HRI (Human-Robot Interaction) sont fortement inspirés des interactions humain-humain (HHI).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Multimodal HRI (Human-Robot Interaction) models are mostly inspired by Human-Human interaction (HHI) behaviors.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Le transfert des comportements HHI aux modèles HRI se heurte à plusieurs problèmes : (1) adapter les comportements humains aux capacités interactives du robot en ce qui concerne ses limitations physiques et ses capacités de perception, d'action et de raisonnement limitées ; (2) les changements drastiques des comportements des partenaires humains face aux robots ou aux agents virtuels ; (3) la modélisation des comportements interactifs conjoints ; (4) la validation des comportements robotiques par les partenaires humains jusqu'à ce qu'ils soient perçus comme adéquats et significatifs.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Transferring HHI behaviors to HRI models faces several issues: (1) adapting the human behaviors to the robot's interactive capabilities with regards to its physical limitations and impoverished perception, action and reasoning capabilities; (2) the drastic changes of human partner behaviors in front of robots or virtual agents; (3) the modeling of joint interactive behaviors; (4) the validation of the robotic behaviors by human partners until they are perceived as adequate and meaningful.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, nous étudions et faisons des progrès sur ces quatre défis.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this thesis, we study and make progress over those four challenges.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>En particulier, nous traitons les deux premiers problèmes (transfert de HHI vers HRI) en adaptant le scénario et en utilisant la téléopération immersive.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In particular, we solve the two first issues (transfer from HHI to HRI) by adapting the scenario and using immersive teleoperation.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>A la fin de cette thèse, nous évaluons une première version de robot autonome équipé des modèles construits par apprentissage.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We also build and evaluate a proof-of-concept autonomous robot to perform the tasks.</seg>
            </tuv>
        </tu>
    </body>
</tmx>