<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2020IPPAX005. segId begin by 1, tuid = segId</note>
        <docid>2020IPPAX005</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Cette thèse se compose de deux parties indépendantes et la première regroupant deux problématiques distinctes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Two independent subjects are studied in this thesis, the first of which consists of two distinct problems.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Dans la première partie, nous étudions d’abord le problème de Principal-Agent dans des systèmes dégénérés, qui apparaissent naturellement dans des environnements à l’observation partielle où l’Agent et le Principal n’observent qu’une partie du système.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the first part, we begin with the Principal-Agent problem in degenerate systems, which appear naturally in partially observed random environment in which the Agent and the Principal can only observe one part of the system.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Nous présentons une approche se basant sur le principe du maximum stochastique, dont le but est d’étendre les travaux existants qui utilisent le principe de la programmation dynamique dans des systèmes non-dégénérés.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our approach is based on the stochastic maximum principle, the goal of which is to extend the existing results using dynamic programming principle to the degenerate case.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Ensuite nous utilisons la condition suffisante du problème de l’Agent pour vérifier que le contrat optimal obtenu est bien implémentable.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Afterward, we use the sufficient condition of the Agent's problem to verify that the previously obtained optimal contract is indeed implementable.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Une étude parallèle est consacrée à l’existence et l’unicité de la solution d'EDSPRs dépendantes de la trajectoire dans le chapitre IV.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Meanwhile, a parallel study is devoted to the wellposedness of path-dependent FBSDEs in the chapter IV.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Enfin, nous étudions le problème de hasard moral avec plusieurs Principals.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Finally, we study the Principal-Agent problem with multiple Principals.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>L’Agent ne peut travailler que pour un seul Principal à la fois et fait donc face à un problème de switching optimal.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The Agent can only work for one Principal at a time and therefore needs to solve an optimal switching problem.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>En utilisant la méthode de randomisation nous montrons que la fonction valeur de l’Agent et son effort optimal sont donnés par un processus d’Itô.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>By using randomization, we show that the value function of the Agent's problem and his optimal control are given by an Itô process.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Cette représentation nous aide à résoudre ensuite le problème du Principal lorsqu’il y a une infinité de Principals en équilibre selon un jeu à champ-moyen.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This representation allows us to solve the Principal's problem in the mean-field case when there is an infinite number of Principals.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Nous justifions la formulation à champ-moyen par un argument de propagation de chaos.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We justify the mean-field formulation using an argument of backward propagation of chaos.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>La deuxième partie de cette thèse est constituée des chapitres V et VI.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The second part of the thesis consists of chapter V and VI.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>La motivation de ces travaux est de donner un fondement théorique rigoureux pour la convergence des algorithmes du type descente de gradient très souvent utilisés dans la résolution des problème non-convexes comme la calibration d’un réseau de neurones.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The motivation of this work is to give a rigorous theoretical underpinning for the convergence of gradient-descent type of algorithms frequently used in non-convex optimization problems like calibrating a deep neural network.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Nous montrons que la fonction d’énergie correspondante admet un unique minimiseur qui peut être caractérisé par une condition du premier ordre utilisant la dérivation dans l’espace des mesures au sens de Lions.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We show that the corresponding energy function has a unique minimiser which can be characterized by some first order condition using derivatives in measure space.</seg>
            </tuv>
        </tu>
        <tu tuid="14">
            <tuv xml:lang="FR">
                <seg>Nous présentons ensuite une analyse du comportement à long terme de la dynamique de Langevin à champ-moyen, qui possède une structure de flot de gradient dans la métrique de 2-Wasserstein.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We present a probabilistic analysis of the long-time behavior of the mean-field Langevin dynamics, which have a gradient flow structure in 2-Wasserstein metric.</seg>
            </tuv>
        </tu>
        <tu tuid="15">
            <tuv xml:lang="FR">
                <seg>Nous montrons que le flot de la loi marginale induite par la dynamique de Langevin à champ-moyen converge vers une loi stationnaire en utilisant le principe d’invariance de La Salle, qui est le minimiseur de la fonction d’énergie.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>By using a generalization of LaSalle's invariance principle, we show that the flow of marginal laws induced by the mean-field Langevin dynamics converges to the stationary distribution, which is exactly the minimiser of the energy function.</seg>
            </tuv>
        </tu>
        <tu tuid="16">
            <tuv xml:lang="FR">
                <seg>Dans le cas des réseaux de neurones profonds, nous les modélisons à l’aide d’un problème de contrôle optimal en temps continu.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>As for deep neural networks, we model them as some continuous-time optimal control problems.</seg>
            </tuv>
        </tu>
        <tu tuid="17">
            <tuv xml:lang="FR">
                <seg>Nous donnons d’abord la conditiondu premier ordre à l’aide du principe de Pontryagin, qui nous aidera ensuiteà introduire le système d’équation de Langevin à champ-moyen, dont la mesure invariante correspond au minimiseur du problème de contrôle optimal.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Firstly, we find the first order condition by using Pontryagin maximum principle, which later helps us find the associated mean-field Langevin system, the invariant measure of which is again the minimiser of the optimal control problem.</seg>
            </tuv>
        </tu>
        <tu tuid="18">
            <tuv xml:lang="FR">
                <seg>Enfin, avec la méthode de couplage par réflexion nous montrons que la loi marginale du système de Langevin à champ-moyen converge vers la mesure invariante avec une vitesse exponentielle.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>As last, by using the reflection coupling, we show that the marginal distribution of the mean-field Langevin system converges to the unique invariant measure exponentially.</seg>
            </tuv>
        </tu>
    </body>
</tmx>