<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2017AVIG0222. segId begin by 1, tuid = segId</note>
        <docid>2017AVIG0222</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Les méthodes de compréhension de la parole visent à extraire des éléments de sens pertinents du signal parlé.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Application of spoken language understanding aim to extract relevant items of meaning from spoken signal.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>On distingue principalement deux catégories dans la compréhension du signal parlé : la compréhension de dialogues homme/machine et la compréhension de dialogues homme/homme.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>There is two distinct types of spoken language understanding: understanding of human/human dialogue and understanding in human/machine dialogue.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>En fonction du type de conversation, la structure des dialogues et les objectifs de compréhension varient.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Given a type of conversation, the structure of dialogues and the goal of the understanding process varies.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Cependant, dans les deux cas, les systèmes automatiques reposent le plus souvent sur une étape de reconnaissance automatique de la parole pour réaliser une transcription textuelle du signal parlé.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>However, in both cases, most of the time, automatic systems have a step of speech recognition to generate the textual transcript of the spoken signal.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Les systèmes de reconnaissance automatique de la parole, même les plus avancés, produisent dans des contextes acoustiques complexes des transcriptions erronées ou partiellement erronées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Speech recognition systems in adverse conditions, even the most advanced one, produce erroneous or partly erroneous transcript of speech.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Ces erreurs s'expliquent par la présence d'informations de natures et de fonction variées, telles que celles liées aux spécificités du locuteur ou encore l'environnement sonore.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Those errors can be explained by the presence of information of various natures and functions such as speaker and ambience specificities.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Celles-ci peuvent avoir un impact négatif important pour la compréhension.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>They can have an important adverse impact on the performance of the understanding process.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Dans un premier temps, les travaux de cette thèse montrent que l'utilisation d'autoencodeur profond permet de produire une représentation latente des transcriptions d'un plus haut niveau d'abstraction.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The first part of the contribution in this thesis shows that using deep autoencoders produce a more abstract latent representation of the transcript.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Cette représentation permet au système de compréhension de la parole d'être plus robuste aux erreurs de transcriptions automatiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This latent representation allow spoken language understanding system to be more robust to automatic transcription mistakes.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Dans un second temps, nous proposons deux approches pour générer des représentations robustes en combinant plusieurs vues d'un même dialogue dans le but d'améliorer les performances du système la compréhension.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the other part, we propose two different approaches to generate more robust representation by combining multiple views of a given dialogue in order to improve the results of the spoken language understanding system.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>La seconde approche propose d'introduire une forme d'information de supervision dans les processus de débruitages par autoencodeur.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The second one introduce new autoencoders architectures that use supervision in the denoising autoencoders.</seg>
            </tuv>
        </tu>
    </body>
</tmx>