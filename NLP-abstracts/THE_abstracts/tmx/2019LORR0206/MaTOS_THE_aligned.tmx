<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2019LORR0206. segId begin by 1, tuid = segId</note>
        <docid>2019LORR0206</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Cette thèse porte sur l'identification des expressions polylexicales, abordée au moyen d'une analyse par transitions.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This thesis focuses on the identification of multi-word expressions, addressed through a transition-based system.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Une expression polylexicale (EP) est une construction linguistique composée de plusieurs éléments dont la combinaison montre une irrégularité à un ou plusieurs niveaux linguistiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>A multi-word expression (MWE) is a linguistic construct composed of several elements whose combination shows irregularity at one or more linguistic levels.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>La tâche d'identification d'EPs consiste à annoter en contexte les occurrences d'EPs dans des textes, i.e à détecter les ensembles de tokens formant de telles occurrences.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Identifying MWEs in context amounts to annotating the occurrences of MWEs in texts, i.e. to detecting sets of tokens forming such occurrences.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>L'analyse par transitions est une approche célèbre qui construit une sortie structurée à partir d'une séquence d'éléments, en appliquant une séquence de «transitions» choisies parmi un ensemble prédéfini, pour construire incrémentalement la sortie.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Transition-based analysis is a famous NLP technique to build a structured output from a sequence of elements, applying a sequence of actions (called «transitions») chosen from a predefined set, to incrementally build the output structure.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, nous proposons un système par transitions dédié à l'identification des EPs au sein de phrases représentées comme des séquences de tokens, et étudions diverses architectures pour le classifieur qui sélectionne les transitions à appliquer, permettant de construire l'analyse de la phrase.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this thesis, we propose a transition system dedicated to MWE identification within sentences represented as token sequences, and we study various architectures for the classifier which selects the transitions to apply to build the sentence analysis.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>La première variante de notre système utilise un classifieur linéaire de type machine à vecteur support.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The first variant of our system uses a linear support vector machine (SVM) classifier.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Les variantes suivantes utilisent des modèles neuronaux : un simple perceptron multicouche, puis des variantes intégrant une ou plusieurs couches récurrentes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The following variants use neural models: a simple multilayer perceptron (MLP), followed by variants integrating one or more recurrent layers.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Le scénario privilégié est une identification d'EPs n'utilisant pas d'informations syntaxiques, alors même que l'on sait les deux tâches liées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The preferred scenario is an identification of MWEs without the use of syntactic information, even though we know the two related tasks.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Nous étudions ensuite une approche par apprentissage multitâche, réalisant conjointement l’étiquetage morphosyntaxique, l’identification des EPs par transitions et l’analyse syntaxique en dépendances par transitions.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We further study a multitasking approach, which jointly performs and take mutual advantage of morphosyntactic tagging, transition-based MWE identification and dependency parsing.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>La thèse comporte une partie expérimentale importante.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The thesis comprises an important experimental part.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Nous avons d'une part étudié quelles techniques de ré-échantillonnage des données permettent une bonne stabilité de l'apprentissage malgré des initialisations aléatoires.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Firstly, we studied which resampling techniques allow good learning stability despite random initializations.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>D'autre part, nous avons proposé une méthode de réglage des hyperparamètres de nos modèles par analyse de tendances au sein d'une recherche aléatoire de combinaison d'hyperparamètres.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Secondly, we proposed a method for tuning the hyperparameters of our models by trend analysis within a random search for a hyperparameter combination.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Nos variantes produisent de très bons résultats, et notamment les scores d’état de l’art pour de nombreuses langues de PARSEME.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our variants produce very good results, including state-of-the-art scores for many languages in the PARSEME 1.0 and 1.1 datasets.</seg>
            </tuv>
        </tu>
        <tu tuid="14">
            <tuv xml:lang="FR">
                <seg>L’une des variantes s'est classée première pour la plupart des langues de PARSEME 1.0.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>One of the variants ranked first for most languages in the PARSEME 1.0 shared task.</seg>
            </tuv>
        </tu>
        <tu tuid="15">
            <tuv xml:lang="FR">
                <seg>Pourtant, nos modèles ont des performances faibles sur les EPs non vues à l'apprentissage.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>By the way, our models have poor performance on MWEs that are were not seen at learning time.</seg>
            </tuv>
        </tu>
    </body>
</tmx>