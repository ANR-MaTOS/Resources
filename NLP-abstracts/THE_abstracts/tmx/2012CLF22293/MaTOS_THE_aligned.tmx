<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2012CLF22293. segId begin by 1, tuid = segId</note>
        <docid>2012CLF22293</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>L'apprentissage statistique cherche à modéliser un lien fonctionnel entre deux variables X et Y à partir d'un échantillon aléatoire de réalisations de (X,Y).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Statistical learning aims to modelize a functional link between two variables X and Y thanks to a random sample of realizations of the couple (X,Y).</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Lorsque la variable Y prend un nombre binaire de valeurs, l'apprentissage s'appelle la classification (ou discrimination en français) et apprendre le lien fonctionnel s'apparente à apprendre la frontière d'une variété dans l'espace de la variable X.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>When the variable Y takes a binary number of values, learning is named classification and learn the functional link is equivalent to learn the boundary of a manifold in the feature space of the variable X.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, nous nous plaçons dans le contexte de l'apprentissage actif, i.e. nous supposons que l'échantillon d'apprentissage n'est plus aléatoire et que nous pouvons, par l'intermédiaire d'un oracle, générer les points sur lesquels l'apprentissage de la variété va s'effectuer.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this PhD thesis, we are placed in the context of active learning, i.e. we suppose that learning sample is not random and that we can, thanks to an oracle, generate points for learning the manifold.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Dans le cas où la variable Y est continue (régression), des travaux précédents montrent que le critère de la faible discrépance pour générer les premiers points d'apprentissage est adéquat.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the case where the variable Y is continue (regression), previous works show that criterion of low discrepacy to generate learning points is adequat.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Nous montrons, de manière surprenante, que ces résultats ne peuvent pas être transférés à la classification.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We show that, surprisingly, this result cannot be transfered to classification talks.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Dans ce manuscrit, nous proposons alors le critère de la dispersion pour la classification.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this PhD thesis, we propose the criterion of dispersion for classification problems.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Ce critère étant difficile à mettre en pratique, nous proposons un nouvel algorithme pour générer un plan d'expérience à faible dispersion dans le carré unité.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This criterion being difficult to realize, we propose a new algorithm to generate low dispersion samples in the unit cube.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Après une première approximation de la variété, des approximations successives peuvent être réalisées afin d'affiner la connaissance de celle-ci.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>After a first approximation of the manifold, successive approximations can be realized in order to refine its knowledge.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Deux méthodes d'échantillonnage sont alors envisageables : le « selective sampling » qui choisit les points à présenter à un oracle parmi un ensemble fini de candidats et l'« adaptative sampling » qui permet de choisir n'importe quels points de l'espace de la variable X.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Two methods of sampling are possible: the «selective sampling» which selects points to present to the oracle in a finite set of candidate points, and the «adaptative sampling» which allows to select any point in the feature space of the variable X.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Le deuxième échantillonnage peut être vu comme un passage à la limite du premier.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The second sampling can be viewed as the infinite limit of the first.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Néanmoins, en pratique, il n'est pas raisonnable d'utiliser cette méthode.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Nevertheless, in practice, it is not reasonable to use this method.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Nous proposons alors un nouvel algorithme basé sur le critère de dispersion, menant de front exploitation et exploration, pour approximer une variété.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Then, we propose a new algorithm, based on dispersion criterion, leading both exploration and exploitation to approximate a manifold.</seg>
            </tuv>
        </tu>
    </body>
</tmx>