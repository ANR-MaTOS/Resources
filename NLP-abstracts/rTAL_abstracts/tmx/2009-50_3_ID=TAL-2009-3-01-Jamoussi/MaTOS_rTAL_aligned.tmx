<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for TAL-2009-50_3_ID=TAL-2009-3-01-Jamoussi. segId begin by 1, tuid = segId</note>
        <docid>2009-50_3_ID=TAL-2009-3-01-Jamoussi</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>L'idée que nous défendons dans cet article est qu'il est possible d'obtenir des concepts sémantiques significatifs par des méthodes de classification automatique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The idea we defend in this paper is the possibility to obtain significant semantic concepts using clustering methods.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Pour ce faire, nous commençons par proposer des mesures permettant de quantifier les relations sémantiques entre mots.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We start by defining some semantic measures to quantify the semantic relations between words.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Ensuite, nous utilisons les méthodes de classification non supervisée pour construire les concepts d'une manière automatique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Then, we use some clustering methods to build up concepts in an automatic way.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Nous testons alors deux méthodes de partitionnement : l'algorithme des K-means et les cartes de Kohonen.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We test two well known methods: the K-means algorithm and the Kohonen maps.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Ensuite, nous utilisons le réseau bayésien AutoClass conçu pour la classification non supervisée.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Then, we propose the use of a Bayesian network conceived for clustering and called AutoClass.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Pour grouper les mots du vocabulaire en différentes classes, nous avons testé trois représentations vectorielles des mots.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To group the words of the vocabulary in various classes, we test three vector representations of words.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>La première est une représentation contextuelle simple.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The first is a simple contextual representation.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>La deuxième associe à chaque mot un vecteur de valeurs représentant sa similarité avec tous les mots du lexique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The second associates to each word a vector which represents its similarity with each word of the vocabulary.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Enfin, la troisième représentation est une combinaison des deux premières.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The third representation is a combination of the first and the second one.</seg>
            </tuv>
        </tu>
    </body>
</tmx>