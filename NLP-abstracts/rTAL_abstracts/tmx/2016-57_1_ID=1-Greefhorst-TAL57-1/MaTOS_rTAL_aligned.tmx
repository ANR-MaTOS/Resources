<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for TAL-2016-57_1_ID=1-Greefhorst-TAL57-1. segId begin by 1, tuid = segId</note>
        <docid>2016-57_1_ID=1-Greefhorst-TAL57-1</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>La prédiction de la liaison en français est un problème de modélisation nontrivial.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Predicting liaison in French is a non-trivial problem to model.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Nous comparons un algorithme d'apprentissage automatique basé sur la mémoire avec un point de comparaison basé sur des règles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We compare a memory-based machine-learning algorithm with a rule-based baseline.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>L'apprentissage automatique est entraîné à prédire si la liaison se produit entre deux mots consécutifs en évaluant des traits lexicaux, orthographiques, morphosyntaxiques et sociolinguistiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The memory-based learner is trained to predict whether liaison occurs between two words on the basis of lexical, orthographic, morphosyntactic, and sociolinguistic features.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Notre étude montre que la meilleure performance est obtenue en utilisant uniquement des trais lexicaux et syntaxiques, à savoir les lettres finales et initiales, la catégorie de laision (obligatoire ou optionelle), les étiquettes morphosyntaxiques, le nombre de syllabed par mot et la distance Levenshtein des vingt mots phonologiques les plus proches.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Best performance is obtained using only a selection of lexical and syntactic features (a window of the five last letters of a word and the five first letters of the following word, whether the liaison is obligatory or optional, Part-of-Speech tags, the number of syllables in a word and the Levenshtein distance to the 20 nearest phonological neighbors.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Contrairement à nos attentes, inclure des traits sociolinguistiques rend la précision et le rappel plus bas.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Counter to our expectations, including sociolinguistic features even lowered the precision and recall of our predictions.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>L'utilisation des traits lexicaux et syntaxiques a mené à une précision de .80 et un rappel de .85.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Selecting only lexical and syntactic features yields a best overall performance at a precision of .80, with recall at .85.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Elle est non seulement plus élevée que le point de comparaison basé sur des règles, mais aussi plus élevée que celle d'IGTree (un algorithme d'arbres de décision) et celle d'une classification naïve bayésienne.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The F-scores, the harmonic mean of precision and recall, of the memory-based algorithm are higher than that of a baseline based on the rules of Grevisse and Goosse (2011), IGTree (a decision-tree learner) and the Naive Bayes classifier.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Ripper, un algoritme d'induction de règles plus sophistiqué, a pu produire des résultats similaires à l'algorithme basé sur la mémoire, mais Ripper détecte moins d'instances de liaison optionelle, ce qui résulte en un rappel plus bas pour cette catégorie.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Ripper, a more sophisticated rule induction algorithm, was able to produce similar results to our memory-based algorithm, but when it comes to optional liaison contexts, Ripper misses more instances in which real speakers would produce a liaison.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Il paraît que la possibilité de généralisation des exemples spécifiques en contexte aide la prédiction de la liaison.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>It appears that predicting liaison benefits from being able to generalize from specific examples in context.</seg>
            </tuv>
        </tu>
    </body>
</tmx>