<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2016LORR0260. segId begin by 1, tuid = segId</note>
        <docid>2016LORR0260</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Le but de cette thèse est de proposer des méthodes pour récupérer les noms propres manquants dans un système de reconnaissance.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The goal of this thesis is to model the semantic and topical context of new proper names in order to retrieve those which are relevant to the spoken content in the audio document.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Nous proposons de modéliser le contexte sémantique et d'utiliser des informations thématiques contenus dans les documents audio à transcrire.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Training context models is a challenging problem in this task because several new names come with a low amount of data and the context model should be robust to errors in the automatic transcription.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Des modèles probabilistes de thème et des projections dans un espace continu obtenues à l'aide de réseaux de neurones sont explorés pour la tâche de récupération des noms propres pertinents.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Probabilistic topic models and word embeddings from neural network models are explored for the task of retrieval of relevant proper names.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Une évaluation approfondie de ces représentations contextuelles a été réalisée.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>A thorough evaluation of these contextual representations is performed.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>En s'appuyant sur ce modèle, nous proposons un nouveau modèle (Neural Bag-of-Weighted-Words, NBOW2) qui permet d'estimer un degré d'importance pour chacun des mots du document et a la capacité de capturer des mots spécifiques à ce document.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The proposed Neural Bag-of-Weighted-Words (NBOW2) model learns to assign a degree of importance to input words and has the ability to capture task specific key-words.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Des expériences de reconnaissance automatique de bulletins d'information télévisés montrent l'efficacité du modèle proposé.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Experiments on automatic speech recognition on French broadcast news videos demonstrate the effectiveness of the proposed models.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>L'évaluation de NBOW2 sur d'autres tâches telles que la classification de textes montre des bonnes performances</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Evaluation of the NBOW2 model on standard text classification tasks shows that it learns interesting information and gives best classification accuracies among the BOW models</seg>
            </tuv>
        </tu>
    </body>
</tmx>