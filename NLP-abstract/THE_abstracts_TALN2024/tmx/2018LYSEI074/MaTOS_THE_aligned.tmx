<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2018LYSEI074. segId begin by 1, tuid = segId</note>
        <docid>2018LYSEI074</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>La vidéosurveillance est d’une grande valeur pour la sécurité publique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Video surveillance systems are of a great value for public safety.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>En tant que l’un des plus importantes applications de vidéosurveillance, la ré-identification de personnes est définie comme le problème de l’identification d’individus dans des images captées par différentes caméras de surveillance à champs non-recouvrants.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>As one of the most import surveillance applications, person re-identification is defined as the problem of identifying people across images that have been captured by different surveillance cameras without overlapping fields of view.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Dans la première approche, nous utilisons les attributs des piétons tels que genre, accessoires et vêtements.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The attributes are defined as semantic mid-level descriptions of persons, such as gender, accessories, clothing etc.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Nous fusionnons ensuite ces deux branches pour la ré-identification.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The same person shows very different appearances from different points of view.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Deuxièmement, nous proposons un CNN prenant en compte différentes orientations du corps humain.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To deal with this issue, we consider that the images under various orientations are from different domains.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Comme troisième contribution de cette thèse, nous proposons une nouvelle fonction de coût basée sur une liste d’exemples.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The combined orientation-specific CNN feature representations are used for the person re-identification task.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Elle introduit une pondération basée sur le désordre du classement et permet d’optimiser directement les mesures d’évaluation.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Thirdly, learning a similarity metric for person images is a crucial aspect of person re-identification.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Enfin, pour un groupe de personnes, nous proposons d’extraire une représentation de caractéristiques visuelles invariante à la position d’un individu dans une image de group.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>As the third contribution, we propose a novel listwise loss function taking into account the order in the ranking of gallery images with respect to different probe images.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Cette prise en compte de contexte de groupe réduit ainsi l’ambigüité de ré-identification.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this case, using only the appearance of single person leads to strong ambiguities.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Pour chacune de ces quatre contributions, nous avons effectué de nombreuses expériences sur les différentes bases de données publiques pour montrer l’efficacité des approches proposées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>As the last contribution, we propose to learn a deep feature representation with displacement invariance for group context and introduce a method to combine the group context and single-person appearance.</seg>
            </tuv>
        </tu>
    </body>
</tmx>