<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2016LORIS424. segId begin by 1, tuid = segId</note>
        <docid>2016LORIS424</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Cette thèse porte sur l'analyse et la génération de mouvements expressifs pour des personnages humains virtuels.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This thesis addresses the analysis and generation of expressive movements for virtual human characters.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Sur la base de résultats d'état de l'art issus de trois domaines de recherche différents (la perception des émotions et du mouvement biologique, la reconnaissance automatique des émotions et l'animation de personnages), une représentation en faible dimension des mouvements a été proposée.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Based on previous results from three different research areas (perception of emotions and biological motion, automatic recognition of affect and computer character animation), a low-dimensional motion representation is proposed.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Cette représentation est constituée de trajectoires spatio-temporelles des extrémités des chaînes articulées (tête, mains et pieds) et du pelvis.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This representation consists of the spatio-temporal trajectories of end-effectors (i.e., head, hands and feet) and pelvis.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Nous avons soutenu que cette représentation est à la fois appropriée et suffisante pour caractériser le contenu expressif du mouvement humain et pour contrôler la génération de mouvements corporels expressifs.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We have argued that this representation is both suitable and sufficient for characterizing the underlying expressive content in human motion and for controlling the generation of expressive whole-body movements.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Pour étayer ces affirmations, cette thèse propose :</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In order to prove these claims, this thesis proposes:</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>i.) Une nouvelle base de données de mouvements capturés.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>i.) A new motion capture database inspired by physical theater theory.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Cette base de données a été inspirée par la théorie du théâtre physique et contient des exemples de différentes catégories de mouvements (à savoir des mouvements périodiques, des mouvements fonctionnels, des mouvements spontanés et des séquences de mouvements théâtraux), produit avec des états émotionnels distincts (joie, tristesse, détente, stress et neutre) et interprétés par plusieurs acteurs.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This database contains examples from different motion classes (i.e., periodic movements, functional behaviors, spontaneous motions, and theater-inspired motion sequences) and distinct emotional states (happiness, sadness, relaxedness, stress and neutral) performed by several actors.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>ii.) Une étude perceptuelle et une approche basée classification automatique conçus pour évaluer qualitativement et quantitativement la quantité d'information liée aux émotions encore véhiculée et codée dans la représentation proposée.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>ii.) A user study and automatic classification framework de-signed to qualitatively and quantitatively assess the amount of emotion-related information conveyed and encoded in the proposed representation.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Nous avons observé que, bien que de légères différences dans la performance aient été trouvées par rapport à la situation dans laquelle le corps entier a été utilisé, notre représentation conserve la plupart des qualités de mouvements liées à l'expression de l'affect et d'émotions.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We have observed that although slight differences in performance were found with respect to the cases in which the entire body was used, our proposed representation preserves most of the motion cues salient to the expression of affect and emotions.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>iii.) Un système de synthèse de mouvement capable : (a) de reconstruire des mouvements du corps entier à partir de la représentation à faible dimension proposée, (b) de produire de nouvelles trajectoires extrémités expressives (incluant la trajectoire du pelvis).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>iii.) A simple motion synthesis system able to capable of: a) reconstructing whole-body movements from the proposed low-dimensional representation, and b) producing novel end-effector (and pelvis) expressive trajectories.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Une évaluation quantitative et qualitative des mouvements du corps entier générés montre que ces mouvements sont aussi expressifs que les mouvements enregistrés à partir d'acteurs humains.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>A quantitative and qualitative evaluation of the generated whole body motions shows that these motions are as expressive as the movements recorded from human actors</seg>
            </tuv>
        </tu>
    </body>
</tmx>