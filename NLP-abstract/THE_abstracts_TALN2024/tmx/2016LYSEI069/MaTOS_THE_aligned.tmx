<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2016LYSEI069. segId begin by 1, tuid = segId</note>
        <docid>2016LYSEI069</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Cette thèse s'intéresse à la détection et la reconnaissance du texte arabe incrusté dans les vidéos.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This thesis focuses on Arabic embedded text detection and recognition in videos.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Dans ce contexte, nous proposons différents prototypes de détection et d'OCR vidéo (Optical Character Recognition) qui sont robustes à la complexité du texte arabe (différentes échelles, tailles, polices, etc.)</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Different approaches robust to Arabic text variability (fonts, scales, sizes, etc.) as well as to environmental and acquisition condition challenges (contrasts, degradation, complex background, etc.) are proposed.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Nous introduisons différents détecteurs de texte arabe qui se basent sur l'apprentissage artificiel sans aucun prétraitement.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We introduce different machine learning-based solutions for robust text detection without relying on any pre-processing.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Les détecteurs se basent sur des Réseaux de Neurones à Convolution (ConvNet) ainsi que sur des schémas de boosting pour apprendre la sélection des caractéristiques textuelles manuellement conçus.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The first method is based on Convolutional Neural Networks (ConvNet) while the others use a specific boosting cascade to select relevant hand-crafted text features.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Nous utilisons différents modèles d'apprentissage profond, regroupant des Auto-Encodeurs, des ConvNets et un modèle d'apprentissage non-supervisé, qui génèrent automatiquement ces caractéristiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Standing out from the dominant methodology of hand-crafted features, we propose to learn relevant text representations from data using different deep learning methods, namely Deep Auto-Encoders, ConvNets and unsupervised learning models.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Chaque modèle résulte en un système d'OCR bien spécifique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Each one leads to a specific OCR (Optical Character Recognition) solution.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Le processus de reconnaissance se base sur une approche connexionniste récurrente pour l'apprentissage de l'étiquetage des séquences de caractéristiques sans aucune segmentation préalable.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Sequence labeling is performed without any prior segmentation using a recurrent connectionist learning model.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Nos modèles d'OCR proposés sont comparés à d'autres modèles qui se basent sur des caractéristiques manuellement conçues.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Proposed solutions are compared to other methods based on non-connectionist and hand-crafted features.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Nous proposons un schéma de décodage conjoint qui intègre les inférences du LM en parallèle avec celles de l'OCR tout en introduisant un ensemble d’hyper-paramètres afin d'améliorer la reconnaissance et réduire le temps de réponse.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Both OCR and language model probabilities are incorporated in a joint decoding scheme where additional hyper-parameters are introduced to boost recognition results and reduce the response time.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Afin de surpasser le manque de corpus textuels arabes issus de contenus multimédia, nous mettons au point de nouveaux corpus manuellement annotés à partir des flux TV arabes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Given the lack of public multimedia Arabic datasets, we propose novel annotated datasets issued from Arabic videos.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Le corpus conçu pour l'OCR, nommé ALIF et composée de 6,532 images de texte annotées</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The OCR dataset, called ALIF, is publicly available for research purposes.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Nos systèmes ont été développés et évalués sur ces corpus.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our proposed solutions were extensively evaluated.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>L’étude des résultats a permis de valider nos approches et de montrer leurs efficacité et généricité avec plus de 97% en taux de détection, 88.63% en taux de reconnaissance mots sur le corpus ALIF dépassant ainsi un des systèmes d'OCR commerciaux les mieux connus par 36 points.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Obtained results highlight the genericity and the efficiency of our approaches, reaching a word recognition rate of 88.63% on the ALIF dataset and outperforming well-known commercial OCR engine by more than 36%.</seg>
            </tuv>
        </tu>
    </body>
</tmx>