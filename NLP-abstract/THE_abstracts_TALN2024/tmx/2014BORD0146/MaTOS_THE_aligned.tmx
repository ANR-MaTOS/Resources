<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2014BORD0146. segId begin by 1, tuid = segId</note>
        <docid>2014BORD0146</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>De manière simple, il peut être présenté ainsi : imaginez que vous êtes dans un labyrinthe, dont vous connaissez toutes les routes menant à chacune des portes de sortie.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This thesis investigates how a machine can be taught a new task from unlabeled human in structions, which is without knowing beforehand how to associate the human communicative signals with their meanings.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Pour cela, il vous indiquera la direction à prendre à chaque intersection.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>It therefore removes the need for an expert to tune the system for each specific user, which constitutes an important step towards flexible personalized teaching interfaces, a key for the future of personal robotics.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Malheureusement, cet homme ne parle pas votre langue, et les mots qu'il utilise pour dire ``droite'' ou ``gauche'' vous sont inconnus.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our approach assumes the robot has access to a limited set of task hypotheses, which include the task the user wants to solve.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Est-il possible de trouver le trésor et de comprendre l'association entre les mots du vieil homme et leurs significations ?</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our method consists of generating interpretation hypotheses of the teaching signals with respect to each hypothetic task.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Ce problème, bien qu'en apparence abstrait, est relié à des problématiques concrètes dans le domaine de l'interaction homme-machine.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>By building a set of hypothetic interpretation, i.e. a set of signal label pairs for each task, the task the user wants to solve is the one that explains better the history of interaction.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Remplaçons le vieil homme par un utilisateur souhaitant guider un robot vers une sortie spécifique du labyrinthe.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We consider different scenarios, including a pick and place robotics experiment with speech as the modality of interaction, and a navigation task in a brain computer interaction scenario.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Ce robot ne sait pas en avance quelle est la bonne sortie mais il sait où se trouvent chacune des portes et comment s'y rendre.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In these scenarios, a teacher instructs a robot to perform a new task using initially unclassified signals, whose associated meaning can be a feedback (correct/incorrect) or a guidance (go left, right, up, ...).</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Imaginons maintenant que ce robot ne comprenne pas a priori le langage de l'humain; en effet, il est très difficile de construire un robot à même de comprendre parfaitement chaque langue, accent et préférence de chacun.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our results show that a) it is possible to learn the meaning of unlabeled and noisy teaching signals, as well as a new task at the same time, and b) it is possible to reuse the acquired knowledge about the teaching signals for learning new tasks faster.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Il faudra alors que le robot apprenne l'association entre les mots de l'utilisateur et leur sens, tout en réalisant la tâche que l'humain lui indique (i.e.trouver la bonne porte).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We further introduce a planning strategy that exploits uncertainty from the task and the signals' meanings to allow more efficient learning sessions.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>En effet, le résoudre reviendrait à créer des interfaces ne nécessitant pas de phase de calibration car la machine pourrait s'adapter,automatiquement et pendant l'interaction, à différentes personnes qui ne parlent pas la même langue ou qui n'utilisent pas les mêmes mots pour dire la même chose.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We present a study where several real human subjects control successfully a virtual device using their brain and without relying on a calibration phase.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Cela veut aussi dire qu'il serait facile de considérer d’autres modalités d'interaction (par exemple des gestes, des expressions faciales ou des ondes cérébrales).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our system identifies, from scratch, the target intended by the user as well as the decoder of brain signals.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, nous présentons une solution à ce problème.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Based on this work, but from another perspective, we introduce a new experimental setup to study how humans behave in asymmetric collaborative tasks.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Nous appliquons nos algorithmes à deux exemples typiques de l'interaction homme robot et de l'interaction cerveau machine: une tâche d'organisation d'une série d'objets selon les préférences de l'utilisateur qui guide le robot par la voix, et une tâche de déplacement sur une grille guidé par les signaux cérébraux de l'utilisateur.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this setup, two humans have to collaborate to solve a task but the channels of communication they can use are constrained and force them to invent and agree on a shared interaction protocol in order to solve the task.</seg>
            </tuv>
        </tu>
        <tu tuid="14">
            <tuv xml:lang="FR">
                <seg>Ces dernières expériences ont été faites avec des utilisateurs réels.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>These constraints allow analyzing how a communication protocol is progressively established through the interplay and history of individual actions.</seg>
            </tuv>
        </tu>
    </body>
</tmx>