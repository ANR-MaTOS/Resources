<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2017LORR0212. segId begin by 1, tuid = segId</note>
        <docid>2017LORR0212</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, nous traitons le problème de la séparation de sources audio multicanale par réseaux de neurones profonds (deep neural networks, DNNs).</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This thesis addresses the problem of multichannel audio source separation by exploiting deep neural networks (DNNs).</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Notre approche se base sur le cadre classique de séparation par algorithme espérance-maximisation (EM) basé sur un modèle gaussien multicanal, dans lequel les sources sont caractérisées par leurs spectres de puissance à court terme et leurs matrices de covariance spatiales.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We build upon the classical expectation-maximization (EM) based source separation framework employing a multichannel Gaussian model, in which the sources are characterized by their power spectral densities and their source spatial covariance matrices.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Nous explorons et optimisons l'usage des DNNs pour estimer ces paramètres spectraux et spatiaux.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We explore and optimize the use of DNNs for estimating these spectral and spatial parameters.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>À partir des paramètres estimés, nous calculons un filtre de Wiener multicanal variant dans le temps pour séparer chaque source.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Employing the estimated source parameters, we then derive a time-varying multichannel Wiener filter for the separation of each source.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Nous étudions en détail l'impact de plusieurs choix de conception pour les DNNs spectraux et spatiaux.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We extensively study the impact of various design choices for the spectral and spatial DNNs.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Nous considérons plusieurs fonctions de coût, représentations temps-fréquence, architectures, et tailles d'ensembles d'apprentissage.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We consider different cost functions, time-frequency representations, architectures, and training data sizes.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Ces fonctions de coût incluent en particulier une nouvelle fonction liée à la tâche pour les DNNs spectraux : le rapport signal-à-distorsion.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Those cost functions notably include a newly proposed task-oriented signal-to-distortion ratio cost function for spectral DNNs.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Nous présentons aussi une formule d'estimation pondérée des paramètres spatiaux, qui généralise la formulation EM exacte.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Furthermore, we present a weighted spatial parameter estimation formula, which generalizes the corresponding exact EM formulation.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Sur une tâche de séparation de voix chantée, nos systèmes sont remarquablement proches de la méthode de l'état de l'art actuel et améliorent le rapport source-interférence de 2 dB.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>On a singing-voice separation task, our systems perform remarkably close to the current state-of-the-art method and provide up to 2 dB improvement of the source-to-interference ratio.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Sur une tâche de rehaussement de la parole, nos systèmes surpassent la formation de voies GEV-BAN de l'état de l'art de 14%, 7% et 1% relatifs en terme d'amélioration du taux d'erreur sur les mots sur des données à 6, 4 et 2 canaux respectivement</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>On a speech enhancement task, our systems outperforms the state-of-the-art GEV-BAN beamformer by 14%, 7%, and 1% relative word error rate improvement on 6-channel, 4-channel, and 2-channel data, respectively</seg>
            </tuv>
        </tu>
    </body>
</tmx>