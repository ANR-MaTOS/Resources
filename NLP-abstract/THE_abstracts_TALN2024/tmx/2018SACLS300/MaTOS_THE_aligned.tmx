<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2018SACLS300. segId begin by 1, tuid = segId</note>
        <docid>2018SACLS300</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, nous nous intéressons particulièrement aux données issues de l'imagerie par résonance magnétique fonctionnelle (IRMf), que nous étudions dans un cadre d'apprentissage statistique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this work, we consider data from functional Magnetic Resonance Imaging (fMRI), that we study in a machine learning setting: we learn a model of brain activity that should generalize on unseen data.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Tout d'abord, nous considérons les données d'IRMf de repos, que nous traitons grâce à des méthodes de factorisation de matrices.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We first focus on unsupervised analysis of terabyte-scale fMRI data acquired on subjects at rest (resting-state fMRI).</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Notre méthode principale introduit une réduction aléatoire de la dimension des données dans une boucle d'apprentissage en ligne.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We present new methods for running sparse matrix factorization/dictionary learning on hundreds of fMRI records in reasonable time.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>L'algorithme proposé converge plus de 10 fois plus vite que les meilleures méthodes existantes, pour différentes configurations et sur plusieurs jeux de données.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our leading approach relies on introducing randomness in stochastic optimization loops and provides speed-up of an order of magnitude on a variety of settings and datasets.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Nous effectuons une vaste validation expérimentale de notre approche de sous-échantillonnage aléatoire.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We provide an extended empirical validation of our stochastic subsampling approach, for datasets from fMRI, hyperspectral imaging and collaborative filtering.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Nous proposons une étude théorique des propriétés de convergence de notre algorithme.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We derive convergence properties for our algorithm, in a theoretical analysis that reaches beyond the matrix factorization problem.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Dans un second temps, nous nous intéressons aux données d'IRMf d'activation.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We then turn to work with fMRI data acquired on subject undergoing behavioral protocols (task fMRI).</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Nous démontrons comment agréger différents études acquises suivant des protocoles distincts afin d'apprendre des modèles joints de décodage plus justes et interprétables.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We investigate how to aggregate data from many source studies, acquired with many different protocols, in order to learn more accurate and interpretable decoding models, that predicts stimuli or tasks from brain maps.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Cela suscite un transfert d'information entre les études.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>As a consequence, our multi-study model performs better than single-study decoding.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>En conséquence, notre modèle multi-étude est plus performant que les modèles de décodage appris sur chaque étude séparément.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our approach identifies universally relevant representation of brain activity, supported by a few task-optimized networks learned during model fitting.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Notre approche identifie une représentation universellement pertinente de l'activité cérébrale, supportée par un petit nombre de réseaux optimisés pour l'identification de tâches.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Finally, on a related topic, we show how to use dynamic programming within end-to-end trained deep networks, with applications in natural language processing.</seg>
            </tuv>
        </tu>
    </body>
</tmx>