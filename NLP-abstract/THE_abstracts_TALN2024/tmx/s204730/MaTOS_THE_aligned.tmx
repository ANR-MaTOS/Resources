<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-s204730. segId begin by 1, tuid = segId</note>
        <docid>s204730</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Cette thèse explore l'utilisation de fonctions de perte structurées dans deux domaines distincts.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This thesis explores the use of structured losses in two different domains.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Dans la première contribution, nous nous intéressons à l'apprentissage par renforcement multi-agent, dans le contexte d'environnements qui peuvent être séparés en plusieurs tâches faiblement dépendantes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the first contribution, we focus on multi-agent reinforcement learning (MARL), in environments that can be separated into several loosely coupled tasks.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>On s'attache à trouver des politiques qui se généralisent à plus d'agents et de tâches que les scénarios d'entraînement, permettant ainsi d'augmenter la taille des problèmes qui peuvent être approchés.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We set out to find policies that can generalize well to more agents and tasks than seen during training, effectively scaling up the size of problems that can be tackled.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Notre solution affecte les agents aux tâches en résolvant un problème d'optimisation centralisé dont la fonction objectif est paramétrée par un réseau de neurones.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our solution assigns agents to tasks by approximately solving a centralized optimization problem whose objective function is parameterized by a neural network.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>On montre que l'expressivité du problème d'optimisation et celle du réseau de neurones influencent la capacité du modèle à généraliser, et qu'avec les bons choix, la politique peut généraliser à plus de 5 fois plus d'agents que pendant l'entraînement.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We study how the expressivity of the optimization problem and that of the neural network influence the generalization capabilities of the model, and show that with the right choices, the policy can generalize to more than 5 times more agents than seen during training.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Dans la seconde contribution, nous formulons la détection d'objets comme un problème de prédiction d'ensemble, et nous concevons un modèle dans cette optique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the second contribution we formulate object detection as a set prediction problem, and design a model that can effectively tackle this formulation.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Notre solution utilise un réseau convolutionel profond, comme souvent en vision par ordinateur, et un encodeur-décodeur de Transformer, une architecture qui a récemment permis d'importants progrès en traitement du langage.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our solution leverages a deep convolutional network, as is customary in computer vision, and a transformer encoder-decoder network, an architecture that has enabled significant progress in natural language processing.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Remarquablement, notre solution n'incorpore que peu de biais inductif, et ne nécessite donc pas de composants spécifiques à la détection d'objets, tels que les ancres de détection.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Crucially, our solution incorporates minimal inductive bias, thereby alleviating the need for hand-designed detection-specific components such as anchors or non-maximal suppression.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Avec un nombre de paramètres comparable, notre modèle égale la performance de modèles de référence, tels que Retinanet et Faster R-CNN sur le dataset de détection COCO.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>With a comparable parameter budget, our model matches the performance of well-established and highly-optimized baselines such as Retinanet and Faster R-CNN on the challenging COCO detection dataset.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Pour finir, nous montrons que la méthode peut naturellement être étendue à la segmentation panoptique, où elle surpasse les approches concurrentes, démontrant ainsi sa généralité.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Finally, we show that the method can be naturally extended to perform panoptic segmentation, where it outperforms competing approaches, thus showing the versatility of the model.</seg>
            </tuv>
        </tu>
    </body>
</tmx>