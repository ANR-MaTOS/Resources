<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2016LYSES062. segId begin by 1, tuid = segId</note>
        <docid>2016LYSES062</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>La notion de métrique joue un rôle clef dans les problèmes d'apprentissage automatique tels que la classification, le clustering et le ranking.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The notion of metric plays a key role in machine learning problems, such as classification, clustering and ranking.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>L'apprentissage à partir de données de métriques adaptées à une tâche spécifique a suscité un intérêt croissant ces dernières années.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Learning metrics from training data in order to make them adapted to the task at hand has attracted a growing interest in the past years.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Ce domaine vise généralement à trouver les meilleurs paramètres pour une métrique donnée sous certaines contraintes imposées par les données.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This research field, known as metric learning, usually aims at finding the best parameters for a given metric under some constraints from the data.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>La métrique apprise est utilisée dans un algorithme d'apprentissage automatique dans le but d'améliorer sa performance.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The learned metric is used in a machine learning algorithm in hopes of improving performance.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>La plupart des méthodes d'apprentissage de métriques optimisent les paramètres d'une distance de Mahalanobis pour des vecteurs de features.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Most of the metric learning algorithms focus on learning the parameters of Mahalanobis distances for feature vectors.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Les méthodes actuelles de l'état de l'art arrivent à traiter des jeux de données de tailles significatives.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Current state of the art methods scale well for datasets of significant size.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>En revanche, le sujet plus complexe des séries temporelles multivariées n'a reçu qu'une attention limitée, malgré l'omniprésence de ce type de données dans les applications réelles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>On the other hand, the more complex topic of multivariate time series has received only limited attention, despite the omnipresence of this type of data in applications.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Une importante partie de la recherche sur les séries temporelles est basée sur la dynamic time warping (DTW), qui détermine l'alignement optimal entre deux séries temporelles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>An important part of the research on time series is based on the dynamic time warping (DTW) computing the optimal alignment between two time series.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>L'état actuel de l'apprentissage de métriques souffre de certaines limitations.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The current state of metric learning suffers from some significant limitations which we aim to address in this thesis.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>La plus importante est probablement le manque de garanties théoriques concernant la métrique apprise et sa performance pour la classification.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The most important one is probably the lack of theoretical guarantees for the learned metric and its performance for classification.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>La théorie des fonctions de similarité (ℰ, ϓ, T)-bonnes a été l'un des premiers résultats liant les propriétés d'une similarité à celles du classifieur qui l'utilise.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The theory of (ℰ, ϓ, τ)-good similarity functions has been one of the first results relating the properties of a similarity to its classification performance.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Une deuxième limitation vient du fait que la plupart des méthodes imposent des propriétés de distance, qui sont coûteuses en terme de calcul et souvent non justifiées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>A second limitation in metric learning comes from the fact that most methods work with metrics that enforce distance properties, which are computationally expensive and often not justified.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, nous abordons les limitations précédentes à travers deux contributions principales.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this thesis, we address these limitations through two main contributions.</seg>
            </tuv>
        </tu>
        <tu tuid="14">
            <tuv xml:lang="FR">
                <seg>La première est un nouveau cadre général pour l'apprentissage conjoint d'une fonction de similarité et d'un classifieur linéaire.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The first one is a novel general framework for jointly learning a similarity function and a linear classifier.</seg>
            </tuv>
        </tu>
        <tu tuid="15">
            <tuv xml:lang="FR">
                <seg>Cette formulation est inspirée de la théorie de similarités (ℰ, ϓ, τ)-bonnes, fournissant un lien entre la similarité et le classifieur linéaire.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This formulation is inspired from the (ℰ, ϓ, τ)-good theory, providing a link between the similarity and the linear classifier.</seg>
            </tuv>
        </tu>
        <tu tuid="16">
            <tuv xml:lang="FR">
                <seg>Elle est convexe pour une large gamme de fonctions de similarité et de régulariseurs.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>It is also convex for a broad range of similarity functions and regularizers.</seg>
            </tuv>
        </tu>
        <tu tuid="17">
            <tuv xml:lang="FR">
                <seg>Nous dérivons deux bornes de généralisation équivalentes à travers les cadres de robustesse algorithmique et de convergence uniforme basée sur la complexité de Rademacher, prouvant les propriétés théoriques de notre formulation.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We derive two equivalent generalization bounds through the frameworks of algorithmic robustness and uniform convergence using the Rademacher complexity, proving the good theoretical properties of our framework.</seg>
            </tuv>
        </tu>
        <tu tuid="18">
            <tuv xml:lang="FR">
                <seg>Notre deuxième contribution est une méthode d'apprentissage de similarités basée sur DTW pour la classification de séries temporelles multivariées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our second contribution is a method for learning similarity functions based on DTW for multivariate time series classification.</seg>
            </tuv>
        </tu>
        <tu tuid="19">
            <tuv xml:lang="FR">
                <seg>Le problème est convexe et utilise la théorie des fonctions (ℰ, ϓ, T)-bonnes liant la performance de la métrique à celle du classifieur linéaire associé.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The formulation is convex and makes use of the(ℰ, ϓ, τ)-good framework for relating the performance of the metric to that of its associated linear classifier.</seg>
            </tuv>
        </tu>
        <tu tuid="20">
            <tuv xml:lang="FR">
                <seg>A l'aide de la stabilité uniforme, nous prouvons la consistance de la similarité apprise conduisant à la dérivation d'une borne de généralisation.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Using uniform stability arguments, we prove the consistency of the learned similarity leading to the derivation of a generalization bound.</seg>
            </tuv>
        </tu>
    </body>
</tmx>