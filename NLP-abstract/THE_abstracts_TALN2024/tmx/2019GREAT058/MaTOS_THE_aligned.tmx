<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2019GREAT058. segId begin by 1, tuid = segId</note>
        <docid>2019GREAT058</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>L’analyse automatique des expressions faciales représente à l’heure actuelle une problématique importante associée à de multiples applications telles que la reconnaissance de visages ou encore les interactions homme machine.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Facial expression analysis is an important problem in many biometric tasks, such as face recognition, face animation, affective computing and human computer interface.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, nous nous attaquons au problème de la reconnaissance d’expressions faciales à partir d’une image ou d’une séquence d’images.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this thesis, we aim at analyzing facial expressions of a face using images and video sequences.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Nous abordons le problème sous trois angles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We divided the problem into three leading parts.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Tout d’abord, nous étudions les macro-expressions faciales et nous proposons de comparer l’efficacité de trois descripteurs différents.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>First, we study Macro Facial Expressions for Emotion Recognition and we propose three different levels of feature representations.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Nous examinons aussi l’apport de descripteurs spatio-temporels capables de prendre en compte des informations dynamiques utiles pour séparer les classes ambigües.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Then, we incorporate the time dimension to extract spatio-temporal features with the objective to describe subtle feature deformations to discriminate ambiguous classes.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>La grosse limitation des méthodes de classification supervisée est qu’elles sont très coûteuses en termes de labélisation de données.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Second, we direct our research toward transfer learning, where we aim at Adapting Facial Expression Category Models to New Domains and Tasks.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Ainsi nous nous sommes intéressés à l’adaptation de domaine et à l’apprentissage avec peu ou pas de données labélisées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Thus we study domain adaptation and zero shot learning for developing a method that solves the two tasks jointly.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>La méthode proposée nous permet de traiter des données non labélisées provenant de distributions différentes de celles du domaine source de l’apprentissage ou encore des données qui ne concernent pas les mêmes labels mais qui partagent le même contexte.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our method is suitable for unlabelled target datasets coming from different data distributions than the source domain and for unlabelled target datasets with different label distributions but sharing the same context as the source domain.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Le transfert de connaissance s’appuie sur un apprentissage euclidien et des réseaux de neurones convolutifs de manière à définir une fonction de mise en correspondance entre les informations visuelles provenant des expressions faciales et un espace sémantique issu d’un modèle de langage naturel.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Therefore, to permit knowledge transfer between domains and tasks, we use Euclidean learning and Convolutional Neural Networks to design a mapping function that map the visual information coming from facial expressions into a semantic space coming from a Natural Language model that encodes the visual attribute description or use the label information.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Dans un troisième temps, nous nous sommes intéressés à la reconnaissance des micro-expressions faciales.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The consistency between the two subspaces is maximized by aligning them using the visual feature distribution.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Ainsi nous proposons un réseau de neurones auto-encodeur récurrent destiné à capturer les changements spatiaux et temporels associés à toutes les déformations du visage autres que celles dues aux micro-expressions.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Then, a statistical based model for estimating the probability density function of normal facial behaviours while associating a discriminating score to spot micro-expressions is learned based on a Gaussian Mixture Model.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Ensuite, nous apprenons un modèle statistique basé sur un mélange de gaussiennes afin d’estimer la densité de probabilité de ces déformations autres que celles dues aux micro-expressions.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Finally, an adaptive thresholding technique for identifying micro expressions from natural facial behaviour is proposed.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Tous nos algorithmes sont testés et évalués sur des bases d’expressions faciales actées et/ou spontanées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our algorithms are tested over deliberate and spontaneous facial expression benchmarks.</seg>
            </tuv>
        </tu>
    </body>
</tmx>