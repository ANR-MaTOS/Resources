<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2020UPASN017. segId begin by 1, tuid = segId</note>
        <docid>2020UPASN017</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Analyse de données géométriques, au delà des convolutionsPour modéliser des interactions entre points, une méthode simple est de se reposer sur des sommes pondérées communément appelées "convolutions".</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Geometric data analysis, beyond convolutionsTo model interactions between points, a simple option is to rely on weighted sums known as convolutions.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Au cours de la dernière décennie, cette opération est devenue la brique de construction essentielle à la révolution du "deep learning".</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Over the last decade, this operation has become a building block for deep learning architectures with an impact on many applied fields.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Le produit de convolution est, toutefois, loin d'être l'alpha et l'oméga des mathématiques appliquées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We should not forget, however, that the convolution product is far from being the be-all and end-all of computational mathematics.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Pour permettre aux chercheurs d'explorer de nouvelles directions, nous présentons des implémentations robustes et efficaces de trois opérations souvent sous</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To let researchers explore new directions, we present robust, efficient and principled implementations of three underrated operations: 1.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Le transport optimal, qui généralise la notion de "tri" aux espaces de dimension D &amp;gt; 1.3.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Optimal transport, which generalizes sorting to spaces of dimension D &amp;gt; 1.3.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Le tir géodésique sur une variété Riemannienne, qui se substitue à l'interpolation linéaire sur des espaces de données où aucune structure vectorielle ne peut être correctement définie.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Hamiltonian geodesic shooting, which replaces linear interpolation when no relevant algebraic structure can be defined on a metric space of features.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Nos routines PyTorch/NumPy sont compatibles avec la différentiation automatique, et s'exécutent en quelques secondes sur des nuages de plusieurs millions de points.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our PyTorch/NumPy routines fully support automatic differentiation and scale up to millions of samples in seconds.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Elle sont de 10 à 1,000 fois plus performantes que des implémentations GPU standards et conservent une empreinte mémoire linéaire.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>They generally outperform baseline GPU implementations with x10 to x1,000 speed-ups and keep linear instead of quadratic memory footprints.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Ces nouveaux outils sont empaquetés dans les bibliothèques "KeOps" et "GeomLoss", avec des applications qui vont de l'apprentissage automatique à l'imagerie médicale.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>These new tools are packaged in the KeOps (kernel methods) and GeomLoss (optimal transport) libraries, with applications that range from machine learning to medical imaging.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Notre documentation est accessible aux adresses www.kernel-operations.io/keops et /geomloss.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Documentation is available at: www.kernel-operations.io/keops and /geomloss.</seg>
            </tuv>
        </tu>
    </body>
</tmx>