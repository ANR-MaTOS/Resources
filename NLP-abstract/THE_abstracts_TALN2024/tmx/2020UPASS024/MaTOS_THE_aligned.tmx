<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2020UPASS024. segId begin by 1, tuid = segId</note>
        <docid>2020UPASS024</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>La recherche de réponses à des questions relève de deux disciplines : le traitement du langage naturel et la recherche d'information.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Question Answering is a discipline which lies in between natural language processing and information retrieval domains.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>L'émergence de l'apprentissage profond dans plusieurs domaines de recherche tels que la vision par ordinateur, le traitement du langage naturel etc. a conduit à l'émergence de modèles de bout en bout.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Emergence of deep learning approaches in several fields of research such as computer vision, natural language processing, speech recognition etc. has led to the rise of end-to-end models.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Dans le cadre du projet GoASQ, l'objectif est d'étudier, comparer et combiner différentes approches pour répondre à des questions formulées en langage naturel sur des données textuelles, en domaine ouvert et en domaine biomédical.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the context of GoASQ project, we investigate, compare and combine different approaches for answering questions formulated in natural language over textual data on open domain and biomedical domain data.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Ce travail se concentre principalement sur 1) la construction de modèles permettant de traiter des ensembles de données à petite et à grande échelle, et 2) l'exploitation de connaissances sémantiques pour répondre aux questions par leur intégration dans les différents modèles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The thesis work mainly focuses on 1) Building models for small scale and large scale datasets, and 2) Leveraging structured and semantic information into question answering models.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Nous visons à fusionner des connaissances issues de textes libres, d'ontologies, de représentations d'entités, etc.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Hybrid data in our research context is fusion of knowledge from free text, ontologies, entity information etc. applied towards free text question answering.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Afin de faciliter l'utilisation des modèles neuronaux sur des données de domaine de spécialité, nous nous plaçons dans le cadre de l'adaptation de domaine.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The current state-of-the-art models for question answering use deep learning based models.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Nous avons proposé deux modèles de tâches de QR différents, évalués sur la tâche BIOASQ de réponse à des questions biomédicales.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In order to facilitate using them on small scale datasets on closed domain data, we propose to use domain adaptation.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Nous montrons par nos résultats expérimentaux que le modèle de QR ouvert convient mieux qu'une modélisation de type Compréhension machine.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We model the BIOASQ biomedical question answering task dataset into two different QA task models and show how the Open Domain Question Answering task suits better than the Reading Comprehension task by comparing experimental results.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Nous pré-entrainons le modèle de Compréhension machine, qui sert de base à notre modèle, sur différents ensembles de données pour montrer la variabilité des performances.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We pre-train the Reading Comprehension model with different datasets to show the variability in performance when these models are adapted to biomedical domain.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Nous constatons que l'utilisation d'un ensemble de données particulier pour le pré-entraînement donne les meilleurs résultats lors du test et qu'une combinaison de quatre jeux de données donne les meilleurs résultats lors de l'adaptation au domaine biomédical.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We find that using one particular dataset (SQUAD v2.0 dataset) for pre-training performs the best on single dataset pre-training and a combination of four Reading Comprehension datasets performed the best towards the biomedical domain adaptation.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Nous avons testé des modèles de langage à grande échelle, comme BERT, qui sont adaptés à la tâche de réponse aux questions.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We perform some of the above experiments using large scale pre-trained language models like BERT which are fine-tuned to the question answering task.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Les performances varient en fonction du type des données utilisées pour pré-entrainer BERT.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The performance varies based on the type of data used to pre-train BERT.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Ainsi, le modèle de langue appris sur des données biomédicales, BIOBERT, constitue le meilleur choix pour le QR biomédical.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>For BERT pre-training on the language modelling task, we find the biomedical data trained BIOBERT to be the best choice for biomedical QA.</seg>
            </tuv>
        </tu>
        <tu tuid="14">
            <tuv xml:lang="FR">
                <seg>Nous avons annoté manuellement et automatiquement un jeu de données par les variantes des réponses de BIOASQ et montré l'importance d'apprendre un modèle de QR avec ces variantes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We highlight the necessity for using Lexical and Expected Answer Types in open domain and biomedical domain question answering by performing several verification experiments.</seg>
            </tuv>
        </tu>
        <tu tuid="15">
            <tuv xml:lang="FR">
                <seg>Ces types sont ensuite utilisés pour mettre en évidence les entités dans les jeux de données, ce qui montre des améliorations sur l'état de l'art.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>These types are used to highlight entities in two QA tasks which shows improvements while using entity embeddings based on the answer type annotations.</seg>
            </tuv>
        </tu>
        <tu tuid="16">
            <tuv xml:lang="FR">
                <seg>Par ailleurs l'exploitation de représentations vectorielles d'entités dans les modèles se montre positif pour le domaine ouvert.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We manually annotated an answer variant dataset for BIOASQ and show the importance of learning a QA model with answer variants present in the paragraphs.</seg>
            </tuv>
        </tu>
        <tu tuid="17">
            <tuv xml:lang="FR">
                <seg>Nous faisons l'hypothèse que les résultats obtenus à partir de modèles d'apprentissage profond peuvent être encore améliorés en utilisant des traits sémantiques et des traits collectifs calculés à partir des différents paragraphes sélectionnés pour répondre à une question.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Our hypothesis is that the results obtained from deep learning models can further be improved using semantic features and collective features from different paragraphs for a question.</seg>
            </tuv>
        </tu>
        <tu tuid="18">
            <tuv xml:lang="FR">
                <seg>Nous utilisons des modèles de classification binaires pour améliorer la prédiction de la réponse parmi les K candidats à l'aide de ces caractéristiques, conduisant à un modèle hybride qui surpasse les résultats de l'état de l'art.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We propose to use ranking models based on binary classification methods to better rank Top-1 prediction among Top-K predictions using these features, leading to an hybrid model that outperforms state-of-art-results on several datasets.</seg>
            </tuv>
        </tu>
        <tu tuid="19">
            <tuv xml:lang="FR">
                <seg>Enfin, nous avons évalué des modèles de QR ouvert sur des ensembles de données construits pour les tâches de Compréhension machine et Sélection de phrases.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We experiment with several overall Open Domain Question Answering models on QA sub-task datasets built for Reading Comprehension and Answer Sentence Selection tasks.</seg>
            </tuv>
        </tu>
        <tu tuid="20">
            <tuv xml:lang="FR">
                <seg>Nous montrons la différence de performance lorsque la tâche à résoudre est une tâche de QR ouverte et soulignons le fossé important qu'il reste à franchir dans la construction de modèles de bout en bout pour la tâche complète de réponse aux questions.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We show the difference in performance when these are modelled as overall QA task and highlight the wide gap in building end-to-end models for overall question answering task.</seg>
            </tuv>
        </tu>
    </body>
</tmx>