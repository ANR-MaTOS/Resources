<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2017GREAM054. segId begin by 1, tuid = segId</note>
        <docid>2017GREAM054</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Le texte est l'une des sources d'informations les plus répandues et les plus persistantes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Text is one of the most pervasive and persistent sources of information.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>L'analyse de contenu du texte se réfère à des méthodes d'étude et de récupération d'informations à partir de documents.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Content analysis of text in its broad sense refers to methods for studying and retrieving information from documents.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Aujourd'hui, avec une quantité de texte disponible en ligne toujours croissante l'analyse de contenu du texte revêt une grande importance parce qu' elle permet une variété d'applications.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Nowadays, with the ever increasing amounts of text becoming available online is several languages and different styles, content analysis of text is of tremendous importance as it enables a variety of applications.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>À cette fin, les méthodes d'apprentissage de la représentation sans supervision telles que les modèles thématiques et les word embeddings constituent des outils importants.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To this end, unsupervised representation learning methods such as topic models and word embeddings constitute prominent tools.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>L'objectif de cette dissertation est d'étudier et de relever des défis dans ce domaine.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The goal of this dissertation is to study and address challenging problems in this area, focusing on both the design of novel text mining algorithms and tools, as well as on studying how these tools can be applied to text collections written in a single or several languages.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Dans la première partie de la thèse, nous nous concentrons sur les modèles thématiques et plus précisément sur la manière d'incorporer des informations antérieures sur la structure du texte à ces modèles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the first part of the thesis we focus on topic models and more precisely on how to incorporate prior information of text structure to such models.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Les modèles de sujets sont basés sur le principe du sac-de-mots et, par conséquent, les mots sont échangeables.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Topic models are built on the premise of bag-of-words, and therefore words are exchangeable.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Bien que cette hypothèse profite les calculs des probabilités conditionnelles, cela entraîne une perte d'information.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>While this assumption benefits the calculations of the conditional probabilities it results in loss of information.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Pour éviter cette limitation, nous proposons deux mécanismes qui étendent les modèles de sujets en intégrant leur connaissance de la structure du texte.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To overcome this limitation we propose two mechanisms that extend topic models by integrating knowledge of text structure to them.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Nous supposons que les documents sont répartis dans des segments de texte cohérents.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We assume that the documents are partitioned in thematically coherent text segments.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Le premier mécanisme attribue le même sujet aux mots d'un segment.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The first mechanism assigns the same topic to the words of a segment.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>La seconde, capitalise sur les propriétés de copulas, un outil principalement utilisé dans les domaines de l'économie et de la gestion des risques, qui sert à modéliser les distributions communes de densité de probabilité des variables aléatoires tout en n'accédant qu'à leurs marginaux.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The second, capitalizes on the properties of copulas, a tool mainly used in the fields of economics and risk management that is used to model the joint probability density distributions of random variables while having access only to their marginals.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>En règle générale, une collection de documents pour ces modèles se présente sous la forme de paires de documents comparables.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Typically, a document collection for such models is in the form of comparable document pairs.</seg>
            </tuv>
        </tu>
        <tu tuid="14">
            <tuv xml:lang="FR">
                <seg>Les documents d'une paire sont écrits dans différentes langues et sont thématiquement similaires.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The documents of a pair are written in different languages and are thematically similar.</seg>
            </tuv>
        </tu>
        <tu tuid="15">
            <tuv xml:lang="FR">
                <seg>À moins de traductions, les documents d'une paire sont semblables dans une certaine mesure seulement.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Unless translations, the documents of a pair are similar to some extent only.</seg>
            </tuv>
        </tu>
        <tu tuid="16">
            <tuv xml:lang="FR">
                <seg>Pendant ce temps, les modèles de sujets représentatifs supposent que les documents ont des distributions thématiques identiques, ce qui constitue une hypothèse forte et limitante.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Meanwhile, representative topic models assume that the documents have identical topic distributions, which is a strong and limiting assumption.</seg>
            </tuv>
        </tu>
        <tu tuid="17">
            <tuv xml:lang="FR">
                <seg>Pour le surmonter, nous proposons de nouveaux modèles thématiques bilingues qui intègrent la notion de similitude interlingue des documents qui constituent les paires dans leurs processus générateurs et d'inférence.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To overcome it we propose novel bilingual topic models that incorporate the notion of cross-lingual similarity of the documents that constitute the pairs in their generative and inference processes.</seg>
            </tuv>
        </tu>
        <tu tuid="18">
            <tuv xml:lang="FR">
                <seg>La dernière partie de la thèse porte sur l'utilisation d'embeddings de mots et de réseaux de neurones pour trois applications d'exploration de texte.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The last part of the thesis concerns the use of word embeddings and neural networks for three text mining applications.</seg>
            </tuv>
        </tu>
        <tu tuid="19">
            <tuv xml:lang="FR">
                <seg>Tout d'abord, nous abordons la classification du document polylinguistique où nous soutenons que les traductions d'un document peuvent être utilisées pour enrichir sa représentation.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>First, we discuss polylingual document classification where we argue that translations of a document can be used to enrich its representation.</seg>
            </tuv>
        </tu>
        <tu tuid="20">
            <tuv xml:lang="FR">
                <seg>À l'aide d'un codeur automatique pour obtenir ces représentations de documents robustes, nous démontrons des améliorations dans la tâche de classification de documents multi-classes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Using an auto-encoder to obtain these robust document representations we demonstrate improvements in the task of multi-class document classification.</seg>
            </tuv>
        </tu>
        <tu tuid="21">
            <tuv xml:lang="FR">
                <seg>Deuxièmement, nous explorons la classification des tweets à plusieurs tâches en soutenant que, en formant conjointement des systèmes de classification utilisant des tâches corrélées, on peut améliorer la performance obtenue.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Second, we explore multi-task sentiment classification of tweets arguing that by jointly training classification systems using correlated tasks can improve the obtained performance.</seg>
            </tuv>
        </tu>
        <tu tuid="22">
            <tuv xml:lang="FR">
                <seg>À cette fin, nous montrons comment réaliser des performances de pointe sur une tâche de classification du sentiment en utilisant des réseaux neuronaux récurrents.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To this end we show how can achieve state-of-the-art performance on a sentiment classification task using recurrent neural networks.</seg>
            </tuv>
        </tu>
        <tu tuid="23">
            <tuv xml:lang="FR">
                <seg>La troisième application que nous explorons est la récupération d'informations entre langues.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The third application we explore is cross-lingual information retrieval.</seg>
            </tuv>
        </tu>
        <tu tuid="24">
            <tuv xml:lang="FR">
                <seg>Compte tenu d'un document écrit dans une langue, la tâche consiste à récupérer les documents les plus similaires à partir d'un ensemble de documents écrits dans une autre langue.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Given a document written in one language, the task consists in retrieving the most similar documents from a pool of documents written in another language.</seg>
            </tuv>
        </tu>
        <tu tuid="25">
            <tuv xml:lang="FR">
                <seg>Dans cette ligne de recherche, nous montrons qu'en adaptant le problème du transport pour la tâche d'estimation des distances documentaires, on peut obtenir des améliorations importantes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this line of research, we show that by adapting the transportation problem for the task of estimating document distances one can achieve important improvements.</seg>
            </tuv>
        </tu>
    </body>
</tmx>