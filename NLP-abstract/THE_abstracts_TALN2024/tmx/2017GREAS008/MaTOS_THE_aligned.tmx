<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2017GREAS008. segId begin by 1, tuid = segId</note>
        <docid>2017GREAS008</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Restorer la faculté de parler chez des personnes paralysées et aphasiques pourrait être envisagée via l’utilisation d’une interface cerveau</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Restoring natural speech in paralyzed and aphasic people could be achieved using a brain-computer interface controlling a speech synthesizer in real-time.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>L’objectif de cette thèse était de développer trois aspects nécessaires à la mise au point d’une telle preuve de concept.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The aim of this thesis was thus to develop three main steps toward such proof of concept.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Premièrement, un synthétiseur permettant de produire en temps-réel de la parole intelligible et controlé par un nombre raisonable de paramètres est nécessaire.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>First, a prerequisite was to develop a speech synthesizer producing intelligible speech in real-time with a reasonable number of control parameters.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Nous avons donc développé un synthétiseur produisant de la parole intelligible à partir de données articulatoires.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We thus developed a speech synthesizer that produced intelligible speech from articulatory data.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Dans un premier temps, nous avons enregistré un large corpus de données articulatoire et acoustiques synchrones chez un locuteur.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This was achieved by first recording a large dataset of synchronous articulatory and acoustic data in a single speaker.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Ensuite, nous avons utilisé des techniques d’apprentissage automatique, en particulier des réseaux de neurones profonds, pour construire un modèle permettant de convertir des données articulatoires en parole.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Then, we used machine learning techniques, especially deep neural networks, to build a model able to convert articulatory data into speech.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Ce synthétisuer a été construit pour fonctionner en temps réel.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This synthesizer was built to run in real time.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Enfin, comme première étape vers un contrôle neuronal de ce synthétiseur, nous avons testé qu’il pouvait être contrôlé en temps réel par plusieurs locuteurs, pour produire de la parole inetlligible à partir de leurs mouvements articulatoires dans un paradigme de boucle fermée.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Finally, as a first step toward future brain control of this synthesizer, we tested that it could be controlled in real-time by several speakers to produce intelligible speech from articulatory movements in a closed-loop paradigm.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Deuxièmement, nous avons étudié le décodage de la parole et de ses propriétés articulatoires à partir d’activités neuronales essentiellement enregistrées dans le cortex moteur de la parole.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Second, we investigated the feasibility of decoding speech and articulatory features from neural activity essentially recorded in the speech motor cortex.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Nous avons construit un outil permettant de localiser les aires corticales actives, en ligne pendant des chirurgies éveillées à l’hôpital de Grenoble, et nous avons testé ce système chez deux patients atteints d’un cancer du cerveau.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We built a tool that allowed to localize active cortical speech areas online during awake brain surgery at the Grenoble Hospital and tested this system in two patients with brain cancer.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Les résultats ont montré que le cortex moteur exhibe une activité spécifique pendant la production de parole dans les bandes beta et gamma du signal, y compris lors de l’imagination de la parole.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Results show that the motor cortex exhibits specific activity during speech production in the beta and gamma bands, which are also present during speech imagination.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Les données enregistrées ont ensuite pu être analysées pour décoder l’intention de parler du sujet (réelle ou imaginée), ainsi que la vibration des cordes vocales et les trajectoires des articulateurs principaux du conduit vocal significativement au dessus du niveau de la chance.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The recorded data could be successfully analyzed to decode speech intention, voicing activity and the trajectories of the main articulators of the vocal tract above chance.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>Enfin, nous nous sommes intéressés aux questions éthiques qui accompagnent le développement et l’usage des interfaces cerveau</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Finally, we addressed ethical issues that arise with the development and use of brain-computer interfaces.</seg>
            </tuv>
        </tu>
    </body>
</tmx>