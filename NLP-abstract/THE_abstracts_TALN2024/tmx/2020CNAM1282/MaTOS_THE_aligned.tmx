<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2020CNAM1282. segId begin by 1, tuid = segId</note>
        <docid>2020CNAM1282</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>Cette thèse porte sur la reconnaissance visuelle "zero-shot", qui vise à classifier des images de catégories non rencontrées par le modèle pendant la phase d’apprentissage.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This thesis focuses on zero-shot visual recognition, which aims to recognize images from unseen categories, i.e. categories not seen by the model during training.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Après avoir classé les méthodes existantes en trois grandes catégories, nous défendons l’idée que les méthodes dites de classement se basent habituellement sur plusieurs hypothèses implicites préjudiciables.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>After categorizing existing methods into three main families, we argue that ranking methods habitually make several detrimental implicit assumptions.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Nous proposons d’adapter leur fonction de coût pour leur permettre d’intégrer des relations inter et intra-classe.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We propose to adapt the usual formulation of the hinge rank loss so that such methods may take inter and intra-class relations into account.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Nous proposons également un processus permettant de diminuer l’écart entre les performances sur les classes vues et non vues dont souffrent fréquemment ces méthodes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We also propose a simple process to address the gap between accuracies on seen and unseen classes, from which these methods frequently suffer in a generalized zero-shot learning setting.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Dans notre évaluation expérimentale, ces contributions permettent à notre modèle d’égaler ou surpasser les performances des méthodes génératives, tant en étant moins restrictif.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In our experimental evaluation, the combination of these contributions enables our proposed model to equal or surpass the performance of generative methods, while being arguably less restrictive.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Dans un second temps, nous nous intéressons aux représentations sémantiques utilisées dans un contexte d’</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In a second part, we focus on the semantic representations used in a large-scale zero-shot learning setting.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Dans ce contexte, l’information sémantique provient généralement de plongements lexicaux des noms de classe.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this setting, semantic information customarily comes from word embeddings of the class names.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Nous soutenons que les plongements habituels souffrent d’un manque de contenu visuel dans les corpus servant à leur apprentissage.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We argue that usual embeddings suffer from a lack of visual content in training corpora.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Nous proposons donc de nouveaux corpus de texte davantage connotés visuellement, ainsi qu’une méthode permettant d’adapter les modèles de plongement à ces corpus.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We thus propose new visually oriented text corpora as well as a method to adapt word embedding models to these corpora.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Nous proposons en outre de compléter ces représentations non supervisées par de courtes descriptions en langage naturel, dont la production ne requiert qu’un effort minimal comparé à des attributs génériques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We further propose to complete unsupervised representations with short descriptions in natural language, whose generation requires minimal effort when compared to extensive attributes.</seg>
            </tuv>
        </tu>
    </body>
</tmx>