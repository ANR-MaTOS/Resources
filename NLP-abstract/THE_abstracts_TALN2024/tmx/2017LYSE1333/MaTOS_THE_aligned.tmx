<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2017LYSE1333. segId begin by 1, tuid = segId</note>
        <docid>2017LYSE1333</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>L'apprentissage multi-label est un problème d'apprentissage supervisé où chaque instance peut être associée à plusieurs labels cibles simultanément.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Multi-label learning is a specific supervised learning problem where each instance can be associated with multiple target labels simultaneously.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Il est omniprésent dans l'apprentissage automatique et apparaît naturellement dans de nombreuses applications du monde réel telles que la classification de documents, l'étiquetage automatique de musique et l'annotation d'images.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Multi-label learning is ubiquitous in machine learning and arises naturally in many real-world applications such as document classification, automatic music tagging and image annotation.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Nous discutons d'abord pourquoi les algorithmes multi-label de l'etat-de-l'art utilisant un comité de modèle souffrent de certains inconvénients pratiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We first discuss why the state-of-the art single multi-label algorithms using an effective committee of multi-label models suffer from certain practical drawbacks.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Nous proposons ensuite une nouvelle stratégie pour construire et agréger les modèles ensemblistes multi-label basés sur k-labels.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We then propose a novel strategy to build and aggregate k-labelsets based committee in the context of ensemble multi-label classification.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Nous analysons ensuite en profondeur l'effet de l'étape d'agrégation au sein des approches ensemblistes multi-label et étudions comment cette agrégation influece les performances de prédictive du modèle en fonction de la nature de fonction cout à optimiser.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We then analyze the effect of the aggregation step within ensemble multi-label approaches in depth and investigate how this aggregation impacts the prediction performances with respect to the objective multi-label loss metric.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Nous abordons ensuite le problème spécifique de la selection de variables dans le contexte multi-label en se basant sur le paradigme ensembliste.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We then address the specific problem of identifying relevant subsets of features-among potentially irrelevant and redundant features-in the multi-label context based on the ensemble paradigm.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Trois méthodes de sélection de caractéristiques multi-label basées sur le paradigme des forêts aléatoires sont proposées.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Three wrapper multi-label feature selection methods based on the Random Forest paradigm are proposed.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Ces méthodes diffèrent dans la façon dont elles considèrent la dépendance entre les labels dans le processus de sélection des varibales.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>These methods differ in the way they consider label dependence within the feature selection process.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Enfin, nous étendons les problèmes de classification et de sélection de variables au cadre d'apprentissage semi-supervisé.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Finally, we extend the multi-label classification and feature selection problems to the semi-supervised setting and consider the situation where only few labelled instances are available.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>Nous proposons une nouvelle approche de sélection de variables multi-label semi-supervisée basée sur le paradigme de l'ensemble.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We propose a new semi-supervised multi-label feature selection approach based on the ensemble paradigm.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Le modèle proposé associe des principes issues de la co-training en conjonction avec une métrique interne d'évaluation d'importnance des varaibles basée sur les out-of-bag.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>The proposed model combines ideas from co-training and multi-label k-labelsets committee construction in tandem with an inner out-of-bag label feature importance evaluation.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Testés de manière satisfaisante sur plusieurs données de référence, les approches développées dans cette thèse sont prometteuses pour une variété d'applications dans l'apprentissage multi-label supervisé et semi-supervisé.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Satisfactorily tested on several benchmark data, the approaches developed in this thesis show promise for a variety of applications in supervised and semi-supervised multi-label learning</seg>
            </tuv>
        </tu>
    </body>
</tmx>