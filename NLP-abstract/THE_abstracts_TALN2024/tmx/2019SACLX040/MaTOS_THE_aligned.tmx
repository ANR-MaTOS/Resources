<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2019SACLX040. segId begin by 1, tuid = segId</note>
        <docid>2019SACLX040</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>De nombreux problèmes en Apprentissage Statistique consistent à minimiser une fonction non convexe et non lisse définie sur un espace euclidien.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Many problems in machine learning pertain to tackling the minimization of a possibly non-convex and non-smooth function defined on a Euclidean space.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Les algorithmes d'optimisation utilisés pour résoudre ce genre de problèmes ont été largement étudié pour des fonctions convexes et grandement utilisés en pratique.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Optimization methods, used to solve those problems, have been widely studied in the literature for convex objective functions and are extensively used in practice.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>Cependant, l'accrudescence du nombre d'observation dans l'évaluation de ce risque empirique ajoutée à l'utilisation de fonctions de perte de plus en plus sophistiquées représentent des obstacles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>However, recent breakthroughs in statistical modeling, such as deep learning, coupled with an explosion of data samples, require improvements of non-convex optimization procedure for large datasets.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>Ces obstacles requièrent d'améliorer les algorithmes existants avec des mis à jour moins coûteuses, idéalement indépendantes du nombre d'observations, et d'en garantir le comportement théorique sous des hypothèses moins restrictives, telles que la non convexité de la fonction à optimiser.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>This thesis is an attempt to address those two challenges by developing algorithms with cheaper updates, ideally independent of the number of samples, and improving the theoretical understanding of non-convex optimization that remains rather limited.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Dans ce manuscrit de thèse, nous nous intéressons à la minimisation de fonctions objectives pour des modèles à données latentes, ie, lorsque les données sont partiellement observées ce qui inclut le sens conventionnel des données manquantes mais est un terme plus général que cela.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this manuscript, we are interested in the minimization of such objective functions for latent data models, ie, when the data is partially observed which includes the conventional sense of missing data but is much broader than that.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Dans une première partie, nous considérons la minimisation d'une fonction (possiblement) non convexe et non lisse en utilisant des mises à jour incrémentales et en ligne.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the first part, we consider the minimization of a (possibly) non-convex and non-smooth objective function using incremental and online updates.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Nous proposons et analysons plusieurs algorithmes à travers quelques applications.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>To that end, we propose several algorithms through some applications.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Dans une seconde partie, nous nous concentrons sur le problème de maximisation de vraisemblance non convexe en ayant recourt à l'algorithme EM et ses variantes stochastiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In the second part, we focus on the maximization of non-convex likelihood using the EM algorithm and its stochastic variants.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Nous en analysons plusieurs versions rapides et moins coûteuses et nous proposons deux nouveaux algorithmes du type EM dans le but d'accélérer la convergence des paramètres estimés.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We analyze several faster and cheaper algorithms and propose two new variants aiming at speeding the convergence of the estimated parameters.</seg>
            </tuv>
        </tu>
    </body>
</tmx>