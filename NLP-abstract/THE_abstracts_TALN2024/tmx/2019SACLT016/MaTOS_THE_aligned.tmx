<?xml version='1.0' encoding='utf-8'?>
<tmx version="1.4b">
    <header creationtool="xml.etree.ElementTree" creationtoolversion="1.3.0" datatype="PlainText" segtype="sentence" adminlang="en-us" srclang="FR" o-tmf="XML" creationdate="2023-04-28" creationid="MaTOS">
        <note>This is the sentence alignement file for THE-theses.fr-2019SACLT016. segId begin by 1, tuid = segId</note>
        <docid>2019SACLT016</docid>
        <elem type="sourceLanguage">FR</elem>
        <elem type="targetLanguage">EN</elem>
    </header>
    <body>
        <tu tuid="1">
            <tuv xml:lang="FR">
                <seg>La reconnaissance des opinions d'un locuteur dans une interaction orale est une étape cruciale pour améliorer la communication entre un humain et un agent virtuel.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Recognizing a speaker's opinions in an oral interaction is a crucial step in improving communication between a human and a virtual agent.</seg>
            </tuv>
        </tu>
        <tu tuid="2">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, nous nous situons dans une problématique de traitement automatique de la parole (TAP) sur les phénomènes d'opinions dans des interactions orales spontanées naturelles.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this thesis, we find ourselves in a problematic of automatic speech processing (APT) on opinion phenomena in natural spontaneous oral interactions.</seg>
            </tuv>
        </tu>
        <tu tuid="3">
            <tuv xml:lang="FR">
                <seg>L'analyse d'opinion est une tâche peu souvent abordée en TAP qui se concentrait jusqu'à peu sur les émotions à l'aide du contenu vocal et non verbal.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Opinion analysis is a task that is not often addressed in TAP that focused until recently on emotions using voice and non-verbal content.</seg>
            </tuv>
        </tu>
        <tu tuid="4">
            <tuv xml:lang="FR">
                <seg>De plus, la plupart des systèmes récents existants n'utilisent pas le contexte interactionnel afin d'analyser les opinions du locuteur.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In addition, most existing legacy systems do not use the interactional context to analyze the speaker's opinions.</seg>
            </tuv>
        </tu>
        <tu tuid="5">
            <tuv xml:lang="FR">
                <seg>Dans cette thèse, nous nous penchons sur ces sujet.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>In this thesis, we focus on these topics.</seg>
            </tuv>
        </tu>
        <tu tuid="6">
            <tuv xml:lang="FR">
                <seg>Nous nous situons dans le cadre de la détection automatique en utilisant des modèles d'apprentissage statistiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We are in the context of automatic detection using statistical learning models.</seg>
            </tuv>
        </tu>
        <tu tuid="7">
            <tuv xml:lang="FR">
                <seg>Après une étude sur la modélisation de la dynamique de l'opinion par un modèle à états latents à l'intérieur d'un monologue, nous étudions la manière d'intégrer le contexte interactionnel dialogique, et enfin d'intégrer l'audio au texte avec différents types de fusion.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>A study on modeling the dynamics of opinion by a model with latent states within a monologue, we study how to integrate the context interactional dialogical, and finally to integrate audio to text with different types of fusion.</seg>
            </tuv>
        </tu>
        <tu tuid="8">
            <tuv xml:lang="FR">
                <seg>Nous avons travaillé sur une base de données de Vlogs au niveau d'un sentiment global, puis sur une base de données d'interactions dyadiques multimodales composée de conversations ouvertes, au niveau du tour de parole et de la paire de tours de parole.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We worked on a basic Vlogs data at a global sense, and on the basis of multimodal data dyadic interactions composed of open conversations, at the turn of speech and word pair of towers.</seg>
            </tuv>
        </tu>
        <tu tuid="9">
            <tuv xml:lang="FR">
                <seg>Pour finir, nous avons fait annoté une base de données en opinion car les base de données existantes n'étaient pas satisfaisantes vis-à-vis de la tâche abordée, et ne permettaient pas une comparaison claire avec d'autres systèmes à l'état de l'art.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Finally, we annotated database in opinion because existing database were not satisfactory vis-à-vis the task addressed, and did not allow a clear comparison with other systems in the state art.</seg>
            </tuv>
        </tu>
        <tu tuid="10">
            <tuv xml:lang="FR">
                <seg>A l'aube du changement important porté par l'avènement des méthodes neuronales, nous étudions différents types de représentations : les anciennes représentations construites à la main, rigides mais précises, et les nouvelles représentations apprises de manière statistique, générales et sémantiques.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>At the dawn of significant change brought by the advent of neural methods, we study different types of representations: the ancient representations built by hand, rigid, but precise, and new representations learned statistically, and general semantics.</seg>
            </tuv>
        </tu>
        <tu tuid="11">
            <tuv xml:lang="FR">
                <seg>Nous étudions différentes segmentations permettant de prendre en compte le caractère asynchrone de la multi-modalité.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>We study different segmentations to take into account the asynchronous nature of multi-modality.</seg>
            </tuv>
        </tu>
        <tu tuid="12">
            <tuv xml:lang="FR">
                <seg>Dernièrement, nous utilisons un modèle d'apprentissage à états latents qui peut s'adapter à une base de données de taille restreinte, pour la tâche atypique qu'est l'analyse d'opinion, et nous montrons qu'il permet à la fois une adaptation des descripteurs du domaine écrit au domaine oral, et servir de couche d'attention via son pouvoir de clusterisation.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Recently, we are using a latent state learning model that can adapt to a small database, for the atypical task of opinion analysis, and we show that it allows both an adaptation of the descriptors of the written domain to the oral domain, and serve as an attention layer via its clustering power.</seg>
            </tuv>
        </tu>
        <tu tuid="13">
            <tuv xml:lang="FR">
                <seg>La fusion multimodale complexe n'étant pas bien gérée par le classifieur utilisé, et l'audio étant moins impactant sur l'opinion que le texte, nous étudions différentes méthodes de sélection de paramètres pour résoudre ces problèmes.</seg>
            </tuv>
            <tuv xml:lang="EN">
                <seg>Complex multimodal fusion is not well managed by the classifier used, and audio being less impacting on opinion than text, we study different methods of parameter selection to solve these problems.</seg>
            </tuv>
        </tu>
    </body>
</tmx>